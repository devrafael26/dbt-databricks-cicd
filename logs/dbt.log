[0m13:55:40.496468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023085152250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023085150590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023085152690>]}


============================== 13:55:40.509469 | 91b15751-623c-42d6-b65a-6198b932e628 ==============================
[0m13:55:40.509469 [info ] [MainThread]: Running with dbt=1.10.3
[0m13:55:40.513469 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt init dbt_databricks_cicd', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:55:40.602465 [debug] [MainThread]: Starter project path: C:\Users\diniz\Python\Lib\site-packages\dbt\include\starter_project
[0m13:55:40.740468 [info ] [MainThread]: 
Your new dbt project "dbt_databricks_cicd" was created!

For more information on how to configure the profiles.yml file,
please consult the dbt documentation here:

  https://docs.getdbt.com/docs/configure-your-profile

One more thing:

Need help? Don't hesitate to reach out to us via GitHub issues or on Slack:

  https://community.getdbt.com/

Happy modeling!

[0m13:55:40.742469 [info ] [MainThread]: Setting up your profile.
[0m13:55:40.755483 [debug] [MainThread]: Command `dbt init` succeeded at 13:55:40.754468 after 0.46 seconds
[0m13:55:40.757468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000230FE95DB10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002308515D590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000230FE6C8510>]}
[0m13:55:40.758467 [debug] [MainThread]: Flushing usage events
[0m13:55:41.769467 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m14:45:37.663258 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028FB22AE390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028FB22ADF90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028FB22AE290>]}


============================== 14:45:37.670660 | 551868b6-09c8-4fa4-8bae-0325ff622ce6 ==============================
[0m14:45:37.670660 [info ] [MainThread]: Running with dbt=1.10.3
[0m14:45:37.673661 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'invocation_command': 'dbt debug --target sqlserver', 'send_anonymous_usage_stats': 'True'}
[0m14:45:37.732410 [info ] [MainThread]: dbt version: 1.10.3
[0m14:45:37.733411 [info ] [MainThread]: python version: 3.11.1
[0m14:45:37.735446 [info ] [MainThread]: python path: C:\Users\diniz\Python\python.exe
[0m14:45:37.736447 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m14:45:37.743405 [info ] [MainThread]: Using profiles dir at C:\Users\diniz\.dbt
[0m14:45:37.744405 [info ] [MainThread]: Using profiles.yml file at C:\Users\diniz\.dbt\profiles.yml
[0m14:45:37.745406 [info ] [MainThread]: Using dbt_project.yml file at D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\dbt_project.yml
[0m14:45:37.747405 [info ] [MainThread]: Configuration:
[0m14:45:37.748406 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m14:45:37.750406 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m14:45:37.751404 [info ] [MainThread]: Required dependencies:
[0m14:45:37.753407 [debug] [MainThread]: Executing "git --help"
[0m14:45:37.846409 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m14:45:37.848409 [debug] [MainThread]: STDERR: "b''"
[0m14:45:37.850410 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m14:45:37.853410 [info ] [MainThread]: Connection test skipped since no profile was found
[0m14:45:37.855408 [info ] [MainThread]: [31m2 checks failed:[0m
[0m14:45:37.857407 [info ] [MainThread]: Could not load dbt_project.yml
Profile loading failed for the following reason:
Runtime Error
  The profile 'meu_projeto_dbt' does not have a target named 'sqlserver'. The valid target names for this profile are:
   - dev

Runtime Error
  The profile 'sqlserver_dbt_cicd' does not have a target named 'sqlserver'. The valid target names for this profile are:
   - dev

Runtime Error
  The profile 'dbt_databricks_cicd' does not have a target named 'sqlserver'. The valid target names for this profile are:
   - dev


[0m14:45:37.860412 [info ] [MainThread]: Project loading failed for the following reason:
 project path <D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\dbt_project.yml> not found

[0m14:45:37.864409 [debug] [MainThread]: Command `dbt debug` failed at 14:45:37.863415 after 0.34 seconds
[0m14:45:37.865407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028FB23170D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028FB2317750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028FAB848690>]}
[0m14:45:37.868408 [debug] [MainThread]: Flushing usage events
[0m14:45:38.675114 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:56:59.174010 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF26A1D250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF26A1F350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF26A1F090>]}


============================== 07:56:59.189675 | 7bc27e43-11cd-4729-8b16-c35bb33ef816 ==============================
[0m07:56:59.189675 [info ] [MainThread]: Running with dbt=1.10.3
[0m07:56:59.189675 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'log_path': 'logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'invocation_command': 'dbt debug --target sqlserver', 'send_anonymous_usage_stats': 'True'}
[0m07:56:59.236528 [info ] [MainThread]: dbt version: 1.10.3
[0m07:56:59.236528 [info ] [MainThread]: python version: 3.11.1
[0m07:56:59.236528 [info ] [MainThread]: python path: C:\Users\diniz\Python\python.exe
[0m07:56:59.236528 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m07:56:59.252147 [info ] [MainThread]: Using profiles dir at C:\Users\diniz\.dbt
[0m07:56:59.252147 [info ] [MainThread]: Using profiles.yml file at C:\Users\diniz\.dbt\profiles.yml
[0m07:56:59.252147 [info ] [MainThread]: Using dbt_project.yml file at D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\dbt_project.yml
[0m07:56:59.252147 [info ] [MainThread]: Configuration:
[0m07:56:59.252147 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m07:56:59.252147 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m07:56:59.252147 [info ] [MainThread]: Required dependencies:
[0m07:56:59.252147 [debug] [MainThread]: Executing "git --help"
[0m07:56:59.361511 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m07:56:59.361511 [debug] [MainThread]: STDERR: "b''"
[0m07:56:59.361511 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m07:56:59.361511 [info ] [MainThread]: Connection test skipped since no profile was found
[0m07:56:59.361511 [info ] [MainThread]: [31m2 checks failed:[0m
[0m07:56:59.377157 [info ] [MainThread]: Could not load dbt_project.yml
Profile loading failed for the following reason:
Runtime Error
  The profile 'meu_projeto_dbt' does not have a target named 'sqlserver'. The valid target names for this profile are:
   - dev

Runtime Error
  The profile 'sqlserver_dbt_cicd' does not have a target named 'sqlserver'. The valid target names for this profile are:
   - dev

Runtime Error
  The profile 'dbt_databricks_cicd' does not have a target named 'sqlserver'. The valid target names for this profile are:
   - dev


[0m07:56:59.377157 [info ] [MainThread]: Project loading failed for the following reason:
 project path <D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\dbt_project.yml> not found

[0m07:56:59.377157 [debug] [MainThread]: Command `dbt debug` failed at 07:56:59.377157 after 0.35 seconds
[0m07:56:59.377157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF266FB110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF26A13250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF26A13550>]}
[0m07:56:59.377157 [debug] [MainThread]: Flushing usage events
[0m07:57:00.970963 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:59:14.793149 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194EB821C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194E832BD10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194EB823C90>]}


============================== 07:59:14.808778 | 45db8e4b-6b9d-4c25-adc3-9c2ff28ea03b ==============================
[0m07:59:14.808778 [info ] [MainThread]: Running with dbt=1.10.3
[0m07:59:14.808778 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt debug --target sqlserver', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m07:59:14.855649 [info ] [MainThread]: dbt version: 1.10.3
[0m07:59:14.855649 [info ] [MainThread]: python version: 3.11.1
[0m07:59:14.855649 [info ] [MainThread]: python path: C:\Users\diniz\Python\python.exe
[0m07:59:14.855649 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m07:59:20.541128 [info ] [MainThread]: Using profiles dir at C:\Users\diniz\.dbt
[0m07:59:20.541128 [info ] [MainThread]: Using profiles.yml file at C:\Users\diniz\.dbt\profiles.yml
[0m07:59:20.541128 [info ] [MainThread]: Using dbt_project.yml file at D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\dbt_project.yml
[0m07:59:20.541128 [info ] [MainThread]: Configuration:
[0m07:59:20.541128 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m07:59:20.541128 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m07:59:20.541128 [info ] [MainThread]: Required dependencies:
[0m07:59:20.556743 [debug] [MainThread]: Executing "git --help"
[0m07:59:20.666124 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m07:59:20.666124 [debug] [MainThread]: STDERR: "b''"
[0m07:59:20.666124 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m07:59:20.666124 [info ] [MainThread]: Connection test skipped since no profile was found
[0m07:59:20.666124 [info ] [MainThread]: [31m2 checks failed:[0m
[0m07:59:20.681745 [info ] [MainThread]: Could not load dbt_project.yml
Profile loading failed for the following reason:
Runtime Error
  The profile 'meu_projeto_dbt' does not have a target named 'sqlserver'. The valid target names for this profile are:
   - dev

Runtime Error
  The profile 'sqlserver_dbt_cicd' does not have a target named 'sqlserver'. The valid target names for this profile are:
   - dev


[0m07:59:20.681745 [info ] [MainThread]: Project loading failed for the following reason:
 project path <D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\dbt_project.yml> not found

[0m07:59:20.681745 [debug] [MainThread]: Command `dbt debug` failed at 07:59:20.681745 after 6.03 seconds
[0m07:59:20.681745 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194E4D7BAD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194E4D7BB10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000194EB84B8D0>]}
[0m07:59:20.681745 [debug] [MainThread]: Flushing usage events
[0m07:59:21.291192 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:07:05.738680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292AB2F1B90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292AB2F0B90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292AB2F2E50>]}


============================== 08:07:05.738680 | e209bcf5-f9d0-4613-af66-aaa8da9fedf2 ==============================
[0m08:07:05.738680 [info ] [MainThread]: Running with dbt=1.10.3
[0m08:07:05.738680 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug --target sqlserver', 'send_anonymous_usage_stats': 'True'}
[0m08:07:05.785556 [info ] [MainThread]: dbt version: 1.10.3
[0m08:07:05.785556 [info ] [MainThread]: python version: 3.11.1
[0m08:07:05.785556 [info ] [MainThread]: python path: C:\Users\diniz\Python\python.exe
[0m08:07:05.785556 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m08:07:06.400586 [info ] [MainThread]: Using profiles dir at C:\Users\diniz\.dbt
[0m08:07:06.400586 [info ] [MainThread]: Using profiles.yml file at C:\Users\diniz\.dbt\profiles.yml
[0m08:07:06.400586 [info ] [MainThread]: Using dbt_project.yml file at D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\dbt_project.yml
[0m08:07:06.400586 [info ] [MainThread]: Configuration:
[0m08:07:06.400586 [info ] [MainThread]:   profiles.yml file [[31mERROR invalid[0m]
[0m08:07:06.400586 [info ] [MainThread]:   dbt_project.yml file [[31mERROR not found[0m]
[0m08:07:06.400586 [info ] [MainThread]: Required dependencies:
[0m08:07:06.416206 [debug] [MainThread]: Executing "git --help"
[0m08:07:06.494291 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m08:07:06.494291 [debug] [MainThread]: STDERR: "b''"
[0m08:07:06.494291 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m08:07:06.494291 [info ] [MainThread]: Connection test skipped since no profile was found
[0m08:07:06.509914 [info ] [MainThread]: [31m2 checks failed:[0m
[0m08:07:06.509914 [info ] [MainThread]: Could not load dbt_project.yml
Profile loading failed for the following reason:
Runtime Error
  The profile 'meu_projeto_dbt' does not have a target named 'sqlserver'. The valid target names for this profile are:
   - dev


[0m08:07:06.509914 [info ] [MainThread]: Project loading failed for the following reason:
 project path <D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\dbt_project.yml> not found

[0m08:07:06.509914 [debug] [MainThread]: Command `dbt debug` failed at 08:07:06.509914 after 0.92 seconds
[0m08:07:06.509914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292AB3AA8D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292AB2F3110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000292A48F86D0>]}
[0m08:07:06.509914 [debug] [MainThread]: Flushing usage events
[0m08:07:07.119366 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:51:41.921165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014707427A10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014707427390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000147074279D0>]}


============================== 13:51:41.921165 | 2f1e4d17-763e-4f02-bef5-b798081c56db ==============================
[0m13:51:41.921165 [info ] [MainThread]: Running with dbt=1.10.3
[0m13:51:41.936778 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'invocation_command': 'dbt run --select top_customers.sql', 'send_anonymous_usage_stats': 'True'}
[0m13:51:48.296275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2f1e4d17-763e-4f02-bef5-b798081c56db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001470747C050>]}
[0m13:51:48.405579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2f1e4d17-763e-4f02-bef5-b798081c56db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014707457250>]}
[0m13:51:48.421210 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m13:51:49.374294 [debug] [MainThread]: checksum: 1bfacb87e6914c9942cfa2c4badfc1df19d859fe8ec086286ef238a7d920f97b, vars: {}, profile: , target: , version: 1.10.3
[0m13:51:49.561832 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m13:51:49.561832 [debug] [MainThread]: previous checksum: 1bfacb87e6914c9942cfa2c4badfc1df19d859fe8ec086286ef238a7d920f97b, current checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331
[0m13:51:49.561832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2f1e4d17-763e-4f02-bef5-b798081c56db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000147063B8990>]}
[0m13:51:53.509491 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.example
[0m13:51:53.525110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2f1e4d17-763e-4f02-bef5-b798081c56db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000147072142D0>]}
[0m13:51:53.607963 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m13:51:53.639182 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m13:51:53.748547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2f1e4d17-763e-4f02-bef5-b798081c56db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000147091316D0>]}
[0m13:51:53.748547 [info ] [MainThread]: Found 510 macros
[0m13:51:53.764172 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2f1e4d17-763e-4f02-bef5-b798081c56db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014707413ED0>]}
[0m13:51:53.764172 [warn ] [MainThread]: The selection criterion 'top_customers.sql' does not match any enabled nodes
[0m13:51:53.764172 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m13:51:53.764172 [debug] [MainThread]: Command end result
[0m13:51:53.811045 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m13:51:53.811045 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m13:51:53.826670 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m13:51:53.826670 [debug] [MainThread]: Command `dbt run` succeeded at 13:51:53.826670 after 12.05 seconds
[0m13:51:53.826670 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014708CDC150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014700BE0390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000014700BE0F90>]}
[0m13:51:53.826670 [debug] [MainThread]: Flushing usage events
[0m13:51:54.420644 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:57:34.848089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BAA84AB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BAA84A510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BAA849E50>]}


============================== 12:57:34.863713 | 4ba7188d-4a67-44ba-ba32-99aa26fb1cff ==============================
[0m12:57:34.863713 [info ] [MainThread]: Running with dbt=1.10.3
[0m12:57:34.863713 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'invocation_command': 'dbt debug --target sqlserver', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m12:57:34.926216 [info ] [MainThread]: dbt version: 1.10.3
[0m12:57:34.926216 [info ] [MainThread]: python version: 3.11.1
[0m12:57:34.926216 [info ] [MainThread]: python path: C:\Users\diniz\Python\python.exe
[0m12:57:34.926216 [info ] [MainThread]: os info: Windows-10-10.0.19045-SP0
[0m12:57:35.566838 [info ] [MainThread]: Using profiles dir at C:\Users\diniz\.dbt
[0m12:57:35.566838 [info ] [MainThread]: Using profiles.yml file at C:\Users\diniz\.dbt\profiles.yml
[0m12:57:35.566838 [info ] [MainThread]: Using dbt_project.yml file at D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\dbt_project.yml
[0m12:57:35.566838 [info ] [MainThread]: adapter type: sqlserver
[0m12:57:35.566838 [info ] [MainThread]: adapter version: 1.9.0
[0m12:57:35.754380 [info ] [MainThread]: Configuration:
[0m12:57:35.754380 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m12:57:35.754380 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m12:57:35.754380 [info ] [MainThread]: Required dependencies:
[0m12:57:35.754380 [debug] [MainThread]: Executing "git --help"
[0m12:57:35.848088 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare]\n           [--git-dir=<path>] [--work-tree=<path>] [--namespace=<name>]\n           [--super-prefix=<path>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m12:57:35.848088 [debug] [MainThread]: STDERR: "b''"
[0m12:57:35.848088 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m12:57:35.863726 [info ] [MainThread]: Connection:
[0m12:57:35.863726 [info ] [MainThread]:   server: LAPTOP-NV4PR600
[0m12:57:35.863726 [info ] [MainThread]:   database: MY_DB
[0m12:57:35.863726 [info ] [MainThread]:   schema: dbo
[0m12:57:35.863726 [info ] [MainThread]:   UID: dbt_user
[0m12:57:35.863726 [info ] [MainThread]:   client_id: None
[0m12:57:35.863726 [info ] [MainThread]:   authentication: sql
[0m12:57:35.863726 [info ] [MainThread]:   encrypt: True
[0m12:57:35.879338 [info ] [MainThread]:   trust_cert: True
[0m12:57:35.879338 [info ] [MainThread]:   retries: 3
[0m12:57:35.879338 [info ] [MainThread]:   login_timeout: 0
[0m12:57:35.879338 [info ] [MainThread]:   query_timeout: 0
[0m12:57:35.879338 [info ] [MainThread]:   trace_flag: False
[0m12:57:35.879338 [info ] [MainThread]:   port: 1433
[0m12:57:35.879338 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m12:57:36.926216 [debug] [MainThread]: Acquiring new sqlserver connection 'debug'
[0m12:57:36.926216 [debug] [MainThread]: Using sqlserver connection "debug"
[0m12:57:36.926216 [debug] [MainThread]: On debug: select 1 as id
[0m12:57:36.926216 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:57:36.926216 [debug] [MainThread]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:57:37.160585 [debug] [MainThread]: sqlserver adapter: Connected to db: MY_DB
[0m12:57:37.160585 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m12:57:37.160585 [debug] [MainThread]: On debug: Close
[0m12:57:37.160585 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m12:57:37.176221 [info ] [MainThread]: [32mAll checks passed![0m
[0m12:57:37.176221 [debug] [MainThread]: Command `dbt debug` succeeded at 12:57:37.176221 after 2.48 seconds
[0m12:57:37.176221 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m12:57:37.176221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BA9FB8BD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BAC002E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025BA40810D0>]}
[0m12:57:37.176221 [debug] [MainThread]: Flushing usage events
[0m12:57:37.769986 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:57:50.976124 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8A7596950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8A7596A10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8A7595810>]}


============================== 12:57:50.991753 | 994df4c5-fb78-47e3-8bc2-31c4a888b3f5 ==============================
[0m12:57:50.991753 [info ] [MainThread]: Running with dbt=1.10.3
[0m12:57:50.991753 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'invocation_command': 'dbt compile --target sqlserver', 'send_anonymous_usage_stats': 'True'}
[0m12:57:52.116789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '994df4c5-fb78-47e3-8bc2-31c4a888b3f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8A75ED150>]}
[0m12:57:52.226170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '994df4c5-fb78-47e3-8bc2-31c4a888b3f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8A75C7610>]}
[0m12:57:52.226170 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m12:57:53.022997 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m12:57:53.116748 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m12:57:53.132418 [debug] [MainThread]: previous checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, current checksum: 1bfacb87e6914c9942cfa2c4badfc1df19d859fe8ec086286ef238a7d920f97b
[0m12:57:53.132418 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m12:57:53.132418 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '994df4c5-fb78-47e3-8bc2-31c4a888b3f5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8A6C87F10>]}
[0m12:57:57.444872 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "stg_ecommerce".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("stg_ecommerce").
  
  To fix this, change the name of one of these resources:
  - model.dbt_databricks_cicd.stg_ecommerce (dbt_databricks_cicd/models\staging\stg_ecommerce.sql)
  - model.dbt_databricks_cicd.stg_ecommerce (dbt_databricks_cicd/models\raw\stg_ecommerce.sql)
[0m12:57:57.460497 [debug] [MainThread]: Command `dbt compile` failed at 12:57:57.460497 after 6.63 seconds
[0m12:57:57.460497 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8A75E7F90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8A75E6310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8A910B4D0>]}
[0m12:57:57.460497 [debug] [MainThread]: Flushing usage events
[0m12:57:58.038766 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:00:46.935483 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7B99B6650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7B99B4ED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7B99B6150>]}


============================== 13:00:46.935483 | e925cd27-bfe3-4227-9215-8ef5ef34f32f ==============================
[0m13:00:46.935483 [info ] [MainThread]: Running with dbt=1.10.3
[0m13:00:46.951108 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'invocation_command': 'dbt compile --target sqlserver', 'send_anonymous_usage_stats': 'True'}
[0m13:00:47.841739 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e925cd27-bfe3-4227-9215-8ef5ef34f32f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7B9A07190>]}
[0m13:00:48.029231 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e925cd27-bfe3-4227-9215-8ef5ef34f32f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7BB250F10>]}
[0m13:00:48.029231 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m13:00:48.794893 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m13:00:48.857404 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m13:00:48.872984 [debug] [MainThread]: previous checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, current checksum: 1bfacb87e6914c9942cfa2c4badfc1df19d859fe8ec086286ef238a7d920f97b
[0m13:00:48.872984 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m13:00:48.872984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e925cd27-bfe3-4227-9215-8ef5ef34f32f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7B8954A50>]}
[0m13:00:51.482364 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_databricks_cicd.src_ecommerce' (dbt_databricks_cicd/models\raw\src_ecommerce.sql) depends on a source named 'sqlserver_data.ecommerce' which was not found
[0m13:00:51.482364 [debug] [MainThread]: Command `dbt compile` failed at 13:00:51.482364 after 4.69 seconds
[0m13:00:51.482364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7B99B69D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7B99B7290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001A7B3120550>]}
[0m13:00:51.482364 [debug] [MainThread]: Flushing usage events
[0m13:00:52.076249 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:32:54.562335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B4E0D16C50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B4E0D16E10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B4E0CC5810>]}


============================== 13:32:54.577920 | eff3b742-ca70-44e3-8bdd-f883728b7bf2 ==============================
[0m13:32:54.577920 [info ] [MainThread]: Running with dbt=1.10.3
[0m13:32:54.577920 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt compile --target sqlserver', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:32:55.577965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eff3b742-ca70-44e3-8bdd-f883728b7bf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B4E253BC50>]}
[0m13:32:55.687293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eff3b742-ca70-44e3-8bdd-f883728b7bf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B4DFD14210>]}
[0m13:32:55.687293 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m13:32:56.437292 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m13:32:56.499840 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m13:32:56.515422 [debug] [MainThread]: previous checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, current checksum: 1bfacb87e6914c9942cfa2c4badfc1df19d859fe8ec086286ef238a7d920f97b
[0m13:32:56.515422 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m13:32:56.515422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'eff3b742-ca70-44e3-8bdd-f883728b7bf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B4E03D8390>]}
[0m13:32:59.140465 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.dbt_databricks_cicd.src_ecommerce' (dbt_databricks_cicd/models\raw\src_ecommerce.sql) depends on a source named 'sqlserver_data.ecommerce' which was not found
[0m13:32:59.140465 [debug] [MainThread]: Command `dbt compile` failed at 13:32:59.140465 after 4.71 seconds
[0m13:32:59.140465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B4E0D15E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B4E0D171D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002B4E2C543D0>]}
[0m13:32:59.140465 [debug] [MainThread]: Flushing usage events
[0m13:32:59.796790 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:36:34.125058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A3F626510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A3F677E10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A3F626C90>]}


============================== 13:36:34.140677 | ffc2fb01-695f-4c9f-84d1-8f00ef95c40b ==============================
[0m13:36:34.140677 [info ] [MainThread]: Running with dbt=1.10.3
[0m13:36:34.140677 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt compile --target sqlserver', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m13:36:35.078220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ffc2fb01-695f-4c9f-84d1-8f00ef95c40b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A40DDF150>]}
[0m13:36:35.187591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ffc2fb01-695f-4c9f-84d1-8f00ef95c40b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A3E674310>]}
[0m13:36:35.187591 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m13:36:35.953177 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m13:36:36.031299 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m13:36:36.031299 [debug] [MainThread]: previous checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, current checksum: 1bfacb87e6914c9942cfa2c4badfc1df19d859fe8ec086286ef238a7d920f97b
[0m13:36:36.031299 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m13:36:36.031299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ffc2fb01-695f-4c9f-84d1-8f00ef95c40b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A3ED38310>]}
[0m13:36:39.234424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ffc2fb01-695f-4c9f-84d1-8f00ef95c40b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A414D4050>]}
[0m13:36:39.406304 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m13:36:39.421936 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m13:36:39.500056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ffc2fb01-695f-4c9f-84d1-8f00ef95c40b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A41650910>]}
[0m13:36:39.500056 [info ] [MainThread]: Found 9 models, 20 data tests, 2 sources, 510 macros
[0m13:36:39.500056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ffc2fb01-695f-4c9f-84d1-8f00ef95c40b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A4122A190>]}
[0m13:36:39.500056 [info ] [MainThread]: 
[0m13:36:39.500056 [info ] [MainThread]: Concurrency: 1 threads (target='sqlserver')
[0m13:36:39.515679 [info ] [MainThread]: 
[0m13:36:39.515679 [debug] [MainThread]: Acquiring new sqlserver connection 'master'
[0m13:36:39.515679 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_MY_DB_dbo'
[0m13:36:39.546968 [debug] [ThreadPool]: dbt-sqlserver
[0m13:36:39.546968 [debug] [ThreadPool]: Using sqlserver connection "list_MY_DB_dbo"
[0m13:36:39.546968 [debug] [ThreadPool]: On list_MY_DB_dbo: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_MY_DB_dbo"} */
USE [MY_DB];
    with base as (
      select
        DB_NAME() as [database],
        t.name as [name],
        SCHEMA_NAME(t.schema_id) as [schema],
        'table' as table_type
      from sys.tables as t with (nolock)
      union all
      select
        DB_NAME() as [database],
        v.name as [name],
        SCHEMA_NAME(v.schema_id) as [schema],
        'view' as table_type
      from sys.views as v with (nolock)
    )
    select * from base
    where [schema] like 'dbo'
    
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m13:36:39.546968 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:36:39.562553 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:36:39.671970 [debug] [ThreadPool]: sqlserver adapter: Connected to db: MY_DB
[0m13:36:39.734425 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:36:39.734425 [debug] [ThreadPool]: On list_MY_DB_dbo: ROLLBACK
[0m13:36:39.734425 [debug] [ThreadPool]: On list_MY_DB_dbo: Close
[0m13:36:39.734425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ffc2fb01-695f-4c9f-84d1-8f00ef95c40b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A41425150>]}
[0m13:36:39.750058 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m13:36:39.750058 [debug] [Thread-1 (]: Acquiring new sqlserver connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m13:36:39.750058 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m13:36:39.765677 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m13:36:39.765677 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m13:36:39.781303 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m13:36:39.781303 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m13:36:39.781303 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m13:36:39.781303 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m13:36:39.781303 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m13:36:39.781303 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m13:36:39.796969 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m13:36:39.796969 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m13:36:39.796969 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931)
[0m13:36:39.796969 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m13:36:39.796969 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"
[0m13:36:39.796969 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m13:36:39.812548 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m13:36:39.812548 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f
[0m13:36:39.812548 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931, now test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f)
[0m13:36:39.812548 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f
[0m13:36:39.812548 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f"
[0m13:36:39.828177 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f
[0m13:36:39.828177 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f
[0m13:36:39.828177 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m13:36:39.828177 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f, now test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93)
[0m13:36:39.828177 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m13:36:39.828177 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93"
[0m13:36:39.843802 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m13:36:39.843802 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m13:36:39.843802 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4
[0m13:36:39.843802 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93, now test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4)
[0m13:36:39.843802 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4
[0m13:36:39.843802 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4"
[0m13:36:39.859473 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4
[0m13:36:39.859473 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4
[0m13:36:39.859473 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m13:36:39.859473 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023)
[0m13:36:39.859473 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m13:36:39.875096 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"
[0m13:36:39.875096 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m13:36:39.875096 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m13:36:39.875096 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m13:36:39.875096 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6)
[0m13:36:39.875096 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m13:36:39.890713 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"
[0m13:36:39.890713 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m13:36:39.890713 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m13:36:39.890713 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m13:36:39.890713 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823)
[0m13:36:39.906341 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m13:36:40.000058 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"
[0m13:36:40.000058 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m13:36:40.000058 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m13:36:40.015676 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m13:36:40.015676 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32)
[0m13:36:40.015676 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m13:36:40.031303 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"
[0m13:36:40.031303 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m13:36:40.031303 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m13:36:40.041589 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m13:36:40.041589 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a)
[0m13:36:40.041589 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m13:36:40.046609 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"
[0m13:36:40.046609 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m13:36:40.046609 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m13:36:40.046609 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m13:36:40.046609 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd)
[0m13:36:40.062260 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m13:36:40.062260 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"
[0m13:36:40.062260 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m13:36:40.062260 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m13:36:40.062260 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m13:36:40.062260 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23)
[0m13:36:40.062260 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m13:36:40.077883 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"
[0m13:36:40.077883 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m13:36:40.077883 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m13:36:40.077883 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m13:36:40.077883 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325)
[0m13:36:40.077883 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m13:36:40.093505 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"
[0m13:36:40.093505 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m13:36:40.093505 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m13:36:40.093505 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04
[0m13:36:40.109129 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04)
[0m13:36:40.109129 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04
[0m13:36:40.109129 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04"
[0m13:36:40.109129 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04
[0m13:36:40.109129 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04
[0m13:36:40.109129 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa
[0m13:36:40.124763 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa)
[0m13:36:40.124763 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa
[0m13:36:40.124763 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa"
[0m13:36:40.124763 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa
[0m13:36:40.124763 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa
[0m13:36:40.124763 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7
[0m13:36:40.140376 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7)
[0m13:36:40.140376 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7
[0m13:36:40.140376 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7"
[0m13:36:40.140376 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7
[0m13:36:40.140376 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7
[0m13:36:40.140376 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2
[0m13:36:40.140376 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2)
[0m13:36:40.156042 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2
[0m13:36:40.156042 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2"
[0m13:36:40.156042 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2
[0m13:36:40.156042 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2
[0m13:36:40.156042 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596
[0m13:36:40.156042 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596)
[0m13:36:40.171625 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596
[0m13:36:40.171625 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596"
[0m13:36:40.171625 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596
[0m13:36:40.171625 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596
[0m13:36:40.171625 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34
[0m13:36:40.187259 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34)
[0m13:36:40.187259 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34
[0m13:36:40.187259 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34"
[0m13:36:40.187259 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34
[0m13:36:40.202915 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34
[0m13:36:40.202915 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4
[0m13:36:40.202915 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4)
[0m13:36:40.202915 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4
[0m13:36:40.202915 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4"
[0m13:36:40.202915 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4
[0m13:36:40.218508 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4
[0m13:36:40.218508 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec
[0m13:36:40.218508 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec)
[0m13:36:40.218508 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec
[0m13:36:40.218508 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec"
[0m13:36:40.234234 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec
[0m13:36:40.234234 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec
[0m13:36:40.234234 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_discount_by_category
[0m13:36:40.234234 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec, now model.dbt_databricks_cicd.avg_discount_by_category)
[0m13:36:40.234234 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_discount_by_category
[0m13:36:40.234234 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m13:36:40.234234 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_discount_by_category
[0m13:36:40.249753 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_discount_by_category
[0m13:36:40.249753 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m13:36:40.249753 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_discount_by_category, now model.dbt_databricks_cicd.avg_ticket_by_category)
[0m13:36:40.249753 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_ticket_by_category
[0m13:36:40.249753 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m13:36:40.249753 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_ticket_by_category
[0m13:36:40.249753 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m13:36:40.249753 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.monthly_revenue
[0m13:36:40.265375 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_ticket_by_category, now model.dbt_databricks_cicd.monthly_revenue)
[0m13:36:40.265375 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.monthly_revenue
[0m13:36:40.265375 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.monthly_revenue"
[0m13:36:40.265375 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.monthly_revenue
[0m13:36:40.265375 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.monthly_revenue
[0m13:36:40.265375 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.payment_distribution
[0m13:36:40.265375 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.monthly_revenue, now model.dbt_databricks_cicd.payment_distribution)
[0m13:36:40.265375 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.payment_distribution
[0m13:36:40.281002 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.payment_distribution"
[0m13:36:40.281002 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.payment_distribution
[0m13:36:40.281002 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.payment_distribution
[0m13:36:40.281002 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.sales_by_category
[0m13:36:40.281002 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.payment_distribution, now model.dbt_databricks_cicd.sales_by_category)
[0m13:36:40.281002 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.sales_by_category
[0m13:36:40.296669 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.sales_by_category"
[0m13:36:40.296669 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.sales_by_category
[0m13:36:40.296669 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.sales_by_category
[0m13:36:40.296669 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_5_products
[0m13:36:40.296669 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.sales_by_category, now model.dbt_databricks_cicd.top_5_products)
[0m13:36:40.296669 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_5_products
[0m13:36:40.296669 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_5_products"
[0m13:36:40.312292 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_5_products
[0m13:36:40.312292 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_5_products
[0m13:36:40.312292 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_customers
[0m13:36:40.312292 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_5_products, now model.dbt_databricks_cicd.top_customers)
[0m13:36:40.312292 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_customers
[0m13:36:40.312292 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_customers"
[0m13:36:40.327883 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_customers
[0m13:36:40.327883 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_customers
[0m13:36:40.327883 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:36:40.327883 [debug] [MainThread]: Connection 'list_MY_DB_dbo' was properly closed.
[0m13:36:40.327883 [debug] [MainThread]: Connection 'model.dbt_databricks_cicd.top_customers' was properly closed.
[0m13:36:40.343540 [debug] [MainThread]: Command end result
[0m13:36:40.390417 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m13:36:40.390417 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m13:36:40.406042 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m13:36:40.421670 [debug] [MainThread]: Command `dbt compile` succeeded at 13:36:40.406042 after 6.50 seconds
[0m13:36:40.421670 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A38DB10D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A38DB04D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023A38DB0550>]}
[0m13:36:40.421670 [debug] [MainThread]: Flushing usage events
[0m13:36:40.999774 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m13:42:52.709779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAA9088250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAA8E44790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAA8E44AD0>]}


============================== 13:42:52.709779 | be3f9c1c-7109-44c7-8dde-96b7cdf04aee ==============================
[0m13:42:52.709779 [info ] [MainThread]: Running with dbt=1.10.3
[0m13:42:52.709779 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'invocation_command': 'dbt build --target sqlserver', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m13:42:53.631696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'be3f9c1c-7109-44c7-8dde-96b7cdf04aee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAA87B7B10>]}
[0m13:42:53.741040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'be3f9c1c-7109-44c7-8dde-96b7cdf04aee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAAA8F0FD0>]}
[0m13:42:53.741040 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m13:42:54.522286 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m13:42:54.912914 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:42:54.912914 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:42:55.022282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'be3f9c1c-7109-44c7-8dde-96b7cdf04aee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAAAD4B910>]}
[0m13:42:55.256697 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m13:42:55.256697 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m13:42:55.412948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'be3f9c1c-7109-44c7-8dde-96b7cdf04aee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAAAD43710>]}
[0m13:42:55.412948 [info ] [MainThread]: Found 9 models, 20 data tests, 2 sources, 510 macros
[0m13:42:55.428528 [info ] [MainThread]: 
[0m13:42:55.428528 [info ] [MainThread]: Concurrency: 1 threads (target='sqlserver')
[0m13:42:55.428528 [info ] [MainThread]: 
[0m13:42:55.428528 [debug] [MainThread]: Acquiring new sqlserver connection 'master'
[0m13:42:55.444194 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_MY_DB'
[0m13:42:55.475412 [debug] [ThreadPool]: dbt-sqlserver
[0m13:42:55.475412 [debug] [ThreadPool]: Using sqlserver connection "list_MY_DB"
[0m13:42:55.475412 [debug] [ThreadPool]: On list_MY_DB: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_MY_DB"} */
USE [MY_DB];
    select  name as [schema]
    from sys.schemas with (nolock) 
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m13:42:55.475412 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:42:55.475412 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:55.584787 [debug] [ThreadPool]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:55.584787 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:42:55.584787 [debug] [ThreadPool]: On list_MY_DB: Close
[0m13:42:55.600405 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_MY_DB_dbo'
[0m13:42:55.600405 [debug] [ThreadPool]: dbt-sqlserver
[0m13:42:55.616030 [debug] [ThreadPool]: Using sqlserver connection "list_MY_DB_dbo"
[0m13:42:55.616030 [debug] [ThreadPool]: On list_MY_DB_dbo: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_MY_DB_dbo"} */
USE [MY_DB];
    with base as (
      select
        DB_NAME() as [database],
        t.name as [name],
        SCHEMA_NAME(t.schema_id) as [schema],
        'table' as table_type
      from sys.tables as t with (nolock)
      union all
      select
        DB_NAME() as [database],
        v.name as [name],
        SCHEMA_NAME(v.schema_id) as [schema],
        'view' as table_type
      from sys.views as v with (nolock)
    )
    select * from base
    where [schema] like 'dbo'
    
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m13:42:55.616030 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:42:55.616030 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:55.616030 [debug] [ThreadPool]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:55.662946 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m13:42:55.662946 [debug] [ThreadPool]: On list_MY_DB_dbo: ROLLBACK
[0m13:42:55.662946 [debug] [ThreadPool]: On list_MY_DB_dbo: Close
[0m13:42:55.662946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'be3f9c1c-7109-44c7-8dde-96b7cdf04aee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAAA997910>]}
[0m13:42:55.662946 [debug] [MainThread]: On master: COMMIT
[0m13:42:55.678534 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m13:42:55.678534 [info ] [Thread-1 (]: 1 of 29 START test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m13:42:55.678534 [debug] [Thread-1 (]: Acquiring new sqlserver connection 'test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931'
[0m13:42:55.678534 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m13:42:55.709780 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"
[0m13:42:55.725422 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m13:42:55.756698 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"
[0m13:42:55.772285 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"
[0m13:42:55.772285 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_7999099e1334cef9eb7ae8ca8d3f9f76_2110]
   as 
    
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from "my_db"."dbo"."ecommerce"
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    ''Credit Card'',''Net Banking'',''UPI'',''Debit Card'',''Cash on Delivery''
)



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_7999099e1334cef9eb7ae8ca8d3f9f76_2110]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_7999099e1334cef9eb7ae8ca8d3f9f76_2110]
  ;')
[0m13:42:55.772285 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m13:42:55.772285 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:55.772285 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:55.819159 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:55.819159 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931: ROLLBACK
[0m13:42:55.819159 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931: Close
[0m13:42:55.819159 [info ] [Thread-1 (]: 1 of 29 PASS source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[32mPASS[0m in 0.14s]
[0m13:42:55.834788 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m13:42:55.834788 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f
[0m13:42:55.834788 [info ] [Thread-1 (]: 2 of 29 START test source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m13:42:55.834788 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931, now test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f)
[0m13:42:55.834788 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f
[0m13:42:55.850405 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f"
[0m13:42:55.850405 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f
[0m13:42:55.850405 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f"
[0m13:42:55.850405 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f"
[0m13:42:55.866035 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_b50dc3e1996b1a7b7983fa1efb770b9d_4118]
   as 
    
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from "workspace"."default"."sales_ecommerce"
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    ''Credit Card'',''Net Banking'',''UPI'',''Debit Card'',''Cash on Delivery''
)



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_b50dc3e1996b1a7b7983fa1efb770b9d_4118]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_b50dc3e1996b1a7b7983fa1efb770b9d_4118]
  ;')
[0m13:42:55.866035 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:55.866035 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:55.866035 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:55.881760 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:55.881760 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f: ROLLBACK
[0m13:42:55.881760 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f: Close
[0m13:42:55.881760 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_accepted_values_sqlserv_2459675a1bb0ad6a307b59b3a1008a3b.sql[0m
('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")
[0m13:42:56.053530 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")

[0m13:42:56.053530 [error] [Thread-1 (]: 2 of 29 ERROR source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[31mERROR[0m in 0.22s]
[0m13:42:56.069155 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f
[0m13:42:56.069155 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m13:42:56.069155 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f' to be skipped because of status 'error'.  Reason: ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)").
[0m13:42:56.069155 [info ] [Thread-1 (]: 3 of 29 START test source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date  [RUN]
[0m13:42:56.069155 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.0dadca1b7f, now test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93)
[0m13:42:56.069155 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m13:42:56.084782 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93"
[0m13:42:56.084782 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m13:42:56.100406 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93"
[0m13:42:56.100406 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93"
[0m13:42:56.100406 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_10725fd4f752a6e354b6f1e3cdf8fb3a_16396]
   as 
    
    with actual as (
        select
            column_name,
            data_type
        from INFORMATION_SCHEMA.COLUMNS
        where TABLE_NAME = ''ecommerce''
          and TABLE_SCHEMA = ''dbo''
    ),
    expected as (
        select * from (values
            (''User_ID'', ''varchar''),
            (''Product_ID'', ''varchar''),
            (''Category'', ''varchar''),
            (''Price'', ''float''),
            (''Discount'', ''int''),
            (''Final_Price'', ''float''),
            (''Payment_Method'', ''varchar''),
            (''Purchase_Date'', ''date'')
            
        ) as t(column_name, data_type)
    ),
    diff_expected as (
        select * from expected
        EXCEPT
        select * from actual
    ),
    diff_actual as (
        select * from actual
        EXCEPT
        select * from expected
    )
    select * from diff_expected
    UNION ALL
    select * from diff_actual

  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_10725fd4f752a6e354b6f1e3cdf8fb3a_16396]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_10725fd4f752a6e354b6f1e3cdf8fb3a_16396]
  ;')
[0m13:42:56.100406 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:56.100406 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:56.100406 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:56.178571 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:56.194162 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93: ROLLBACK
[0m13:42:56.194162 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93: Close
[0m13:42:56.194162 [info ] [Thread-1 (]: 3 of 29 PASS source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date  [[32mPASS[0m in 0.13s]
[0m13:42:56.194162 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m13:42:56.194162 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4
[0m13:42:56.194162 [info ] [Thread-1 (]: 4 of 29 START test source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date  [RUN]
[0m13:42:56.194162 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93, now test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4)
[0m13:42:56.194162 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4
[0m13:42:56.209782 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4"
[0m13:42:56.209782 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4
[0m13:42:56.209782 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4"
[0m13:42:56.225409 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4"
[0m13:42:56.225409 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_00ec5b81e7471cf033246a1127887a0e_13452]
   as 
    
    with actual as (
        select
            column_name,
            data_type
        from INFORMATION_SCHEMA.COLUMNS
        where TABLE_NAME = ''sales_ecommerce''
          and TABLE_SCHEMA = ''default''
    ),
    expected as (
        select * from (values
            (''User_ID'', ''varchar''),
            (''Product_ID'', ''varchar''),
            (''Category'', ''varchar''),
            (''Price'', ''float''),
            (''Discount'', ''int''),
            (''Final_Price'', ''float''),
            (''Payment_Method'', ''varchar''),
            (''Purchase_Date'', ''date'')
            
        ) as t(column_name, data_type)
    ),
    diff_expected as (
        select * from expected
        EXCEPT
        select * from actual
    ),
    diff_actual as (
        select * from actual
        EXCEPT
        select * from expected
    )
    select * from diff_expected
    UNION ALL
    select * from diff_actual

  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_00ec5b81e7471cf033246a1127887a0e_13452]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_00ec5b81e7471cf033246a1127887a0e_13452]
  ;')
[0m13:42:56.225409 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:56.225409 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:56.225409 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:56.287915 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:56.287915 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4: ROLLBACK
[0m13:42:56.287915 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4: Close
[0m13:42:56.287915 [error] [Thread-1 (]: 4 of 29 FAIL 8 source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date  [[31mFAIL 8[0m in 0.09s]
[0m13:42:56.303538 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4
[0m13:42:56.303538 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m13:42:56.303538 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4' to be skipped because of status 'fail'.  Reason: Got 8 results, configured to fail if != 0.
[0m13:42:56.303538 [info ] [Thread-1 (]: 5 of 29 START test source_not_null_sqlserver_data_ecommerce_Category ........... [RUN]
[0m13:42:56.303538 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.216f82bfa4, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023)
[0m13:42:56.303538 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m13:42:56.319154 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"
[0m13:42:56.319154 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m13:42:56.319154 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"
[0m13:42:56.334806 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"
[0m13:42:56.334806 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_491fe7bb43562776c9b8b25f5b1f0e65_18577]
   as 
    
    
    



select Category
from "my_db"."dbo"."ecommerce"
where Category is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_491fe7bb43562776c9b8b25f5b1f0e65_18577]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_491fe7bb43562776c9b8b25f5b1f0e65_18577]
  ;')
[0m13:42:56.334806 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:56.334806 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:56.334806 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:56.350446 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:56.350446 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023: ROLLBACK
[0m13:42:56.350446 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023: Close
[0m13:42:56.350446 [info ] [Thread-1 (]: 5 of 29 PASS source_not_null_sqlserver_data_ecommerce_Category ................. [[32mPASS[0m in 0.05s]
[0m13:42:56.350446 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m13:42:56.366033 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m13:42:56.366033 [info ] [Thread-1 (]: 6 of 29 START test source_not_null_sqlserver_data_ecommerce_Discount ........... [RUN]
[0m13:42:56.366033 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6)
[0m13:42:56.366033 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m13:42:56.366033 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"
[0m13:42:56.381659 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m13:42:56.381659 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"
[0m13:42:56.381659 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"
[0m13:42:56.381659 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_5a693b107c6d94cc971f3f52da874160_17625]
   as 
    
    
    



select Discount
from "my_db"."dbo"."ecommerce"
where Discount is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_5a693b107c6d94cc971f3f52da874160_17625]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_5a693b107c6d94cc971f3f52da874160_17625]
  ;')
[0m13:42:56.381659 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:56.381659 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:56.397281 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:56.397281 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:56.397281 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6: ROLLBACK
[0m13:42:56.412915 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6: Close
[0m13:42:56.412915 [info ] [Thread-1 (]: 6 of 29 PASS source_not_null_sqlserver_data_ecommerce_Discount ................. [[32mPASS[0m in 0.05s]
[0m13:42:56.412915 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m13:42:56.412915 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m13:42:56.412915 [info ] [Thread-1 (]: 7 of 29 START test source_not_null_sqlserver_data_ecommerce_Final_Price ........ [RUN]
[0m13:42:56.412915 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823)
[0m13:42:56.412915 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m13:42:56.428572 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"
[0m13:42:56.428572 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m13:42:56.428572 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"
[0m13:42:56.428572 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"
[0m13:42:56.428572 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_0c828dfdcf5b3aad6aaa994913a3962f_5050]
   as 
    
    
    



select Final_Price
from "my_db"."dbo"."ecommerce"
where Final_Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_0c828dfdcf5b3aad6aaa994913a3962f_5050]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_0c828dfdcf5b3aad6aaa994913a3962f_5050]
  ;')
[0m13:42:56.444173 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:56.444173 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:56.444173 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:56.444173 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:56.459786 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823: ROLLBACK
[0m13:42:56.459786 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823: Close
[0m13:42:56.459786 [info ] [Thread-1 (]: 7 of 29 PASS source_not_null_sqlserver_data_ecommerce_Final_Price .............. [[32mPASS[0m in 0.05s]
[0m13:42:56.459786 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m13:42:56.459786 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m13:42:56.459786 [info ] [Thread-1 (]: 8 of 29 START test source_not_null_sqlserver_data_ecommerce_Payment_Method ..... [RUN]
[0m13:42:56.459786 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32)
[0m13:42:56.459786 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m13:42:56.475412 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"
[0m13:42:56.475412 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m13:42:56.491075 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"
[0m13:42:56.491075 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"
[0m13:42:56.491075 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_21a139b11381849eb19de652fee70f66_12527]
   as 
    
    
    



select Payment_Method
from "my_db"."dbo"."ecommerce"
where Payment_Method is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_21a139b11381849eb19de652fee70f66_12527]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_21a139b11381849eb19de652fee70f66_12527]
  ;')
[0m13:42:56.491075 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:56.491075 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:56.491075 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:56.506698 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:56.506698 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32: ROLLBACK
[0m13:42:56.506698 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32: Close
[0m13:42:56.506698 [info ] [Thread-1 (]: 8 of 29 PASS source_not_null_sqlserver_data_ecommerce_Payment_Method ........... [[32mPASS[0m in 0.05s]
[0m13:42:56.506698 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m13:42:56.522297 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m13:42:56.522297 [info ] [Thread-1 (]: 9 of 29 START test source_not_null_sqlserver_data_ecommerce_Price .............. [RUN]
[0m13:42:56.522297 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a)
[0m13:42:56.522297 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m13:42:56.522297 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"
[0m13:42:56.522297 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m13:42:56.537910 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"
[0m13:42:56.537910 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"
[0m13:42:56.537910 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_e72d4251eae6aeb393f5f649a06f5ac0_4816]
   as 
    
    
    



select Price
from "my_db"."dbo"."ecommerce"
where Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_e72d4251eae6aeb393f5f649a06f5ac0_4816]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_e72d4251eae6aeb393f5f649a06f5ac0_4816]
  ;')
[0m13:42:56.537910 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:56.537910 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:56.537910 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:56.553537 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:56.553537 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a: ROLLBACK
[0m13:42:56.553537 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a: Close
[0m13:42:56.553537 [info ] [Thread-1 (]: 9 of 29 PASS source_not_null_sqlserver_data_ecommerce_Price .................... [[32mPASS[0m in 0.03s]
[0m13:42:56.569158 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m13:42:56.569158 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m13:42:56.569158 [info ] [Thread-1 (]: 10 of 29 START test source_not_null_sqlserver_data_ecommerce_Product_ID ........ [RUN]
[0m13:42:56.569158 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd)
[0m13:42:56.569158 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m13:42:56.569158 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"
[0m13:42:56.584781 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m13:42:56.584781 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"
[0m13:42:56.584781 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"
[0m13:42:56.584781 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_aa576225f643234fe9ca29dea78b3ee4_3566]
   as 
    
    
    



select Product_ID
from "my_db"."dbo"."ecommerce"
where Product_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_aa576225f643234fe9ca29dea78b3ee4_3566]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_aa576225f643234fe9ca29dea78b3ee4_3566]
  ;')
[0m13:42:56.584781 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:56.600411 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:56.600411 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:56.600411 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:56.616031 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd: ROLLBACK
[0m13:42:56.616031 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd: Close
[0m13:42:56.616031 [info ] [Thread-1 (]: 10 of 29 PASS source_not_null_sqlserver_data_ecommerce_Product_ID .............. [[32mPASS[0m in 0.05s]
[0m13:42:56.616031 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m13:42:56.616031 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m13:42:56.616031 [info ] [Thread-1 (]: 11 of 29 START test source_not_null_sqlserver_data_ecommerce_Purchase_Date ..... [RUN]
[0m13:42:56.616031 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23)
[0m13:42:56.616031 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m13:42:56.631657 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"
[0m13:42:56.631657 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m13:42:56.631657 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"
[0m13:42:56.647301 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"
[0m13:42:56.647301 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_0f53a46810cccddc285b5a5f2fa86299_14720]
   as 
    
    
    



select Purchase_Date
from "my_db"."dbo"."ecommerce"
where Purchase_Date is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_0f53a46810cccddc285b5a5f2fa86299_14720]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_0f53a46810cccddc285b5a5f2fa86299_14720]
  ;')
[0m13:42:56.647301 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:56.647301 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:56.647301 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:56.663010 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:56.663010 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23: ROLLBACK
[0m13:42:56.663010 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23: Close
[0m13:42:56.663010 [info ] [Thread-1 (]: 11 of 29 PASS source_not_null_sqlserver_data_ecommerce_Purchase_Date ........... [[32mPASS[0m in 0.05s]
[0m13:42:56.663010 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m13:42:56.663010 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m13:42:56.663010 [info ] [Thread-1 (]: 12 of 29 START test source_not_null_sqlserver_data_ecommerce_User_ID ........... [RUN]
[0m13:42:56.678529 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325)
[0m13:42:56.678529 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m13:42:56.678529 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"
[0m13:42:56.678529 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m13:42:56.694160 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"
[0m13:42:56.694160 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"
[0m13:42:56.694160 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_cf5a2a1ccc69e2afe103181343e9f1f0_3244]
   as 
    
    
    



select User_ID
from "my_db"."dbo"."ecommerce"
where User_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_cf5a2a1ccc69e2afe103181343e9f1f0_3244]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_cf5a2a1ccc69e2afe103181343e9f1f0_3244]
  ;')
[0m13:42:56.694160 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:56.694160 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:56.694160 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:56.709792 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:56.709792 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325: ROLLBACK
[0m13:42:56.709792 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325: Close
[0m13:42:56.709792 [info ] [Thread-1 (]: 12 of 29 PASS source_not_null_sqlserver_data_ecommerce_User_ID ................. [[32mPASS[0m in 0.03s]
[0m13:42:56.709792 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m13:42:56.709792 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04
[0m13:42:56.725407 [info ] [Thread-1 (]: 13 of 29 START test source_not_null_sqlserver_data_sales_ecommerce_Category .... [RUN]
[0m13:42:56.725407 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04)
[0m13:42:56.725407 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04
[0m13:42:56.725407 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04"
[0m13:42:56.741029 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04
[0m13:42:56.741029 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04"
[0m13:42:56.741029 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04"
[0m13:42:56.741029 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_0d74b39eb8545add87cd446b19d85149_8066]
   as 
    
    
    



select Category
from "workspace"."default"."sales_ecommerce"
where Category is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_0d74b39eb8545add87cd446b19d85149_8066]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_0d74b39eb8545add87cd446b19d85149_8066]
  ;')
[0m13:42:56.741029 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:56.741029 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:56.741029 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:56.756660 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:56.756660 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04: ROLLBACK
[0m13:42:56.756660 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04: Close
[0m13:42:56.756660 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_sales_ecommerce_Category.sql[0m
('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")
[0m13:42:56.756660 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")

[0m13:42:56.772285 [error] [Thread-1 (]: 13 of 29 ERROR source_not_null_sqlserver_data_sales_ecommerce_Category ......... [[31mERROR[0m in 0.05s]
[0m13:42:56.772285 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04
[0m13:42:56.772285 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa
[0m13:42:56.772285 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04' to be skipped because of status 'error'.  Reason: ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)").
[0m13:42:56.772285 [info ] [Thread-1 (]: 14 of 29 START test source_not_null_sqlserver_data_sales_ecommerce_Discount .... [RUN]
[0m13:42:56.772285 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Category.c17a290e04, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa)
[0m13:42:56.772285 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa
[0m13:42:56.787909 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa"
[0m13:42:56.787909 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa
[0m13:42:56.787909 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa"
[0m13:42:56.787909 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa"
[0m13:42:56.803532 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_740123bfb0fa861927990afc0b5efe4f_5908]
   as 
    
    
    



select Discount
from "workspace"."default"."sales_ecommerce"
where Discount is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_740123bfb0fa861927990afc0b5efe4f_5908]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_740123bfb0fa861927990afc0b5efe4f_5908]
  ;')
[0m13:42:56.803532 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:56.803532 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:56.803532 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:56.803532 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:56.803532 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa: ROLLBACK
[0m13:42:56.803532 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa: Close
[0m13:42:56.803532 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_sales_ecommerce_Discount.sql[0m
('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")
[0m13:42:56.819170 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")

[0m13:42:56.819170 [error] [Thread-1 (]: 14 of 29 ERROR source_not_null_sqlserver_data_sales_ecommerce_Discount ......... [[31mERROR[0m in 0.05s]
[0m13:42:56.819170 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa
[0m13:42:56.819170 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7
[0m13:42:56.819170 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa' to be skipped because of status 'error'.  Reason: ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)").
[0m13:42:56.819170 [info ] [Thread-1 (]: 15 of 29 START test source_not_null_sqlserver_data_sales_ecommerce_Final_Price . [RUN]
[0m13:42:56.834793 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Discount.4373208bfa, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7)
[0m13:42:56.834793 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7
[0m13:42:56.834793 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7"
[0m13:42:56.834793 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7
[0m13:42:56.850414 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7"
[0m13:42:56.850414 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7"
[0m13:42:56.850414 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_3037c8ece9cb58b14bf62f030dbe2ff8_7369]
   as 
    
    
    



select Final_Price
from "workspace"."default"."sales_ecommerce"
where Final_Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_3037c8ece9cb58b14bf62f030dbe2ff8_7369]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_3037c8ece9cb58b14bf62f030dbe2ff8_7369]
  ;')
[0m13:42:56.850414 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:56.850414 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:56.850414 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:56.866041 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:56.866041 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7: ROLLBACK
[0m13:42:56.866041 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7: Close
[0m13:42:56.866041 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_sales_ecommerce_Final_Price.sql[0m
('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")
[0m13:42:56.866041 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")

[0m13:42:56.866041 [error] [Thread-1 (]: 15 of 29 ERROR source_not_null_sqlserver_data_sales_ecommerce_Final_Price ...... [[31mERROR[0m in 0.05s]
[0m13:42:56.866041 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7
[0m13:42:56.881659 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2
[0m13:42:56.881659 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7' to be skipped because of status 'error'.  Reason: ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)").
[0m13:42:56.881659 [info ] [Thread-1 (]: 16 of 29 START test source_not_null_sqlserver_data_sales_ecommerce_Payment_Method  [RUN]
[0m13:42:56.881659 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Final_Price.9068bfe6a7, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2)
[0m13:42:56.881659 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2
[0m13:42:56.897287 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2"
[0m13:42:56.897287 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2
[0m13:42:56.897287 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2"
[0m13:42:56.897287 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2"
[0m13:42:56.897287 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_3cfe25ddb861ff5e744fd3a0ffd68836_11281]
   as 
    
    
    



select Payment_Method
from "workspace"."default"."sales_ecommerce"
where Payment_Method is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_3cfe25ddb861ff5e744fd3a0ffd68836_11281]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_3cfe25ddb861ff5e744fd3a0ffd68836_11281]
  ;')
[0m13:42:56.897287 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:56.912908 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:56.912908 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:56.912908 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:56.928532 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2: ROLLBACK
[0m13:42:56.928532 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2: Close
[0m13:42:56.928532 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.sql[0m
('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")
[0m13:42:56.944158 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")

[0m13:42:56.944158 [error] [Thread-1 (]: 16 of 29 ERROR source_not_null_sqlserver_data_sales_ecommerce_Payment_Method ... [[31mERROR[0m in 0.06s]
[0m13:42:56.944158 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2
[0m13:42:56.944158 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596
[0m13:42:56.959792 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2' to be skipped because of status 'error'.  Reason: ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)").
[0m13:42:56.959792 [info ] [Thread-1 (]: 17 of 29 START test source_not_null_sqlserver_data_sales_ecommerce_Price ....... [RUN]
[0m13:42:56.959792 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.1102f0b1a2, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596)
[0m13:42:56.959792 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596
[0m13:42:56.975408 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596"
[0m13:42:56.975408 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596
[0m13:42:56.991033 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596"
[0m13:42:56.991033 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596"
[0m13:42:56.991033 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_2b8e9565935d02960cbcc5201d65c6ed_4049]
   as 
    
    
    



select Price
from "workspace"."default"."sales_ecommerce"
where Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_2b8e9565935d02960cbcc5201d65c6ed_4049]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_2b8e9565935d02960cbcc5201d65c6ed_4049]
  ;')
[0m13:42:56.991033 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:56.991033 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:56.991033 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:57.006661 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:57.006661 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596: ROLLBACK
[0m13:42:57.006661 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596: Close
[0m13:42:57.006661 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_sales_ecommerce_Price.sql[0m
('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")
[0m13:42:57.006661 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")

[0m13:42:57.022295 [error] [Thread-1 (]: 17 of 29 ERROR source_not_null_sqlserver_data_sales_ecommerce_Price ............ [[31mERROR[0m in 0.05s]
[0m13:42:57.022295 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596
[0m13:42:57.022295 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34
[0m13:42:57.022295 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596' to be skipped because of status 'error'.  Reason: ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)").
[0m13:42:57.022295 [info ] [Thread-1 (]: 18 of 29 START test source_not_null_sqlserver_data_sales_ecommerce_Product_ID .. [RUN]
[0m13:42:57.022295 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Price.8a1476f596, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34)
[0m13:42:57.022295 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34
[0m13:42:57.037910 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34"
[0m13:42:57.037910 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34
[0m13:42:57.037910 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34"
[0m13:42:57.053557 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34"
[0m13:42:57.053557 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_b0704b9205f22bd5564f588535cee6ce_6551]
   as 
    
    
    



select Product_ID
from "workspace"."default"."sales_ecommerce"
where Product_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_b0704b9205f22bd5564f588535cee6ce_6551]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_b0704b9205f22bd5564f588535cee6ce_6551]
  ;')
[0m13:42:57.053557 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:57.053557 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:57.053557 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:57.053557 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:57.069156 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34: ROLLBACK
[0m13:42:57.069156 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34: Close
[0m13:42:57.069156 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_sales_ecommerce_Product_ID.sql[0m
('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")
[0m13:42:57.069156 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")

[0m13:42:57.069156 [error] [Thread-1 (]: 18 of 29 ERROR source_not_null_sqlserver_data_sales_ecommerce_Product_ID ....... [[31mERROR[0m in 0.05s]
[0m13:42:57.069156 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34
[0m13:42:57.069156 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4
[0m13:42:57.069156 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34' to be skipped because of status 'error'.  Reason: ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)").
[0m13:42:57.084782 [info ] [Thread-1 (]: 19 of 29 START test source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date  [RUN]
[0m13:42:57.084782 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Product_ID.d70e8aff34, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4)
[0m13:42:57.084782 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4
[0m13:42:57.084782 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4"
[0m13:42:57.100406 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4
[0m13:42:57.100406 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4"
[0m13:42:57.100406 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4"
[0m13:42:57.100406 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_a8bd3adc71b9237a0184b91248f727ab_16862]
   as 
    
    
    



select Purchase_Date
from "workspace"."default"."sales_ecommerce"
where Purchase_Date is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_a8bd3adc71b9237a0184b91248f727ab_16862]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_a8bd3adc71b9237a0184b91248f727ab_16862]
  ;')
[0m13:42:57.100406 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:57.116032 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:57.116032 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:57.116032 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:57.116032 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4: ROLLBACK
[0m13:42:57.116032 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4: Close
[0m13:42:57.116032 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.sql[0m
('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")
[0m13:42:57.131662 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")

[0m13:42:57.131662 [error] [Thread-1 (]: 19 of 29 ERROR source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date .... [[31mERROR[0m in 0.05s]
[0m13:42:57.131662 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4
[0m13:42:57.131662 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec
[0m13:42:57.131662 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4' to be skipped because of status 'error'.  Reason: ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)").
[0m13:42:57.131662 [info ] [Thread-1 (]: 20 of 29 START test source_not_null_sqlserver_data_sales_ecommerce_User_ID ..... [RUN]
[0m13:42:57.131662 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.9b6a91aed4, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec)
[0m13:42:57.147297 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec
[0m13:42:57.147297 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec"
[0m13:42:57.147297 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec
[0m13:42:57.162906 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec"
[0m13:42:57.162906 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec"
[0m13:42:57.162906 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec"} */

    -- Create target schema if it does not
  USE [MY_DB];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_3bfa3f2ad42467f2cc1e719d22841892_6843]
   as 
    
    
    



select User_ID
from "workspace"."default"."sales_ecommerce"
where User_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_3bfa3f2ad42467f2cc1e719d22841892_6843]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_3bfa3f2ad42467f2cc1e719d22841892_6843]
  ;')
[0m13:42:57.162906 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:57.162906 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:57.162906 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:57.162906 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:57.178573 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec: ROLLBACK
[0m13:42:57.178573 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec: Close
[0m13:42:57.178573 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_sales_ecommerce_User_ID.sql[0m
('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")
[0m13:42:57.178573 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")

[0m13:42:57.178573 [error] [Thread-1 (]: 20 of 29 ERROR source_not_null_sqlserver_data_sales_ecommerce_User_ID .......... [[31mERROR[0m in 0.05s]
[0m13:42:57.178573 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec
[0m13:42:57.194192 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec' to be skipped because of status 'error'.  Reason: ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)").
[0m13:42:57.178573 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m13:42:57.194192 [info ] [Thread-1 (]: 21 of 29 START sql view model dbo.src_ecommerce ................................ [RUN]
[0m13:42:57.194192 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_sales_ecommerce_User_ID.47a66c98ec, now model.dbt_databricks_cicd.src_ecommerce)
[0m13:42:57.194192 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m13:42:57.194192 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m13:42:57.209806 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m13:42:57.272290 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m13:42:57.272290 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m13:42:57.272290 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [MY_DB];
    
    

    

    
    USE [MY_DB];
    EXEC('
        create view "dbo"."src_ecommerce__dbt_tmp" as select * from "my_db"."dbo"."ecommerce";
    ')


[0m13:42:57.272290 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:57.272290 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:57.272290 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:57.287912 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:57.303535 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m13:42:57.303535 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [MY_DB];
      EXEC sp_rename 'dbo.src_ecommerce__dbt_tmp', 'src_ecommerce'
[0m13:42:57.522297 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:57.569154 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: COMMIT
[0m13:42:57.584781 [debug] [Thread-1 (]: Applying DROP to: "MY_DB"."dbo"."src_ecommerce__dbt_backup"
[0m13:42:57.600404 [debug] [Thread-1 (]: dbt-sqlserver
[0m13:42:57.600404 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m13:42:57.600404 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

        USE [MY_DB];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'MY_DB'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'src_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m13:42:57.678535 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:57.678535 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m13:42:57.678535 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

      
      
    
    USE [MY_DB];
    EXEC('DROP view IF EXISTS "dbo"."src_ecommerce__dbt_backup";');

[0m13:42:57.678535 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:57.694156 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: ROLLBACK
[0m13:42:57.694156 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: Close
[0m13:42:57.709793 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be3f9c1c-7109-44c7-8dde-96b7cdf04aee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAAB6FBB50>]}
[0m13:42:57.709793 [info ] [Thread-1 (]: 21 of 29 OK created sql view model dbo.src_ecommerce ........................... [[32mOK[0m in 0.50s]
[0m13:42:57.709793 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m13:42:57.709793 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m13:42:57.709793 [info ] [Thread-1 (]: 22 of 29 START sql view model dbo.stg_ecommerce ................................ [RUN]
[0m13:42:57.709793 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m13:42:57.709793 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m13:42:57.725410 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m13:42:57.725410 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m13:42:57.741029 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m13:42:57.741029 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m13:42:57.741029 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [MY_DB];
    
    

    

    
    USE [MY_DB];
    EXEC('
        create view "dbo"."stg_ecommerce__dbt_tmp" as select * from "my_db"."dbo"."ecommerce";
    ')


[0m13:42:57.741029 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:57.741029 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:57.756661 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:57.756661 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:57.756661 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m13:42:57.756661 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [MY_DB];
      EXEC sp_rename 'dbo.stg_ecommerce__dbt_tmp', 'stg_ecommerce'
[0m13:42:57.772284 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:57.772284 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: COMMIT
[0m13:42:57.787907 [debug] [Thread-1 (]: Applying DROP to: "MY_DB"."dbo"."stg_ecommerce__dbt_backup"
[0m13:42:57.787907 [debug] [Thread-1 (]: dbt-sqlserver
[0m13:42:57.787907 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m13:42:57.787907 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

        USE [MY_DB];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'MY_DB'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'stg_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m13:42:57.803533 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:57.819154 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m13:42:57.819154 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

      
      
    
    USE [MY_DB];
    EXEC('DROP view IF EXISTS "dbo"."stg_ecommerce__dbt_backup";');

[0m13:42:57.819154 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:57.819154 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: ROLLBACK
[0m13:42:57.819154 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: Close
[0m13:42:57.819154 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be3f9c1c-7109-44c7-8dde-96b7cdf04aee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAAB0084D0>]}
[0m13:42:57.834792 [info ] [Thread-1 (]: 22 of 29 OK created sql view model dbo.stg_ecommerce ........................... [[32mOK[0m in 0.11s]
[0m13:42:57.834792 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m13:42:57.834792 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_discount_by_category
[0m13:42:57.834792 [info ] [Thread-1 (]: 23 of 29 START sql view model dbo.avg_discount_by_category ..................... [RUN]
[0m13:42:57.834792 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now model.dbt_databricks_cicd.avg_discount_by_category)
[0m13:42:57.834792 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_discount_by_category
[0m13:42:57.866031 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m13:42:57.866031 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_discount_by_category
[0m13:42:57.881656 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m13:42:57.881656 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.avg_discount_by_category"
[0m13:42:57.881656 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_discount_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.avg_discount_by_category"} */
USE [MY_DB];
    
    

    

    
    USE [MY_DB];
    EXEC('
        create view "dbo"."avg_discount_by_category__dbt_tmp" as SELECT
  Category,
  ROUND(AVG(CAST(`Discount` AS DOUBLE)), 2) AS avg_discount_percent
FROM "MY_DB"."dbo"."stg_ecommerce"
GROUP BY Category
ORDER BY avg_discount_percent DESC;;
    ')


[0m13:42:57.897296 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:57.897296 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:57.897296 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:57.897296 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:57.897296 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_discount_by_category: ROLLBACK
[0m13:42:57.912909 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_discount_by_category: Close
[0m13:42:57.912909 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\avg_discount_by_category.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)")
[0m13:42:57.959782 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 336, in execute
    return self._execute_model(hook_ctx, context_config, model, context, materialization_macro)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 296, in _execute_model
    result = MacroGenerator(
             ^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 81, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 568, in execute
    while cursor.nextset():
          ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)")

[0m13:42:57.959782 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be3f9c1c-7109-44c7-8dde-96b7cdf04aee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAAAD4C7D0>]}
[0m13:42:57.959782 [error] [Thread-1 (]: 23 of 29 ERROR creating sql view model dbo.avg_discount_by_category ............ [[31mERROR[0m in 0.12s]
[0m13:42:57.975405 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_discount_by_category
[0m13:42:57.975405 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m13:42:57.975405 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.avg_discount_by_category' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)").
[0m13:42:57.975405 [info ] [Thread-1 (]: 24 of 29 START sql view model dbo.avg_ticket_by_category ....................... [RUN]
[0m13:42:57.975405 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_discount_by_category, now model.dbt_databricks_cicd.avg_ticket_by_category)
[0m13:42:57.975405 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_ticket_by_category
[0m13:42:57.991033 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m13:42:58.006657 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_ticket_by_category
[0m13:42:58.022293 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m13:42:58.022293 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m13:42:58.022293 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_ticket_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.avg_ticket_by_category"} */
USE [MY_DB];
    
    

    

    
    USE [MY_DB];
    EXEC('
        create view "dbo"."avg_ticket_by_category__dbt_tmp" as 

SELECT
    Category,
    ROUND(AVG(CAST(REPLACE(`Final_Price`, '','', ''.'') AS DOUBLE)), 2) AS avg_ticket
FROM "MY_DB"."dbo"."stg_ecommerce"
GROUP BY Category
ORDER BY avg_ticket DESC;
    ')


[0m13:42:58.037923 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:58.037923 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:58.037923 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:58.037923 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:58.037923 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_ticket_by_category: ROLLBACK
[0m13:42:58.037923 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_ticket_by_category: Close
[0m13:42:58.053531 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\avg_ticket_by_category.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)")
[0m13:42:58.053531 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 336, in execute
    return self._execute_model(hook_ctx, context_config, model, context, materialization_macro)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 296, in _execute_model
    result = MacroGenerator(
             ^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 81, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 568, in execute
    while cursor.nextset():
          ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)")

[0m13:42:58.069155 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be3f9c1c-7109-44c7-8dde-96b7cdf04aee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAAAD37310>]}
[0m13:42:58.069155 [error] [Thread-1 (]: 24 of 29 ERROR creating sql view model dbo.avg_ticket_by_category .............. [[31mERROR[0m in 0.08s]
[0m13:42:58.069155 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m13:42:58.069155 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.monthly_revenue
[0m13:42:58.069155 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.avg_ticket_by_category' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)").
[0m13:42:58.069155 [info ] [Thread-1 (]: 25 of 29 START sql view model dbo.monthly_revenue .............................. [RUN]
[0m13:42:58.069155 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_ticket_by_category, now model.dbt_databricks_cicd.monthly_revenue)
[0m13:42:58.069155 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.monthly_revenue
[0m13:42:58.084783 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.monthly_revenue"
[0m13:42:58.084783 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.monthly_revenue
[0m13:42:58.084783 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.monthly_revenue"
[0m13:42:58.084783 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.monthly_revenue"
[0m13:42:58.100407 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.monthly_revenue: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.monthly_revenue"} */
USE [MY_DB];
    
    

    

    
    USE [MY_DB];
    EXEC('
        create view "dbo"."monthly_revenue__dbt_tmp" as SELECT
  CAST(DATE_TRUNC(''month'', CAST(Purchase_Date AS DATE)) AS DATE) AS month,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, '','', ''.'') AS DOUBLE)), 2) AS monthly_revenue
FROM "MY_DB"."dbo"."stg_ecommerce"
GROUP BY 1
ORDER BY 1;;
    ')


[0m13:42:58.100407 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:58.100407 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:58.100407 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:58.100407 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:58.100407 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.monthly_revenue: ROLLBACK
[0m13:42:58.100407 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.monthly_revenue: Close
[0m13:42:58.116031 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\monthly_revenue.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]'DATE_TRUNC' não é um nome da função interna reconhecido. (195) (SQLMoreResults)")
[0m13:42:58.116031 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 336, in execute
    return self._execute_model(hook_ctx, context_config, model, context, materialization_macro)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 296, in _execute_model
    result = MacroGenerator(
             ^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 81, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 568, in execute
    while cursor.nextset():
          ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]'DATE_TRUNC' não é um nome da função interna reconhecido. (195) (SQLMoreResults)")

[0m13:42:58.116031 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be3f9c1c-7109-44c7-8dde-96b7cdf04aee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAAB054FD0>]}
[0m13:42:58.116031 [error] [Thread-1 (]: 25 of 29 ERROR creating sql view model dbo.monthly_revenue ..................... [[31mERROR[0m in 0.05s]
[0m13:42:58.116031 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.monthly_revenue
[0m13:42:58.116031 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.payment_distribution
[0m13:42:58.116031 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.monthly_revenue' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]'DATE_TRUNC' não é um nome da função interna reconhecido. (195) (SQLMoreResults)").
[0m13:42:58.116031 [info ] [Thread-1 (]: 26 of 29 START sql view model dbo.payment_distribution ......................... [RUN]
[0m13:42:58.131674 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.monthly_revenue, now model.dbt_databricks_cicd.payment_distribution)
[0m13:42:58.131674 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.payment_distribution
[0m13:42:58.131674 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.payment_distribution"
[0m13:42:58.131674 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.payment_distribution
[0m13:42:58.147320 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.payment_distribution"
[0m13:42:58.147320 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.payment_distribution"
[0m13:42:58.147320 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.payment_distribution: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.payment_distribution"} */
USE [MY_DB];
    
    

    

    
    USE [MY_DB];
    EXEC('
        create view "dbo"."payment_distribution__dbt_tmp" as SELECT
  Payment_Method,
  COUNT(*) AS total_transactions,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, '','', ''.'') AS DOUBLE)), 2) AS total_value
FROM "MY_DB"."dbo"."stg_ecommerce"
GROUP BY Payment_Method
ORDER BY total_value DESC;;
    ')


[0m13:42:58.147320 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:58.147320 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:58.147320 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:58.162909 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:58.162909 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.payment_distribution: ROLLBACK
[0m13:42:58.162909 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.payment_distribution: Close
[0m13:42:58.162909 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\payment_distribution.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)")
[0m13:42:58.162909 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 336, in execute
    return self._execute_model(hook_ctx, context_config, model, context, materialization_macro)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 296, in _execute_model
    result = MacroGenerator(
             ^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 81, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 568, in execute
    while cursor.nextset():
          ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)")

[0m13:42:58.162909 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be3f9c1c-7109-44c7-8dde-96b7cdf04aee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAAAFF8610>]}
[0m13:42:58.162909 [error] [Thread-1 (]: 26 of 29 ERROR creating sql view model dbo.payment_distribution ................ [[31mERROR[0m in 0.03s]
[0m13:42:58.178529 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.payment_distribution
[0m13:42:58.178529 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.sales_by_category
[0m13:42:58.178529 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.payment_distribution' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)").
[0m13:42:58.178529 [info ] [Thread-1 (]: 27 of 29 START sql view model dbo.sales_by_category ............................ [RUN]
[0m13:42:58.178529 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.payment_distribution, now model.dbt_databricks_cicd.sales_by_category)
[0m13:42:58.178529 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.sales_by_category
[0m13:42:58.194195 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.sales_by_category"
[0m13:42:58.194195 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.sales_by_category
[0m13:42:58.194195 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.sales_by_category"
[0m13:42:58.194195 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.sales_by_category"
[0m13:42:58.209813 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.sales_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.sales_by_category"} */
USE [MY_DB];
    
    

    

    
    USE [MY_DB];
    EXEC('
        create view "dbo"."sales_by_category__dbt_tmp" as SELECT
  Category,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, '','', ''.'') AS DOUBLE)), 2) AS total_revenue
FROM "MY_DB"."dbo"."stg_ecommerce"
GROUP BY Category
ORDER BY total_revenue DESC;;
    ')


[0m13:42:58.209813 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:58.209813 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:58.209813 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:58.209813 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:58.209813 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.sales_by_category: ROLLBACK
[0m13:42:58.209813 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.sales_by_category: Close
[0m13:42:58.209813 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\sales_by_category.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)")
[0m13:42:58.225438 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 336, in execute
    return self._execute_model(hook_ctx, context_config, model, context, materialization_macro)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 296, in _execute_model
    result = MacroGenerator(
             ^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 81, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 568, in execute
    while cursor.nextset():
          ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)")

[0m13:42:58.225438 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be3f9c1c-7109-44c7-8dde-96b7cdf04aee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAAAB1FB90>]}
[0m13:42:58.225438 [error] [Thread-1 (]: 27 of 29 ERROR creating sql view model dbo.sales_by_category ................... [[31mERROR[0m in 0.05s]
[0m13:42:58.225438 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.sales_by_category
[0m13:42:58.225438 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_5_products
[0m13:42:58.225438 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.sales_by_category' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)").
[0m13:42:58.225438 [info ] [Thread-1 (]: 28 of 29 START sql view model dbo.top_5_products ............................... [RUN]
[0m13:42:58.225438 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.sales_by_category, now model.dbt_databricks_cicd.top_5_products)
[0m13:42:58.241034 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_5_products
[0m13:42:58.241034 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_5_products"
[0m13:42:58.241034 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_5_products
[0m13:42:58.256698 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_5_products"
[0m13:42:58.256698 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.top_5_products"
[0m13:42:58.256698 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_5_products: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.top_5_products"} */
USE [MY_DB];
    
    

    

    
    USE [MY_DB];
    EXEC('
        create view "dbo"."top_5_products__dbt_tmp" as 

WITH base AS (
    SELECT
        product_id,
        ROUND(SUM(CAST(REPLACE(`Final_Price`, '','', ''.'') AS DOUBLE)), 2)AS total_sales
    FROM "MY_DB"."dbo"."stg_ecommerce"
    GROUP BY product_id
)

SELECT
    product_id,
    total_sales
FROM base
ORDER BY total_sales DESC
LIMIT 5;
    ')


[0m13:42:58.272281 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:58.272281 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:58.272281 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:58.272281 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:58.272281 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_5_products: ROLLBACK
[0m13:42:58.287907 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_5_products: Close
[0m13:42:58.287907 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\top_5_products.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults); [42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'LIMIT'. (102)")
[0m13:42:58.287907 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 336, in execute
    return self._execute_model(hook_ctx, context_config, model, context, materialization_macro)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 296, in _execute_model
    result = MacroGenerator(
             ^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 81, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 568, in execute
    while cursor.nextset():
          ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults); [42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'LIMIT'. (102)")

[0m13:42:58.287907 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be3f9c1c-7109-44c7-8dde-96b7cdf04aee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAAB7D9850>]}
[0m13:42:58.287907 [error] [Thread-1 (]: 28 of 29 ERROR creating sql view model dbo.top_5_products ...................... [[31mERROR[0m in 0.06s]
[0m13:42:58.303529 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_5_products
[0m13:42:58.303529 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_customers
[0m13:42:58.303529 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.top_5_products' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults); [42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'LIMIT'. (102)").
[0m13:42:58.303529 [info ] [Thread-1 (]: 29 of 29 START sql view model dbo.top_customers ................................ [RUN]
[0m13:42:58.303529 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_5_products, now model.dbt_databricks_cicd.top_customers)
[0m13:42:58.303529 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_customers
[0m13:42:58.319156 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_customers"
[0m13:42:58.319156 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_customers
[0m13:42:58.334795 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_customers"
[0m13:42:58.334795 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.top_customers"
[0m13:42:58.350406 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_customers: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.top_customers"} */
USE [MY_DB];
    
    

    

    
    USE [MY_DB];
    EXEC('
        create view "dbo"."top_customers__dbt_tmp" as 

SELECT
  User_ID,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, '','', ''.'') AS DOUBLE)), 2) AS total_spent
FROM "MY_DB"."dbo"."stg_ecommerce"
GROUP BY User_ID
ORDER BY total_spent DESC
LIMIT 10;;
    ')


[0m13:42:58.350406 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m13:42:58.350406 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=MY_DB;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m13:42:58.350406 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: MY_DB
[0m13:42:58.350406 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m13:42:58.350406 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_customers: ROLLBACK
[0m13:42:58.350406 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_customers: Close
[0m13:42:58.366030 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\top_customers.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)")
[0m13:42:58.366030 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 336, in execute
    return self._execute_model(hook_ctx, context_config, model, context, materialization_macro)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 296, in _execute_model
    result = MacroGenerator(
             ^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 81, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 568, in execute
    while cursor.nextset():
          ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)")

[0m13:42:58.366030 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be3f9c1c-7109-44c7-8dde-96b7cdf04aee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAAB037B10>]}
[0m13:42:58.381657 [error] [Thread-1 (]: 29 of 29 ERROR creating sql view model dbo.top_customers ....................... [[31mERROR[0m in 0.06s]
[0m13:42:58.381657 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_customers
[0m13:42:58.381657 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.top_customers' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)").
[0m13:42:58.381657 [debug] [MainThread]: On master: COMMIT
[0m13:42:58.381657 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:42:58.381657 [debug] [MainThread]: Connection 'list_MY_DB' was properly closed.
[0m13:42:58.381657 [debug] [MainThread]: Connection 'list_MY_DB_dbo' was properly closed.
[0m13:42:58.397290 [debug] [MainThread]: Connection 'model.dbt_databricks_cicd.top_customers' was properly closed.
[0m13:42:58.397290 [info ] [MainThread]: 
[0m13:42:58.397290 [info ] [MainThread]: Finished running 20 data tests, 9 view models in 0 hours 0 minutes and 2.97 seconds (2.97s).
[0m13:42:58.412905 [debug] [MainThread]: Command end result
[0m13:42:58.475403 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m13:42:58.475403 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m13:42:58.491029 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m13:42:58.491029 [info ] [MainThread]: 
[0m13:42:58.491029 [info ] [MainThread]: [31mCompleted with 17 errors, 0 partial successes, and 0 warnings:[0m
[0m13:42:58.491029 [info ] [MainThread]: 
[0m13:42:58.491029 [error] [MainThread]: [31mFailure in test source_accepted_values_sqlserver_data_sales_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m13:42:58.506695 [error] [MainThread]:   ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")
[0m13:42:58.506695 [info ] [MainThread]: 
[0m13:42:58.506695 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_accepted_values_sqlserv_2459675a1bb0ad6a307b59b3a1008a3b.sql
[0m13:42:58.506695 [info ] [MainThread]: 
[0m13:42:58.506695 [error] [MainThread]: [31mFailure in test source_assert_schema_matches_sqlserver_data_sales_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m13:42:58.506695 [error] [MainThread]:   Got 8 results, configured to fail if != 0
[0m13:42:58.506695 [info ] [MainThread]: 
[0m13:42:58.506695 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_assert_schema_matches_s_a3c180804a3eda59a19801a4d38a627b.sql
[0m13:42:58.522297 [info ] [MainThread]: 
[0m13:42:58.522297 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_sales_ecommerce_Category (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m13:42:58.522297 [error] [MainThread]:   ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")
[0m13:42:58.522297 [info ] [MainThread]: 
[0m13:42:58.522297 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_sales_ecommerce_Category.sql
[0m13:42:58.522297 [info ] [MainThread]: 
[0m13:42:58.522297 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_sales_ecommerce_Discount (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m13:42:58.537944 [error] [MainThread]:   ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")
[0m13:42:58.537944 [info ] [MainThread]: 
[0m13:42:58.537944 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_sales_ecommerce_Discount.sql
[0m13:42:58.537944 [info ] [MainThread]: 
[0m13:42:58.537944 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_sales_ecommerce_Final_Price (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m13:42:58.537944 [error] [MainThread]:   ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")
[0m13:42:58.537944 [info ] [MainThread]: 
[0m13:42:58.553574 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_sales_ecommerce_Final_Price.sql
[0m13:42:58.553574 [info ] [MainThread]: 
[0m13:42:58.553574 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_sales_ecommerce_Payment_Method (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m13:42:58.553574 [error] [MainThread]:   ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")
[0m13:42:58.553574 [info ] [MainThread]: 
[0m13:42:58.553574 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_sales_ecommerce_Payment_Method.sql
[0m13:42:58.553574 [info ] [MainThread]: 
[0m13:42:58.569197 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_sales_ecommerce_Price (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m13:42:58.569197 [error] [MainThread]:   ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")
[0m13:42:58.569197 [info ] [MainThread]: 
[0m13:42:58.569197 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_sales_ecommerce_Price.sql
[0m13:42:58.569197 [info ] [MainThread]: 
[0m13:42:58.569197 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_sales_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m13:42:58.584778 [error] [MainThread]:   ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")
[0m13:42:58.584778 [info ] [MainThread]: 
[0m13:42:58.584778 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_sales_ecommerce_Product_ID.sql
[0m13:42:58.584778 [info ] [MainThread]: 
[0m13:42:58.584778 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m13:42:58.584778 [error] [MainThread]:   ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")
[0m13:42:58.584778 [info ] [MainThread]: 
[0m13:42:58.584778 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_sales_ecommerce_Purchase_Date.sql
[0m13:42:58.600444 [info ] [MainThread]: 
[0m13:42:58.600444 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_sales_ecommerce_User_ID (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m13:42:58.600444 [error] [MainThread]:   ('42S02', "[42S02] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Nome de objeto 'workspace.default.sales_ecommerce' inválido. (208) (SQLMoreResults)")
[0m13:42:58.600444 [info ] [MainThread]: 
[0m13:42:58.600444 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_sales_ecommerce_User_ID.sql
[0m13:42:58.600444 [info ] [MainThread]: 
[0m13:42:58.600444 [error] [MainThread]: [31mFailure in model avg_discount_by_category (dbt_databricks_cicd/models\mart\avg_discount_by_category.sql)[0m
[0m13:42:58.616070 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)")
[0m13:42:58.616070 [info ] [MainThread]: 
[0m13:42:58.616070 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\avg_discount_by_category.sql
[0m13:42:58.616070 [info ] [MainThread]: 
[0m13:42:58.616070 [error] [MainThread]: [31mFailure in model avg_ticket_by_category (dbt_databricks_cicd/models\mart\avg_ticket_by_category.sql)[0m
[0m13:42:58.616070 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)")
[0m13:42:58.616070 [info ] [MainThread]: 
[0m13:42:58.631677 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\avg_ticket_by_category.sql
[0m13:42:58.631677 [info ] [MainThread]: 
[0m13:42:58.631677 [error] [MainThread]: [31mFailure in model monthly_revenue (dbt_databricks_cicd/models\mart\monthly_revenue.sql)[0m
[0m13:42:58.631677 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]'DATE_TRUNC' não é um nome da função interna reconhecido. (195) (SQLMoreResults)")
[0m13:42:58.631677 [info ] [MainThread]: 
[0m13:42:58.631677 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\monthly_revenue.sql
[0m13:42:58.631677 [info ] [MainThread]: 
[0m13:42:58.631677 [error] [MainThread]: [31mFailure in model payment_distribution (dbt_databricks_cicd/models\mart\payment_distribution.sql)[0m
[0m13:42:58.647302 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)")
[0m13:42:58.647302 [info ] [MainThread]: 
[0m13:42:58.647302 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\payment_distribution.sql
[0m13:42:58.647302 [info ] [MainThread]: 
[0m13:42:58.647302 [error] [MainThread]: [31mFailure in model sales_by_category (dbt_databricks_cicd/models\mart\sales_by_category.sql)[0m
[0m13:42:58.647302 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)")
[0m13:42:58.647302 [info ] [MainThread]: 
[0m13:42:58.662906 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\sales_by_category.sql
[0m13:42:58.662906 [info ] [MainThread]: 
[0m13:42:58.662906 [error] [MainThread]: [31mFailure in model top_5_products (dbt_databricks_cicd/models\mart\top_5_products.sql)[0m
[0m13:42:58.662906 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults); [42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'LIMIT'. (102)")
[0m13:42:58.662906 [info ] [MainThread]: 
[0m13:42:58.662906 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\top_5_products.sql
[0m13:42:58.662906 [info ] [MainThread]: 
[0m13:42:58.678532 [error] [MainThread]: [31mFailure in model top_customers (dbt_databricks_cicd/models\mart\top_customers.sql)[0m
[0m13:42:58.678532 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a '`'. (102) (SQLMoreResults)")
[0m13:42:58.678532 [info ] [MainThread]: 
[0m13:42:58.678532 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\top_customers.sql
[0m13:42:58.678532 [info ] [MainThread]: 
[0m13:42:58.678532 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=17 SKIP=0 NO-OP=0 TOTAL=29
[0m13:42:58.678532 [debug] [MainThread]: Command `dbt build` failed at 13:42:58.678532 after 6.12 seconds
[0m13:42:58.694161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAA9053890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAA9050810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001AAA8D443D0>]}
[0m13:42:58.694161 [debug] [MainThread]: Flushing usage events
[0m13:42:59.413023 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:14:32.699028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E64309710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E6430B0D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E643096D0>]}


============================== 09:14:32.714651 | fb22409a-3a5a-4d55-a9d0-da747ef10c29 ==============================
[0m09:14:32.714651 [info ] [MainThread]: Running with dbt=1.10.3
[0m09:14:32.714651 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt test --target databricks', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:14:34.949028 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m09:14:34.964652 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m09:14:34.964652 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m09:14:41.382982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fb22409a-3a5a-4d55-a9d0-da747ef10c29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E6D6E7AD0>]}
[0m09:14:41.492391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fb22409a-3a5a-4d55-a9d0-da747ef10c29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E63A79D90>]}
[0m09:14:41.507975 [info ] [MainThread]: Registered adapter: databricks=1.10.4
[0m09:14:42.601726 [debug] [MainThread]: checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, vars: {}, profile: , target: databricks, version: 1.10.3
[0m09:14:42.789267 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m09:14:42.789267 [debug] [MainThread]: previous checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, current checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331
[0m09:14:42.789267 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m09:14:42.789267 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m09:14:42.789267 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m09:14:42.789267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'fb22409a-3a5a-4d55-a9d0-da747ef10c29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E63A18410>]}
[0m09:14:47.929857 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.staging.sqlserver
[0m09:14:47.945536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fb22409a-3a5a-4d55-a9d0-da747ef10c29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E707E6550>]}
[0m09:14:48.133023 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m09:14:48.133023 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m09:14:48.242351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fb22409a-3a5a-4d55-a9d0-da747ef10c29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E70F12D90>]}
[0m09:14:48.242351 [info ] [MainThread]: Found 9 models, 27 data tests, 1 source, 682 macros
[0m09:14:48.242351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fb22409a-3a5a-4d55-a9d0-da747ef10c29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E70C16B10>]}
[0m09:14:48.257979 [info ] [MainThread]: 
[0m09:14:48.257979 [info ] [MainThread]: Concurrency: 1 threads (target='databricks')
[0m09:14:48.257979 [info ] [MainThread]: 
[0m09:14:48.257979 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=0s, language=None, compute-name=) - Creating connection
[0m09:14:48.257979 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m09:14:48.273600 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace_default, idle-time=0s, language=None, compute-name=) - Creating connection
[0m09:14:48.273600 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace_default'
[0m09:14:48.304867 [debug] [ThreadPool]: Using databricks connection "list_workspace_default"
[0m09:14:48.304867 [debug] [ThreadPool]: On list_workspace_default: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "connection_name": "list_workspace_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'workspace' 
  AND table_schema = 'default'

  
[0m09:14:48.304867 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:14:49.664227 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f06ed1-1edc-1518-9304-afdee1fba535) - Created
[0m09:15:09.571919 [debug] [ThreadPool]: SQL status: OK in 21.270 seconds
[0m09:15:09.603175 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f06ed1-1edc-1518-9304-afdee1fba535, command-id=01f06ed1-1f26-19ec-a7e0-383cbed7e374) - Closing
[0m09:15:10.025054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fb22409a-3a5a-4d55-a9d0-da747ef10c29', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E70C41A10>]}
[0m09:15:10.040713 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:15:10.040713 [info ] [Thread-1 (]: 1 of 27 START test not_null_avg_discount_by_category_Category .................. [RUN]
[0m09:15:10.040713 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, idle-time=0s, language=None, compute-name=) - Creating connection
[0m09:15:10.040713 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b'
[0m09:15:10.040713 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:15:10.071936 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m09:15:10.087548 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:15:10.118805 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m09:15:10.134430 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m09:15:10.134430 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_discount_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:15:10.134430 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m09:15:10.900122 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887) - Created
[0m09:15:15.743804 [debug] [Thread-1 (]: SQL status: OK in 5.610 seconds
[0m09:15:15.743804 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, command-id=01f06ed1-2bc6-1052-9a9d-08fdd3d91aff) - Closing
[0m09:15:15.759423 [info ] [Thread-1 (]: 1 of 27 PASS not_null_avg_discount_by_category_Category ........................ [[32mPASS[0m in 5.72s]
[0m09:15:15.759423 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:15:15.759423 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:15:15.759423 [info ] [Thread-1 (]: 2 of 27 START test not_null_avg_discount_by_category_avg_discount_percent ...... [RUN]
[0m09:15:15.759423 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101)
[0m09:15:15.759423 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:15:15.759423 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:15:15.775084 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m09:15:15.775084 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:15:15.790678 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m09:15:15.790678 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m09:15:15.790678 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_discount_percent
from `workspace`.`default`.`avg_discount_by_category`
where avg_discount_percent is null



  
  
      
    ) dbt_internal_test
[0m09:15:19.681376 [debug] [Thread-1 (]: SQL status: OK in 3.890 seconds
[0m09:15:19.696937 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, command-id=01f06ed1-2eaf-1a0e-b4e0-e0be84b0418b) - Closing
[0m09:15:19.696937 [info ] [Thread-1 (]: 2 of 27 PASS not_null_avg_discount_by_category_avg_discount_percent ............ [[32mPASS[0m in 3.94s]
[0m09:15:19.696937 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:15:19.712554 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:15:19.712554 [info ] [Thread-1 (]: 3 of 27 START test not_null_avg_ticket_by_category_Category .................... [RUN]
[0m09:15:19.712554 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f)
[0m09:15:19.712554 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, idle-time=0.015616893768310547s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:15:19.712554 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:15:19.728178 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m09:15:19.728178 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:15:19.743807 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m09:15:19.743807 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m09:15:19.743807 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_ticket_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:15:20.884459 [debug] [Thread-1 (]: SQL status: OK in 1.140 seconds
[0m09:15:20.884459 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, command-id=01f06ed1-310a-1445-9614-c24b09887f84) - Closing
[0m09:15:20.884459 [info ] [Thread-1 (]: 3 of 27 PASS not_null_avg_ticket_by_category_Category .......................... [[32mPASS[0m in 1.17s]
[0m09:15:20.884459 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:15:20.884459 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:15:20.884459 [info ] [Thread-1 (]: 4 of 27 START test not_null_avg_ticket_by_category_avg_ticket .................. [RUN]
[0m09:15:20.900046 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41)
[0m09:15:20.900046 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, idle-time=0.015587329864501953s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:15:20.900046 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:15:20.900046 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m09:15:20.915674 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:15:20.915674 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m09:15:20.915674 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m09:15:20.915674 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_ticket
from `workspace`.`default`.`avg_ticket_by_category`
where avg_ticket is null



  
  
      
    ) dbt_internal_test
[0m09:15:21.853224 [debug] [Thread-1 (]: SQL status: OK in 0.940 seconds
[0m09:15:21.853224 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, command-id=01f06ed1-31bd-1fcf-a540-656aba5cf66c) - Closing
[0m09:15:21.853224 [info ] [Thread-1 (]: 4 of 27 PASS not_null_avg_ticket_by_category_avg_ticket ........................ [[32mPASS[0m in 0.97s]
[0m09:15:21.853224 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:15:21.868843 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:15:21.868843 [info ] [Thread-1 (]: 5 of 27 START test not_null_monthly_revenue_month .............................. [RUN]
[0m09:15:21.868843 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, now test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b)
[0m09:15:21.868843 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, idle-time=0.015619039535522461s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:15:21.868843 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:15:21.868843 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m09:15:21.884433 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:15:21.884433 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m09:15:21.884433 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m09:15:21.884433 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select month
from `workspace`.`default`.`monthly_revenue`
where month is null



  
  
      
    ) dbt_internal_test
[0m09:15:22.962560 [debug] [Thread-1 (]: SQL status: OK in 1.080 seconds
[0m09:15:22.962560 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, command-id=01f06ed1-3252-1b4e-8c18-42839b70fdcf) - Closing
[0m09:15:22.962560 [info ] [Thread-1 (]: 5 of 27 PASS not_null_monthly_revenue_month .................................... [[32mPASS[0m in 1.09s]
[0m09:15:22.978175 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:15:22.978175 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:15:22.978175 [info ] [Thread-1 (]: 6 of 27 START test not_null_monthly_revenue_monthly_revenue .................... [RUN]
[0m09:15:22.978175 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, now test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b)
[0m09:15:22.978175 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, idle-time=0.015614986419677734s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:15:22.978175 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:15:22.993797 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m09:15:22.993797 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:15:22.993797 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m09:15:23.009422 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m09:15:23.009422 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select monthly_revenue
from `workspace`.`default`.`monthly_revenue`
where monthly_revenue is null



  
  
      
    ) dbt_internal_test
[0m09:15:24.056356 [debug] [Thread-1 (]: SQL status: OK in 1.050 seconds
[0m09:15:24.056356 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, command-id=01f06ed1-32fc-16c8-8982-7158a4d7ba99) - Closing
[0m09:15:24.056356 [info ] [Thread-1 (]: 6 of 27 PASS not_null_monthly_revenue_monthly_revenue .......................... [[32mPASS[0m in 1.08s]
[0m09:15:24.056356 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:15:24.071963 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:15:24.071963 [info ] [Thread-1 (]: 7 of 27 START test not_null_payment_distribution_Payment_Method ................ [RUN]
[0m09:15:24.071963 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, now test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae)
[0m09:15:24.071963 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, idle-time=0.015606403350830078s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:15:24.071963 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:15:24.071963 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m09:15:24.087548 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:15:24.087548 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m09:15:24.087548 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m09:15:24.087548 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`payment_distribution`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m09:15:25.040746 [debug] [Thread-1 (]: SQL status: OK in 0.950 seconds
[0m09:15:25.056338 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, command-id=01f06ed1-33a2-1cc5-bab9-a18560e4f99a) - Closing
[0m09:15:25.056338 [info ] [Thread-1 (]: 7 of 27 PASS not_null_payment_distribution_Payment_Method ...................... [[32mPASS[0m in 0.98s]
[0m09:15:25.056338 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:15:25.056338 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:15:25.056338 [info ] [Thread-1 (]: 8 of 27 START test not_null_payment_distribution_total_transactions ............ [RUN]
[0m09:15:25.056338 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, now test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8)
[0m09:15:25.056338 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:15:25.071922 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:15:25.071922 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m09:15:25.071922 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:15:25.087562 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m09:15:25.087562 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m09:15:25.087562 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_transactions
from `workspace`.`default`.`payment_distribution`
where total_transactions is null



  
  
      
    ) dbt_internal_test
[0m09:15:25.962613 [debug] [Thread-1 (]: SQL status: OK in 0.860 seconds
[0m09:15:25.962613 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, command-id=01f06ed1-343b-1b9a-8596-1c00eda081f0) - Closing
[0m09:15:25.962613 [info ] [Thread-1 (]: 8 of 27 PASS not_null_payment_distribution_total_transactions .................. [[32mPASS[0m in 0.91s]
[0m09:15:25.962613 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:15:25.962613 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:15:25.962613 [info ] [Thread-1 (]: 9 of 27 START test not_null_payment_distribution_total_value ................... [RUN]
[0m09:15:25.978176 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, now test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03)
[0m09:15:25.978176 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, idle-time=0.015563011169433594s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:15:25.978176 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:15:25.978176 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m09:15:25.978176 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:15:25.993803 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m09:15:25.993803 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m09:15:25.993803 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_value
from `workspace`.`default`.`payment_distribution`
where total_value is null



  
  
      
    ) dbt_internal_test
[0m09:15:26.962625 [debug] [Thread-1 (]: SQL status: OK in 0.970 seconds
[0m09:15:26.978212 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, command-id=01f06ed1-34c5-1a26-a086-32e211856195) - Closing
[0m09:15:26.978212 [info ] [Thread-1 (]: 9 of 27 PASS not_null_payment_distribution_total_value ......................... [[32mPASS[0m in 1.00s]
[0m09:15:26.978212 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:15:26.978212 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:15:26.978212 [info ] [Thread-1 (]: 10 of 27 START test not_null_sales_by_category_Category ........................ [RUN]
[0m09:15:26.978212 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, now test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507)
[0m09:15:26.978212 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:15:26.978212 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:15:26.993800 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m09:15:26.993800 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:15:26.993800 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m09:15:27.009421 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m09:15:27.009421 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`sales_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:15:27.915720 [debug] [Thread-1 (]: SQL status: OK in 0.910 seconds
[0m09:15:27.931359 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, command-id=01f06ed1-355f-1243-94dd-1faeb75fa2eb) - Closing
[0m09:15:27.931359 [info ] [Thread-1 (]: 10 of 27 PASS not_null_sales_by_category_Category .............................. [[32mPASS[0m in 0.95s]
[0m09:15:27.931359 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:15:27.931359 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:15:27.946940 [info ] [Thread-1 (]: 11 of 27 START test not_null_sales_by_category_total_orders .................... [RUN]
[0m09:15:27.946940 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, now test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e)
[0m09:15:27.946940 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, idle-time=0.015581369400024414s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:15:27.946940 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:15:27.962555 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m09:15:27.962555 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:15:27.978176 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m09:15:27.978176 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m09:15:27.978176 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`sales_by_category`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m09:15:28.634486 [debug] [Thread-1 (]: SQL status: OK in 0.660 seconds
[0m09:15:28.634486 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, command-id=01f06ed1-35f2-1bf3-a92d-c302d3170d6c) - Closing
[0m09:15:28.650059 [info ] [Thread-1 (]: 11 of 27 PASS not_null_sales_by_category_total_orders .......................... [[32mPASS[0m in 0.70s]
[0m09:15:28.650059 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:15:28.650059 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:15:28.650059 [info ] [Thread-1 (]: 12 of 27 START test not_null_sales_by_category_total_revenue ................... [RUN]
[0m09:15:28.650059 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, now test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd)
[0m09:15:28.665682 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, idle-time=0.015624046325683594s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:15:28.665682 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:15:28.681303 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m09:15:28.681303 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:15:28.681303 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m09:15:28.681303 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m09:15:28.696947 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_revenue
from `workspace`.`default`.`sales_by_category`
where total_revenue is null



  
  
      
    ) dbt_internal_test
[0m09:15:29.603220 [debug] [Thread-1 (]: SQL status: OK in 0.910 seconds
[0m09:15:29.603220 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, command-id=01f06ed1-365f-1c38-a47d-60e4fd580f11) - Closing
[0m09:15:29.603220 [info ] [Thread-1 (]: 12 of 27 PASS not_null_sales_by_category_total_revenue ......................... [[32mPASS[0m in 0.95s]
[0m09:15:29.603220 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:15:29.603220 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:15:29.603220 [info ] [Thread-1 (]: 13 of 27 START test not_null_top_5_products_product_id ......................... [RUN]
[0m09:15:29.618831 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, now test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe)
[0m09:15:29.618831 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, idle-time=0.015610694885253906s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:15:29.618831 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:15:29.618831 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m09:15:29.618831 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:15:29.634428 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m09:15:29.634428 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m09:15:29.634428 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select product_id
from `workspace`.`default`.`top_5_products`
where product_id is null



  
  
      
    ) dbt_internal_test
[0m09:15:30.790748 [debug] [Thread-1 (]: SQL status: OK in 1.160 seconds
[0m09:15:30.806362 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, command-id=01f06ed1-36f0-1bb2-9161-42a26c92ff0e) - Closing
[0m09:15:30.806362 [info ] [Thread-1 (]: 13 of 27 PASS not_null_top_5_products_product_id ............................... [[32mPASS[0m in 1.19s]
[0m09:15:30.806362 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:15:30.806362 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:15:30.821923 [info ] [Thread-1 (]: 14 of 27 START test not_null_top_5_products_total_sales ........................ [RUN]
[0m09:15:30.821923 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, now test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818)
[0m09:15:30.821923 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, idle-time=0.01556086540222168s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:15:30.821923 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:15:30.821923 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m09:15:30.821923 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:15:30.837586 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m09:15:30.853170 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m09:15:30.853170 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_sales
from `workspace`.`default`.`top_5_products`
where total_sales is null



  
  
      
    ) dbt_internal_test
[0m09:15:31.775117 [debug] [Thread-1 (]: SQL status: OK in 0.920 seconds
[0m09:15:31.775117 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, command-id=01f06ed1-37a9-140b-b3f5-2a4cc33515cf) - Closing
[0m09:15:31.775117 [info ] [Thread-1 (]: 14 of 27 PASS not_null_top_5_products_total_sales .............................. [[32mPASS[0m in 0.95s]
[0m09:15:31.775117 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:15:31.775117 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:15:31.790710 [info ] [Thread-1 (]: 15 of 27 START test not_null_top_customers_User_ID ............................. [RUN]
[0m09:15:31.790710 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, now test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0)
[0m09:15:31.790710 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, idle-time=0.015593290328979492s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:15:31.790710 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:15:31.790710 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m09:15:31.806302 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:15:31.806302 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m09:15:31.806302 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m09:15:31.806302 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`top_customers`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m09:15:32.759460 [debug] [Thread-1 (]: SQL status: OK in 0.950 seconds
[0m09:15:32.759460 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, command-id=01f06ed1-383b-1b17-87b0-78f8ec7bce78) - Closing
[0m09:15:32.759460 [info ] [Thread-1 (]: 15 of 27 PASS not_null_top_customers_User_ID ................................... [[32mPASS[0m in 0.97s]
[0m09:15:32.759460 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:15:32.759460 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:15:32.759460 [info ] [Thread-1 (]: 16 of 27 START test not_null_top_customers_total_orders ........................ [RUN]
[0m09:15:32.759460 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, now test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746)
[0m09:15:32.759460 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:15:32.775047 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:15:32.775047 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m09:15:32.775047 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:15:32.790679 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m09:15:32.790679 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m09:15:32.790679 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`top_customers`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m09:15:33.493868 [debug] [Thread-1 (]: SQL status: OK in 0.700 seconds
[0m09:15:33.509496 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, command-id=01f06ed1-38d1-1929-8473-4937553b6134) - Closing
[0m09:15:33.509496 [info ] [Thread-1 (]: 16 of 27 PASS not_null_top_customers_total_orders .............................. [[32mPASS[0m in 0.75s]
[0m09:15:33.509496 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:15:33.509496 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:15:33.525099 [info ] [Thread-1 (]: 17 of 27 START test not_null_top_customers_total_spent ......................... [RUN]
[0m09:15:33.525099 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, now test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73)
[0m09:15:33.525099 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73, idle-time=0.01560354232788086s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:15:33.525099 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:15:33.525099 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m09:15:33.540680 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:15:33.540680 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m09:15:33.540680 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m09:15:33.540680 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_spent
from `workspace`.`default`.`top_customers`
where total_spent is null



  
  
      
    ) dbt_internal_test
[0m09:15:34.571987 [debug] [Thread-1 (]: SQL status: OK in 1.030 seconds
[0m09:15:34.571987 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, command-id=01f06ed1-3944-1562-bd7e-de0c9e9977d7) - Closing
[0m09:15:34.571987 [info ] [Thread-1 (]: 17 of 27 PASS not_null_top_customers_total_spent ............................... [[32mPASS[0m in 1.05s]
[0m09:15:34.571987 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:15:34.571987 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m09:15:34.587557 [info ] [Thread-1 (]: 18 of 27 START test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m09:15:34.587557 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73, now test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931)
[0m09:15:34.587557 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931, idle-time=0.01557016372680664s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:15:34.587557 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m09:15:34.587557 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"
[0m09:15:34.603180 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m09:15:34.603180 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"
[0m09:15:34.603180 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"
[0m09:15:34.603180 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from `my_db`.`dbo`.`ecommerce`
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    'Credit Card','Net Banking','UPI','Debit Card','Cash on Delivery'
)



  
  
      
    ) dbt_internal_test
[0m09:15:35.150106 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from `my_db`.`dbo`.`ecommerce`
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    'Credit Card','Net Banking','UPI','Debit Card','Cash on Delivery'
)



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed1-39e6-1b2a-9143-1b1576aa3ce7
[0m09:15:35.306298 [debug] [Thread-1 (]: Database Error in test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_accepted_values_sqlserv_de5401a33d073d59e860da01ddb6837b.sql
[0m09:15:35.306298 [error] [Thread-1 (]: 18 of 27 ERROR source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[31mERROR[0m in 0.72s]
[0m09:15:35.306298 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m09:15:35.306298 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m09:15:35.306298 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931' to be skipped because of status 'error'.  Reason: Database Error in test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_accepted_values_sqlserv_de5401a33d073d59e860da01ddb6837b.sql.
[0m09:15:35.306298 [info ] [Thread-1 (]: 19 of 27 START test source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date  [RUN]
[0m09:15:35.306298 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931, now test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93)
[0m09:15:35.306298 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m09:15:35.306298 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m09:15:35.321931 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93"
[0m09:15:35.321931 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m09:15:35.337545 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93"
[0m09:15:35.337545 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93"
[0m09:15:35.337545 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    with actual as (
        select
            column_name,
            data_type
        from INFORMATION_SCHEMA.COLUMNS
        where TABLE_NAME = 'ecommerce'
          and TABLE_SCHEMA = 'dbo'
    ),
    expected as (
        select * from (values
            ('User_ID', 'varchar'),
            ('Product_ID', 'varchar'),
            ('Category', 'varchar'),
            ('Price', 'float'),
            ('Discount', 'int'),
            ('Final_Price', 'float'),
            ('Payment_Method', 'varchar'),
            ('Purchase_Date', 'date')
            
        ) as t(column_name, data_type)
    ),
    diff_expected as (
        select * from expected
        EXCEPT
        select * from actual
    ),
    diff_actual as (
        select * from actual
        EXCEPT
        select * from expected
    )
    select * from diff_expected
    UNION ALL
    select * from diff_actual

  
  
      
    ) dbt_internal_test
[0m09:15:37.306308 [debug] [Thread-1 (]: SQL status: OK in 1.970 seconds
[0m09:15:37.306308 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, command-id=01f06ed1-3a57-111e-8453-7b6ec2c55b6c) - Closing
[0m09:15:37.306308 [error] [Thread-1 (]: 19 of 27 FAIL 8 source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date  [[31mFAIL 8[0m in 2.00s]
[0m09:15:37.321936 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m09:15:37.321936 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m09:15:37.321936 [info ] [Thread-1 (]: 20 of 27 START test source_not_null_sqlserver_data_ecommerce_Category .......... [RUN]
[0m09:15:37.321936 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023)
[0m09:15:37.321936 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023, idle-time=0.01562786102294922s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m09:15:37.337606 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m09:15:37.353183 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"
[0m09:15:37.353183 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m09:15:37.368871 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"
[0m09:15:37.368871 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"
[0m09:15:37.368871 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `my_db`.`dbo`.`ecommerce`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:15:37.835182 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `my_db`.`dbo`.`ecommerce`
where Category is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed1-3b8c-1578-809b-221fa79a1f09
[0m09:15:37.835182 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Category (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Category.sql
[0m09:15:37.835182 [error] [Thread-1 (]: 20 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Category ............... [[31mERROR[0m in 0.51s]
[0m09:15:37.835182 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m09:15:37.850748 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Category (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Category.sql.
[0m09:15:37.835182 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m09:15:37.850748 [info ] [Thread-1 (]: 21 of 27 START test source_not_null_sqlserver_data_ecommerce_Discount .......... [RUN]
[0m09:15:37.850748 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6)
[0m09:15:37.850748 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6, idle-time=0.01556539535522461s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m09:15:37.850748 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m09:15:37.850748 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"
[0m09:15:37.866408 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m09:15:37.866408 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"
[0m09:15:37.866408 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"
[0m09:15:37.866408 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Discount
from `my_db`.`dbo`.`ecommerce`
where Discount is null



  
  
      
    ) dbt_internal_test
[0m09:15:38.225885 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Discount
from `my_db`.`dbo`.`ecommerce`
where Discount is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed1-3bd8-1e6e-8b29-e99f3a2fcdf0
[0m09:15:38.241406 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Discount (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Discount.sql
[0m09:15:38.241406 [error] [Thread-1 (]: 21 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Discount ............... [[31mERROR[0m in 0.39s]
[0m09:15:38.241406 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m09:15:38.241406 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m09:15:38.241406 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Discount (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Discount.sql.
[0m09:15:38.241406 [info ] [Thread-1 (]: 22 of 27 START test source_not_null_sqlserver_data_ecommerce_Final_Price ....... [RUN]
[0m09:15:38.241406 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823)
[0m09:15:38.257032 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m09:15:38.257032 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m09:15:38.257032 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"
[0m09:15:38.257032 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m09:15:38.272613 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"
[0m09:15:38.272613 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"
[0m09:15:38.272613 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Final_Price
from `my_db`.`dbo`.`ecommerce`
where Final_Price is null



  
  
      
    ) dbt_internal_test
[0m09:15:38.678868 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Final_Price
from `my_db`.`dbo`.`ecommerce`
where Final_Price is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed1-3c17-163e-b60e-454aa16bc772
[0m09:15:38.694496 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Final_Price (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Final_Price.sql
[0m09:15:38.694496 [error] [Thread-1 (]: 22 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Final_Price ............ [[31mERROR[0m in 0.45s]
[0m09:15:38.694496 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m09:15:38.694496 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m09:15:38.694496 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Final_Price (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Final_Price.sql.
[0m09:15:38.694496 [info ] [Thread-1 (]: 23 of 27 START test source_not_null_sqlserver_data_ecommerce_Payment_Method .... [RUN]
[0m09:15:38.694496 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32)
[0m09:15:38.710130 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32, idle-time=0.015633106231689453s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m09:15:38.710130 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m09:15:38.710130 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"
[0m09:15:38.725743 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m09:15:38.725743 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"
[0m09:15:38.725743 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"
[0m09:15:38.725743 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `my_db`.`dbo`.`ecommerce`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m09:15:39.257042 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `my_db`.`dbo`.`ecommerce`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed1-3c5d-11fb-a4ad-c6f27025e8c5
[0m09:15:39.272623 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Payment_Method (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Payment_Method.sql
[0m09:15:39.272623 [error] [Thread-1 (]: 23 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Payment_Method ......... [[31mERROR[0m in 0.58s]
[0m09:15:39.272623 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m09:15:39.288253 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m09:15:39.288253 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Payment_Method (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Payment_Method.sql.
[0m09:15:39.288253 [info ] [Thread-1 (]: 24 of 27 START test source_not_null_sqlserver_data_ecommerce_Price ............. [RUN]
[0m09:15:39.288253 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a)
[0m09:15:39.288253 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a, idle-time=0.01562976837158203s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m09:15:39.288253 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m09:15:39.303904 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"
[0m09:15:39.303904 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m09:15:39.303904 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"
[0m09:15:39.319494 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"
[0m09:15:39.319494 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Price
from `my_db`.`dbo`.`ecommerce`
where Price is null



  
  
      
    ) dbt_internal_test
[0m09:15:39.725815 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Price
from `my_db`.`dbo`.`ecommerce`
where Price is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed1-3cb5-108e-a26c-7c8ac04945d5
[0m09:15:39.741434 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Price (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Price.sql
[0m09:15:39.741434 [error] [Thread-1 (]: 24 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Price .................. [[31mERROR[0m in 0.45s]
[0m09:15:39.756994 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m09:15:39.756994 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m09:15:39.756994 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Price (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Price.sql.
[0m09:15:39.756994 [info ] [Thread-1 (]: 25 of 27 START test source_not_null_sqlserver_data_ecommerce_Product_ID ........ [RUN]
[0m09:15:39.756994 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd)
[0m09:15:39.756994 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd, idle-time=0.015559911727905273s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m09:15:39.756994 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m09:15:39.772615 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"
[0m09:15:39.772615 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m09:15:39.788279 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"
[0m09:15:39.788279 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"
[0m09:15:39.788279 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Product_ID
from `my_db`.`dbo`.`ecommerce`
where Product_ID is null



  
  
      
    ) dbt_internal_test
[0m09:15:40.147691 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Product_ID
from `my_db`.`dbo`.`ecommerce`
where Product_ID is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed1-3cfd-1876-9362-e0d6104555d1
[0m09:15:40.163281 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Product_ID.sql
[0m09:15:40.163281 [error] [Thread-1 (]: 25 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Product_ID ............. [[31mERROR[0m in 0.41s]
[0m09:15:40.163281 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m09:15:40.163281 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m09:15:40.163281 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Product_ID.sql.
[0m09:15:40.163281 [info ] [Thread-1 (]: 26 of 27 START test source_not_null_sqlserver_data_ecommerce_Purchase_Date ..... [RUN]
[0m09:15:40.178867 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23)
[0m09:15:40.178867 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23, idle-time=0.015586137771606445s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m09:15:40.178867 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m09:15:40.194494 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"
[0m09:15:40.194494 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m09:15:40.210116 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"
[0m09:15:40.210116 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"
[0m09:15:40.225741 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Purchase_Date
from `my_db`.`dbo`.`ecommerce`
where Purchase_Date is null



  
  
      
    ) dbt_internal_test
[0m09:15:40.585120 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Purchase_Date
from `my_db`.`dbo`.`ecommerce`
where Purchase_Date is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed1-3d3f-124e-b282-d37a37fa4f9c
[0m09:15:40.600741 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Purchase_Date (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Purchase_Date.sql
[0m09:15:40.600741 [error] [Thread-1 (]: 26 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Purchase_Date .......... [[31mERROR[0m in 0.42s]
[0m09:15:40.600741 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m09:15:40.600741 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m09:15:40.616364 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Purchase_Date (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Purchase_Date.sql.
[0m09:15:40.616364 [info ] [Thread-1 (]: 27 of 27 START test source_not_null_sqlserver_data_ecommerce_User_ID ........... [RUN]
[0m09:15:40.616364 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325)
[0m09:15:40.616364 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325, idle-time=0.015623331069946289s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m09:15:40.616364 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m09:15:40.631990 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"
[0m09:15:40.631990 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m09:15:40.647625 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"
[0m09:15:40.647625 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"
[0m09:15:40.647625 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `my_db`.`dbo`.`ecommerce`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m09:15:41.053871 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `my_db`.`dbo`.`ecommerce`
where User_ID is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed1-3d80-1f23-ba07-af4d5f41ab20
[0m09:15:41.069554 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_User_ID.sql
[0m09:15:41.069554 [error] [Thread-1 (]: 27 of 27 ERROR source_not_null_sqlserver_data_ecommerce_User_ID ................ [[31mERROR[0m in 0.45s]
[0m09:15:41.069554 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m09:15:41.069554 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_User_ID.sql.
[0m09:15:41.069554 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=31.044500827789307s, language=None, compute-name=) - Reusing connection previously named master
[0m09:15:41.085122 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:15:41.085122 [debug] [MainThread]: Connection 'list_workspace_default' was properly closed.
[0m09:15:41.085122 [debug] [MainThread]: On list_workspace_default: Close
[0m09:15:41.085122 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f06ed1-1edc-1518-9304-afdee1fba535) - Closing
[0m09:15:41.303926 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325' was properly closed.
[0m09:15:41.303926 [debug] [MainThread]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325: Close
[0m09:15:41.303926 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f06ed1-2ba3-1e1e-99e3-4e4c0642c887) - Closing
[0m09:15:41.522701 [info ] [MainThread]: 
[0m09:15:41.538275 [info ] [MainThread]: Finished running 27 data tests in 0 hours 0 minutes and 53.26 seconds (53.26s).
[0m09:15:41.553926 [debug] [MainThread]: Command end result
[0m09:15:41.631989 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m09:15:41.631989 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m09:15:41.647617 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m09:15:41.647617 [info ] [MainThread]: 
[0m09:15:41.647617 [info ] [MainThread]: [31mCompleted with 10 errors, 0 partial successes, and 0 warnings:[0m
[0m09:15:41.663262 [info ] [MainThread]: 
[0m09:15:41.663262 [error] [MainThread]: [31mFailure in test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:15:41.663262 [error] [MainThread]:   Database Error in test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_accepted_values_sqlserv_de5401a33d073d59e860da01ddb6837b.sql
[0m09:15:41.663262 [info ] [MainThread]: 
[0m09:15:41.663262 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_accepted_values_sqlserv_de5401a33d073d59e860da01ddb6837b.sql
[0m09:15:41.663262 [info ] [MainThread]: 
[0m09:15:41.678904 [error] [MainThread]: [31mFailure in test source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:15:41.678904 [error] [MainThread]:   Got 8 results, configured to fail if != 0
[0m09:15:41.678904 [info ] [MainThread]: 
[0m09:15:41.678904 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_assert_schema_matches_s_a76a1d3a3c37dcddf2ac3a6e53d8459a.sql
[0m09:15:41.678904 [info ] [MainThread]: 
[0m09:15:41.678904 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Category (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:15:41.678904 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Category (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Category.sql
[0m09:15:41.694490 [info ] [MainThread]: 
[0m09:15:41.694490 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Category.sql
[0m09:15:41.694490 [info ] [MainThread]: 
[0m09:15:41.694490 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Discount (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:15:41.694490 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Discount (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Discount.sql
[0m09:15:41.694490 [info ] [MainThread]: 
[0m09:15:41.710114 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Discount.sql
[0m09:15:41.710114 [info ] [MainThread]: 
[0m09:15:41.710114 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Final_Price (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:15:41.710114 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Final_Price (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Final_Price.sql
[0m09:15:41.710114 [info ] [MainThread]: 
[0m09:15:41.710114 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Final_Price.sql
[0m09:15:41.725739 [info ] [MainThread]: 
[0m09:15:41.725739 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Payment_Method (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:15:41.725739 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Payment_Method (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Payment_Method.sql
[0m09:15:41.725739 [info ] [MainThread]: 
[0m09:15:41.725739 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Payment_Method.sql
[0m09:15:41.725739 [info ] [MainThread]: 
[0m09:15:41.725739 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Price (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:15:41.741365 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Price (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Price.sql
[0m09:15:41.741365 [info ] [MainThread]: 
[0m09:15:41.741365 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Price.sql
[0m09:15:41.741365 [info ] [MainThread]: 
[0m09:15:41.741365 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:15:41.756988 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Product_ID.sql
[0m09:15:41.756988 [info ] [MainThread]: 
[0m09:15:41.756988 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Product_ID.sql
[0m09:15:41.756988 [info ] [MainThread]: 
[0m09:15:41.756988 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Purchase_Date (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:15:41.756988 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Purchase_Date (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Purchase_Date.sql
[0m09:15:41.772654 [info ] [MainThread]: 
[0m09:15:41.772654 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Purchase_Date.sql
[0m09:15:41.772654 [info ] [MainThread]: 
[0m09:15:41.772654 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:15:41.772654 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_User_ID.sql
[0m09:15:41.788298 [info ] [MainThread]: 
[0m09:15:41.788298 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_User_ID.sql
[0m09:15:41.788298 [info ] [MainThread]: 
[0m09:15:41.788298 [info ] [MainThread]: Done. PASS=17 WARN=0 ERROR=10 SKIP=0 NO-OP=0 TOTAL=27
[0m09:15:41.788298 [debug] [MainThread]: Command `dbt test` failed at 09:15:41.788298 after 69.24 seconds
[0m09:15:41.788298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E64356E10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E643570D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024E70687610>]}
[0m09:15:41.803907 [debug] [MainThread]: Flushing usage events
[0m09:15:42.491446 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:18:48.415377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBA48C4850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBA48E6FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBA48E6950>]}


============================== 09:18:48.415377 | ba9fa600-f4e2-4997-9456-25c58fccaf99 ==============================
[0m09:18:48.415377 [info ] [MainThread]: Running with dbt=1.10.3
[0m09:18:48.431000 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt test --target databricks', 'send_anonymous_usage_stats': 'True'}
[0m09:18:50.305996 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m09:18:50.305996 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m09:18:50.305996 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m09:18:52.102912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ba9fa600-f4e2-4997-9456-25c58fccaf99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBA489AE50>]}
[0m09:18:52.243505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ba9fa600-f4e2-4997-9456-25c58fccaf99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBA4009B90>]}
[0m09:18:52.259125 [info ] [MainThread]: Registered adapter: databricks=1.10.4
[0m09:18:53.352876 [debug] [MainThread]: checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, vars: {}, profile: , target: databricks, version: 1.10.3
[0m09:18:53.540375 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m09:18:53.556000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ba9fa600-f4e2-4997-9456-25c58fccaf99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBA3FA0110>]}
[0m09:18:57.259123 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_databricks_cicd.raw.sqlserver
- models.dbt_databricks_cicd.staging.sqlserver
[0m09:18:57.290380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ba9fa600-f4e2-4997-9456-25c58fccaf99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBB11CF850>]}
[0m09:18:57.462248 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m09:18:57.462248 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m09:18:57.540371 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ba9fa600-f4e2-4997-9456-25c58fccaf99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBB14EFF10>]}
[0m09:18:57.540371 [info ] [MainThread]: Found 9 models, 27 data tests, 1 source, 682 macros
[0m09:18:57.556000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ba9fa600-f4e2-4997-9456-25c58fccaf99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBB1207E90>]}
[0m09:18:57.556000 [info ] [MainThread]: 
[0m09:18:57.556000 [info ] [MainThread]: Concurrency: 1 threads (target='databricks')
[0m09:18:57.556000 [info ] [MainThread]: 
[0m09:18:57.571629 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=0s, language=None, compute-name=) - Creating connection
[0m09:18:57.571629 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m09:18:57.587295 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace_default, idle-time=0s, language=None, compute-name=) - Creating connection
[0m09:18:57.587295 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace_default'
[0m09:18:57.602899 [debug] [ThreadPool]: Using databricks connection "list_workspace_default"
[0m09:18:57.602899 [debug] [ThreadPool]: On list_workspace_default: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "connection_name": "list_workspace_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'workspace' 
  AND table_schema = 'default'

  
[0m09:18:57.602899 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:18:58.384131 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f06ed1-b33d-1e80-a952-dcc52fafbee1) - Created
[0m09:18:59.134191 [debug] [ThreadPool]: SQL status: OK in 1.530 seconds
[0m09:18:59.134191 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f06ed1-b33d-1e80-a952-dcc52fafbee1, command-id=01f06ed1-b361-1030-bcc3-82c29e8d1af6) - Closing
[0m09:18:59.149750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ba9fa600-f4e2-4997-9456-25c58fccaf99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBB1199610>]}
[0m09:18:59.149750 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:18:59.149750 [info ] [Thread-1 (]: 1 of 27 START test not_null_avg_discount_by_category_Category .................. [RUN]
[0m09:18:59.165373 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, idle-time=0s, language=None, compute-name=) - Creating connection
[0m09:18:59.165373 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b'
[0m09:18:59.165373 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:18:59.212247 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m09:18:59.212247 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:18:59.243504 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m09:18:59.259134 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m09:18:59.259134 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_discount_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:18:59.259134 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m09:18:59.993569 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e) - Created
[0m09:19:01.321637 [debug] [Thread-1 (]: SQL status: OK in 2.060 seconds
[0m09:19:01.337266 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, command-id=01f06ed1-b452-155a-931c-8a16a7173d59) - Closing
[0m09:19:01.352885 [info ] [Thread-1 (]: 1 of 27 PASS not_null_avg_discount_by_category_Category ........................ [[32mPASS[0m in 2.19s]
[0m09:19:01.352885 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:19:01.352885 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:19:01.352885 [info ] [Thread-1 (]: 2 of 27 START test not_null_avg_discount_by_category_avg_discount_percent ...... [RUN]
[0m09:19:01.352885 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101)
[0m09:19:01.352885 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:19:01.352885 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:19:01.368537 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m09:19:01.368537 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:19:01.384170 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m09:19:01.384170 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m09:19:01.384170 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_discount_percent
from `workspace`.`default`.`avg_discount_by_category`
where avg_discount_percent is null



  
  
      
    ) dbt_internal_test
[0m09:19:01.806037 [debug] [Thread-1 (]: SQL status: OK in 0.420 seconds
[0m09:19:01.806037 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, command-id=01f06ed1-b526-145d-9cc3-773c423dfc04) - Closing
[0m09:19:01.806037 [info ] [Thread-1 (]: 2 of 27 PASS not_null_avg_discount_by_category_avg_discount_percent ............ [[32mPASS[0m in 0.45s]
[0m09:19:01.806037 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:19:01.806037 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:19:01.806037 [info ] [Thread-1 (]: 3 of 27 START test not_null_avg_ticket_by_category_Category .................... [RUN]
[0m09:19:01.821621 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f)
[0m09:19:01.821621 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, idle-time=0.01558375358581543s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:19:01.821621 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:19:01.821621 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m09:19:01.821621 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:19:01.837248 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m09:19:01.837248 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m09:19:01.837248 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_ticket_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:19:02.274765 [debug] [Thread-1 (]: SQL status: OK in 0.440 seconds
[0m09:19:02.290439 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, command-id=01f06ed1-b56c-153f-9956-7bbfdbf7ee1f) - Closing
[0m09:19:02.290439 [info ] [Thread-1 (]: 3 of 27 PASS not_null_avg_ticket_by_category_Category .......................... [[32mPASS[0m in 0.47s]
[0m09:19:02.290439 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:19:02.290439 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:19:02.306021 [info ] [Thread-1 (]: 4 of 27 START test not_null_avg_ticket_by_category_avg_ticket .................. [RUN]
[0m09:19:02.306021 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41)
[0m09:19:02.306021 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, idle-time=0.015581846237182617s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:19:02.306021 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:19:02.321667 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m09:19:02.321667 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:19:02.321667 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m09:19:02.337248 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m09:19:02.337248 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_ticket
from `workspace`.`default`.`avg_ticket_by_category`
where avg_ticket is null



  
  
      
    ) dbt_internal_test
[0m09:19:02.790461 [debug] [Thread-1 (]: SQL status: OK in 0.450 seconds
[0m09:19:02.806008 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, command-id=01f06ed1-b5b6-1ac3-aa41-296ad1f07870) - Closing
[0m09:19:02.806008 [info ] [Thread-1 (]: 4 of 27 PASS not_null_avg_ticket_by_category_avg_ticket ........................ [[32mPASS[0m in 0.50s]
[0m09:19:02.806008 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:19:02.806008 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:19:02.806008 [info ] [Thread-1 (]: 5 of 27 START test not_null_monthly_revenue_month .............................. [RUN]
[0m09:19:02.806008 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, now test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b)
[0m09:19:02.806008 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:19:02.821621 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:19:02.821621 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m09:19:02.821621 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:19:02.837323 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m09:19:02.837323 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m09:19:02.837323 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select month
from `workspace`.`default`.`monthly_revenue`
where month is null



  
  
      
    ) dbt_internal_test
[0m09:19:03.212251 [debug] [Thread-1 (]: SQL status: OK in 0.370 seconds
[0m09:19:03.227872 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, command-id=01f06ed1-b604-1747-9538-9d1d6858f3c1) - Closing
[0m09:19:03.227872 [info ] [Thread-1 (]: 5 of 27 PASS not_null_monthly_revenue_month .................................... [[32mPASS[0m in 0.42s]
[0m09:19:03.227872 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:19:03.227872 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:19:03.243498 [info ] [Thread-1 (]: 6 of 27 START test not_null_monthly_revenue_monthly_revenue .................... [RUN]
[0m09:19:03.243498 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, now test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b)
[0m09:19:03.243498 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, idle-time=0.015625715255737305s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:19:03.243498 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:19:03.259134 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m09:19:03.259134 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:19:03.259134 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m09:19:03.259134 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m09:19:03.274768 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select monthly_revenue
from `workspace`.`default`.`monthly_revenue`
where monthly_revenue is null



  
  
      
    ) dbt_internal_test
[0m09:19:03.696626 [debug] [Thread-1 (]: SQL status: OK in 0.420 seconds
[0m09:19:03.712249 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, command-id=01f06ed1-b645-1511-b555-ad79e272236c) - Closing
[0m09:19:03.712249 [info ] [Thread-1 (]: 6 of 27 PASS not_null_monthly_revenue_monthly_revenue .......................... [[32mPASS[0m in 0.47s]
[0m09:19:03.712249 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:19:03.712249 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:19:03.727880 [info ] [Thread-1 (]: 7 of 27 START test not_null_payment_distribution_Payment_Method ................ [RUN]
[0m09:19:03.727880 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, now test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae)
[0m09:19:03.727880 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, idle-time=0.015631437301635742s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:19:03.727880 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:19:03.743512 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m09:19:03.759128 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:19:03.759128 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m09:19:03.774754 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m09:19:03.774754 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`payment_distribution`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m09:19:04.149772 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m09:19:04.149772 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, command-id=01f06ed1-b693-18ab-abe5-ca3caaf5f7f4) - Closing
[0m09:19:04.149772 [info ] [Thread-1 (]: 7 of 27 PASS not_null_payment_distribution_Payment_Method ...................... [[32mPASS[0m in 0.42s]
[0m09:19:04.165379 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:19:04.165379 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:19:04.165379 [info ] [Thread-1 (]: 8 of 27 START test not_null_payment_distribution_total_transactions ............ [RUN]
[0m09:19:04.181061 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, now test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8)
[0m09:19:04.181061 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, idle-time=0.03128862380981445s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:19:04.181061 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:19:04.212251 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m09:19:04.212251 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:19:04.227874 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m09:19:04.227874 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m09:19:04.227874 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_transactions
from `workspace`.`default`.`payment_distribution`
where total_transactions is null



  
  
      
    ) dbt_internal_test
[0m09:19:04.649772 [debug] [Thread-1 (]: SQL status: OK in 0.420 seconds
[0m09:19:04.649772 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, command-id=01f06ed1-b6d9-13a3-bf52-b72120133b9d) - Closing
[0m09:19:04.649772 [info ] [Thread-1 (]: 8 of 27 PASS not_null_payment_distribution_total_transactions .................. [[32mPASS[0m in 0.48s]
[0m09:19:04.649772 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:19:04.665373 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:19:04.665373 [info ] [Thread-1 (]: 9 of 27 START test not_null_payment_distribution_total_value ................... [RUN]
[0m09:19:04.665373 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, now test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03)
[0m09:19:04.665373 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, idle-time=0.015600919723510742s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:19:04.665373 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:19:04.680998 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m09:19:04.680998 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:19:04.696685 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m09:19:04.696685 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m09:19:04.696685 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_value
from `workspace`.`default`.`payment_distribution`
where total_value is null



  
  
      
    ) dbt_internal_test
[0m09:19:05.071709 [debug] [Thread-1 (]: SQL status: OK in 0.380 seconds
[0m09:19:05.071709 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, command-id=01f06ed1-b71f-142e-aa14-68d77085d3b7) - Closing
[0m09:19:05.087255 [info ] [Thread-1 (]: 9 of 27 PASS not_null_payment_distribution_total_value ......................... [[32mPASS[0m in 0.41s]
[0m09:19:05.087255 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:19:05.087255 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:19:05.087255 [info ] [Thread-1 (]: 10 of 27 START test not_null_sales_by_category_Category ........................ [RUN]
[0m09:19:05.087255 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, now test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507)
[0m09:19:05.087255 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, idle-time=0.015546321868896484s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:19:05.087255 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:19:05.102873 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m09:19:05.102873 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:19:05.118542 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m09:19:05.118542 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m09:19:05.118542 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`sales_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:19:05.509165 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m09:19:05.524811 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, command-id=01f06ed1-b760-155b-ab9f-59646509300f) - Closing
[0m09:19:05.524811 [info ] [Thread-1 (]: 10 of 27 PASS not_null_sales_by_category_Category .............................. [[32mPASS[0m in 0.44s]
[0m09:19:05.524811 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:19:05.540412 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:19:05.540412 [info ] [Thread-1 (]: 11 of 27 START test not_null_sales_by_category_total_orders .................... [RUN]
[0m09:19:05.540412 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, now test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e)
[0m09:19:05.540412 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, idle-time=0.015601158142089844s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:19:05.540412 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:19:05.556044 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m09:19:05.571623 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:19:05.571623 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m09:19:05.571623 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m09:19:05.571623 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`sales_by_category`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m09:19:05.962269 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m09:19:05.962269 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, command-id=01f06ed1-b7a5-1663-8b31-7733ceee8ce1) - Closing
[0m09:19:05.962269 [info ] [Thread-1 (]: 11 of 27 PASS not_null_sales_by_category_total_orders .......................... [[32mPASS[0m in 0.42s]
[0m09:19:05.977883 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:19:05.977883 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:19:05.977883 [info ] [Thread-1 (]: 12 of 27 START test not_null_sales_by_category_total_revenue ................... [RUN]
[0m09:19:05.977883 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, now test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd)
[0m09:19:05.977883 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, idle-time=0.015614032745361328s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:19:05.977883 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:19:05.993502 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m09:19:05.993502 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:19:05.993502 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m09:19:06.009171 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m09:19:06.009171 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_revenue
from `workspace`.`default`.`sales_by_category`
where total_revenue is null



  
  
      
    ) dbt_internal_test
[0m09:19:06.634197 [debug] [Thread-1 (]: SQL status: OK in 0.630 seconds
[0m09:19:06.649749 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, command-id=01f06ed1-b7e7-1e6c-aef9-7196818cfb22) - Closing
[0m09:19:06.649749 [info ] [Thread-1 (]: 12 of 27 PASS not_null_sales_by_category_total_revenue ......................... [[32mPASS[0m in 0.67s]
[0m09:19:06.649749 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:19:06.649749 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:19:06.649749 [info ] [Thread-1 (]: 13 of 27 START test not_null_top_5_products_product_id ......................... [RUN]
[0m09:19:06.649749 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, now test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe)
[0m09:19:06.665380 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, idle-time=0.015630245208740234s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:19:06.665380 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:19:06.665380 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m09:19:06.665380 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:19:06.681041 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m09:19:06.681041 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m09:19:06.681041 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select product_id
from `workspace`.`default`.`top_5_products`
where product_id is null



  
  
      
    ) dbt_internal_test
[0m09:19:07.071629 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m09:19:07.071629 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, command-id=01f06ed1-b84f-1419-abe7-9f44fbf97f47) - Closing
[0m09:19:07.071629 [info ] [Thread-1 (]: 13 of 27 PASS not_null_top_5_products_product_id ............................... [[32mPASS[0m in 0.42s]
[0m09:19:07.071629 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:19:07.071629 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:19:07.071629 [info ] [Thread-1 (]: 14 of 27 START test not_null_top_5_products_total_sales ........................ [RUN]
[0m09:19:07.071629 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, now test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818)
[0m09:19:07.087249 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, idle-time=0.015620231628417969s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:19:07.087249 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:19:07.087249 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m09:19:07.102913 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:19:07.102913 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m09:19:07.102913 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m09:19:07.102913 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_sales
from `workspace`.`default`.`top_5_products`
where total_sales is null



  
  
      
    ) dbt_internal_test
[0m09:19:07.509198 [debug] [Thread-1 (]: SQL status: OK in 0.410 seconds
[0m09:19:07.524748 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, command-id=01f06ed1-b88f-1c3b-86cd-24e9515426e6) - Closing
[0m09:19:07.524748 [info ] [Thread-1 (]: 14 of 27 PASS not_null_top_5_products_total_sales .............................. [[32mPASS[0m in 0.45s]
[0m09:19:07.524748 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:19:07.524748 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:19:07.524748 [info ] [Thread-1 (]: 15 of 27 START test not_null_top_customers_User_ID ............................. [RUN]
[0m09:19:07.524748 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, now test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0)
[0m09:19:07.524748 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:19:07.540414 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:19:07.540414 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m09:19:07.540414 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:19:07.556043 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m09:19:07.556043 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m09:19:07.556043 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`top_customers`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m09:19:07.946689 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m09:19:07.946689 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, command-id=01f06ed1-b8d4-1a7b-9d4b-407ca20a413e) - Closing
[0m09:19:07.946689 [info ] [Thread-1 (]: 15 of 27 PASS not_null_top_customers_User_ID ................................... [[32mPASS[0m in 0.42s]
[0m09:19:07.962250 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:19:07.962250 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:19:07.962250 [info ] [Thread-1 (]: 16 of 27 START test not_null_top_customers_total_orders ........................ [RUN]
[0m09:19:07.962250 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, now test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746)
[0m09:19:07.962250 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, idle-time=0.015561103820800781s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:19:07.962250 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:19:07.977915 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m09:19:07.977915 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:19:07.977915 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m09:19:07.993549 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m09:19:07.993549 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`top_customers`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m09:19:08.352948 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m09:19:08.368523 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, command-id=01f06ed1-b916-11f2-9aba-dff706efb7c6) - Closing
[0m09:19:08.368523 [info ] [Thread-1 (]: 16 of 27 PASS not_null_top_customers_total_orders .............................. [[32mPASS[0m in 0.41s]
[0m09:19:08.384135 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:19:08.384135 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:19:08.384135 [info ] [Thread-1 (]: 17 of 27 START test not_null_top_customers_total_spent ......................... [RUN]
[0m09:19:08.384135 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, now test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73)
[0m09:19:08.399776 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73, idle-time=0.03125286102294922s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:19:08.399776 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:19:08.415434 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m09:19:08.415434 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:19:08.415434 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m09:19:08.430996 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m09:19:08.430996 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_spent
from `workspace`.`default`.`top_customers`
where total_spent is null



  
  
      
    ) dbt_internal_test
[0m09:19:08.821726 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m09:19:08.837270 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, command-id=01f06ed1-b959-1f09-b4c2-c8efadf42c7c) - Closing
[0m09:19:08.837270 [info ] [Thread-1 (]: 17 of 27 PASS not_null_top_customers_total_spent ............................... [[32mPASS[0m in 0.45s]
[0m09:19:08.852878 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:19:08.852878 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m09:19:08.852878 [info ] [Thread-1 (]: 18 of 27 START test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m09:19:08.852878 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73, now test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931)
[0m09:19:08.852878 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931, idle-time=0.01560831069946289s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:19:08.852878 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m09:19:08.868505 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"
[0m09:19:08.868505 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m09:19:08.884170 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"
[0m09:19:08.884170 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"
[0m09:19:08.884170 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from `my_db`.`dbo`.`ecommerce`
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    'Credit Card','Net Banking','UPI','Debit Card','Cash on Delivery'
)



  
  
      
    ) dbt_internal_test
[0m09:19:09.243541 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from `my_db`.`dbo`.`ecommerce`
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    'Credit Card','Net Banking','UPI','Debit Card','Cash on Delivery'
)



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed1-b99f-172f-b880-e068afafd314
[0m09:19:09.259145 [debug] [Thread-1 (]: Database Error in test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_accepted_values_sqlserv_de5401a33d073d59e860da01ddb6837b.sql
[0m09:19:09.259145 [error] [Thread-1 (]: 18 of 27 ERROR source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[31mERROR[0m in 0.41s]
[0m09:19:09.274747 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m09:19:09.274747 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m09:19:09.274747 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931' to be skipped because of status 'error'.  Reason: Database Error in test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_accepted_values_sqlserv_de5401a33d073d59e860da01ddb6837b.sql.
[0m09:19:09.274747 [info ] [Thread-1 (]: 19 of 27 START test source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date  [RUN]
[0m09:19:09.274747 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931, now test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93)
[0m09:19:09.274747 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93, idle-time=0.01560211181640625s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m09:19:09.274747 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m09:19:09.290415 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93"
[0m09:19:09.290415 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m09:19:09.290415 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93"
[0m09:19:09.306000 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93"
[0m09:19:09.306000 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    with actual as (
        select
            column_name,
            data_type
        from INFORMATION_SCHEMA.COLUMNS
        where TABLE_NAME = 'ecommerce'
          and TABLE_SCHEMA = 'dbo'
    ),
    expected as (
        select * from (values
            ('User_ID', 'varchar'),
            ('Product_ID', 'varchar'),
            ('Category', 'varchar'),
            ('Price', 'float'),
            ('Discount', 'int'),
            ('Final_Price', 'float'),
            ('Payment_Method', 'varchar'),
            ('Purchase_Date', 'date')
            
        ) as t(column_name, data_type)
    ),
    diff_expected as (
        select * from expected
        EXCEPT
        select * from actual
    ),
    diff_actual as (
        select * from actual
        EXCEPT
        select * from expected
    )
    select * from diff_expected
    UNION ALL
    select * from diff_actual

  
  
      
    ) dbt_internal_test
[0m09:19:10.337327 [debug] [Thread-1 (]: SQL status: OK in 1.030 seconds
[0m09:19:10.352934 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, command-id=01f06ed1-b9de-1812-8b8b-7add540d1dcd) - Closing
[0m09:19:10.352934 [error] [Thread-1 (]: 19 of 27 FAIL 8 source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date  [[31mFAIL 8[0m in 1.08s]
[0m09:19:10.352934 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m09:19:10.352934 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m09:19:10.352934 [info ] [Thread-1 (]: 20 of 27 START test source_not_null_sqlserver_data_ecommerce_Category .......... [RUN]
[0m09:19:10.368508 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023)
[0m09:19:10.368508 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023, idle-time=0.015574932098388672s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m09:19:10.368508 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m09:19:10.368508 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"
[0m09:19:10.384122 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m09:19:10.384122 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"
[0m09:19:10.384122 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"
[0m09:19:10.384122 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `my_db`.`dbo`.`ecommerce`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:19:10.743572 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `my_db`.`dbo`.`ecommerce`
where Category is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed1-ba84-1687-b6c6-f1bdd9067688
[0m09:19:10.743572 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Category (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Category.sql
[0m09:19:10.759129 [error] [Thread-1 (]: 20 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Category ............... [[31mERROR[0m in 0.38s]
[0m09:19:10.759129 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m09:19:10.759129 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m09:19:10.759129 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Category (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Category.sql.
[0m09:19:10.759129 [info ] [Thread-1 (]: 21 of 27 START test source_not_null_sqlserver_data_ecommerce_Discount .......... [RUN]
[0m09:19:10.759129 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6)
[0m09:19:10.759129 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6, idle-time=0.015557050704956055s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m09:19:10.759129 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m09:19:10.774748 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"
[0m09:19:10.774748 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m09:19:10.790441 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"
[0m09:19:10.790441 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"
[0m09:19:10.790441 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Discount
from `my_db`.`dbo`.`ecommerce`
where Discount is null



  
  
      
    ) dbt_internal_test
[0m09:19:11.134186 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Discount
from `my_db`.`dbo`.`ecommerce`
where Discount is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed1-bac1-11d6-95ab-f63a27c5ec84
[0m09:19:11.149774 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Discount (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Discount.sql
[0m09:19:11.149774 [error] [Thread-1 (]: 21 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Discount ............... [[31mERROR[0m in 0.39s]
[0m09:19:11.149774 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m09:19:11.165386 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m09:19:11.165386 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Discount (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Discount.sql.
[0m09:19:11.165386 [info ] [Thread-1 (]: 22 of 27 START test source_not_null_sqlserver_data_ecommerce_Final_Price ....... [RUN]
[0m09:19:11.165386 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823)
[0m09:19:11.165386 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823, idle-time=0.015611886978149414s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m09:19:11.165386 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m09:19:11.181041 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"
[0m09:19:11.181041 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m09:19:11.196622 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"
[0m09:19:11.196622 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"
[0m09:19:11.196622 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Final_Price
from `my_db`.`dbo`.`ecommerce`
where Final_Price is null



  
  
      
    ) dbt_internal_test
[0m09:19:11.556074 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Final_Price
from `my_db`.`dbo`.`ecommerce`
where Final_Price is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed1-bb00-153d-8f9d-0b99e52b757a
[0m09:19:11.556074 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Final_Price (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Final_Price.sql
[0m09:19:11.571629 [error] [Thread-1 (]: 22 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Final_Price ............ [[31mERROR[0m in 0.39s]
[0m09:19:11.571629 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m09:19:11.571629 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m09:19:11.571629 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Final_Price (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Final_Price.sql.
[0m09:19:11.571629 [info ] [Thread-1 (]: 23 of 27 START test source_not_null_sqlserver_data_ecommerce_Payment_Method .... [RUN]
[0m09:19:11.571629 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32)
[0m09:19:11.571629 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32, idle-time=0.015554428100585938s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m09:19:11.571629 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m09:19:11.587249 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"
[0m09:19:11.587249 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m09:19:11.602918 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"
[0m09:19:11.602918 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"
[0m09:19:11.602918 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `my_db`.`dbo`.`ecommerce`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m09:19:12.056018 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `my_db`.`dbo`.`ecommerce`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed1-bb3e-14dd-b214-351b04eebb63
[0m09:19:12.071642 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Payment_Method (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Payment_Method.sql
[0m09:19:12.071642 [error] [Thread-1 (]: 23 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Payment_Method ......... [[31mERROR[0m in 0.50s]
[0m09:19:12.071642 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m09:19:12.071642 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m09:19:12.071642 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Payment_Method (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Payment_Method.sql.
[0m09:19:12.087255 [info ] [Thread-1 (]: 24 of 27 START test source_not_null_sqlserver_data_ecommerce_Price ............. [RUN]
[0m09:19:12.087255 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a)
[0m09:19:12.087255 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a, idle-time=0.015612602233886719s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m09:19:12.087255 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m09:19:12.087255 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"
[0m09:19:12.102888 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m09:19:12.102888 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"
[0m09:19:12.102888 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"
[0m09:19:12.102888 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Price
from `my_db`.`dbo`.`ecommerce`
where Price is null



  
  
      
    ) dbt_internal_test
[0m09:19:12.446696 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Price
from `my_db`.`dbo`.`ecommerce`
where Price is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed1-bb8a-1e90-bdf2-6e81bc2fb894
[0m09:19:12.462273 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Price (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Price.sql
[0m09:19:12.462273 [error] [Thread-1 (]: 24 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Price .................. [[31mERROR[0m in 0.38s]
[0m09:19:12.477876 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m09:19:12.477876 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m09:19:12.477876 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Price (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Price.sql.
[0m09:19:12.477876 [info ] [Thread-1 (]: 25 of 27 START test source_not_null_sqlserver_data_ecommerce_Product_ID ........ [RUN]
[0m09:19:12.477876 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd)
[0m09:19:12.477876 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd, idle-time=0.015602350234985352s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m09:19:12.477876 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m09:19:12.493503 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"
[0m09:19:12.493503 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m09:19:12.509163 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"
[0m09:19:12.509163 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"
[0m09:19:12.509163 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Product_ID
from `my_db`.`dbo`.`ecommerce`
where Product_ID is null



  
  
      
    ) dbt_internal_test
[0m09:19:12.852879 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Product_ID
from `my_db`.`dbo`.`ecommerce`
where Product_ID is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed1-bbc7-1211-8645-852b02fcbc15
[0m09:19:12.868519 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Product_ID.sql
[0m09:19:12.868519 [error] [Thread-1 (]: 25 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Product_ID ............. [[31mERROR[0m in 0.39s]
[0m09:19:12.868519 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m09:19:12.868519 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m09:19:12.868519 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Product_ID.sql.
[0m09:19:12.884160 [info ] [Thread-1 (]: 26 of 27 START test source_not_null_sqlserver_data_ecommerce_Purchase_Date ..... [RUN]
[0m09:19:12.884160 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23)
[0m09:19:12.884160 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23, idle-time=0.015641212463378906s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m09:19:12.884160 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m09:19:12.884160 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"
[0m09:19:12.899760 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m09:19:12.899760 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"
[0m09:19:12.899760 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"
[0m09:19:12.899760 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Purchase_Date
from `my_db`.`dbo`.`ecommerce`
where Purchase_Date is null



  
  
      
    ) dbt_internal_test
[0m09:19:13.259221 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Purchase_Date
from `my_db`.`dbo`.`ecommerce`
where Purchase_Date is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed1-bc04-1e70-b700-d7323002b018
[0m09:19:13.274775 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Purchase_Date (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Purchase_Date.sql
[0m09:19:13.274775 [error] [Thread-1 (]: 26 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Purchase_Date .......... [[31mERROR[0m in 0.39s]
[0m09:19:13.274775 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m09:19:13.290379 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Purchase_Date (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Purchase_Date.sql.
[0m09:19:13.290379 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m09:19:13.290379 [info ] [Thread-1 (]: 27 of 27 START test source_not_null_sqlserver_data_ecommerce_User_ID ........... [RUN]
[0m09:19:13.290379 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325)
[0m09:19:13.290379 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325, idle-time=0.015603780746459961s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m09:19:13.290379 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m09:19:13.306006 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"
[0m09:19:13.306006 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m09:19:13.306006 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"
[0m09:19:13.306006 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"
[0m09:19:13.321626 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `my_db`.`dbo`.`ecommerce`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m09:19:13.665390 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `my_db`.`dbo`.`ecommerce`
where User_ID is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed1-bc43-1373-bcdd-7b8db9769f83
[0m09:19:13.665390 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_User_ID.sql
[0m09:19:13.665390 [error] [Thread-1 (]: 27 of 27 ERROR source_not_null_sqlserver_data_ecommerce_User_ID ................ [[31mERROR[0m in 0.38s]
[0m09:19:13.681010 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m09:19:13.681010 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_User_ID.sql.
[0m09:19:13.681010 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=14.53126072883606s, language=None, compute-name=) - Reusing connection previously named master
[0m09:19:13.681010 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:19:13.681010 [debug] [MainThread]: Connection 'list_workspace_default' was properly closed.
[0m09:19:13.681010 [debug] [MainThread]: On list_workspace_default: Close
[0m09:19:13.681010 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f06ed1-b33d-1e80-a952-dcc52fafbee1) - Closing
[0m09:19:13.899753 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325' was properly closed.
[0m09:19:13.899753 [debug] [MainThread]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325: Close
[0m09:19:13.899753 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f06ed1-b434-1433-a8f9-ee8faa0baf0e) - Closing
[0m09:19:14.102951 [info ] [MainThread]: 
[0m09:19:14.118504 [info ] [MainThread]: Finished running 27 data tests in 0 hours 0 minutes and 16.55 seconds (16.55s).
[0m09:19:14.134125 [debug] [MainThread]: Command end result
[0m09:19:14.243496 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m09:19:14.259125 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m09:19:14.274753 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m09:19:14.274753 [info ] [MainThread]: 
[0m09:19:14.274753 [info ] [MainThread]: [31mCompleted with 10 errors, 0 partial successes, and 0 warnings:[0m
[0m09:19:14.274753 [info ] [MainThread]: 
[0m09:19:14.274753 [error] [MainThread]: [31mFailure in test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:19:14.290377 [error] [MainThread]:   Database Error in test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_accepted_values_sqlserv_de5401a33d073d59e860da01ddb6837b.sql
[0m09:19:14.290377 [info ] [MainThread]: 
[0m09:19:14.290377 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_accepted_values_sqlserv_de5401a33d073d59e860da01ddb6837b.sql
[0m09:19:14.290377 [info ] [MainThread]: 
[0m09:19:14.290377 [error] [MainThread]: [31mFailure in test source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:19:14.290377 [error] [MainThread]:   Got 8 results, configured to fail if != 0
[0m09:19:14.290377 [info ] [MainThread]: 
[0m09:19:14.305996 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_assert_schema_matches_s_a76a1d3a3c37dcddf2ac3a6e53d8459a.sql
[0m09:19:14.305996 [info ] [MainThread]: 
[0m09:19:14.305996 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Category (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:19:14.305996 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Category (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Category.sql
[0m09:19:14.305996 [info ] [MainThread]: 
[0m09:19:14.305996 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Category.sql
[0m09:19:14.321621 [info ] [MainThread]: 
[0m09:19:14.321621 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Discount (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:19:14.321621 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Discount (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Discount.sql
[0m09:19:14.321621 [info ] [MainThread]: 
[0m09:19:14.321621 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Discount.sql
[0m09:19:14.321621 [info ] [MainThread]: 
[0m09:19:14.337248 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Final_Price (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:19:14.337248 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Final_Price (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Final_Price.sql
[0m09:19:14.337248 [info ] [MainThread]: 
[0m09:19:14.337248 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Final_Price.sql
[0m09:19:14.337248 [info ] [MainThread]: 
[0m09:19:14.337248 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Payment_Method (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:19:14.352883 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Payment_Method (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Payment_Method.sql
[0m09:19:14.352883 [info ] [MainThread]: 
[0m09:19:14.352883 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Payment_Method.sql
[0m09:19:14.352883 [info ] [MainThread]: 
[0m09:19:14.352883 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Price (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:19:14.352883 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Price (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Price.sql
[0m09:19:14.352883 [info ] [MainThread]: 
[0m09:19:14.368498 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Price.sql
[0m09:19:14.368498 [info ] [MainThread]: 
[0m09:19:14.368498 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:19:14.368498 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Product_ID.sql
[0m09:19:14.368498 [info ] [MainThread]: 
[0m09:19:14.368498 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Product_ID.sql
[0m09:19:14.368498 [info ] [MainThread]: 
[0m09:19:14.384130 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Purchase_Date (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:19:14.384130 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Purchase_Date (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Purchase_Date.sql
[0m09:19:14.384130 [info ] [MainThread]: 
[0m09:19:14.384130 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_Purchase_Date.sql
[0m09:19:14.384130 [info ] [MainThread]: 
[0m09:19:14.384130 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\schema.yml)[0m
[0m09:19:14.399755 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_User_ID.sql
[0m09:19:14.399755 [info ] [MainThread]: 
[0m09:19:14.399755 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\schema.yml\source_not_null_sqlserver_data_ecommerce_User_ID.sql
[0m09:19:14.399755 [info ] [MainThread]: 
[0m09:19:14.399755 [info ] [MainThread]: Done. PASS=17 WARN=0 ERROR=10 SKIP=0 NO-OP=0 TOTAL=27
[0m09:19:14.415380 [debug] [MainThread]: Command `dbt test` failed at 09:19:14.415380 after 26.14 seconds
[0m09:19:14.415380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBA14A57D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FB9E180550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FBA48837D0>]}
[0m09:19:14.415380 [debug] [MainThread]: Flushing usage events
[0m09:19:15.009183 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:24:42.326892 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000261C58C0C50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000261C58C0210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000261C58C1290>]}


============================== 09:24:42.342514 | 331f5dc6-e9ff-4705-aabd-8ddb4f72b6ec ==============================
[0m09:24:42.342514 [info ] [MainThread]: Running with dbt=1.10.3
[0m09:24:42.342514 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt test --target databricks', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:24:44.155015 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m09:24:44.155015 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m09:24:44.155015 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m09:24:45.951890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '331f5dc6-e9ff-4705-aabd-8ddb4f72b6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000261D01C7AD0>]}
[0m09:24:46.076889 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '331f5dc6-e9ff-4705-aabd-8ddb4f72b6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000261C5039C50>]}
[0m09:24:46.076889 [info ] [MainThread]: Registered adapter: databricks=1.10.4
[0m09:24:47.201891 [debug] [MainThread]: checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, vars: {}, profile: , target: databricks, version: 1.10.3
[0m09:24:47.686263 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m09:24:47.686263 [debug] [MainThread]: Partial parsing: added file: dbt_databricks_cicd://dbt_databricks_cicd/models\raw\sqlserver\schema.yml
[0m09:24:47.686263 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://dbt_databricks_cicd/models\raw\schema.yml
[0m09:24:48.701887 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two sources with the name "sqlserver_data_ecommerce".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for source("sqlserver_data", "ecommerce").
  
  To fix this, change the name of one of these resources:
  - source.dbt_databricks_cicd.sqlserver_data.ecommerce (dbt_databricks_cicd/models\raw\schema.yml)
  - source.dbt_databricks_cicd.sqlserver_data.ecommerce (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
[0m09:24:48.717555 [debug] [MainThread]: Command `dbt test` failed at 09:24:48.701887 after 6.54 seconds
[0m09:24:48.717555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000261BF100510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000261C5917FD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000261C59171D0>]}
[0m09:24:48.717555 [debug] [MainThread]: Flushing usage events
[0m09:24:49.311305 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:31:41.524110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291C1B97790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291C1B40350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291C1B41CD0>]}


============================== 09:31:41.524110 | dc00555c-bcf7-4d01-a76c-7ba7868fa0fc ==============================
[0m09:31:41.524110 [info ] [MainThread]: Running with dbt=1.10.3
[0m09:31:41.524110 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt test --target databricks', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:31:43.319126 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m09:31:43.319126 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m09:31:43.319126 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m09:31:45.147249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dc00555c-bcf7-4d01-a76c-7ba7868fa0fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291C1B55150>]}
[0m09:31:45.287879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dc00555c-bcf7-4d01-a76c-7ba7868fa0fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291C12B9C90>]}
[0m09:31:45.287879 [info ] [MainThread]: Registered adapter: databricks=1.10.4
[0m09:31:46.350334 [debug] [MainThread]: checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, vars: {}, profile: , target: databricks, version: 1.10.3
[0m09:31:46.787873 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 0 files changed.
[0m09:31:46.787873 [debug] [MainThread]: Partial parsing: added file: dbt_databricks_cicd://dbt_databricks_cicd/models\raw\sqlserver\schema.yml
[0m09:31:48.084750 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.dbt_databricks_cicd.raw.sqlserver
- models.dbt_databricks_cicd.staging.sqlserver
[0m09:31:48.100374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dc00555c-bcf7-4d01-a76c-7ba7868fa0fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291CCD05710>]}
[0m09:31:48.319124 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m09:31:48.319124 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m09:31:48.412834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dc00555c-bcf7-4d01-a76c-7ba7868fa0fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291CE766850>]}
[0m09:31:48.412834 [info ] [MainThread]: Found 9 models, 27 data tests, 1 source, 682 macros
[0m09:31:48.412834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dc00555c-bcf7-4d01-a76c-7ba7868fa0fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291CE333110>]}
[0m09:31:48.428466 [info ] [MainThread]: 
[0m09:31:48.428466 [info ] [MainThread]: Concurrency: 1 threads (target='databricks')
[0m09:31:48.428466 [info ] [MainThread]: 
[0m09:31:48.428466 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=0s, language=None, compute-name=) - Creating connection
[0m09:31:48.428466 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m09:31:48.444089 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace_default, idle-time=0s, language=None, compute-name=) - Creating connection
[0m09:31:48.444089 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace_default'
[0m09:31:48.475429 [debug] [ThreadPool]: Using databricks connection "list_workspace_default"
[0m09:31:48.475429 [debug] [ThreadPool]: On list_workspace_default: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "connection_name": "list_workspace_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'workspace' 
  AND table_schema = 'default'

  
[0m09:31:48.475429 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:31:49.756644 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f06ed3-7eee-1bbe-b910-5065cf86bb17) - Created
[0m09:32:07.303535 [debug] [ThreadPool]: SQL status: OK in 18.830 seconds
[0m09:32:07.350335 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f06ed3-7eee-1bbe-b910-5065cf86bb17, command-id=01f06ed3-7f2d-103c-8c1e-ae2a56d128d2) - Closing
[0m09:32:07.694158 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dc00555c-bcf7-4d01-a76c-7ba7868fa0fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291CE202190>]}
[0m09:32:07.725346 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:32:07.725346 [info ] [Thread-1 (]: 1 of 27 START test not_null_avg_discount_by_category_Category .................. [RUN]
[0m09:32:07.725346 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, idle-time=0s, language=None, compute-name=) - Creating connection
[0m09:32:07.725346 [debug] [Thread-1 (]: Acquiring new databricks connection 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b'
[0m09:32:07.725346 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:32:07.756593 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m09:32:07.756593 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:32:07.787886 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m09:32:07.787886 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m09:32:07.787886 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_discount_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:32:07.803462 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m09:32:08.569161 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc) - Created
[0m09:32:12.272219 [debug] [Thread-1 (]: SQL status: OK in 4.470 seconds
[0m09:32:12.272219 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, command-id=01f06ed3-8a5a-13b7-a2be-c8402ecb2a0e) - Closing
[0m09:32:12.287899 [info ] [Thread-1 (]: 1 of 27 PASS not_null_avg_discount_by_category_Category ........................ [[32mPASS[0m in 4.56s]
[0m09:32:12.303465 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:32:12.303465 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:32:12.303465 [info ] [Thread-1 (]: 2 of 27 START test not_null_avg_discount_by_category_avg_discount_percent ...... [RUN]
[0m09:32:12.303465 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101)
[0m09:32:12.303465 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, idle-time=0.015566825866699219s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:32:12.303465 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:32:12.319088 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m09:32:12.319088 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:32:12.319088 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m09:32:12.334709 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m09:32:12.334709 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_discount_percent
from `workspace`.`default`.`avg_discount_by_category`
where avg_discount_percent is null



  
  
      
    ) dbt_internal_test
[0m09:32:13.397274 [debug] [Thread-1 (]: SQL status: OK in 1.060 seconds
[0m09:32:13.397274 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, command-id=01f06ed3-8c98-18f9-bc5f-2633bb2c719d) - Closing
[0m09:32:13.397274 [info ] [Thread-1 (]: 2 of 27 PASS not_null_avg_discount_by_category_avg_discount_percent ............ [[32mPASS[0m in 1.09s]
[0m09:32:13.412836 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:32:13.412836 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:32:13.412836 [info ] [Thread-1 (]: 3 of 27 START test not_null_avg_ticket_by_category_Category .................... [RUN]
[0m09:32:13.412836 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f)
[0m09:32:13.428533 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, idle-time=0.03125905990600586s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:32:13.428533 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:32:13.444092 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m09:32:13.444092 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:32:13.444092 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m09:32:13.444092 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m09:32:13.444092 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_ticket_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:32:14.256701 [debug] [Thread-1 (]: SQL status: OK in 0.810 seconds
[0m09:32:14.256701 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, command-id=01f06ed3-8d42-1532-a215-c32980f2daa0) - Closing
[0m09:32:14.256701 [info ] [Thread-1 (]: 3 of 27 PASS not_null_avg_ticket_by_category_Category .......................... [[32mPASS[0m in 0.84s]
[0m09:32:14.272214 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:32:14.272214 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:32:14.272214 [info ] [Thread-1 (]: 4 of 27 START test not_null_avg_ticket_by_category_avg_ticket .................. [RUN]
[0m09:32:14.272214 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41)
[0m09:32:14.272214 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, idle-time=0.015512943267822266s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:32:14.272214 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:32:14.287846 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m09:32:14.287846 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:32:14.303460 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m09:32:14.303460 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m09:32:14.303460 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_ticket
from `workspace`.`default`.`avg_ticket_by_category`
where avg_ticket is null



  
  
      
    ) dbt_internal_test
[0m09:32:15.162918 [debug] [Thread-1 (]: SQL status: OK in 0.860 seconds
[0m09:32:15.162918 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, command-id=01f06ed3-8dc4-1455-adac-daf0561d4f9d) - Closing
[0m09:32:15.162918 [info ] [Thread-1 (]: 4 of 27 PASS not_null_avg_ticket_by_category_avg_ticket ........................ [[32mPASS[0m in 0.89s]
[0m09:32:15.178457 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:32:15.178457 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:32:15.178457 [info ] [Thread-1 (]: 5 of 27 START test not_null_monthly_revenue_month .............................. [RUN]
[0m09:32:15.178457 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, now test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b)
[0m09:32:15.178457 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, idle-time=0.015538215637207031s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:32:15.178457 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:32:15.209715 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m09:32:15.209715 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:32:15.225334 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m09:32:15.225334 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m09:32:15.225334 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select month
from `workspace`.`default`.`monthly_revenue`
where month is null



  
  
      
    ) dbt_internal_test
[0m09:32:16.162839 [debug] [Thread-1 (]: SQL status: OK in 0.940 seconds
[0m09:32:16.162839 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, command-id=01f06ed3-8e52-100f-ae14-539c19f42d4b) - Closing
[0m09:32:16.162839 [info ] [Thread-1 (]: 5 of 27 PASS not_null_monthly_revenue_month .................................... [[32mPASS[0m in 0.98s]
[0m09:32:16.162839 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:32:16.162839 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:32:16.162839 [info ] [Thread-1 (]: 6 of 27 START test not_null_monthly_revenue_monthly_revenue .................... [RUN]
[0m09:32:16.178458 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, now test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b)
[0m09:32:16.178458 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, idle-time=0.015619277954101562s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:32:16.178458 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:32:16.209706 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m09:32:16.209706 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:32:16.225334 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m09:32:16.225334 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m09:32:16.225334 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select monthly_revenue
from `workspace`.`default`.`monthly_revenue`
where monthly_revenue is null



  
  
      
    ) dbt_internal_test
[0m09:32:17.131660 [debug] [Thread-1 (]: SQL status: OK in 0.890 seconds
[0m09:32:17.131660 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, command-id=01f06ed3-8ee9-1e16-92d1-c242102721d6) - Closing
[0m09:32:17.131660 [info ] [Thread-1 (]: 6 of 27 PASS not_null_monthly_revenue_monthly_revenue .......................... [[32mPASS[0m in 0.95s]
[0m09:32:17.147207 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:32:17.147207 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:32:17.147207 [info ] [Thread-1 (]: 7 of 27 START test not_null_payment_distribution_Payment_Method ................ [RUN]
[0m09:32:17.147207 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, now test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae)
[0m09:32:17.147207 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, idle-time=0.015546798706054688s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:32:17.147207 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:32:17.162833 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m09:32:17.162833 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:32:17.162833 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m09:32:17.162833 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m09:32:17.178459 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`payment_distribution`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m09:32:18.014764 [debug] [Thread-1 (]: SQL status: OK in 0.840 seconds
[0m09:32:18.030393 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, command-id=01f06ed3-8f79-1a29-941d-004bcd588c49) - Closing
[0m09:32:18.030393 [info ] [Thread-1 (]: 7 of 27 PASS not_null_payment_distribution_Payment_Method ...................... [[32mPASS[0m in 0.88s]
[0m09:32:18.030393 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:32:18.046028 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:32:18.046028 [info ] [Thread-1 (]: 8 of 27 START test not_null_payment_distribution_total_transactions ............ [RUN]
[0m09:32:18.046028 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, now test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8)
[0m09:32:18.046028 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, idle-time=0.015635013580322266s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:32:18.046028 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:32:18.073748 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m09:32:18.073748 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:32:18.089387 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m09:32:18.104997 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m09:32:18.104997 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_transactions
from `workspace`.`default`.`payment_distribution`
where total_transactions is null



  
  
      
    ) dbt_internal_test
[0m09:32:18.799171 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m09:32:18.814713 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, command-id=01f06ed3-9008-1562-80fd-0d8d383bc9f4) - Closing
[0m09:32:18.814713 [info ] [Thread-1 (]: 8 of 27 PASS not_null_payment_distribution_total_transactions .................. [[32mPASS[0m in 0.77s]
[0m09:32:18.814713 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:32:18.814713 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:32:18.814713 [info ] [Thread-1 (]: 9 of 27 START test not_null_payment_distribution_total_value ................... [RUN]
[0m09:32:18.814713 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, now test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03)
[0m09:32:18.814713 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:32:18.830340 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:32:18.845975 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m09:32:18.845975 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:32:18.845975 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m09:32:18.845975 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m09:32:18.845975 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_value
from `workspace`.`default`.`payment_distribution`
where total_value is null



  
  
      
    ) dbt_internal_test
[0m09:32:19.549150 [debug] [Thread-1 (]: SQL status: OK in 0.700 seconds
[0m09:32:19.564770 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, command-id=01f06ed3-9079-1de7-96f3-83e41b29267a) - Closing
[0m09:32:19.564770 [info ] [Thread-1 (]: 9 of 27 PASS not_null_payment_distribution_total_value ......................... [[32mPASS[0m in 0.75s]
[0m09:32:19.564770 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:32:19.580361 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:32:19.580361 [info ] [Thread-1 (]: 10 of 27 START test not_null_sales_by_category_Category ........................ [RUN]
[0m09:32:19.580361 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, now test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507)
[0m09:32:19.580361 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, idle-time=0.015591859817504883s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:32:19.595984 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:32:19.595984 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m09:32:19.611594 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:32:19.611594 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m09:32:19.611594 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m09:32:19.611594 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`sales_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:32:20.517931 [debug] [Thread-1 (]: SQL status: OK in 0.910 seconds
[0m09:32:20.533465 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, command-id=01f06ed3-90ef-1a2e-aa15-5ed6890843e8) - Closing
[0m09:32:20.533465 [info ] [Thread-1 (]: 10 of 27 PASS not_null_sales_by_category_Category .............................. [[32mPASS[0m in 0.95s]
[0m09:32:20.533465 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:32:20.533465 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:32:20.533465 [info ] [Thread-1 (]: 11 of 27 START test not_null_sales_by_category_total_orders .................... [RUN]
[0m09:32:20.533465 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, now test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e)
[0m09:32:20.533465 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:32:20.549126 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:32:20.549126 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m09:32:20.549126 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:32:20.564721 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m09:32:20.564721 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m09:32:20.564721 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`sales_by_category`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m09:32:21.314867 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m09:32:21.314867 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, command-id=01f06ed3-9180-1814-824f-a10605a16208) - Closing
[0m09:32:21.330409 [info ] [Thread-1 (]: 11 of 27 PASS not_null_sales_by_category_total_orders .......................... [[32mPASS[0m in 0.80s]
[0m09:32:21.330409 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:32:21.330409 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:32:21.345978 [info ] [Thread-1 (]: 12 of 27 START test not_null_sales_by_category_total_revenue ................... [RUN]
[0m09:32:21.345978 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, now test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd)
[0m09:32:21.345978 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, idle-time=0.015568733215332031s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:32:21.345978 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:32:21.361594 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m09:32:21.361594 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:32:21.361594 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m09:32:21.361594 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m09:32:21.361594 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_revenue
from `workspace`.`default`.`sales_by_category`
where total_revenue is null



  
  
      
    ) dbt_internal_test
[0m09:32:22.236710 [debug] [Thread-1 (]: SQL status: OK in 0.880 seconds
[0m09:32:22.236710 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, command-id=01f06ed3-91fc-154d-86ae-8ae0c310708c) - Closing
[0m09:32:22.236710 [info ] [Thread-1 (]: 12 of 27 PASS not_null_sales_by_category_total_revenue ......................... [[32mPASS[0m in 0.89s]
[0m09:32:22.252251 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:32:22.252251 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:32:22.252251 [info ] [Thread-1 (]: 13 of 27 START test not_null_top_5_products_product_id ......................... [RUN]
[0m09:32:22.252251 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, now test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe)
[0m09:32:22.252251 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, idle-time=0.015541315078735352s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:32:22.252251 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:32:22.267879 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m09:32:22.267879 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:32:22.267879 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m09:32:22.283466 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m09:32:22.283466 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select product_id
from `workspace`.`default`.`top_5_products`
where product_id is null



  
  
      
    ) dbt_internal_test
[0m09:32:23.049165 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m09:32:23.064749 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, command-id=01f06ed3-9285-15aa-a243-5332af367570) - Closing
[0m09:32:23.064749 [info ] [Thread-1 (]: 13 of 27 PASS not_null_top_5_products_product_id ............................... [[32mPASS[0m in 0.81s]
[0m09:32:23.064749 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:32:23.064749 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:32:23.064749 [info ] [Thread-1 (]: 14 of 27 START test not_null_top_5_products_total_sales ........................ [RUN]
[0m09:32:23.064749 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, now test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818)
[0m09:32:23.064749 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:32:23.064749 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:32:23.080376 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m09:32:23.080376 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:32:23.095966 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m09:32:23.095966 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m09:32:23.095966 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_sales
from `workspace`.`default`.`top_5_products`
where total_sales is null



  
  
      
    ) dbt_internal_test
[0m09:32:23.767890 [debug] [Thread-1 (]: SQL status: OK in 0.670 seconds
[0m09:32:23.767890 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, command-id=01f06ed3-9301-1de4-9239-31251748e661) - Closing
[0m09:32:23.767890 [info ] [Thread-1 (]: 14 of 27 PASS not_null_top_5_products_total_sales .............................. [[32mPASS[0m in 0.70s]
[0m09:32:23.783472 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:32:23.783472 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:32:23.783472 [info ] [Thread-1 (]: 15 of 27 START test not_null_top_customers_User_ID ............................. [RUN]
[0m09:32:23.783472 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, now test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0)
[0m09:32:23.783472 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, idle-time=0.015581846237182617s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:32:23.783472 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:32:23.799130 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m09:32:23.799130 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:32:23.799130 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m09:32:23.814710 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m09:32:23.814710 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`top_customers`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m09:32:24.549163 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m09:32:24.564750 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, command-id=01f06ed3-936f-1153-98a5-b8f928060200) - Closing
[0m09:32:24.564750 [info ] [Thread-1 (]: 15 of 27 PASS not_null_top_customers_User_ID ................................... [[32mPASS[0m in 0.78s]
[0m09:32:24.564750 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:32:24.564750 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:32:24.564750 [info ] [Thread-1 (]: 16 of 27 START test not_null_top_customers_total_orders ........................ [RUN]
[0m09:32:24.564750 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, now test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746)
[0m09:32:24.580374 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:32:24.580374 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:32:24.580374 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m09:32:24.580374 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:32:24.595966 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m09:32:24.595966 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m09:32:24.595966 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`top_customers`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m09:32:25.330351 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m09:32:25.330351 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, command-id=01f06ed3-93e6-1922-bf34-6d73b5f9c56e) - Closing
[0m09:32:25.330351 [info ] [Thread-1 (]: 16 of 27 PASS not_null_top_customers_total_orders .............................. [[32mPASS[0m in 0.77s]
[0m09:32:25.345965 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:32:25.345965 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:32:25.345965 [info ] [Thread-1 (]: 17 of 27 START test not_null_top_customers_total_spent ......................... [RUN]
[0m09:32:25.345965 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, now test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73)
[0m09:32:25.345965 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73, idle-time=0.01561427116394043s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:32:25.361602 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:32:25.361602 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m09:32:25.377211 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:32:25.377211 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m09:32:25.377211 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m09:32:25.377211 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_spent
from `workspace`.`default`.`top_customers`
where total_spent is null



  
  
      
    ) dbt_internal_test
[0m09:32:26.049083 [debug] [Thread-1 (]: SQL status: OK in 0.670 seconds
[0m09:32:26.049083 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, command-id=01f06ed3-945e-168c-aed2-612363310a3b) - Closing
[0m09:32:26.049083 [info ] [Thread-1 (]: 17 of 27 PASS not_null_top_customers_total_spent ............................... [[32mPASS[0m in 0.70s]
[0m09:32:26.049083 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:32:26.049083 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m09:32:26.049083 [info ] [Thread-1 (]: 18 of 27 START test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m09:32:26.064709 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73, now test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931)
[0m09:32:26.064709 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931, idle-time=0.015626192092895508s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:32:26.064709 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m09:32:26.064709 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"
[0m09:32:26.080337 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m09:32:26.080337 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"
[0m09:32:26.095963 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"
[0m09:32:26.095963 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from `my_db`.`dbo`.`ecommerce`
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    'Credit Card','Net Banking','UPI','Debit Card','Cash on Delivery'
)



  
  
      
    ) dbt_internal_test
[0m09:32:26.564787 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from `my_db`.`dbo`.`ecommerce`
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    'Credit Card','Net Banking','UPI','Debit Card','Cash on Delivery'
)



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed3-94cb-1293-b804-399832ea7216
[0m09:32:26.596002 [debug] [Thread-1 (]: Database Error in test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_accepted_values_sqlserv_de5401a33d073d59e860da01ddb6837b.sql
[0m09:32:26.596002 [error] [Thread-1 (]: 18 of 27 ERROR source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[31mERROR[0m in 0.53s]
[0m09:32:26.596002 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m09:32:26.596002 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m09:32:26.596002 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931' to be skipped because of status 'error'.  Reason: Database Error in test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_accepted_values_sqlserv_de5401a33d073d59e860da01ddb6837b.sql.
[0m09:32:26.596002 [info ] [Thread-1 (]: 19 of 27 START test source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date  [RUN]
[0m09:32:26.596002 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931, now test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93)
[0m09:32:26.611626 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93, idle-time=0.015624284744262695s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m09:32:26.611626 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m09:32:26.611626 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93"
[0m09:32:26.627220 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m09:32:26.627220 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93"
[0m09:32:26.627220 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93"
[0m09:32:26.642839 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    with actual as (
        select
            column_name,
            data_type
        from INFORMATION_SCHEMA.COLUMNS
        where TABLE_NAME = 'ecommerce'
          and TABLE_SCHEMA = 'dbo'
    ),
    expected as (
        select * from (values
            ('User_ID', 'varchar'),
            ('Product_ID', 'varchar'),
            ('Category', 'varchar'),
            ('Price', 'float'),
            ('Discount', 'int'),
            ('Final_Price', 'float'),
            ('Payment_Method', 'varchar'),
            ('Purchase_Date', 'date')
            
        ) as t(column_name, data_type)
    ),
    diff_expected as (
        select * from expected
        EXCEPT
        select * from actual
    ),
    diff_actual as (
        select * from actual
        EXCEPT
        select * from expected
    )
    select * from diff_expected
    UNION ALL
    select * from diff_actual

  
  
      
    ) dbt_internal_test
[0m09:32:28.299142 [debug] [Thread-1 (]: SQL status: OK in 1.660 seconds
[0m09:32:28.299142 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, command-id=01f06ed3-951e-17d5-955e-af43d6e7b9b6) - Closing
[0m09:32:28.314718 [error] [Thread-1 (]: 19 of 27 FAIL 8 source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date  [[31mFAIL 8[0m in 1.72s]
[0m09:32:28.314718 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m09:32:28.314718 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m09:32:28.330401 [info ] [Thread-1 (]: 20 of 27 START test source_not_null_sqlserver_data_ecommerce_Category .......... [RUN]
[0m09:32:28.330401 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023)
[0m09:32:28.330401 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023, idle-time=0.015682220458984375s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date.478b2c7f93
[0m09:32:28.330401 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m09:32:28.346001 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"
[0m09:32:28.346001 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m09:32:28.361601 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"
[0m09:32:28.361601 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"
[0m09:32:28.361601 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `my_db`.`dbo`.`ecommerce`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:32:28.908517 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `my_db`.`dbo`.`ecommerce`
where Category is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed3-9626-151c-8fbf-851e8da487e8
[0m09:32:28.908517 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Category (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Category.sql
[0m09:32:28.924144 [error] [Thread-1 (]: 20 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Category ............... [[31mERROR[0m in 0.59s]
[0m09:32:28.924144 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m09:32:28.924144 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m09:32:28.924144 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Category (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Category.sql.
[0m09:32:28.924144 [info ] [Thread-1 (]: 21 of 27 START test source_not_null_sqlserver_data_ecommerce_Discount .......... [RUN]
[0m09:32:28.924144 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6)
[0m09:32:28.939755 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6, idle-time=0.015610218048095703s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m09:32:28.939755 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m09:32:28.939755 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"
[0m09:32:28.955437 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m09:32:28.955437 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"
[0m09:32:28.955437 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"
[0m09:32:28.955437 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Discount
from `my_db`.`dbo`.`ecommerce`
where Discount is null



  
  
      
    ) dbt_internal_test
[0m09:32:29.314767 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Discount
from `my_db`.`dbo`.`ecommerce`
where Discount is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed3-9680-1d90-b837-d36f1aa0663b
[0m09:32:29.330406 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Discount (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Discount.sql
[0m09:32:29.330406 [error] [Thread-1 (]: 21 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Discount ............... [[31mERROR[0m in 0.41s]
[0m09:32:29.330406 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m09:32:29.330406 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m09:32:29.330406 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Discount (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Discount.sql.
[0m09:32:29.330406 [info ] [Thread-1 (]: 22 of 27 START test source_not_null_sqlserver_data_ecommerce_Final_Price ....... [RUN]
[0m09:32:29.345958 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823)
[0m09:32:29.345958 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823, idle-time=0.015552520751953125s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m09:32:29.345958 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m09:32:29.345958 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"
[0m09:32:29.361625 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m09:32:29.361625 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"
[0m09:32:29.361625 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"
[0m09:32:29.361625 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Final_Price
from `my_db`.`dbo`.`ecommerce`
where Final_Price is null



  
  
      
    ) dbt_internal_test
[0m09:32:29.877211 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Final_Price
from `my_db`.`dbo`.`ecommerce`
where Final_Price is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed3-96be-1a6f-a953-122d33d7e68a
[0m09:32:29.892836 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Final_Price (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Final_Price.sql
[0m09:32:29.892836 [error] [Thread-1 (]: 22 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Final_Price ............ [[31mERROR[0m in 0.55s]
[0m09:32:29.892836 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m09:32:29.892836 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m09:32:29.908461 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Final_Price (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Final_Price.sql.
[0m09:32:29.908461 [info ] [Thread-1 (]: 23 of 27 START test source_not_null_sqlserver_data_ecommerce_Payment_Method .... [RUN]
[0m09:32:29.908461 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32)
[0m09:32:29.908461 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32, idle-time=0.015624761581420898s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m09:32:29.908461 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m09:32:29.924084 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"
[0m09:32:29.939710 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m09:32:29.955336 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"
[0m09:32:29.955336 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"
[0m09:32:29.955336 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `my_db`.`dbo`.`ecommerce`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m09:32:30.314724 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `my_db`.`dbo`.`ecommerce`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed3-9718-103d-a34a-ec4e767d6d14
[0m09:32:30.330408 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Payment_Method (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Payment_Method.sql
[0m09:32:30.330408 [error] [Thread-1 (]: 23 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Payment_Method ......... [[31mERROR[0m in 0.42s]
[0m09:32:30.345980 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m09:32:30.345980 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m09:32:30.345980 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Payment_Method (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Payment_Method.sql.
[0m09:32:30.345980 [info ] [Thread-1 (]: 24 of 27 START test source_not_null_sqlserver_data_ecommerce_Price ............. [RUN]
[0m09:32:30.361590 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a)
[0m09:32:30.361590 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a, idle-time=0.031181812286376953s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m09:32:30.361590 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m09:32:30.392836 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"
[0m09:32:30.392836 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m09:32:30.392836 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"
[0m09:32:30.408463 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"
[0m09:32:30.408463 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Price
from `my_db`.`dbo`.`ecommerce`
where Price is null



  
  
      
    ) dbt_internal_test
[0m09:32:30.767836 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Price
from `my_db`.`dbo`.`ecommerce`
where Price is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed3-975e-1cd5-bb08-74d50dbfb657
[0m09:32:30.783464 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Price (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Price.sql
[0m09:32:30.783464 [error] [Thread-1 (]: 24 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Price .................. [[31mERROR[0m in 0.42s]
[0m09:32:30.799086 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m09:32:30.799086 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m09:32:30.799086 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Price (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Price.sql.
[0m09:32:30.799086 [info ] [Thread-1 (]: 25 of 27 START test source_not_null_sqlserver_data_ecommerce_Product_ID ........ [RUN]
[0m09:32:30.799086 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd)
[0m09:32:30.814709 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd, idle-time=0.03124547004699707s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m09:32:30.814709 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m09:32:30.830338 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"
[0m09:32:30.830338 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m09:32:30.845961 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"
[0m09:32:30.845961 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"
[0m09:32:30.845961 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Product_ID
from `my_db`.`dbo`.`ecommerce`
where Product_ID is null



  
  
      
    ) dbt_internal_test
[0m09:32:31.220994 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Product_ID
from `my_db`.`dbo`.`ecommerce`
where Product_ID is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed3-97a0-112b-9daf-63d961c5675d
[0m09:32:31.236586 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Product_ID.sql
[0m09:32:31.236586 [error] [Thread-1 (]: 25 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Product_ID ............. [[31mERROR[0m in 0.44s]
[0m09:32:31.236586 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m09:32:31.236586 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m09:32:31.236586 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Product_ID.sql.
[0m09:32:31.236586 [info ] [Thread-1 (]: 26 of 27 START test source_not_null_sqlserver_data_ecommerce_Purchase_Date ..... [RUN]
[0m09:32:31.236586 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23)
[0m09:32:31.252210 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23, idle-time=0.015624284744262695s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m09:32:31.252210 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m09:32:31.252210 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"
[0m09:32:31.252210 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m09:32:31.267848 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"
[0m09:32:31.267848 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"
[0m09:32:31.267848 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Purchase_Date
from `my_db`.`dbo`.`ecommerce`
where Purchase_Date is null



  
  
      
    ) dbt_internal_test
[0m09:32:31.689786 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Purchase_Date
from `my_db`.`dbo`.`ecommerce`
where Purchase_Date is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed3-97e0-1cc0-9cc6-6911e9dfde76
[0m09:32:31.705395 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Purchase_Date (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Purchase_Date.sql
[0m09:32:31.720999 [error] [Thread-1 (]: 26 of 27 ERROR source_not_null_sqlserver_data_ecommerce_Purchase_Date .......... [[31mERROR[0m in 0.47s]
[0m09:32:31.720999 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m09:32:31.720999 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m09:32:31.720999 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Purchase_Date (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Purchase_Date.sql.
[0m09:32:31.720999 [info ] [Thread-1 (]: 27 of 27 START test source_not_null_sqlserver_data_ecommerce_User_ID ........... [RUN]
[0m09:32:31.720999 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325)
[0m09:32:31.720999 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325, idle-time=0.015603780746459961s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m09:32:31.720999 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m09:32:31.736586 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"
[0m09:32:31.736586 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m09:32:31.752215 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"
[0m09:32:31.752215 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"
[0m09:32:31.752215 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `my_db`.`dbo`.`ecommerce`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m09:32:32.095963 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `my_db`.`dbo`.`ecommerce`
where User_ID is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:959)
	... 43 more
, operation-id=01f06ed3-982a-104d-8fff-0e0b296006c9
[0m09:32:32.111585 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_User_ID.sql
[0m09:32:32.111585 [error] [Thread-1 (]: 27 of 27 ERROR source_not_null_sqlserver_data_ecommerce_User_ID ................ [[31mERROR[0m in 0.39s]
[0m09:32:32.111585 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m09:32:32.111585 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_User_ID.sql.
[0m09:32:32.127210 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=24.417439937591553s, language=None, compute-name=) - Reusing connection previously named master
[0m09:32:32.127210 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:32:32.127210 [debug] [MainThread]: Connection 'list_workspace_default' was properly closed.
[0m09:32:32.127210 [debug] [MainThread]: On list_workspace_default: Close
[0m09:32:32.127210 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f06ed3-7eee-1bbe-b910-5065cf86bb17) - Closing
[0m09:32:32.346042 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325' was properly closed.
[0m09:32:32.346042 [debug] [MainThread]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325: Close
[0m09:32:32.361650 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f06ed3-8a35-121a-a826-51fefcf65abc) - Closing
[0m09:32:32.564815 [info ] [MainThread]: 
[0m09:32:32.564815 [info ] [MainThread]: Finished running 27 data tests in 0 hours 0 minutes and 44.14 seconds (44.14s).
[0m09:32:32.580360 [debug] [MainThread]: Command end result
[0m09:32:32.674087 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m09:32:32.674087 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m09:32:32.689750 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m09:32:32.689750 [info ] [MainThread]: 
[0m09:32:32.689750 [info ] [MainThread]: [31mCompleted with 10 errors, 0 partial successes, and 0 warnings:[0m
[0m09:32:32.689750 [info ] [MainThread]: 
[0m09:32:32.705337 [error] [MainThread]: [31mFailure in test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)[0m
[0m09:32:32.705337 [error] [MainThread]:   Database Error in test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_accepted_values_sqlserv_de5401a33d073d59e860da01ddb6837b.sql
[0m09:32:32.705337 [info ] [MainThread]: 
[0m09:32:32.705337 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_accepted_values_sqlserv_de5401a33d073d59e860da01ddb6837b.sql
[0m09:32:32.705337 [info ] [MainThread]: 
[0m09:32:32.705337 [error] [MainThread]: [31mFailure in test source_assert_schema_matches_sqlserver_data_ecommerce_varchar__varchar__varchar__float__int__float__varchar__date (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)[0m
[0m09:32:32.705337 [error] [MainThread]:   Got 8 results, configured to fail if != 0
[0m09:32:32.705337 [info ] [MainThread]: 
[0m09:32:32.720960 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_assert_schema_matches_s_a76a1d3a3c37dcddf2ac3a6e53d8459a.sql
[0m09:32:32.720960 [info ] [MainThread]: 
[0m09:32:32.720960 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Category (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)[0m
[0m09:32:32.720960 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Category (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Category.sql
[0m09:32:32.720960 [info ] [MainThread]: 
[0m09:32:32.720960 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Category.sql
[0m09:32:32.736624 [info ] [MainThread]: 
[0m09:32:32.736624 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Discount (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)[0m
[0m09:32:32.736624 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Discount (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Discount.sql
[0m09:32:32.736624 [info ] [MainThread]: 
[0m09:32:32.736624 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Discount.sql
[0m09:32:32.752211 [info ] [MainThread]: 
[0m09:32:32.752211 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Final_Price (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)[0m
[0m09:32:32.752211 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Final_Price (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Final_Price.sql
[0m09:32:32.752211 [info ] [MainThread]: 
[0m09:32:32.752211 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Final_Price.sql
[0m09:32:32.752211 [info ] [MainThread]: 
[0m09:32:32.767837 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Payment_Method (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)[0m
[0m09:32:32.767837 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Payment_Method (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Payment_Method.sql
[0m09:32:32.767837 [info ] [MainThread]: 
[0m09:32:32.767837 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Payment_Method.sql
[0m09:32:32.767837 [info ] [MainThread]: 
[0m09:32:32.767837 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Price (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)[0m
[0m09:32:32.783464 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Price (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Price.sql
[0m09:32:32.783464 [info ] [MainThread]: 
[0m09:32:32.783464 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Price.sql
[0m09:32:32.783464 [info ] [MainThread]: 
[0m09:32:32.783464 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)[0m
[0m09:32:32.783464 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Product_ID.sql
[0m09:32:32.799085 [info ] [MainThread]: 
[0m09:32:32.799085 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Product_ID.sql
[0m09:32:32.799085 [info ] [MainThread]: 
[0m09:32:32.799085 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Purchase_Date (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)[0m
[0m09:32:32.799085 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Purchase_Date (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Purchase_Date.sql
[0m09:32:32.799085 [info ] [MainThread]: 
[0m09:32:32.814735 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_Purchase_Date.sql
[0m09:32:32.814735 [info ] [MainThread]: 
[0m09:32:32.814735 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)[0m
[0m09:32:32.814735 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\sqlserver\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_User_ID.sql
[0m09:32:32.814735 [info ] [MainThread]: 
[0m09:32:32.814735 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\schema.yml\source_not_null_sqlserver_data_ecommerce_User_ID.sql
[0m09:32:32.830339 [info ] [MainThread]: 
[0m09:32:32.830339 [info ] [MainThread]: Done. PASS=17 WARN=0 ERROR=10 SKIP=0 NO-OP=0 TOTAL=27
[0m09:32:32.830339 [debug] [MainThread]: Command `dbt test` failed at 09:32:32.830339 after 51.45 seconds
[0m09:32:32.830339 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291C1B9C3D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291C1B971D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000291CCDE4610>]}
[0m09:32:32.830339 [debug] [MainThread]: Flushing usage events
[0m09:32:33.939778 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:33:47.746749 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019FF8194310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019FF8195D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019FF8196D90>]}


============================== 11:33:47.755753 | 8284fc79-3519-4bbd-b8e6-dfae4a2c8289 ==============================
[0m11:33:47.755753 [info ] [MainThread]: Running with dbt=1.10.3
[0m11:33:47.757752 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt deps', 'send_anonymous_usage_stats': 'True'}
[0m11:33:48.370316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8284fc79-3519-4bbd-b8e6-dfae4a2c8289', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019FF82875D0>]}
[0m11:33:48.503598 [debug] [MainThread]: Set downloads directory='C:\Users\diniz\AppData\Local\Temp\dbt-downloads-aq4f63qe'
[0m11:33:48.506729 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m11:33:49.616565 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m11:33:49.620576 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m11:33:49.794349 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m11:33:49.820900 [info ] [MainThread]: Updating lock file in file path: D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD/package-lock.yml
[0m11:33:49.838512 [debug] [MainThread]: Set downloads directory='C:\Users\diniz\AppData\Local\Temp\dbt-downloads-z1zcikw_'
[0m11:33:49.845538 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m11:33:50.638398 [info ] [MainThread]: Installed from version 1.3.0
[0m11:33:50.639385 [info ] [MainThread]: Up to date!
[0m11:33:50.641384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '8284fc79-3519-4bbd-b8e6-dfae4a2c8289', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019FF8194550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019FF82ADD90>]}
[0m11:33:50.646384 [debug] [MainThread]: Command `dbt deps` succeeded at 11:33:50.646384 after 3.07 seconds
[0m11:33:50.648385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019FF1A46290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019FF19C1290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019FF19C0210>]}
[0m11:33:50.649384 [debug] [MainThread]: Flushing usage events
[0m11:33:51.248922 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:34:17.481569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF800C9690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF800CA610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF800C8510>]}


============================== 11:34:17.489502 | 0eac1926-bd53-4456-b98a-681bde0fc2a0 ==============================
[0m11:34:17.489502 [info ] [MainThread]: Running with dbt=1.10.3
[0m11:34:17.492504 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt build', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:34:23.412692 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0eac1926-bd53-4456-b98a-681bde0fc2a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF8181DA50>]}
[0m11:34:23.537720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0eac1926-bd53-4456-b98a-681bde0fc2a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFFEF51E50>]}
[0m11:34:23.539726 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m11:34:24.711551 [debug] [MainThread]: checksum: 1bfacb87e6914c9942cfa2c4badfc1df19d859fe8ec086286ef238a7d920f97b, vars: {}, profile: , target: , version: 1.10.3
[0m11:34:24.946100 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m11:34:24.948096 [debug] [MainThread]: previous checksum: 1bfacb87e6914c9942cfa2c4badfc1df19d859fe8ec086286ef238a7d920f97b, current checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9
[0m11:34:24.949112 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m11:34:24.951100 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m11:34:24.953744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0eac1926-bd53-4456-b98a-681bde0fc2a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFFF6F4250>]}
[0m11:34:31.695858 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m11:34:31.697856 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m11:34:31.698861 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m11:34:31.699862 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m11:34:31.701859 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m11:34:31.703857 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m11:34:31.704855 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m11:34:31.706852 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m11:34:31.708853 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m11:34:31.711861 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m11:34:31.712857 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m11:34:31.714857 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m11:34:31.715857 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m11:34:31.716856 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m11:34:31.719859 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m11:34:31.721860 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m11:34:31.723856 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m11:34:31.727858 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m11:34:31.729855 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m11:34:31.730861 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m11:34:31.732853 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m11:34:31.734854 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m11:34:31.736853 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m11:34:31.738854 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m11:34:31.740854 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m11:34:31.742858 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m11:34:31.746858 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m11:34:31.962207 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m11:34:31.989697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0eac1926-bd53-4456-b98a-681bde0fc2a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF820DAB10>]}
[0m11:34:32.392995 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m11:34:32.428992 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m11:34:32.662446 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0eac1926-bd53-4456-b98a-681bde0fc2a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF81F4E7D0>]}
[0m11:34:32.664445 [info ] [MainThread]: Found 2 models, 11 data tests, 1 source, 626 macros
[0m11:34:32.671440 [info ] [MainThread]: 
[0m11:34:32.673441 [info ] [MainThread]: Concurrency: 1 threads (target='sqlserver')
[0m11:34:32.674447 [info ] [MainThread]: 
[0m11:34:32.678446 [debug] [MainThread]: Acquiring new sqlserver connection 'master'
[0m11:34:32.699443 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db'
[0m11:34:32.764444 [debug] [ThreadPool]: dbt-sqlserver
[0m11:34:32.767446 [debug] [ThreadPool]: Using sqlserver connection "list_my_db"
[0m11:34:32.769443 [debug] [ThreadPool]: On list_my_db: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db"} */
USE [my_db];
    select  name as [schema]
    from sys.schemas with (nolock) 
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m11:34:32.771443 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:34:32.774441 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:34:33.165432 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m11:34:33.266541 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m11:34:33.270541 [debug] [ThreadPool]: On list_my_db: Close
[0m11:34:33.274541 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db_dbo'
[0m11:34:33.293243 [debug] [ThreadPool]: dbt-sqlserver
[0m11:34:33.295915 [debug] [ThreadPool]: Using sqlserver connection "list_my_db_dbo"
[0m11:34:33.297136 [debug] [ThreadPool]: On list_my_db_dbo: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db_dbo"} */
USE [my_db];
    with base as (
      select
        DB_NAME() as [database],
        t.name as [name],
        SCHEMA_NAME(t.schema_id) as [schema],
        'table' as table_type
      from sys.tables as t with (nolock)
      union all
      select
        DB_NAME() as [database],
        v.name as [name],
        SCHEMA_NAME(v.schema_id) as [schema],
        'view' as table_type
      from sys.views as v with (nolock)
    )
    select * from base
    where [schema] like 'dbo'
    
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m11:34:33.299142 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:34:33.300143 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:34:33.302138 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m11:34:33.665828 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m11:34:33.669835 [debug] [ThreadPool]: On list_my_db_dbo: ROLLBACK
[0m11:34:33.670834 [debug] [ThreadPool]: On list_my_db_dbo: Close
[0m11:34:33.673868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0eac1926-bd53-4456-b98a-681bde0fc2a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF81F428D0>]}
[0m11:34:33.676836 [debug] [MainThread]: On master: COMMIT
[0m11:34:33.687836 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m11:34:33.689839 [info ] [Thread-1 (]: 1 of 13 START sql view model dbo.src_ecommerce ................................. [RUN]
[0m11:34:33.692836 [debug] [Thread-1 (]: Acquiring new sqlserver connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m11:34:33.694836 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m11:34:33.735835 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m11:34:33.744840 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m11:34:34.123406 [debug] [Thread-1 (]: Compilation Error in model src_ecommerce (dbt_databricks_cicd/models\raw\sqlserver\src_ecommerce.sql)
  When searching for a relation, dbt found an approximate match. Instead of guessing 
  which relation to use, dbt will move on. Please delete "MY_DB"."dbo"."src_ecommerce", or rename it to be less ambiguous.
  Searched for: "my_db"."dbo"."src_ecommerce"
  Found: "MY_DB"."dbo"."src_ecommerce"
  
  > in macro load_cached_relation (macros\adapters\relation.sql)
  > called by macro materialization_view_sqlserver (macros\materializations\models\view\view.sql)
  > called by model src_ecommerce (dbt_databricks_cicd/models\raw\sqlserver\src_ecommerce.sql)
[0m11:34:34.137397 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0eac1926-bd53-4456-b98a-681bde0fc2a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF81CF59D0>]}
[0m11:34:34.143401 [error] [Thread-1 (]: 1 of 13 ERROR creating sql view model dbo.src_ecommerce ........................ [[31mERROR[0m in 0.44s]
[0m11:34:34.149410 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m11:34:34.151396 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m11:34:34.153395 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.src_ecommerce' to be skipped because of status 'error'.  Reason: Compilation Error in model src_ecommerce (dbt_databricks_cicd/models\raw\sqlserver\src_ecommerce.sql)
  When searching for a relation, dbt found an approximate match. Instead of guessing 
  which relation to use, dbt will move on. Please delete "MY_DB"."dbo"."src_ecommerce", or rename it to be less ambiguous.
  Searched for: "my_db"."dbo"."src_ecommerce"
  Found: "MY_DB"."dbo"."src_ecommerce"
  
  > in macro load_cached_relation (macros\adapters\relation.sql)
  > called by macro materialization_view_sqlserver (macros\materializations\models\view\view.sql)
  > called by model src_ecommerce (dbt_databricks_cicd/models\raw\sqlserver\src_ecommerce.sql).
[0m11:34:34.155395 [info ] [Thread-1 (]: 2 of 13 START sql view model dbo.stg_ecommerce ................................. [RUN]
[0m11:34:34.162411 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m11:34:34.165402 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m11:34:34.238410 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m11:34:34.247419 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m11:34:34.296396 [debug] [Thread-1 (]: Compilation Error in model stg_ecommerce (dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql)
  When searching for a relation, dbt found an approximate match. Instead of guessing 
  which relation to use, dbt will move on. Please delete "MY_DB"."dbo"."stg_ecommerce", or rename it to be less ambiguous.
  Searched for: "my_db"."dbo"."stg_ecommerce"
  Found: "MY_DB"."dbo"."stg_ecommerce"
  
  > in macro load_cached_relation (macros\adapters\relation.sql)
  > called by macro materialization_view_sqlserver (macros\materializations\models\view\view.sql)
  > called by model stg_ecommerce (dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql)
[0m11:34:34.299400 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0eac1926-bd53-4456-b98a-681bde0fc2a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF801250D0>]}
[0m11:34:34.303399 [error] [Thread-1 (]: 2 of 13 ERROR creating sql view model dbo.stg_ecommerce ........................ [[31mERROR[0m in 0.14s]
[0m11:34:34.352398 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m11:34:34.355398 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.stg_ecommerce' to be skipped because of status 'error'.  Reason: Compilation Error in model stg_ecommerce (dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql)
  When searching for a relation, dbt found an approximate match. Instead of guessing 
  which relation to use, dbt will move on. Please delete "MY_DB"."dbo"."stg_ecommerce", or rename it to be less ambiguous.
  Searched for: "my_db"."dbo"."stg_ecommerce"
  Found: "MY_DB"."dbo"."stg_ecommerce"
  
  > in macro load_cached_relation (macros\adapters\relation.sql)
  > called by macro materialization_view_sqlserver (macros\materializations\models\view\view.sql)
  > called by model stg_ecommerce (dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql).
[0m11:34:34.359401 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m11:34:34.362399 [info ] [Thread-1 (]: 3 of 13 SKIP test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[33mSKIP[0m]
[0m11:34:34.366399 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m11:34:34.369398 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323
[0m11:34:34.370397 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6' to be skipped because of status 'skipped'. 
[0m11:34:34.372397 [info ] [Thread-1 (]: 4 of 13 SKIP test dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0  [[33mSKIP[0m]
[0m11:34:34.417410 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323
[0m11:34:34.420398 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d
[0m11:34:34.422403 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323' to be skipped because of status 'skipped'. 
[0m11:34:34.427399 [info ] [Thread-1 (]: 5 of 13 SKIP test dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0 .... [[33mSKIP[0m]
[0m11:34:34.482423 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d
[0m11:34:34.484397 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m11:34:34.485399 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d' to be skipped because of status 'skipped'. 
[0m11:34:34.488401 [info ] [Thread-1 (]: 6 of 13 SKIP test not_null_stg_ecommerce_Category .............................. [[33mSKIP[0m]
[0m11:34:34.495054 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m11:34:34.497403 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m11:34:34.498404 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14' to be skipped because of status 'skipped'. 
[0m11:34:34.501420 [info ] [Thread-1 (]: 7 of 13 SKIP test not_null_stg_ecommerce_Discount .............................. [[33mSKIP[0m]
[0m11:34:34.505407 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m11:34:34.509877 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m11:34:34.511241 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836' to be skipped because of status 'skipped'. 
[0m11:34:34.513246 [info ] [Thread-1 (]: 8 of 13 SKIP test not_null_stg_ecommerce_Final_Price ........................... [[33mSKIP[0m]
[0m11:34:34.597946 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m11:34:34.599947 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m11:34:34.600945 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc' to be skipped because of status 'skipped'. 
[0m11:34:34.602946 [info ] [Thread-1 (]: 9 of 13 SKIP test not_null_stg_ecommerce_Payment_Method ........................ [[33mSKIP[0m]
[0m11:34:34.606975 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m11:34:34.609950 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m11:34:34.612066 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d' to be skipped because of status 'skipped'. 
[0m11:34:34.613067 [info ] [Thread-1 (]: 10 of 13 SKIP test not_null_stg_ecommerce_Price ................................ [[33mSKIP[0m]
[0m11:34:34.617066 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m11:34:34.619292 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m11:34:34.620290 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a' to be skipped because of status 'skipped'. 
[0m11:34:34.622293 [info ] [Thread-1 (]: 11 of 13 SKIP test not_null_stg_ecommerce_Product_ID ........................... [[33mSKIP[0m]
[0m11:34:34.627829 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m11:34:34.629833 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m11:34:34.630834 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c' to be skipped because of status 'skipped'. 
[0m11:34:34.633830 [info ] [Thread-1 (]: 12 of 13 SKIP test not_null_stg_ecommerce_Purchase_Date ........................ [[33mSKIP[0m]
[0m11:34:34.678099 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m11:34:34.680100 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m11:34:34.681100 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307' to be skipped because of status 'skipped'. 
[0m11:34:34.684116 [info ] [Thread-1 (]: 13 of 13 SKIP test not_null_stg_ecommerce_User_ID .............................. [[33mSKIP[0m]
[0m11:34:34.714534 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m11:34:34.717780 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf' to be skipped because of status 'skipped'. 
[0m11:34:34.721780 [debug] [MainThread]: On master: COMMIT
[0m11:34:34.724786 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:34:34.727788 [debug] [MainThread]: Connection 'list_my_db' was properly closed.
[0m11:34:34.729802 [debug] [MainThread]: Connection 'list_my_db_dbo' was properly closed.
[0m11:34:34.731783 [debug] [MainThread]: Connection 'model.dbt_databricks_cicd.stg_ecommerce' was properly closed.
[0m11:34:34.734779 [info ] [MainThread]: 
[0m11:34:34.737781 [info ] [MainThread]: Finished running 11 data tests, 2 view models in 0 hours 0 minutes and 2.06 seconds (2.06s).
[0m11:34:34.745781 [debug] [MainThread]: Command end result
[0m11:34:35.025777 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m11:34:35.030987 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m11:34:35.043351 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m11:34:35.045351 [info ] [MainThread]: 
[0m11:34:35.047580 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m11:34:35.048582 [info ] [MainThread]: 
[0m11:34:35.050582 [error] [MainThread]: [31mFailure in model src_ecommerce (dbt_databricks_cicd/models\raw\sqlserver\src_ecommerce.sql)[0m
[0m11:34:35.053580 [error] [MainThread]:   Compilation Error in model src_ecommerce (dbt_databricks_cicd/models\raw\sqlserver\src_ecommerce.sql)
  When searching for a relation, dbt found an approximate match. Instead of guessing 
  which relation to use, dbt will move on. Please delete "MY_DB"."dbo"."src_ecommerce", or rename it to be less ambiguous.
  Searched for: "my_db"."dbo"."src_ecommerce"
  Found: "MY_DB"."dbo"."src_ecommerce"
  
  > in macro load_cached_relation (macros\adapters\relation.sql)
  > called by macro materialization_view_sqlserver (macros\materializations\models\view\view.sql)
  > called by model src_ecommerce (dbt_databricks_cicd/models\raw\sqlserver\src_ecommerce.sql)
[0m11:34:35.055587 [info ] [MainThread]: 
[0m11:34:35.059582 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\src_ecommerce.sql
[0m11:34:35.062819 [info ] [MainThread]: 
[0m11:34:35.064818 [error] [MainThread]: [31mFailure in model stg_ecommerce (dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql)[0m
[0m11:34:35.066819 [error] [MainThread]:   Compilation Error in model stg_ecommerce (dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql)
  When searching for a relation, dbt found an approximate match. Instead of guessing 
  which relation to use, dbt will move on. Please delete "MY_DB"."dbo"."stg_ecommerce", or rename it to be less ambiguous.
  Searched for: "my_db"."dbo"."stg_ecommerce"
  Found: "MY_DB"."dbo"."stg_ecommerce"
  
  > in macro load_cached_relation (macros\adapters\relation.sql)
  > called by macro materialization_view_sqlserver (macros\materializations\models\view\view.sql)
  > called by model stg_ecommerce (dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql)
[0m11:34:35.068816 [info ] [MainThread]: 
[0m11:34:35.071817 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql
[0m11:34:35.075837 [info ] [MainThread]: 
[0m11:34:35.080901 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=2 SKIP=11 NO-OP=0 TOTAL=13
[0m11:34:35.084896 [debug] [MainThread]: Command `dbt build` failed at 11:34:35.084896 after 17.75 seconds
[0m11:34:35.086897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF97D1290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF97D0ED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFF97D0250>]}
[0m11:34:35.088908 [debug] [MainThread]: Flushing usage events
[0m11:34:35.681276 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:25:03.348634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA667BA9D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA6680BA50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA667BB110>]}


============================== 12:25:03.360784 | c9011fa9-55a8-4da4-9aa3-c6d7fb53b43c ==============================
[0m12:25:03.360784 [info ] [MainThread]: Running with dbt=1.10.3
[0m12:25:03.362784 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt build', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:25:07.199864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c9011fa9-55a8-4da4-9aa3-c6d7fb53b43c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA6808FC50>]}
[0m12:25:07.328732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c9011fa9-55a8-4da4-9aa3-c6d7fb53b43c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA635548D0>]}
[0m12:25:07.330733 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m12:25:08.514742 [debug] [MainThread]: checksum: 1bfacb87e6914c9942cfa2c4badfc1df19d859fe8ec086286ef238a7d920f97b, vars: {}, profile: , target: , version: 1.10.3
[0m12:25:10.525683 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:25:10.526684 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:25:10.539328 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m12:25:10.625995 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c9011fa9-55a8-4da4-9aa3-c6d7fb53b43c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA68044E10>]}
[0m12:25:10.887683 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m12:25:10.898042 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m12:25:11.086986 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c9011fa9-55a8-4da4-9aa3-c6d7fb53b43c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA687C3F50>]}
[0m12:25:11.089991 [info ] [MainThread]: Found 2 models, 11 data tests, 1 source, 626 macros
[0m12:25:11.095995 [info ] [MainThread]: 
[0m12:25:11.098384 [info ] [MainThread]: Concurrency: 1 threads (target='sqlserver')
[0m12:25:11.100422 [info ] [MainThread]: 
[0m12:25:11.102419 [debug] [MainThread]: Acquiring new sqlserver connection 'master'
[0m12:25:11.113384 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db'
[0m12:25:11.150194 [debug] [ThreadPool]: dbt-sqlserver
[0m12:25:11.151188 [debug] [ThreadPool]: Using sqlserver connection "list_my_db"
[0m12:25:11.152194 [debug] [ThreadPool]: On list_my_db: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db"} */
USE [my_db];
    select  name as [schema]
    from sys.schemas with (nolock) 
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m12:25:11.153195 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:25:11.155194 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:11.349410 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m12:25:11.356843 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:25:11.360751 [debug] [ThreadPool]: On list_my_db: Close
[0m12:25:11.365753 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db_dbo'
[0m12:25:11.376751 [debug] [ThreadPool]: dbt-sqlserver
[0m12:25:11.378754 [debug] [ThreadPool]: Using sqlserver connection "list_my_db_dbo"
[0m12:25:11.381263 [debug] [ThreadPool]: On list_my_db_dbo: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db_dbo"} */
USE [my_db];
    with base as (
      select
        DB_NAME() as [database],
        t.name as [name],
        SCHEMA_NAME(t.schema_id) as [schema],
        'table' as table_type
      from sys.tables as t with (nolock)
      union all
      select
        DB_NAME() as [database],
        v.name as [name],
        SCHEMA_NAME(v.schema_id) as [schema],
        'view' as table_type
      from sys.views as v with (nolock)
    )
    select * from base
    where [schema] like 'dbo'
    
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m12:25:11.382272 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:25:11.384269 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:11.386196 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m12:25:11.447353 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:25:11.450360 [debug] [ThreadPool]: On list_my_db_dbo: ROLLBACK
[0m12:25:11.451361 [debug] [ThreadPool]: On list_my_db_dbo: Close
[0m12:25:11.455356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c9011fa9-55a8-4da4-9aa3-c6d7fb53b43c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA680532D0>]}
[0m12:25:11.457355 [debug] [MainThread]: On master: COMMIT
[0m12:25:11.468901 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m12:25:11.469901 [info ] [Thread-1 (]: 1 of 13 START sql view model dbo.src_ecommerce ................................. [RUN]
[0m12:25:11.472943 [debug] [Thread-1 (]: Acquiring new sqlserver connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m12:25:11.473904 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m12:25:11.491305 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m12:25:11.494269 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m12:25:11.560096 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m12:25:11.563098 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:25:11.564755 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."src_ecommerce__dbt_tmp" as 

select * from "my_db"."dbo"."ecommerce";
    ')


[0m12:25:11.567015 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:25:11.568021 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:11.574357 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:25:11.589538 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:11.602549 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:25:11.604512 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce__dbt_tmp', 'src_ecommerce'
[0m12:25:11.952604 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:11.996861 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: COMMIT
[0m12:25:12.013371 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."src_ecommerce__dbt_backup"
[0m12:25:12.030026 [debug] [Thread-1 (]: dbt-sqlserver
[0m12:25:12.031128 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:25:12.033117 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'src_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m12:25:12.089771 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:12.093773 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:25:12.094774 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."src_ecommerce__dbt_backup";');

[0m12:25:12.099910 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:12.106908 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: ROLLBACK
[0m12:25:12.107910 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: Close
[0m12:25:12.116407 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c9011fa9-55a8-4da4-9aa3-c6d7fb53b43c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA686618D0>]}
[0m12:25:12.117643 [info ] [Thread-1 (]: 1 of 13 OK created sql view model dbo.src_ecommerce ............................ [[32mOK[0m in 0.64s]
[0m12:25:12.120645 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m12:25:12.123645 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m12:25:12.125642 [info ] [Thread-1 (]: 2 of 13 START sql view model dbo.stg_ecommerce ................................. [RUN]
[0m12:25:12.127651 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m12:25:12.130825 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m12:25:12.143088 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:25:12.149495 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m12:25:12.170555 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:25:12.175552 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:25:12.181122 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."stg_ecommerce__dbt_tmp" as 

SELECT
  CAST(User_ID AS STRING) AS User_ID,
  CAST(Product_ID AS STRING) AS Product_ID,
  CAST(Category AS STRING) AS Category,
  CAST(Price AS DOUBLE) AS Price,
  CAST(Discount AS INT) AS Discount,
  CAST(Final_Price AS DOUBLE) AS Final_Price,
  CAST(Payment_Method AS STRING) AS Payment_Method,
  CAST(Purchase_Date AS DATE) AS Purchase_Date
FROM "my_db"."dbo"."ecommerce";
    ')


[0m12:25:12.184125 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:25:12.187373 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:12.190381 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:25:12.217198 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:12.221201 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: ROLLBACK
[0m12:25:12.224201 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: Close
[0m12:25:12.227200 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)")
[0m12:25:12.419438 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 336, in execute
    return self._execute_model(hook_ctx, context_config, model, context, materialization_macro)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 296, in _execute_model
    result = MacroGenerator(
             ^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 81, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 568, in execute
    while cursor.nextset():
          ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)")

[0m12:25:12.421441 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c9011fa9-55a8-4da4-9aa3-c6d7fb53b43c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA68869BD0>]}
[0m12:25:12.422448 [error] [Thread-1 (]: 2 of 13 ERROR creating sql view model dbo.stg_ecommerce ........................ [[31mERROR[0m in 0.29s]
[0m12:25:12.425436 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m12:25:12.427437 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.stg_ecommerce' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)").
[0m12:25:12.432570 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:25:12.433572 [info ] [Thread-1 (]: 3 of 13 SKIP test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[33mSKIP[0m]
[0m12:25:12.435572 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:25:12.436778 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323
[0m12:25:12.437782 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6' to be skipped because of status 'skipped'. 
[0m12:25:12.438781 [info ] [Thread-1 (]: 4 of 13 SKIP test dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0  [[33mSKIP[0m]
[0m12:25:12.440782 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323
[0m12:25:12.442782 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d
[0m12:25:12.442782 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323' to be skipped because of status 'skipped'. 
[0m12:25:12.444780 [info ] [Thread-1 (]: 5 of 13 SKIP test dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0 .... [[33mSKIP[0m]
[0m12:25:12.448269 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d
[0m12:25:12.449266 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:25:12.450266 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d' to be skipped because of status 'skipped'. 
[0m12:25:12.451270 [info ] [Thread-1 (]: 6 of 13 SKIP test not_null_stg_ecommerce_Category .............................. [[33mSKIP[0m]
[0m12:25:12.453269 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:25:12.455270 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:25:12.455270 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14' to be skipped because of status 'skipped'. 
[0m12:25:12.457307 [info ] [Thread-1 (]: 7 of 13 SKIP test not_null_stg_ecommerce_Discount .............................. [[33mSKIP[0m]
[0m12:25:12.459269 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:25:12.463308 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:25:12.465273 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836' to be skipped because of status 'skipped'. 
[0m12:25:12.467593 [info ] [Thread-1 (]: 8 of 13 SKIP test not_null_stg_ecommerce_Final_Price ........................... [[33mSKIP[0m]
[0m12:25:12.469597 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:25:12.471595 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:25:12.471595 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc' to be skipped because of status 'skipped'. 
[0m12:25:12.473598 [info ] [Thread-1 (]: 9 of 13 SKIP test not_null_stg_ecommerce_Payment_Method ........................ [[33mSKIP[0m]
[0m12:25:12.476600 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:25:12.480589 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:25:12.481627 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d' to be skipped because of status 'skipped'. 
[0m12:25:12.482587 [info ] [Thread-1 (]: 10 of 13 SKIP test not_null_stg_ecommerce_Price ................................ [[33mSKIP[0m]
[0m12:25:12.485639 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:25:12.486587 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:25:12.487597 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a' to be skipped because of status 'skipped'. 
[0m12:25:12.488628 [info ] [Thread-1 (]: 11 of 13 SKIP test not_null_stg_ecommerce_Product_ID ........................... [[33mSKIP[0m]
[0m12:25:12.490592 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:25:12.492591 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:25:12.496619 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c' to be skipped because of status 'skipped'. 
[0m12:25:12.498592 [info ] [Thread-1 (]: 12 of 13 SKIP test not_null_stg_ecommerce_Purchase_Date ........................ [[33mSKIP[0m]
[0m12:25:12.500586 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:25:12.501630 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:25:12.502627 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307' to be skipped because of status 'skipped'. 
[0m12:25:12.503590 [info ] [Thread-1 (]: 13 of 13 SKIP test not_null_stg_ecommerce_User_ID .............................. [[33mSKIP[0m]
[0m12:25:12.506628 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:25:12.507586 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf' to be skipped because of status 'skipped'. 
[0m12:25:12.512025 [debug] [MainThread]: On master: COMMIT
[0m12:25:12.513911 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:25:12.515910 [debug] [MainThread]: Connection 'list_my_db' was properly closed.
[0m12:25:12.517101 [debug] [MainThread]: Connection 'list_my_db_dbo' was properly closed.
[0m12:25:12.518142 [debug] [MainThread]: Connection 'model.dbt_databricks_cicd.stg_ecommerce' was properly closed.
[0m12:25:12.520147 [info ] [MainThread]: 
[0m12:25:12.521105 [info ] [MainThread]: Finished running 11 data tests, 2 view models in 0 hours 0 minutes and 1.42 seconds (1.42s).
[0m12:25:12.524144 [debug] [MainThread]: Command end result
[0m12:25:12.609576 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m12:25:12.615576 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m12:25:12.630141 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m12:25:12.632141 [info ] [MainThread]: 
[0m12:25:12.634144 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:25:12.636142 [info ] [MainThread]: 
[0m12:25:12.638664 [error] [MainThread]: [31mFailure in model stg_ecommerce (dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql)[0m
[0m12:25:12.640662 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)")
[0m12:25:12.642663 [info ] [MainThread]: 
[0m12:25:12.646862 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql
[0m12:25:12.648868 [info ] [MainThread]: 
[0m12:25:12.650863 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=11 NO-OP=0 TOTAL=13
[0m12:25:12.654862 [debug] [MainThread]: Command `dbt build` failed at 12:25:12.653864 after 9.50 seconds
[0m12:25:12.655874 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA5FFB1290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA5FFB0ED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001EA5FFB0250>]}
[0m12:25:12.657870 [debug] [MainThread]: Flushing usage events
[0m12:25:14.147881 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:29:34.343423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239B7257850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239B72ABFD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239B7257D10>]}


============================== 12:29:34.350460 | 7f064652-0764-4671-ad11-baeae0c97621 ==============================
[0m12:29:34.350460 [info ] [MainThread]: Running with dbt=1.10.3
[0m12:29:34.352696 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt build', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:29:35.361271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7f064652-0764-4671-ad11-baeae0c97621', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239B8B54850>]}
[0m12:29:35.487461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7f064652-0764-4671-ad11-baeae0c97621', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239B61B1E90>]}
[0m12:29:35.489472 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m12:29:36.317316 [debug] [MainThread]: checksum: 1bfacb87e6914c9942cfa2c4badfc1df19d859fe8ec086286ef238a7d920f97b, vars: {}, profile: , target: , version: 1.10.3
[0m12:29:36.847337 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:29:36.848340 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:29:36.860032 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m12:29:36.944799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7f064652-0764-4671-ad11-baeae0c97621', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239B89D5A50>]}
[0m12:29:37.214524 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m12:29:37.220567 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m12:29:37.320732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7f064652-0764-4671-ad11-baeae0c97621', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239B9263F90>]}
[0m12:29:37.322734 [info ] [MainThread]: Found 2 models, 11 data tests, 1 source, 626 macros
[0m12:29:37.327731 [info ] [MainThread]: 
[0m12:29:37.329730 [info ] [MainThread]: Concurrency: 1 threads (target='sqlserver')
[0m12:29:37.330738 [info ] [MainThread]: 
[0m12:29:37.332732 [debug] [MainThread]: Acquiring new sqlserver connection 'master'
[0m12:29:37.343966 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db'
[0m12:29:37.376791 [debug] [ThreadPool]: dbt-sqlserver
[0m12:29:37.377791 [debug] [ThreadPool]: Using sqlserver connection "list_my_db"
[0m12:29:37.378791 [debug] [ThreadPool]: On list_my_db: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db"} */
USE [my_db];
    select  name as [schema]
    from sys.schemas with (nolock) 
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m12:29:37.379791 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:29:37.381792 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:29:37.508144 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m12:29:37.514405 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:29:37.518123 [debug] [ThreadPool]: On list_my_db: Close
[0m12:29:37.521121 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db_dbo'
[0m12:29:37.532119 [debug] [ThreadPool]: dbt-sqlserver
[0m12:29:37.535092 [debug] [ThreadPool]: Using sqlserver connection "list_my_db_dbo"
[0m12:29:37.536093 [debug] [ThreadPool]: On list_my_db_dbo: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db_dbo"} */
USE [my_db];
    with base as (
      select
        DB_NAME() as [database],
        t.name as [name],
        SCHEMA_NAME(t.schema_id) as [schema],
        'table' as table_type
      from sys.tables as t with (nolock)
      union all
      select
        DB_NAME() as [database],
        v.name as [name],
        SCHEMA_NAME(v.schema_id) as [schema],
        'view' as table_type
      from sys.views as v with (nolock)
    )
    select * from base
    where [schema] like 'dbo'
    
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m12:29:37.537091 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:29:37.538264 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:29:37.540263 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m12:29:37.590145 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:29:37.592189 [debug] [ThreadPool]: On list_my_db_dbo: ROLLBACK
[0m12:29:37.594145 [debug] [ThreadPool]: On list_my_db_dbo: Close
[0m12:29:37.596144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7f064652-0764-4671-ad11-baeae0c97621', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239B8AE6390>]}
[0m12:29:37.598145 [debug] [MainThread]: On master: COMMIT
[0m12:29:37.606204 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m12:29:37.607505 [info ] [Thread-1 (]: 1 of 13 START sql view model dbo.src_ecommerce ................................. [RUN]
[0m12:29:37.609552 [debug] [Thread-1 (]: Acquiring new sqlserver connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m12:29:37.610546 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m12:29:37.626376 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m12:29:37.629378 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m12:29:37.686048 [debug] [Thread-1 (]: Compilation Error in model src_ecommerce (dbt_databricks_cicd/models\raw\sqlserver\src_ecommerce.sql)
  When searching for a relation, dbt found an approximate match. Instead of guessing 
  which relation to use, dbt will move on. Please delete "MY_DB"."dbo"."src_ecommerce", or rename it to be less ambiguous.
  Searched for: "my_db"."dbo"."src_ecommerce"
  Found: "MY_DB"."dbo"."src_ecommerce"
  
  > in macro load_cached_relation (macros\adapters\relation.sql)
  > called by macro materialization_view_sqlserver (macros\materializations\models\view\view.sql)
  > called by model src_ecommerce (dbt_databricks_cicd/models\raw\sqlserver\src_ecommerce.sql)
[0m12:29:37.692048 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f064652-0764-4671-ad11-baeae0c97621', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239B8D93E50>]}
[0m12:29:37.694047 [error] [Thread-1 (]: 1 of 13 ERROR creating sql view model dbo.src_ecommerce ........................ [[31mERROR[0m in 0.08s]
[0m12:29:37.698052 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m12:29:37.703079 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m12:29:37.705080 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.src_ecommerce' to be skipped because of status 'error'.  Reason: Compilation Error in model src_ecommerce (dbt_databricks_cicd/models\raw\sqlserver\src_ecommerce.sql)
  When searching for a relation, dbt found an approximate match. Instead of guessing 
  which relation to use, dbt will move on. Please delete "MY_DB"."dbo"."src_ecommerce", or rename it to be less ambiguous.
  Searched for: "my_db"."dbo"."src_ecommerce"
  Found: "MY_DB"."dbo"."src_ecommerce"
  
  > in macro load_cached_relation (macros\adapters\relation.sql)
  > called by macro materialization_view_sqlserver (macros\materializations\models\view\view.sql)
  > called by model src_ecommerce (dbt_databricks_cicd/models\raw\sqlserver\src_ecommerce.sql).
[0m12:29:37.706086 [info ] [Thread-1 (]: 2 of 13 START sql view model dbo.stg_ecommerce ................................. [RUN]
[0m12:29:37.709323 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m12:29:37.710367 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m12:29:37.722232 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:29:37.724232 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m12:29:37.776228 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:29:37.779188 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:29:37.780236 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."stg_ecommerce__dbt_tmp" as 

SELECT
  CAST(User_ID AS STRING) AS User_ID,
  CAST(Product_ID AS STRING) AS Product_ID,
  CAST(Category AS STRING) AS Category,
  CAST(Price AS DOUBLE) AS Price,
  CAST(Discount AS INT) AS Discount,
  CAST(Final_Price AS DOUBLE) AS Final_Price,
  CAST(Payment_Method AS STRING) AS Payment_Method,
  CAST(Purchase_Date AS DATE) AS Purchase_Date
FROM "my_db"."dbo"."ecommerce";
    ')


[0m12:29:37.781232 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:29:37.784195 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:29:37.791144 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:29:37.793143 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:29:37.795185 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: ROLLBACK
[0m12:29:37.797188 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: Close
[0m12:29:37.798144 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)")
[0m12:29:37.804621 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 336, in execute
    return self._execute_model(hook_ctx, context_config, model, context, materialization_macro)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 296, in _execute_model
    result = MacroGenerator(
             ^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 81, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 568, in execute
    while cursor.nextset():
          ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)")

[0m12:29:37.806580 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f064652-0764-4671-ad11-baeae0c97621', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239B92955D0>]}
[0m12:29:37.807807 [error] [Thread-1 (]: 2 of 13 ERROR creating sql view model dbo.stg_ecommerce ........................ [[31mERROR[0m in 0.10s]
[0m12:29:37.810826 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m12:29:37.812820 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.stg_ecommerce' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)").
[0m12:29:37.816814 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:29:37.819344 [info ] [Thread-1 (]: 3 of 13 SKIP test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[33mSKIP[0m]
[0m12:29:37.821347 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:29:37.824391 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323
[0m12:29:37.824391 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6' to be skipped because of status 'skipped'. 
[0m12:29:37.825344 [info ] [Thread-1 (]: 4 of 13 SKIP test dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0  [[33mSKIP[0m]
[0m12:29:37.828348 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323
[0m12:29:37.829388 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d
[0m12:29:37.830385 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323' to be skipped because of status 'skipped'. 
[0m12:29:37.831345 [info ] [Thread-1 (]: 5 of 13 SKIP test dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0 .... [[33mSKIP[0m]
[0m12:29:37.836789 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d
[0m12:29:37.838789 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:29:37.838789 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d' to be skipped because of status 'skipped'. 
[0m12:29:37.839789 [info ] [Thread-1 (]: 6 of 13 SKIP test not_null_stg_ecommerce_Category .............................. [[33mSKIP[0m]
[0m12:29:37.842795 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:29:37.844799 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:29:37.845829 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14' to be skipped because of status 'skipped'. 
[0m12:29:37.846828 [info ] [Thread-1 (]: 7 of 13 SKIP test not_null_stg_ecommerce_Discount .............................. [[33mSKIP[0m]
[0m12:29:37.851789 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:29:37.852992 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:29:37.854031 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836' to be skipped because of status 'skipped'. 
[0m12:29:37.854992 [info ] [Thread-1 (]: 8 of 13 SKIP test not_null_stg_ecommerce_Final_Price ........................... [[33mSKIP[0m]
[0m12:29:37.858242 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:29:37.860231 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:29:37.861231 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc' to be skipped because of status 'skipped'. 
[0m12:29:37.862280 [info ] [Thread-1 (]: 9 of 13 SKIP test not_null_stg_ecommerce_Payment_Method ........................ [[33mSKIP[0m]
[0m12:29:37.864233 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:29:37.867282 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:29:37.868777 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d' to be skipped because of status 'skipped'. 
[0m12:29:37.870801 [info ] [Thread-1 (]: 10 of 13 SKIP test not_null_stg_ecommerce_Price ................................ [[33mSKIP[0m]
[0m12:29:37.872860 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:29:37.874818 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:29:37.875821 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a' to be skipped because of status 'skipped'. 
[0m12:29:37.876779 [info ] [Thread-1 (]: 11 of 13 SKIP test not_null_stg_ecommerce_Product_ID ........................... [[33mSKIP[0m]
[0m12:29:37.879834 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:29:37.880785 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:29:37.881778 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c' to be skipped because of status 'skipped'. 
[0m12:29:37.884794 [info ] [Thread-1 (]: 12 of 13 SKIP test not_null_stg_ecommerce_Purchase_Date ........................ [[33mSKIP[0m]
[0m12:29:37.888578 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:29:37.890575 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:29:37.891574 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307' to be skipped because of status 'skipped'. 
[0m12:29:37.892576 [info ] [Thread-1 (]: 13 of 13 SKIP test not_null_stg_ecommerce_User_ID .............................. [[33mSKIP[0m]
[0m12:29:37.894573 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:29:37.895614 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf' to be skipped because of status 'skipped'. 
[0m12:29:37.899579 [debug] [MainThread]: On master: COMMIT
[0m12:29:37.902695 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:29:37.903699 [debug] [MainThread]: Connection 'list_my_db' was properly closed.
[0m12:29:37.904700 [debug] [MainThread]: Connection 'list_my_db_dbo' was properly closed.
[0m12:29:37.905699 [debug] [MainThread]: Connection 'model.dbt_databricks_cicd.stg_ecommerce' was properly closed.
[0m12:29:37.906905 [info ] [MainThread]: 
[0m12:29:37.908906 [info ] [MainThread]: Finished running 11 data tests, 2 view models in 0 hours 0 minutes and 0.58 seconds (0.58s).
[0m12:29:37.913911 [debug] [MainThread]: Command end result
[0m12:29:37.999060 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m12:29:38.004246 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m12:29:38.017827 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m12:29:38.019836 [info ] [MainThread]: 
[0m12:29:38.021829 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m12:29:38.023851 [info ] [MainThread]: 
[0m12:29:38.026835 [error] [MainThread]: [31mFailure in model src_ecommerce (dbt_databricks_cicd/models\raw\sqlserver\src_ecommerce.sql)[0m
[0m12:29:38.028838 [error] [MainThread]:   Compilation Error in model src_ecommerce (dbt_databricks_cicd/models\raw\sqlserver\src_ecommerce.sql)
  When searching for a relation, dbt found an approximate match. Instead of guessing 
  which relation to use, dbt will move on. Please delete "MY_DB"."dbo"."src_ecommerce", or rename it to be less ambiguous.
  Searched for: "my_db"."dbo"."src_ecommerce"
  Found: "MY_DB"."dbo"."src_ecommerce"
  
  > in macro load_cached_relation (macros\adapters\relation.sql)
  > called by macro materialization_view_sqlserver (macros\materializations\models\view\view.sql)
  > called by model src_ecommerce (dbt_databricks_cicd/models\raw\sqlserver\src_ecommerce.sql)
[0m12:29:38.030834 [info ] [MainThread]: 
[0m12:29:38.034836 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\sqlserver\src_ecommerce.sql
[0m12:29:38.037525 [info ] [MainThread]: 
[0m12:29:38.040529 [error] [MainThread]: [31mFailure in model stg_ecommerce (dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql)[0m
[0m12:29:38.042526 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)")
[0m12:29:38.044526 [info ] [MainThread]: 
[0m12:29:38.046528 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql
[0m12:29:38.048528 [info ] [MainThread]: 
[0m12:29:38.052242 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=2 SKIP=11 NO-OP=0 TOTAL=13
[0m12:29:38.057120 [debug] [MainThread]: Command `dbt build` failed at 12:29:38.057120 after 3.87 seconds
[0m12:29:38.059123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239B702C110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239B0A21290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239B8A44110>]}
[0m12:29:38.060128 [debug] [MainThread]: Flushing usage events
[0m12:29:38.671726 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:36:36.590794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCCA958410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCCA988090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCCA95BDD0>]}


============================== 12:36:36.597793 | da83edda-8cf1-442f-8624-b32be9f83fd1 ==============================
[0m12:36:36.597793 [info ] [MainThread]: Running with dbt=1.10.3
[0m12:36:36.599796 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m12:36:37.616085 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'da83edda-8cf1-442f-8624-b32be9f83fd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCCA0CA110>]}
[0m12:36:37.738185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'da83edda-8cf1-442f-8624-b32be9f83fd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCC98C1C10>]}
[0m12:36:37.740186 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m12:36:38.575300 [debug] [MainThread]: checksum: 1bfacb87e6914c9942cfa2c4badfc1df19d859fe8ec086286ef238a7d920f97b, vars: {}, profile: , target: , version: 1.10.3
[0m12:36:39.160122 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:36:39.162124 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:36:39.178488 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m12:36:39.318939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'da83edda-8cf1-442f-8624-b32be9f83fd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCCA99AC10>]}
[0m12:36:39.582246 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m12:36:39.588252 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m12:36:39.696034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'da83edda-8cf1-442f-8624-b32be9f83fd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCCC803F90>]}
[0m12:36:39.697031 [info ] [MainThread]: Found 2 models, 11 data tests, 1 source, 626 macros
[0m12:36:39.705025 [info ] [MainThread]: 
[0m12:36:39.706020 [info ] [MainThread]: Concurrency: 1 threads (target='sqlserver')
[0m12:36:39.708296 [info ] [MainThread]: 
[0m12:36:39.711268 [debug] [MainThread]: Acquiring new sqlserver connection 'master'
[0m12:36:39.723436 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db'
[0m12:36:39.758442 [debug] [ThreadPool]: dbt-sqlserver
[0m12:36:39.759440 [debug] [ThreadPool]: Using sqlserver connection "list_my_db"
[0m12:36:39.761439 [debug] [ThreadPool]: On list_my_db: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db"} */
USE [my_db];
    select  name as [schema]
    from sys.schemas with (nolock) 
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m12:36:39.762442 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:36:39.763441 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:39.881954 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m12:36:39.886961 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:36:39.889958 [debug] [ThreadPool]: On list_my_db: Close
[0m12:36:39.892959 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db_dbo'
[0m12:36:39.907189 [debug] [ThreadPool]: dbt-sqlserver
[0m12:36:39.908382 [debug] [ThreadPool]: Using sqlserver connection "list_my_db_dbo"
[0m12:36:39.909382 [debug] [ThreadPool]: On list_my_db_dbo: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db_dbo"} */
USE [my_db];
    with base as (
      select
        DB_NAME() as [database],
        t.name as [name],
        SCHEMA_NAME(t.schema_id) as [schema],
        'table' as table_type
      from sys.tables as t with (nolock)
      union all
      select
        DB_NAME() as [database],
        v.name as [name],
        SCHEMA_NAME(v.schema_id) as [schema],
        'view' as table_type
      from sys.views as v with (nolock)
    )
    select * from base
    where [schema] like 'dbo'
    
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m12:36:39.910381 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:36:39.912382 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:39.913383 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m12:36:39.968741 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:36:39.972735 [debug] [ThreadPool]: On list_my_db_dbo: ROLLBACK
[0m12:36:39.974735 [debug] [ThreadPool]: On list_my_db_dbo: Close
[0m12:36:39.977736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'da83edda-8cf1-442f-8624-b32be9f83fd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCCC117710>]}
[0m12:36:39.978755 [debug] [MainThread]: On master: COMMIT
[0m12:36:39.987739 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m12:36:39.989736 [info ] [Thread-1 (]: 1 of 13 START sql view model dbo.src_ecommerce ................................. [RUN]
[0m12:36:39.991735 [debug] [Thread-1 (]: Acquiring new sqlserver connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m12:36:39.993736 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m12:36:40.011734 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m12:36:40.014737 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m12:36:40.093801 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m12:36:40.096799 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:36:40.097830 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."src_ecommerce__dbt_tmp" as 

select * from "my_db"."dbo"."ecommerce";
    ')


[0m12:36:40.099812 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:36:40.102041 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:40.109248 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:36:40.121762 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:40.134735 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:36:40.136732 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce', 'src_ecommerce__dbt_backup'
[0m12:36:40.414900 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:40.423044 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:36:40.424047 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce__dbt_tmp', 'src_ecommerce'
[0m12:36:40.428012 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:40.461897 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: COMMIT
[0m12:36:40.475895 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."src_ecommerce__dbt_backup"
[0m12:36:40.492862 [debug] [Thread-1 (]: dbt-sqlserver
[0m12:36:40.493865 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:36:40.495865 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'src_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m12:36:40.539241 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:40.544236 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:36:40.545238 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."src_ecommerce__dbt_backup";');

[0m12:36:40.549238 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:40.555332 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: ROLLBACK
[0m12:36:40.556293 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: Close
[0m12:36:40.560626 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da83edda-8cf1-442f-8624-b32be9f83fd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCCC47EC90>]}
[0m12:36:40.562642 [info ] [Thread-1 (]: 1 of 13 OK created sql view model dbo.src_ecommerce ............................ [[32mOK[0m in 0.57s]
[0m12:36:40.564385 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m12:36:40.566382 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m12:36:40.567756 [info ] [Thread-1 (]: 2 of 13 START sql view model dbo.stg_ecommerce ................................. [RUN]
[0m12:36:40.569762 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m12:36:40.570763 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m12:36:40.578760 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:36:40.580763 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m12:36:40.589917 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:36:40.592880 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:36:40.593888 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."stg_ecommerce__dbt_tmp" as 

SELECT
  CAST(User_ID AS STRING) AS User_ID,
  CAST(Product_ID AS STRING) AS Product_ID,
  CAST(Category AS STRING) AS Category,
  CAST(Price AS DOUBLE) AS Price,
  CAST(Discount AS INT) AS Discount,
  CAST(Final_Price AS DOUBLE) AS Final_Price,
  CAST(Payment_Method AS STRING) AS Payment_Method,
  CAST(Purchase_Date AS DATE) AS Purchase_Date
FROM "my_db"."dbo"."ecommerce";
    ')


[0m12:36:40.595885 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:36:40.596883 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:40.598882 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:36:40.602804 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:40.604803 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: ROLLBACK
[0m12:36:40.605805 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: Close
[0m12:36:40.608023 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)")
[0m12:36:40.618128 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 336, in execute
    return self._execute_model(hook_ctx, context_config, model, context, materialization_macro)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\run.py", line 296, in _execute_model
    result = MacroGenerator(
             ^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 81, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 568, in execute
    while cursor.nextset():
          ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)")

[0m12:36:40.620138 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'da83edda-8cf1-442f-8624-b32be9f83fd1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCCC686410>]}
[0m12:36:40.622171 [error] [Thread-1 (]: 2 of 13 ERROR creating sql view model dbo.stg_ecommerce ........................ [[31mERROR[0m in 0.05s]
[0m12:36:40.624131 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m12:36:40.626129 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.stg_ecommerce' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)").
[0m12:36:40.628171 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:36:40.630135 [info ] [Thread-1 (]: 3 of 13 SKIP test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[33mSKIP[0m]
[0m12:36:40.633130 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:36:40.635158 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323
[0m12:36:40.636167 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6' to be skipped because of status 'skipped'. 
[0m12:36:40.637377 [info ] [Thread-1 (]: 4 of 13 SKIP test dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0  [[33mSKIP[0m]
[0m12:36:40.640390 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323
[0m12:36:40.642383 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d
[0m12:36:40.643385 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323' to be skipped because of status 'skipped'. 
[0m12:36:40.644383 [info ] [Thread-1 (]: 5 of 13 SKIP test dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0 .... [[33mSKIP[0m]
[0m12:36:40.646391 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d
[0m12:36:40.648384 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:36:40.650497 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d' to be skipped because of status 'skipped'. 
[0m12:36:40.652426 [info ] [Thread-1 (]: 6 of 13 SKIP test not_null_stg_ecommerce_Category .............................. [[33mSKIP[0m]
[0m12:36:40.655462 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:36:40.657965 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:36:40.658975 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14' to be skipped because of status 'skipped'. 
[0m12:36:40.659960 [info ] [Thread-1 (]: 7 of 13 SKIP test not_null_stg_ecommerce_Discount .............................. [[33mSKIP[0m]
[0m12:36:40.662966 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:36:40.663967 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:36:40.667030 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836' to be skipped because of status 'skipped'. 
[0m12:36:40.669199 [info ] [Thread-1 (]: 8 of 13 SKIP test not_null_stg_ecommerce_Final_Price ........................... [[33mSKIP[0m]
[0m12:36:40.672231 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:36:40.674215 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:36:40.675207 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc' to be skipped because of status 'skipped'. 
[0m12:36:40.676207 [info ] [Thread-1 (]: 9 of 13 SKIP test not_null_stg_ecommerce_Payment_Method ........................ [[33mSKIP[0m]
[0m12:36:40.678246 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:36:40.679244 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:36:40.680238 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d' to be skipped because of status 'skipped'. 
[0m12:36:40.685137 [info ] [Thread-1 (]: 10 of 13 SKIP test not_null_stg_ecommerce_Price ................................ [[33mSKIP[0m]
[0m12:36:40.688957 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:36:40.689990 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:36:40.690946 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a' to be skipped because of status 'skipped'. 
[0m12:36:40.691950 [info ] [Thread-1 (]: 11 of 13 SKIP test not_null_stg_ecommerce_Product_ID ........................... [[33mSKIP[0m]
[0m12:36:40.694946 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:36:40.695945 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:36:40.696946 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c' to be skipped because of status 'skipped'. 
[0m12:36:40.697957 [info ] [Thread-1 (]: 12 of 13 SKIP test not_null_stg_ecommerce_Purchase_Date ........................ [[33mSKIP[0m]
[0m12:36:40.703079 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:36:40.704164 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:36:40.705164 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307' to be skipped because of status 'skipped'. 
[0m12:36:40.706170 [info ] [Thread-1 (]: 13 of 13 SKIP test not_null_stg_ecommerce_User_ID .............................. [[33mSKIP[0m]
[0m12:36:40.709475 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:36:40.710415 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf' to be skipped because of status 'skipped'. 
[0m12:36:40.713413 [debug] [MainThread]: On master: COMMIT
[0m12:36:40.715414 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:36:40.717417 [debug] [MainThread]: Connection 'list_my_db' was properly closed.
[0m12:36:40.719591 [debug] [MainThread]: Connection 'list_my_db_dbo' was properly closed.
[0m12:36:40.721592 [debug] [MainThread]: Connection 'model.dbt_databricks_cicd.stg_ecommerce' was properly closed.
[0m12:36:40.722589 [info ] [MainThread]: 
[0m12:36:40.725624 [info ] [MainThread]: Finished running 11 data tests, 2 view models in 0 hours 0 minutes and 1.01 seconds (1.01s).
[0m12:36:40.729594 [debug] [MainThread]: Command end result
[0m12:36:40.812429 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m12:36:40.818781 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m12:36:40.830744 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m12:36:40.831744 [info ] [MainThread]: 
[0m12:36:40.834557 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m12:36:40.837365 [info ] [MainThread]: 
[0m12:36:40.839356 [error] [MainThread]: [31mFailure in model stg_ecommerce (dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql)[0m
[0m12:36:40.841354 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)")
[0m12:36:40.843357 [info ] [MainThread]: 
[0m12:36:40.845396 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql
[0m12:36:40.847350 [info ] [MainThread]: 
[0m12:36:40.851357 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=11 NO-OP=0 TOTAL=13
[0m12:36:40.855634 [debug] [MainThread]: Command `dbt build` failed at 12:36:40.855634 after 4.44 seconds
[0m12:36:40.856768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCC4130D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCC4130ED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CCC4131290>]}
[0m12:36:40.858773 [debug] [MainThread]: Flushing usage events
[0m12:36:41.448458 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:47:07.210549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F4B58EB0D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F4B58EB210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F4B58BDF50>]}


============================== 15:47:07.218575 | bc7b35be-352e-4b69-95c4-1914eebd8bca ==============================
[0m15:47:07.218575 [info ] [MainThread]: Running with dbt=1.10.3
[0m15:47:07.218575 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:47:08.258821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bc7b35be-352e-4b69-95c4-1914eebd8bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F4B714D5D0>]}
[0m15:47:08.393040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bc7b35be-352e-4b69-95c4-1914eebd8bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F4B4801E50>]}
[0m15:47:08.393040 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m15:47:09.224937 [debug] [MainThread]: checksum: 1bfacb87e6914c9942cfa2c4badfc1df19d859fe8ec086286ef238a7d920f97b, vars: {}, profile: , target: , version: 1.10.3
[0m15:47:09.783237 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:47:09.791241 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql
[0m15:47:11.090240 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m15:47:11.123445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bc7b35be-352e-4b69-95c4-1914eebd8bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F4B777C3D0>]}
[0m15:47:11.329902 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m15:47:11.329902 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m15:47:11.473033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bc7b35be-352e-4b69-95c4-1914eebd8bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F4B7B5F850>]}
[0m15:47:11.473033 [info ] [MainThread]: Found 2 models, 11 data tests, 1 source, 626 macros
[0m15:47:11.482022 [info ] [MainThread]: 
[0m15:47:11.482022 [info ] [MainThread]: Concurrency: 1 threads (target='sqlserver')
[0m15:47:11.490027 [info ] [MainThread]: 
[0m15:47:11.490027 [debug] [MainThread]: Acquiring new sqlserver connection 'master'
[0m15:47:11.515068 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db'
[0m15:47:11.555727 [debug] [ThreadPool]: dbt-sqlserver
[0m15:47:11.555727 [debug] [ThreadPool]: Using sqlserver connection "list_my_db"
[0m15:47:11.555727 [debug] [ThreadPool]: On list_my_db: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db"} */
USE [my_db];
    select  name as [schema]
    from sys.schemas with (nolock) 
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m15:47:11.555727 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:11.555727 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:47:11.697434 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m15:47:11.740103 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:47:11.748015 [debug] [ThreadPool]: On list_my_db: Close
[0m15:47:11.749655 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db_dbo'
[0m15:47:11.764143 [debug] [ThreadPool]: dbt-sqlserver
[0m15:47:11.764143 [debug] [ThreadPool]: Using sqlserver connection "list_my_db_dbo"
[0m15:47:11.764143 [debug] [ThreadPool]: On list_my_db_dbo: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db_dbo"} */
USE [my_db];
    with base as (
      select
        DB_NAME() as [database],
        t.name as [name],
        SCHEMA_NAME(t.schema_id) as [schema],
        'table' as table_type
      from sys.tables as t with (nolock)
      union all
      select
        DB_NAME() as [database],
        v.name as [name],
        SCHEMA_NAME(v.schema_id) as [schema],
        'view' as table_type
      from sys.views as v with (nolock)
    )
    select * from base
    where [schema] like 'dbo'
    
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m15:47:11.772393 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:11.772393 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:47:11.772393 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m15:47:12.463638 [debug] [ThreadPool]: SQL status: OK in 1.000 seconds
[0m15:47:12.463638 [debug] [ThreadPool]: On list_my_db_dbo: ROLLBACK
[0m15:47:12.463638 [debug] [ThreadPool]: On list_my_db_dbo: Close
[0m15:47:12.471638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bc7b35be-352e-4b69-95c4-1914eebd8bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F4B789B610>]}
[0m15:47:12.471638 [debug] [MainThread]: On master: COMMIT
[0m15:47:12.480605 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m15:47:12.480605 [info ] [Thread-1 (]: 1 of 13 START sql view model dbo.src_ecommerce ................................. [RUN]
[0m15:47:12.480605 [debug] [Thread-1 (]: Acquiring new sqlserver connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m15:47:12.480605 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m15:47:12.496639 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m15:47:12.496639 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m15:47:12.580686 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m15:47:12.588949 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:47:12.588949 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."src_ecommerce__dbt_tmp" as 

select * from "my_db"."dbo"."ecommerce";
    ')


[0m15:47:12.588949 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:47:12.597159 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:47:12.613916 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:47:12.798143 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:12.839884 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:47:12.839884 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce', 'src_ecommerce__dbt_backup'
[0m15:47:13.813391 [debug] [Thread-1 (]: SQL status: OK in 1.000 seconds
[0m15:47:13.849609 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:47:13.857576 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce__dbt_tmp', 'src_ecommerce'
[0m15:47:13.878911 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:13.929689 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: COMMIT
[0m15:47:13.945690 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."src_ecommerce__dbt_backup"
[0m15:47:13.970624 [debug] [Thread-1 (]: dbt-sqlserver
[0m15:47:13.970624 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:47:13.970624 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'src_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m15:47:14.437227 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:14.445638 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:47:14.446489 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."src_ecommerce__dbt_backup";');

[0m15:47:14.454493 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:14.462428 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: ROLLBACK
[0m15:47:14.462428 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: Close
[0m15:47:14.470429 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc7b35be-352e-4b69-95c4-1914eebd8bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F4B7721D10>]}
[0m15:47:14.470429 [info ] [Thread-1 (]: 1 of 13 OK created sql view model dbo.src_ecommerce ............................ [[32mOK[0m in 1.98s]
[0m15:47:14.470429 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m15:47:14.478626 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m15:47:14.478626 [info ] [Thread-1 (]: 2 of 13 START sql view model dbo.stg_ecommerce ................................. [RUN]
[0m15:47:14.478626 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m15:47:14.486627 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m15:47:14.495994 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:47:14.495994 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m15:47:14.513316 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:47:14.513316 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:47:14.513316 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."stg_ecommerce__dbt_tmp" as 

SELECT
    
        CAST(User_ID AS VARCHAR) AS User_ID,
        CAST(Product_ID AS VARCHAR) AS Product_ID,
        CAST(Category AS VARCHAR) AS Category,
        CAST(Price AS FLOAT) AS Price,
        CAST(Discount AS INT) AS Discount,
        CAST(Final_Price AS FLOAT) AS Final_Price,
        CAST(Payment_Method AS VARCHAR) AS Payment_Method,
        CAST(Purchase_Date AS DATE) AS Purchase_Date
    
FROM "my_db"."dbo"."ecommerce";
    ')


[0m15:47:14.513316 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:47:14.521318 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:47:14.521318 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:47:14.528945 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:14.536945 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:47:14.536945 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce__dbt_tmp', 'stg_ecommerce'
[0m15:47:15.011419 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:15.011419 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: COMMIT
[0m15:47:15.019461 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."stg_ecommerce__dbt_backup"
[0m15:47:15.019461 [debug] [Thread-1 (]: dbt-sqlserver
[0m15:47:15.019461 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:47:15.027542 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'stg_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m15:47:15.059553 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:15.059553 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:47:15.059553 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."stg_ecommerce__dbt_backup";');

[0m15:47:15.067681 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:15.067681 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: ROLLBACK
[0m15:47:15.067681 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: Close
[0m15:47:15.067681 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc7b35be-352e-4b69-95c4-1914eebd8bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F4B7B75E90>]}
[0m15:47:15.075542 [info ] [Thread-1 (]: 2 of 13 OK created sql view model dbo.stg_ecommerce ............................ [[32mOK[0m in 0.59s]
[0m15:47:15.077457 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m15:47:15.077457 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m15:47:15.077457 [info ] [Thread-1 (]: 3 of 13 START test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m15:47:15.085458 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6)
[0m15:47:15.085458 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m15:47:15.095696 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m15:47:15.103710 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m15:47:15.144161 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m15:47:15.152160 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m15:47:15.152160 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_13844]
   as 
    
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from "my_db"."dbo"."stg_ecommerce"
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    ''Credit Card'',''Net Banking'',''UPI'',''Debit Card'',''Cash on Delivery''
)



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_13844]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_13844]
  ;')
[0m15:47:15.152160 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:47:15.152160 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:47:15.152160 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:47:15.184878 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:15.194674 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: ROLLBACK
[0m15:47:15.194674 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: Close
[0m15:47:15.194674 [info ] [Thread-1 (]: 3 of 13 PASS accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[32mPASS[0m in 0.11s]
[0m15:47:15.194674 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m15:47:15.202713 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323
[0m15:47:15.202713 [info ] [Thread-1 (]: 4 of 13 START test dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0  [RUN]
[0m15:47:15.202713 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323)
[0m15:47:15.202713 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323
[0m15:47:15.219835 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323"
[0m15:47:15.219835 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323
[0m15:47:15.231266 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323"
[0m15:47:15.231266 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323"
[0m15:47:15.231266 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_036a55454a3e25613345e8c7a02686f7_10182]
   as 
    



select
    1
from "my_db"."dbo"."stg_ecommerce"

where not(Discount Discount >= 0)


  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_036a55454a3e25613345e8c7a02686f7_10182]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_036a55454a3e25613345e8c7a02686f7_10182]
  ;')
[0m15:47:15.231266 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:47:15.231266 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:47:15.239567 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:47:15.245012 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:15.245012 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323: ROLLBACK
[0m15:47:15.245012 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323: Close
[0m15:47:15.245012 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Discount'. (102) (SQLMoreResults)")
[0m15:47:15.294503 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Discount'. (102) (SQLMoreResults)")

[0m15:47:15.294503 [error] [Thread-1 (]: 4 of 13 ERROR dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0 .. [[31mERROR[0m in 0.09s]
[0m15:47:15.294503 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323
[0m15:47:15.302813 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Discount'. (102) (SQLMoreResults)").
[0m15:47:15.294503 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d
[0m15:47:15.302813 [info ] [Thread-1 (]: 5 of 13 START test dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0 ... [RUN]
[0m15:47:15.302813 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.bad1b98323, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d)
[0m15:47:15.310843 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d
[0m15:47:15.318820 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d"
[0m15:47:15.326837 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d
[0m15:47:15.334855 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d"
[0m15:47:15.334855 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d"
[0m15:47:15.334855 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_99e045d7ecae2edf84c969ac4172ab54_18824]
   as 
    



select
    1
from "my_db"."dbo"."stg_ecommerce"

where not(Price Price >= 0)


  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_99e045d7ecae2edf84c969ac4172ab54_18824]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_99e045d7ecae2edf84c969ac4172ab54_18824]
  ;')
[0m15:47:15.334855 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:47:15.342816 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:47:15.344794 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:47:15.347434 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:15.347434 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d: ROLLBACK
[0m15:47:15.347434 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d: Close
[0m15:47:15.355475 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Price'. (102) (SQLMoreResults)")
[0m15:47:15.362625 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Price'. (102) (SQLMoreResults)")

[0m15:47:15.362625 [error] [Thread-1 (]: 5 of 13 ERROR dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0 ........ [[31mERROR[0m in 0.06s]
[0m15:47:15.362625 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d
[0m15:47:15.370660 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Price'. (102) (SQLMoreResults)").
[0m15:47:15.362625 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m15:47:15.370660 [info ] [Thread-1 (]: 6 of 13 START test not_null_stg_ecommerce_Category ............................. [RUN]
[0m15:47:15.370660 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.13eba22b2d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14)
[0m15:47:15.379422 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m15:47:15.387466 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m15:47:15.394630 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m15:47:15.402904 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m15:47:15.402904 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m15:47:15.413085 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_13374]
   as 
    
    
    



select Category
from "my_db"."dbo"."stg_ecommerce"
where Category is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_13374]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_13374]
  ;')
[0m15:47:15.413085 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:47:15.413085 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:47:15.413085 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:47:15.429355 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:15.429355 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: ROLLBACK
[0m15:47:15.437395 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: Close
[0m15:47:15.437395 [info ] [Thread-1 (]: 6 of 13 PASS not_null_stg_ecommerce_Category ................................... [[32mPASS[0m in 0.07s]
[0m15:47:15.437395 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m15:47:15.445369 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m15:47:15.448528 [info ] [Thread-1 (]: 7 of 13 START test not_null_stg_ecommerce_Discount ............................. [RUN]
[0m15:47:15.448528 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836)
[0m15:47:15.448528 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m15:47:15.462500 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m15:47:15.462500 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m15:47:15.478253 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m15:47:15.478253 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m15:47:15.478253 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_2712]
   as 
    
    
    



select Discount
from "my_db"."dbo"."stg_ecommerce"
where Discount is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_2712]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_2712]
  ;')
[0m15:47:15.478253 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:47:15.478253 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:47:15.486280 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:47:15.493914 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:15.501916 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: ROLLBACK
[0m15:47:15.501916 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: Close
[0m15:47:15.501916 [info ] [Thread-1 (]: 7 of 13 PASS not_null_stg_ecommerce_Discount ................................... [[32mPASS[0m in 0.05s]
[0m15:47:15.501916 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m15:47:15.512418 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m15:47:15.512418 [info ] [Thread-1 (]: 8 of 13 START test not_null_stg_ecommerce_Final_Price .......................... [RUN]
[0m15:47:15.512418 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc)
[0m15:47:15.512418 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m15:47:15.520421 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m15:47:15.529265 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m15:47:15.529265 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m15:47:15.537307 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m15:47:15.537307 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_9400]
   as 
    
    
    



select Final_Price
from "my_db"."dbo"."stg_ecommerce"
where Final_Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_9400]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_9400]
  ;')
[0m15:47:15.537307 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:47:15.545307 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:47:15.545307 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:47:15.561420 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:15.561420 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: ROLLBACK
[0m15:47:15.561420 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: Close
[0m15:47:15.569312 [info ] [Thread-1 (]: 8 of 13 PASS not_null_stg_ecommerce_Final_Price ................................ [[32mPASS[0m in 0.05s]
[0m15:47:15.569312 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m15:47:15.575927 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m15:47:15.578348 [info ] [Thread-1 (]: 9 of 13 START test not_null_stg_ecommerce_Payment_Method ....................... [RUN]
[0m15:47:15.578348 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d)
[0m15:47:15.578348 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m15:47:15.586356 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m15:47:15.586356 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m15:47:15.595376 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m15:47:15.595376 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m15:47:15.603649 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_11577]
   as 
    
    
    



select Payment_Method
from "my_db"."dbo"."stg_ecommerce"
where Payment_Method is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_11577]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_11577]
  ;')
[0m15:47:15.603649 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:47:15.603649 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:47:15.603649 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:47:15.620834 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:15.620834 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: ROLLBACK
[0m15:47:15.628040 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: Close
[0m15:47:15.628040 [info ] [Thread-1 (]: 9 of 13 PASS not_null_stg_ecommerce_Payment_Method ............................. [[32mPASS[0m in 0.05s]
[0m15:47:15.628040 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m15:47:15.628040 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m15:47:15.636049 [info ] [Thread-1 (]: 10 of 13 START test not_null_stg_ecommerce_Price ............................... [RUN]
[0m15:47:15.636049 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a)
[0m15:47:15.636049 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m15:47:15.645012 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m15:47:15.653031 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m15:47:15.662374 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m15:47:15.662374 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m15:47:15.662374 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_5261]
   as 
    
    
    



select Price
from "my_db"."dbo"."stg_ecommerce"
where Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_5261]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_5261]
  ;')
[0m15:47:15.670375 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:47:15.670375 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:47:15.670375 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:47:15.695244 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:15.695244 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: ROLLBACK
[0m15:47:15.695244 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: Close
[0m15:47:15.695244 [info ] [Thread-1 (]: 10 of 13 PASS not_null_stg_ecommerce_Price ..................................... [[32mPASS[0m in 0.06s]
[0m15:47:15.703250 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m15:47:15.703250 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m15:47:15.711774 [info ] [Thread-1 (]: 11 of 13 START test not_null_stg_ecommerce_Product_ID .......................... [RUN]
[0m15:47:15.711774 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c)
[0m15:47:15.711774 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m15:47:15.719778 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m15:47:15.719778 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m15:47:15.729481 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m15:47:15.729481 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m15:47:15.737490 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_7968]
   as 
    
    
    



select Product_ID
from "my_db"."dbo"."stg_ecommerce"
where Product_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_7968]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_7968]
  ;')
[0m15:47:15.737490 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:47:15.737490 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:47:15.741935 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:47:15.752766 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:15.760112 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: ROLLBACK
[0m15:47:15.760112 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: Close
[0m15:47:15.760112 [info ] [Thread-1 (]: 11 of 13 PASS not_null_stg_ecommerce_Product_ID ................................ [[32mPASS[0m in 0.05s]
[0m15:47:15.760112 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m15:47:15.768116 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m15:47:15.768116 [info ] [Thread-1 (]: 12 of 13 START test not_null_stg_ecommerce_Purchase_Date ....................... [RUN]
[0m15:47:15.768116 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307)
[0m15:47:15.768116 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m15:47:15.786908 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m15:47:15.786908 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m15:47:15.795536 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m15:47:15.795536 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m15:47:15.795536 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_2324]
   as 
    
    
    



select Purchase_Date
from "my_db"."dbo"."stg_ecommerce"
where Purchase_Date is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_2324]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_2324]
  ;')
[0m15:47:15.803838 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:47:15.803838 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:47:15.803838 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:47:15.819842 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:15.827024 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: ROLLBACK
[0m15:47:15.827024 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: Close
[0m15:47:15.827024 [info ] [Thread-1 (]: 12 of 13 PASS not_null_stg_ecommerce_Purchase_Date ............................. [[32mPASS[0m in 0.06s]
[0m15:47:15.827024 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m15:47:15.835033 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m15:47:15.835033 [info ] [Thread-1 (]: 13 of 13 START test not_null_stg_ecommerce_User_ID ............................. [RUN]
[0m15:47:15.835033 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, now test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf)
[0m15:47:15.835033 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m15:47:15.844921 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m15:47:15.852925 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m15:47:15.861306 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m15:47:15.861306 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m15:47:15.861306 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_7185]
   as 
    
    
    



select User_ID
from "my_db"."dbo"."stg_ecommerce"
where User_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_7185]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_7185]
  ;')
[0m15:47:15.861306 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:47:15.861306 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:47:15.869309 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:47:15.877750 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:47:15.885758 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: ROLLBACK
[0m15:47:15.885758 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: Close
[0m15:47:15.885758 [info ] [Thread-1 (]: 13 of 13 PASS not_null_stg_ecommerce_User_ID ................................... [[32mPASS[0m in 0.05s]
[0m15:47:15.885758 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m15:47:15.894647 [debug] [MainThread]: On master: COMMIT
[0m15:47:15.894647 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:47:15.894647 [debug] [MainThread]: Connection 'list_my_db' was properly closed.
[0m15:47:15.894647 [debug] [MainThread]: Connection 'list_my_db_dbo' was properly closed.
[0m15:47:15.894647 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf' was properly closed.
[0m15:47:15.902657 [info ] [MainThread]: 
[0m15:47:15.902657 [info ] [MainThread]: Finished running 11 data tests, 2 view models in 0 hours 0 minutes and 4.41 seconds (4.41s).
[0m15:47:15.910756 [debug] [MainThread]: Command end result
[0m15:47:16.093192 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m15:47:16.101195 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m15:47:16.109814 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m15:47:16.109814 [info ] [MainThread]: 
[0m15:47:16.117818 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m15:47:16.117818 [info ] [MainThread]: 
[0m15:47:16.117818 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m15:47:16.128022 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Discount'. (102) (SQLMoreResults)")
[0m15:47:16.128022 [info ] [MainThread]: 
[0m15:47:16.128022 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\dbt_utils_expression_is_true_stg_ecommerce_Discount__Discount_0.sql
[0m15:47:16.128022 [info ] [MainThread]: 
[0m15:47:16.128022 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m15:47:16.136063 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Price'. (102) (SQLMoreResults)")
[0m15:47:16.136063 [info ] [MainThread]: 
[0m15:47:16.145286 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\dbt_utils_expression_is_true_stg_ecommerce_Price__Price_0.sql
[0m15:47:16.145286 [info ] [MainThread]: 
[0m15:47:16.145286 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=13
[0m15:47:16.153331 [debug] [MainThread]: Command `dbt build` failed at 15:47:16.145286 after 9.08 seconds
[0m15:47:16.153331 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F4AF0A0F10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F4AF0A0250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F4AF0A0D90>]}
[0m15:47:16.153331 [debug] [MainThread]: Flushing usage events
[0m15:47:18.248946 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:53:49.796787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026835000810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026835000D10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026835000050>]}


============================== 15:53:49.804616 | 36a39ca6-66ae-406e-941e-f5f7cdf8e9d9 ==============================
[0m15:53:49.804616 [info ] [MainThread]: Running with dbt=1.10.3
[0m15:53:49.812922 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'debug': 'False', 'version_check': 'True', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt build', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:53:50.796384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '36a39ca6-66ae-406e-941e-f5f7cdf8e9d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002683476A310>]}
[0m15:53:50.920205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '36a39ca6-66ae-406e-941e-f5f7cdf8e9d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026833F61DD0>]}
[0m15:53:50.920205 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m15:53:51.845185 [debug] [MainThread]: checksum: 1bfacb87e6914c9942cfa2c4badfc1df19d859fe8ec086286ef238a7d920f97b, vars: {}, profile: , target: , version: 1.10.3
[0m15:53:52.419026 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:53:52.419026 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://dbt_databricks_cicd/models\staging\databricks\schema.yml
[0m15:53:53.259395 [error] [MainThread]: Encountered an error:
Compilation Error in test accepted_values_stg_ecommerce_Payment_Method___if_target_name_sqlserver_Payment_Method_else_Payment_Method_endif___Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  macro 'dbt_macro__test_accepted_values' takes no keyword argument 'field'
[0m15:53:53.267417 [debug] [MainThread]: Command `dbt build` failed at 15:53:53.267417 after 3.61 seconds
[0m15:53:53.270655 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026835003790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002683505AE10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026836EC9990>]}
[0m15:53:53.270655 [debug] [MainThread]: Flushing usage events
[0m15:53:53.869511 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:55:23.371173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259EA6A6CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259EA6A7F50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259EA6A5810>]}


============================== 15:55:23.379102 | ab72bf55-bb1a-44c6-92a4-bbff9a4a5430 ==============================
[0m15:55:23.379102 [info ] [MainThread]: Running with dbt=1.10.3
[0m15:55:23.379102 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt build', 'send_anonymous_usage_stats': 'True'}
[0m15:55:24.378094 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ab72bf55-bb1a-44c6-92a4-bbff9a4a5430', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259E9E0A290>]}
[0m15:55:24.494694 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ab72bf55-bb1a-44c6-92a4-bbff9a4a5430', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259E9601D90>]}
[0m15:55:24.494694 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m15:55:25.334032 [debug] [MainThread]: checksum: 1bfacb87e6914c9942cfa2c4badfc1df19d859fe8ec086286ef238a7d920f97b, vars: {}, profile: , target: , version: 1.10.3
[0m15:55:25.867913 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:55:25.867913 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://dbt_databricks_cicd/models\staging\databricks\schema.yml
[0m15:55:26.957547 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m15:55:26.984727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ab72bf55-bb1a-44c6-92a4-bbff9a4a5430', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259EAF8C1D0>]}
[0m15:55:27.175642 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m15:55:27.183924 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m15:55:27.292361 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ab72bf55-bb1a-44c6-92a4-bbff9a4a5430', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259EC9EFF10>]}
[0m15:55:27.292361 [info ] [MainThread]: Found 2 models, 11 data tests, 1 source, 626 macros
[0m15:55:27.300422 [info ] [MainThread]: 
[0m15:55:27.300422 [info ] [MainThread]: Concurrency: 1 threads (target='sqlserver')
[0m15:55:27.308424 [info ] [MainThread]: 
[0m15:55:27.308424 [debug] [MainThread]: Acquiring new sqlserver connection 'master'
[0m15:55:27.324426 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db'
[0m15:55:27.350643 [debug] [ThreadPool]: dbt-sqlserver
[0m15:55:27.350643 [debug] [ThreadPool]: Using sqlserver connection "list_my_db"
[0m15:55:27.359308 [debug] [ThreadPool]: On list_my_db: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db"} */
USE [my_db];
    select  name as [schema]
    from sys.schemas with (nolock) 
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m15:55:27.359308 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:55:27.359308 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:55:27.466373 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m15:55:27.475518 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:55:27.475518 [debug] [ThreadPool]: On list_my_db: Close
[0m15:55:27.475518 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db_dbo'
[0m15:55:27.492222 [debug] [ThreadPool]: dbt-sqlserver
[0m15:55:27.492222 [debug] [ThreadPool]: Using sqlserver connection "list_my_db_dbo"
[0m15:55:27.492222 [debug] [ThreadPool]: On list_my_db_dbo: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db_dbo"} */
USE [my_db];
    with base as (
      select
        DB_NAME() as [database],
        t.name as [name],
        SCHEMA_NAME(t.schema_id) as [schema],
        'table' as table_type
      from sys.tables as t with (nolock)
      union all
      select
        DB_NAME() as [database],
        v.name as [name],
        SCHEMA_NAME(v.schema_id) as [schema],
        'view' as table_type
      from sys.views as v with (nolock)
    )
    select * from base
    where [schema] like 'dbo'
    
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m15:55:27.492222 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:55:27.500223 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:55:27.500223 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m15:55:27.549696 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:55:27.549696 [debug] [ThreadPool]: On list_my_db_dbo: ROLLBACK
[0m15:55:27.557705 [debug] [ThreadPool]: On list_my_db_dbo: Close
[0m15:55:27.557705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ab72bf55-bb1a-44c6-92a4-bbff9a4a5430', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259EC6822D0>]}
[0m15:55:27.557705 [debug] [MainThread]: On master: COMMIT
[0m15:55:27.565700 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m15:55:27.573738 [info ] [Thread-1 (]: 1 of 13 START sql view model dbo.src_ecommerce ................................. [RUN]
[0m15:55:27.576171 [debug] [Thread-1 (]: Acquiring new sqlserver connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m15:55:27.576171 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m15:55:27.592900 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m15:55:27.592900 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m15:55:27.666237 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m15:55:27.666237 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:55:27.666237 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."src_ecommerce__dbt_tmp" as 

select * from "my_db"."dbo"."ecommerce";
    ')


[0m15:55:27.666237 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:55:27.666237 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:55:27.675182 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:55:27.683181 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:27.691540 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:55:27.699588 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce', 'src_ecommerce__dbt_backup'
[0m15:55:27.907922 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:27.915967 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:55:27.915967 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce__dbt_tmp', 'src_ecommerce'
[0m15:55:27.924891 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:27.949236 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: COMMIT
[0m15:55:27.966352 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."src_ecommerce__dbt_backup"
[0m15:55:27.974474 [debug] [Thread-1 (]: dbt-sqlserver
[0m15:55:27.982726 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:55:27.982726 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'src_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m15:55:28.008269 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:28.016289 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:55:28.016289 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."src_ecommerce__dbt_backup";');

[0m15:55:28.024848 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:28.024848 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: ROLLBACK
[0m15:55:28.024848 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: Close
[0m15:55:28.032891 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab72bf55-bb1a-44c6-92a4-bbff9a4a5430', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259ECA31690>]}
[0m15:55:28.032891 [info ] [Thread-1 (]: 1 of 13 OK created sql view model dbo.src_ecommerce ............................ [[32mOK[0m in 0.46s]
[0m15:55:28.040856 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m15:55:28.040856 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m15:55:28.040856 [info ] [Thread-1 (]: 2 of 13 START sql view model dbo.stg_ecommerce ................................. [RUN]
[0m15:55:28.048858 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m15:55:28.048858 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m15:55:28.056865 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:55:28.056865 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m15:55:28.064856 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:55:28.072856 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:55:28.076931 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."stg_ecommerce__dbt_tmp" as 

SELECT
    
        CAST(User_ID AS VARCHAR) AS User_ID,
        CAST(Product_ID AS VARCHAR) AS Product_ID,
        CAST(Category AS VARCHAR) AS Category,
        CAST(Price AS FLOAT) AS Price,
        CAST(Discount AS INT) AS Discount,
        CAST(Final_Price AS FLOAT) AS Final_Price,
        CAST(Payment_Method AS VARCHAR) AS Payment_Method,
        CAST(Purchase_Date AS DATE) AS Purchase_Date
    
FROM "my_db"."dbo"."ecommerce";
    ')


[0m15:55:28.076931 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:55:28.076931 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:55:28.076931 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:55:28.084941 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:28.092017 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:55:28.092017 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce', 'stg_ecommerce__dbt_backup'
[0m15:55:28.100062 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:28.107926 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:55:28.107926 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce__dbt_tmp', 'stg_ecommerce'
[0m15:55:28.115924 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:28.115924 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: COMMIT
[0m15:55:28.123930 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."stg_ecommerce__dbt_backup"
[0m15:55:28.131966 [debug] [Thread-1 (]: dbt-sqlserver
[0m15:55:28.131966 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:55:28.131966 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'stg_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m15:55:28.149188 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:28.149188 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:55:28.157931 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."stg_ecommerce__dbt_backup";');

[0m15:55:28.157931 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:28.165970 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: ROLLBACK
[0m15:55:28.165970 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: Close
[0m15:55:28.165970 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab72bf55-bb1a-44c6-92a4-bbff9a4a5430', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259ED10C0D0>]}
[0m15:55:28.173934 [info ] [Thread-1 (]: 2 of 13 OK created sql view model dbo.stg_ecommerce ............................ [[32mOK[0m in 0.12s]
[0m15:55:28.175049 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m15:55:28.175049 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce__Payment_Method___Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.795b5e17fb
[0m15:55:28.175049 [info ] [Thread-1 (]: 3 of 13 START test accepted_values_stg_ecommerce__Payment_Method___Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m15:55:28.183056 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now test.dbt_databricks_cicd.accepted_values_stg_ecommerce__Payment_Method___Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.795b5e17fb)
[0m15:55:28.183056 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.accepted_values_stg_ecommerce__Payment_Method___Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.795b5e17fb
[0m15:55:28.192407 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce__Payment_Method___Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.795b5e17fb"
[0m15:55:28.192407 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.accepted_values_stg_ecommerce__Payment_Method___Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.795b5e17fb
[0m15:55:28.233300 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce__Payment_Method___Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.795b5e17fb"
[0m15:55:28.241034 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.accepted_values_stg_ecommerce__Payment_Method___Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.795b5e17fb"
[0m15:55:28.241034 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce__Payment_Method___Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.795b5e17fb: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.accepted_values_stg_ecommerce__Payment_Method___Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.795b5e17fb"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_68d30dec259a16bd0007d3ca710845eb_9572]
   as 
    
    
    

with all_values as (

    select
        [Payment_Method] as value_field,
        count(*) as n_records

    from "my_db"."dbo"."stg_ecommerce"
    group by [Payment_Method]

)

select *
from all_values
where value_field not in (
    ''Credit Card'',''Net Banking'',''UPI'',''Debit Card'',''Cash on Delivery''
)



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_68d30dec259a16bd0007d3ca710845eb_9572]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_68d30dec259a16bd0007d3ca710845eb_9572]
  ;')
[0m15:55:28.241034 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:55:28.241034 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:55:28.241034 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:55:28.265657 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:28.275349 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce__Payment_Method___Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.795b5e17fb: ROLLBACK
[0m15:55:28.275349 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce__Payment_Method___Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.795b5e17fb: Close
[0m15:55:28.275349 [info ] [Thread-1 (]: 3 of 13 PASS accepted_values_stg_ecommerce__Payment_Method___Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[32mPASS[0m in 0.09s]
[0m15:55:28.283394 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce__Payment_Method___Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.795b5e17fb
[0m15:55:28.283394 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___if_target_name_sqlserver_Discount_0_else_Discount_0_endif_.4c9b307ea8
[0m15:55:28.283394 [info ] [Thread-1 (]: 4 of 13 START test dbt_utils_expression_is_true_stg_ecommerce_Discount___if_target_name_sqlserver_Discount_0_else_Discount_0_endif_  [RUN]
[0m15:55:28.292427 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.accepted_values_stg_ecommerce__Payment_Method___Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.795b5e17fb, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___if_target_name_sqlserver_Discount_0_else_Discount_0_endif_.4c9b307ea8)
[0m15:55:28.292427 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___if_target_name_sqlserver_Discount_0_else_Discount_0_endif_.4c9b307ea8
[0m15:55:28.308428 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___if_target_name_sqlserver_Discount_0_else_Discount_0_endif_.4c9b307ea8"
[0m15:55:28.308428 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___if_target_name_sqlserver_Discount_0_else_Discount_0_endif_.4c9b307ea8
[0m15:55:28.316435 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___if_target_name_sqlserver_Discount_0_else_Discount_0_endif_.4c9b307ea8"
[0m15:55:28.324431 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___if_target_name_sqlserver_Discount_0_else_Discount_0_endif_.4c9b307ea8"
[0m15:55:28.324431 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___if_target_name_sqlserver_Discount_0_else_Discount_0_endif_.4c9b307ea8: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___if_target_name_sqlserver_Discount_0_else_Discount_0_endif_.4c9b307ea8"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_3feee64598b3e11c86203428d3233835_15054]
   as 
    



select
    1
from "my_db"."dbo"."stg_ecommerce"

where not(Discount [Discount] >= 0)


  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_3feee64598b3e11c86203428d3233835_15054]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_3feee64598b3e11c86203428d3233835_15054]
  ;')
[0m15:55:28.324431 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:55:28.324431 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:55:28.324431 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:55:28.332428 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:28.332428 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___if_target_name_sqlserver_Discount_0_else_Discount_0_endif_.4c9b307ea8: ROLLBACK
[0m15:55:28.332428 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___if_target_name_sqlserver_Discount_0_else_Discount_0_endif_.4c9b307ea8: Close
[0m15:55:28.341038 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\dbt_utils_expression_is_true_s_d3e9ed7c35cd0fd765aa015e707708e5.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Discount'. (102) (SQLMoreResults)")
[0m15:55:28.349040 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Discount'. (102) (SQLMoreResults)")

[0m15:55:28.349040 [error] [Thread-1 (]: 4 of 13 ERROR dbt_utils_expression_is_true_stg_ecommerce_Discount___if_target_name_sqlserver_Discount_0_else_Discount_0_endif_  [[31mERROR[0m in 0.06s]
[0m15:55:28.349040 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___if_target_name_sqlserver_Discount_0_else_Discount_0_endif_.4c9b307ea8
[0m15:55:28.357043 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___if_target_name_sqlserver_Price_0_else_Price_0_endif_.6f939c2da1
[0m15:55:28.359724 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___if_target_name_sqlserver_Discount_0_else_Discount_0_endif_.4c9b307ea8' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Discount'. (102) (SQLMoreResults)").
[0m15:55:28.359724 [info ] [Thread-1 (]: 5 of 13 START test dbt_utils_expression_is_true_stg_ecommerce_Price___if_target_name_sqlserver_Price_0_else_Price_0_endif_  [RUN]
[0m15:55:28.359724 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___if_target_name_sqlserver_Discount_0_else_Discount_0_endif_.4c9b307ea8, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___if_target_name_sqlserver_Price_0_else_Price_0_endif_.6f939c2da1)
[0m15:55:28.359724 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___if_target_name_sqlserver_Price_0_else_Price_0_endif_.6f939c2da1
[0m15:55:28.378924 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___if_target_name_sqlserver_Price_0_else_Price_0_endif_.6f939c2da1"
[0m15:55:28.378924 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___if_target_name_sqlserver_Price_0_else_Price_0_endif_.6f939c2da1
[0m15:55:28.391866 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___if_target_name_sqlserver_Price_0_else_Price_0_endif_.6f939c2da1"
[0m15:55:28.391866 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___if_target_name_sqlserver_Price_0_else_Price_0_endif_.6f939c2da1"
[0m15:55:28.391866 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___if_target_name_sqlserver_Price_0_else_Price_0_endif_.6f939c2da1: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___if_target_name_sqlserver_Price_0_else_Price_0_endif_.6f939c2da1"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_62decf62f91a622cc046af79e15cbad8_16344]
   as 
    



select
    1
from "my_db"."dbo"."stg_ecommerce"

where not(Price [Price] >= 0)


  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_62decf62f91a622cc046af79e15cbad8_16344]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_62decf62f91a622cc046af79e15cbad8_16344]
  ;')
[0m15:55:28.391866 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:55:28.391866 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:55:28.399868 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:55:28.399868 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:28.407716 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___if_target_name_sqlserver_Price_0_else_Price_0_endif_.6f939c2da1: ROLLBACK
[0m15:55:28.407716 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___if_target_name_sqlserver_Price_0_else_Price_0_endif_.6f939c2da1: Close
[0m15:55:28.407716 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\dbt_utils_expression_is_true_s_35189776310bf3b6a92f0151387a1ac1.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Price'. (102) (SQLMoreResults)")
[0m15:55:28.415760 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Price'. (102) (SQLMoreResults)")

[0m15:55:28.415760 [error] [Thread-1 (]: 5 of 13 ERROR dbt_utils_expression_is_true_stg_ecommerce_Price___if_target_name_sqlserver_Price_0_else_Price_0_endif_  [[31mERROR[0m in 0.06s]
[0m15:55:28.415760 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___if_target_name_sqlserver_Price_0_else_Price_0_endif_.6f939c2da1
[0m15:55:28.423729 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___if_target_name_sqlserver_Price_0_else_Price_0_endif_.6f939c2da1' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Price'. (102) (SQLMoreResults)").
[0m15:55:28.415760 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m15:55:28.426014 [info ] [Thread-1 (]: 6 of 13 START test not_null_stg_ecommerce_Category ............................. [RUN]
[0m15:55:28.426014 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___if_target_name_sqlserver_Price_0_else_Price_0_endif_.6f939c2da1, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14)
[0m15:55:28.426014 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m15:55:28.445004 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m15:55:28.445004 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m15:55:28.458516 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m15:55:28.458516 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m15:55:28.458516 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_12217]
   as 
    
    
    



select Category
from "my_db"."dbo"."stg_ecommerce"
where Category is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_12217]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_12217]
  ;')
[0m15:55:28.466518 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:55:28.466518 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:55:28.466518 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:55:28.482375 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:28.482375 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: ROLLBACK
[0m15:55:28.482375 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: Close
[0m15:55:28.482375 [info ] [Thread-1 (]: 6 of 13 PASS not_null_stg_ecommerce_Category ................................... [[32mPASS[0m in 0.06s]
[0m15:55:28.491253 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m15:55:28.491253 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m15:55:28.491253 [info ] [Thread-1 (]: 7 of 13 START test not_null_stg_ecommerce_Discount ............................. [RUN]
[0m15:55:28.491253 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836)
[0m15:55:28.499253 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m15:55:28.509721 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m15:55:28.509721 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m15:55:28.517764 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m15:55:28.517764 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m15:55:28.517764 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_8238]
   as 
    
    
    



select Discount
from "my_db"."dbo"."stg_ecommerce"
where Discount is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_8238]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_8238]
  ;')
[0m15:55:28.526280 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:55:28.526280 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:55:28.526280 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:55:28.542024 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:28.550069 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: ROLLBACK
[0m15:55:28.550069 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: Close
[0m15:55:28.550069 [info ] [Thread-1 (]: 7 of 13 PASS not_null_stg_ecommerce_Discount ................................... [[32mPASS[0m in 0.06s]
[0m15:55:28.550069 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m15:55:28.558113 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m15:55:28.558113 [info ] [Thread-1 (]: 8 of 13 START test not_null_stg_ecommerce_Final_Price .......................... [RUN]
[0m15:55:28.558113 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc)
[0m15:55:28.558113 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m15:55:28.576000 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m15:55:28.576000 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m15:55:28.576000 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m15:55:28.584045 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m15:55:28.584045 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_2883]
   as 
    
    
    



select Final_Price
from "my_db"."dbo"."stg_ecommerce"
where Final_Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_2883]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_2883]
  ;')
[0m15:55:28.584045 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:55:28.584045 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:55:28.593171 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:55:28.601173 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:28.608085 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: ROLLBACK
[0m15:55:28.608085 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: Close
[0m15:55:28.608085 [info ] [Thread-1 (]: 8 of 13 PASS not_null_stg_ecommerce_Final_Price ................................ [[32mPASS[0m in 0.05s]
[0m15:55:28.616088 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m15:55:28.616088 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m15:55:28.616088 [info ] [Thread-1 (]: 9 of 13 START test not_null_stg_ecommerce_Price ................................ [RUN]
[0m15:55:28.616088 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a)
[0m15:55:28.624104 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m15:55:28.625972 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m15:55:28.634020 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m15:55:28.642689 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m15:55:28.642689 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m15:55:28.642689 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_7426]
   as 
    
    
    



select Price
from "my_db"."dbo"."stg_ecommerce"
where Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_7426]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_7426]
  ;')
[0m15:55:28.642689 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:55:28.650736 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:55:28.650736 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:55:28.666133 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:28.666133 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: ROLLBACK
[0m15:55:28.673951 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: Close
[0m15:55:28.673951 [info ] [Thread-1 (]: 9 of 13 PASS not_null_stg_ecommerce_Price ...................................... [[32mPASS[0m in 0.06s]
[0m15:55:28.673951 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m15:55:28.673951 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m15:55:28.681952 [info ] [Thread-1 (]: 10 of 13 START test not_null_stg_ecommerce_Product_ID .......................... [RUN]
[0m15:55:28.681952 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c)
[0m15:55:28.681952 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m15:55:28.691284 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m15:55:28.699290 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m15:55:28.699290 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m15:55:28.709939 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m15:55:28.709939 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_14848]
   as 
    
    
    



select Product_ID
from "my_db"."dbo"."stg_ecommerce"
where Product_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_14848]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_14848]
  ;')
[0m15:55:28.709939 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:55:28.709939 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:55:28.709939 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:55:28.725457 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:28.733788 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: ROLLBACK
[0m15:55:28.733788 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: Close
[0m15:55:28.733788 [info ] [Thread-1 (]: 10 of 13 PASS not_null_stg_ecommerce_Product_ID ................................ [[32mPASS[0m in 0.05s]
[0m15:55:28.733788 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m15:55:28.741904 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m15:55:28.741904 [info ] [Thread-1 (]: 11 of 13 START test not_null_stg_ecommerce_Purchase_Date ....................... [RUN]
[0m15:55:28.741904 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307)
[0m15:55:28.741904 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m15:55:28.759358 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m15:55:28.759358 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m15:55:28.767361 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m15:55:28.767361 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m15:55:28.767361 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_17010]
   as 
    
    
    



select Purchase_Date
from "my_db"."dbo"."stg_ecommerce"
where Purchase_Date is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_17010]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_17010]
  ;')
[0m15:55:28.775288 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:55:28.775288 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:55:28.775288 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:55:28.790535 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:28.790535 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: ROLLBACK
[0m15:55:28.790535 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: Close
[0m15:55:28.798576 [info ] [Thread-1 (]: 11 of 13 PASS not_null_stg_ecommerce_Purchase_Date ............................. [[32mPASS[0m in 0.05s]
[0m15:55:28.798576 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m15:55:28.806538 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m15:55:28.806538 [info ] [Thread-1 (]: 12 of 13 START test not_null_stg_ecommerce_User_ID ............................. [RUN]
[0m15:55:28.806538 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, now test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf)
[0m15:55:28.806538 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m15:55:28.822535 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m15:55:28.822535 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m15:55:28.830540 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m15:55:28.830540 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m15:55:28.830540 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_2361]
   as 
    
    
    



select User_ID
from "my_db"."dbo"."stg_ecommerce"
where User_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_2361]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_2361]
  ;')
[0m15:55:28.830540 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:55:28.838683 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:55:28.842664 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:55:28.858057 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:28.858057 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: ROLLBACK
[0m15:55:28.858057 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: Close
[0m15:55:28.866098 [info ] [Thread-1 (]: 12 of 13 PASS not_null_stg_ecommerce_User_ID ................................... [[32mPASS[0m in 0.05s]
[0m15:55:28.866098 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m15:55:28.866098 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce__Payment_Method_.e975cf5289
[0m15:55:28.866098 [info ] [Thread-1 (]: 13 of 13 START test not_null_stg_ecommerce__Payment_Method_ .................... [RUN]
[0m15:55:28.875451 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, now test.dbt_databricks_cicd.not_null_stg_ecommerce__Payment_Method_.e975cf5289)
[0m15:55:28.875451 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce__Payment_Method_.e975cf5289
[0m15:55:28.883487 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce__Payment_Method_.e975cf5289"
[0m15:55:28.883487 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce__Payment_Method_.e975cf5289
[0m15:55:28.891874 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce__Payment_Method_.e975cf5289"
[0m15:55:28.891874 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce__Payment_Method_.e975cf5289"
[0m15:55:28.899876 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce__Payment_Method_.e975cf5289: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce__Payment_Method_.e975cf5289"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_77676b47405189e0b683c9d65dd2c79e_18398]
   as 
    
    
    



select [Payment_Method]
from "my_db"."dbo"."stg_ecommerce"
where [Payment_Method] is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_77676b47405189e0b683c9d65dd2c79e_18398]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_77676b47405189e0b683c9d65dd2c79e_18398]
  ;')
[0m15:55:28.899876 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:55:28.899876 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:55:28.899876 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:55:28.918138 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:55:28.918138 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce__Payment_Method_.e975cf5289: ROLLBACK
[0m15:55:28.924991 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce__Payment_Method_.e975cf5289: Close
[0m15:55:28.924991 [info ] [Thread-1 (]: 13 of 13 PASS not_null_stg_ecommerce__Payment_Method_ .......................... [[32mPASS[0m in 0.05s]
[0m15:55:28.924991 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce__Payment_Method_.e975cf5289
[0m15:55:28.933279 [debug] [MainThread]: On master: COMMIT
[0m15:55:28.933279 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:55:28.933279 [debug] [MainThread]: Connection 'list_my_db' was properly closed.
[0m15:55:28.933279 [debug] [MainThread]: Connection 'list_my_db_dbo' was properly closed.
[0m15:55:28.933279 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.not_null_stg_ecommerce__Payment_Method_.e975cf5289' was properly closed.
[0m15:55:28.941216 [info ] [MainThread]: 
[0m15:55:28.941216 [info ] [MainThread]: Finished running 11 data tests, 2 view models in 0 hours 0 minutes and 1.63 seconds (1.63s).
[0m15:55:28.949263 [debug] [MainThread]: Command end result
[0m15:55:29.106806 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m15:55:29.114847 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m15:55:29.124089 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m15:55:29.124089 [info ] [MainThread]: 
[0m15:55:29.132094 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m15:55:29.132094 [info ] [MainThread]: 
[0m15:55:29.132094 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_stg_ecommerce_Discount___if_target_name_sqlserver_Discount_0_else_Discount_0_endif_ (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m15:55:29.140199 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Discount'. (102) (SQLMoreResults)")
[0m15:55:29.142139 [info ] [MainThread]: 
[0m15:55:29.142139 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\dbt_utils_expression_is_true_s_d3e9ed7c35cd0fd765aa015e707708e5.sql
[0m15:55:29.142139 [info ] [MainThread]: 
[0m15:55:29.150141 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_stg_ecommerce_Price___if_target_name_sqlserver_Price_0_else_Price_0_endif_ (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m15:55:29.150141 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Price'. (102) (SQLMoreResults)")
[0m15:55:29.150141 [info ] [MainThread]: 
[0m15:55:29.158507 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\dbt_utils_expression_is_true_s_35189776310bf3b6a92f0151387a1ac1.sql
[0m15:55:29.158507 [info ] [MainThread]: 
[0m15:55:29.158507 [info ] [MainThread]: Done. PASS=11 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=13
[0m15:55:29.166508 [debug] [MainThread]: Command `dbt build` failed at 15:55:29.166508 after 5.94 seconds
[0m15:55:29.166508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259E3F40D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259E3F40ED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000259E3F41290>]}
[0m15:55:29.166508 [debug] [MainThread]: Flushing usage events
[0m15:55:29.766399 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:59:54.362150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AD37BBAAD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AD37BBBE50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AD37BBBC10>]}


============================== 15:59:54.370196 | a92c792a-6e44-42b1-ba91-b25e8ef8e660 ==============================
[0m15:59:54.370196 [info ] [MainThread]: Running with dbt=1.10.3
[0m15:59:54.370196 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:59:55.385598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a92c792a-6e44-42b1-ba91-b25e8ef8e660', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AD393F4D50>]}
[0m15:59:55.510967 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a92c792a-6e44-42b1-ba91-b25e8ef8e660', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AD36AC1D90>]}
[0m15:59:55.510967 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m15:59:56.342679 [debug] [MainThread]: checksum: 1bfacb87e6914c9942cfa2c4badfc1df19d859fe8ec086286ef238a7d920f97b, vars: {}, profile: , target: , version: 1.10.3
[0m15:59:56.909192 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:59:56.909192 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://dbt_databricks_cicd/models\staging\databricks\schema.yml
[0m15:59:57.967129 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m15:59:58.017511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a92c792a-6e44-42b1-ba91-b25e8ef8e660', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AD39443390>]}
[0m15:59:58.225152 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m15:59:58.225152 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m15:59:58.375256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a92c792a-6e44-42b1-ba91-b25e8ef8e660', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AD39E9FE10>]}
[0m15:59:58.375256 [info ] [MainThread]: Found 2 models, 12 data tests, 1 source, 626 macros
[0m15:59:58.383643 [info ] [MainThread]: 
[0m15:59:58.383643 [info ] [MainThread]: Concurrency: 1 threads (target='sqlserver')
[0m15:59:58.383643 [info ] [MainThread]: 
[0m15:59:58.392341 [debug] [MainThread]: Acquiring new sqlserver connection 'master'
[0m15:59:58.400347 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db'
[0m15:59:58.434053 [debug] [ThreadPool]: dbt-sqlserver
[0m15:59:58.434053 [debug] [ThreadPool]: Using sqlserver connection "list_my_db"
[0m15:59:58.434053 [debug] [ThreadPool]: On list_my_db: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db"} */
USE [my_db];
    select  name as [schema]
    from sys.schemas with (nolock) 
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m15:59:58.441182 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:59:58.441182 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:59:58.548650 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m15:59:58.556693 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:59:58.564678 [debug] [ThreadPool]: On list_my_db: Close
[0m15:59:58.564678 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db_dbo'
[0m15:59:58.572788 [debug] [ThreadPool]: dbt-sqlserver
[0m15:59:58.580834 [debug] [ThreadPool]: Using sqlserver connection "list_my_db_dbo"
[0m15:59:58.580834 [debug] [ThreadPool]: On list_my_db_dbo: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db_dbo"} */
USE [my_db];
    with base as (
      select
        DB_NAME() as [database],
        t.name as [name],
        SCHEMA_NAME(t.schema_id) as [schema],
        'table' as table_type
      from sys.tables as t with (nolock)
      union all
      select
        DB_NAME() as [database],
        v.name as [name],
        SCHEMA_NAME(v.schema_id) as [schema],
        'view' as table_type
      from sys.views as v with (nolock)
    )
    select * from base
    where [schema] like 'dbo'
    
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m15:59:58.580834 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:59:58.580834 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:59:58.580834 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m15:59:58.632489 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:59:58.632489 [debug] [ThreadPool]: On list_my_db_dbo: ROLLBACK
[0m15:59:58.632489 [debug] [ThreadPool]: On list_my_db_dbo: Close
[0m15:59:58.632489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a92c792a-6e44-42b1-ba91-b25e8ef8e660', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AD3967DF10>]}
[0m15:59:58.641031 [debug] [MainThread]: On master: COMMIT
[0m15:59:58.649031 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m15:59:58.649031 [info ] [Thread-1 (]: 1 of 14 START sql view model dbo.src_ecommerce ................................. [RUN]
[0m15:59:58.649031 [debug] [Thread-1 (]: Acquiring new sqlserver connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m15:59:58.657035 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m15:59:58.667216 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m15:59:58.675176 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m15:59:58.740902 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m15:59:58.740902 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:59:58.740902 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."src_ecommerce__dbt_tmp" as 

select * from "my_db"."dbo"."ecommerce";
    ')


[0m15:59:58.748943 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:59:58.748943 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:59:58.757413 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:59:58.757413 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:59:58.774495 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:59:58.774495 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce', 'src_ecommerce__dbt_backup'
[0m15:59:58.981972 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:59:58.990730 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:59:58.990730 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce__dbt_tmp', 'src_ecommerce'
[0m15:59:58.990730 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:59:59.023861 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: COMMIT
[0m15:59:59.039906 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."src_ecommerce__dbt_backup"
[0m15:59:59.055867 [debug] [Thread-1 (]: dbt-sqlserver
[0m15:59:59.055867 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:59:59.055867 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'src_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m15:59:59.087915 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:59:59.090956 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:59:59.090956 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."src_ecommerce__dbt_backup";');

[0m15:59:59.099481 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:59:59.099481 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: ROLLBACK
[0m15:59:59.107118 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: Close
[0m15:59:59.107118 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a92c792a-6e44-42b1-ba91-b25e8ef8e660', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AD39F59190>]}
[0m15:59:59.107118 [info ] [Thread-1 (]: 1 of 14 OK created sql view model dbo.src_ecommerce ............................ [[32mOK[0m in 0.46s]
[0m15:59:59.115127 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m15:59:59.115127 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m15:59:59.115127 [info ] [Thread-1 (]: 2 of 14 START sql view model dbo.stg_ecommerce ................................. [RUN]
[0m15:59:59.125312 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m15:59:59.125312 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m15:59:59.133358 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:59:59.133358 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m15:59:59.142581 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:59:59.142581 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:59:59.142581 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."stg_ecommerce__dbt_tmp" as 

SELECT
    
        CAST(User_ID AS VARCHAR) AS User_ID,
        CAST(Product_ID AS VARCHAR) AS Product_ID,
        CAST(Category AS VARCHAR) AS Category,
        CAST(Price AS FLOAT) AS Price,
        CAST(Discount AS INT) AS Discount,
        CAST(Final_Price AS FLOAT) AS Final_Price,
        CAST(Payment_Method AS VARCHAR) AS Payment_Method,
        CAST(Purchase_Date AS DATE) AS Purchase_Date
    
FROM "my_db"."dbo"."ecommerce";
    ')


[0m15:59:59.150625 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:59:59.150625 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:59:59.150625 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:59:59.158824 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:59:59.166838 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:59:59.173766 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce', 'stg_ecommerce__dbt_backup'
[0m15:59:59.173766 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:59:59.181809 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:59:59.181809 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce__dbt_tmp', 'stg_ecommerce'
[0m15:59:59.190472 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:59:59.190472 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: COMMIT
[0m15:59:59.198522 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."stg_ecommerce__dbt_backup"
[0m15:59:59.198522 [debug] [Thread-1 (]: dbt-sqlserver
[0m15:59:59.206475 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:59:59.207123 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'stg_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m15:59:59.223629 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:59:59.231668 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:59:59.231668 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."stg_ecommerce__dbt_backup";');

[0m15:59:59.231668 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:59:59.240301 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: ROLLBACK
[0m15:59:59.240301 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: Close
[0m15:59:59.240301 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a92c792a-6e44-42b1-ba91-b25e8ef8e660', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AD3A6378D0>]}
[0m15:59:59.240301 [info ] [Thread-1 (]: 2 of 14 OK created sql view model dbo.stg_ecommerce ............................ [[32mOK[0m in 0.12s]
[0m15:59:59.240301 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m15:59:59.248339 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m15:59:59.248339 [info ] [Thread-1 (]: 3 of 14 START test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m15:59:59.248339 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6)
[0m15:59:59.256304 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m15:59:59.274909 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m15:59:59.276626 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m15:59:59.315392 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m15:59:59.322001 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m15:59:59.322001 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_4348]
   as 
    
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from "my_db"."dbo"."stg_ecommerce"
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    ''Credit Card'',''Net Banking'',''UPI'',''Debit Card'',''Cash on Delivery''
)



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_4348]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_4348]
  ;')
[0m15:59:59.322001 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:59:59.322001 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:59:59.322001 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:59:59.349687 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:59:59.349687 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: ROLLBACK
[0m15:59:59.357523 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: Close
[0m15:59:59.357523 [info ] [Thread-1 (]: 3 of 14 PASS accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[32mPASS[0m in 0.11s]
[0m15:59:59.357523 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m15:59:59.357523 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675
[0m15:59:59.365531 [info ] [Thread-1 (]: 4 of 14 START test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0  [RUN]
[0m15:59:59.365531 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675)
[0m15:59:59.365531 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675
[0m15:59:59.489458 [debug] [Thread-1 (]: Compilation Error in test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  'esc' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:59:59.490005 [error] [Thread-1 (]: 4 of 14 ERROR dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0  [[31mERROR[0m in 0.12s]
[0m15:59:59.490005 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675
[0m15:59:59.490005 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc
[0m15:59:59.490005 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675' to be skipped because of status 'error'.  Reason: Compilation Error in test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  'esc' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m15:59:59.498014 [info ] [Thread-1 (]: 5 of 14 START test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0  [RUN]
[0m15:59:59.498014 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc)
[0m15:59:59.498014 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc
[0m15:59:59.507860 [debug] [Thread-1 (]: Compilation Error in test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  'esc' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:59:59.507860 [error] [Thread-1 (]: 5 of 14 ERROR dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 ... [[31mERROR[0m in 0.01s]
[0m15:59:59.515902 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc
[0m15:59:59.515902 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m15:59:59.524459 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc' to be skipped because of status 'error'.  Reason: Compilation Error in test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  'esc' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m15:59:59.524459 [info ] [Thread-1 (]: 6 of 14 START test not_null_stg_ecommerce_Category ............................. [RUN]
[0m15:59:59.524459 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14)
[0m15:59:59.524459 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m15:59:59.540482 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m15:59:59.540482 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m15:59:59.548466 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m15:59:59.556499 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m15:59:59.556499 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_3240]
   as 
    
    
    



select Category
from "my_db"."dbo"."stg_ecommerce"
where Category is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_3240]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_3240]
  ;')
[0m15:59:59.556499 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:59:59.556499 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:59:59.564506 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:59:59.572467 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:59:59.580503 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: ROLLBACK
[0m15:59:59.580503 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: Close
[0m15:59:59.580503 [info ] [Thread-1 (]: 6 of 14 PASS not_null_stg_ecommerce_Category ................................... [[32mPASS[0m in 0.06s]
[0m15:59:59.588469 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m15:59:59.591916 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m15:59:59.591916 [info ] [Thread-1 (]: 7 of 14 START test not_null_stg_ecommerce_Discount ............................. [RUN]
[0m15:59:59.591916 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836)
[0m15:59:59.591916 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m15:59:59.608808 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m15:59:59.608808 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m15:59:59.616818 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m15:59:59.616818 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m15:59:59.616818 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_14275]
   as 
    
    
    



select Discount
from "my_db"."dbo"."stg_ecommerce"
where Discount is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_14275]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_14275]
  ;')
[0m15:59:59.624634 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:59:59.624634 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:59:59.624634 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:59:59.640058 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:59:59.640058 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: ROLLBACK
[0m15:59:59.640058 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: Close
[0m15:59:59.640058 [info ] [Thread-1 (]: 7 of 14 PASS not_null_stg_ecommerce_Discount ................................... [[32mPASS[0m in 0.05s]
[0m15:59:59.648102 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m15:59:59.648102 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m15:59:59.648102 [info ] [Thread-1 (]: 8 of 14 START test not_null_stg_ecommerce_Final_Price .......................... [RUN]
[0m15:59:59.658657 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc)
[0m15:59:59.658657 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m15:59:59.666698 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m15:59:59.666698 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m15:59:59.675913 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m15:59:59.675913 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m15:59:59.684201 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_16272]
   as 
    
    
    



select Final_Price
from "my_db"."dbo"."stg_ecommerce"
where Final_Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_16272]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_16272]
  ;')
[0m15:59:59.684201 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:59:59.684201 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:59:59.684201 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:59:59.699203 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:59:59.699203 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: ROLLBACK
[0m15:59:59.699203 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: Close
[0m15:59:59.706602 [info ] [Thread-1 (]: 8 of 14 PASS not_null_stg_ecommerce_Final_Price ................................ [[32mPASS[0m in 0.05s]
[0m15:59:59.706602 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m15:59:59.706602 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m15:59:59.714605 [info ] [Thread-1 (]: 9 of 14 START test not_null_stg_ecommerce_Payment_Method ....................... [RUN]
[0m15:59:59.714605 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d)
[0m15:59:59.714605 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m15:59:59.724261 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m15:59:59.724261 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m15:59:59.732300 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m15:59:59.740294 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m15:59:59.742474 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_4249]
   as 
    
    
    



select Payment_Method
from "my_db"."dbo"."stg_ecommerce"
where Payment_Method is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_4249]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_4249]
  ;')
[0m15:59:59.742474 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:59:59.742474 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:59:59.742474 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:59:59.757699 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:59:59.765744 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: ROLLBACK
[0m15:59:59.765744 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: Close
[0m15:59:59.765744 [info ] [Thread-1 (]: 9 of 14 PASS not_null_stg_ecommerce_Payment_Method ............................. [[32mPASS[0m in 0.05s]
[0m15:59:59.774329 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m15:59:59.774329 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m15:59:59.774329 [info ] [Thread-1 (]: 10 of 14 START test not_null_stg_ecommerce_Price ............................... [RUN]
[0m15:59:59.774329 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a)
[0m15:59:59.774329 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m15:59:59.791878 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m15:59:59.791878 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m15:59:59.799875 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m15:59:59.799875 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m15:59:59.807878 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_12799]
   as 
    
    
    



select Price
from "my_db"."dbo"."stg_ecommerce"
where Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_12799]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_12799]
  ;')
[0m15:59:59.807878 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:59:59.807878 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:59:59.807878 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:59:59.823881 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:59:59.823881 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: ROLLBACK
[0m15:59:59.823881 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: Close
[0m15:59:59.831916 [info ] [Thread-1 (]: 10 of 14 PASS not_null_stg_ecommerce_Price ..................................... [[32mPASS[0m in 0.06s]
[0m15:59:59.831916 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m15:59:59.831916 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m15:59:59.841315 [info ] [Thread-1 (]: 11 of 14 START test not_null_stg_ecommerce_Product_ID .......................... [RUN]
[0m15:59:59.841315 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c)
[0m15:59:59.841315 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m15:59:59.849324 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m15:59:59.849324 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m15:59:59.860088 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m15:59:59.860088 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m15:59:59.860088 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_14538]
   as 
    
    
    



select Product_ID
from "my_db"."dbo"."stg_ecommerce"
where Product_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_14538]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_14538]
  ;')
[0m15:59:59.860088 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:59:59.868347 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:59:59.868347 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:59:59.883807 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:59:59.891851 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: ROLLBACK
[0m15:59:59.891851 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: Close
[0m15:59:59.891851 [info ] [Thread-1 (]: 11 of 14 PASS not_null_stg_ecommerce_Product_ID ................................ [[32mPASS[0m in 0.05s]
[0m15:59:59.899813 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m15:59:59.899813 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m15:59:59.899813 [info ] [Thread-1 (]: 12 of 14 START test not_null_stg_ecommerce_Purchase_Date ....................... [RUN]
[0m15:59:59.899813 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307)
[0m15:59:59.899813 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m15:59:59.918033 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m15:59:59.918033 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m15:59:59.925270 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m15:59:59.925270 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m15:59:59.933269 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_13278]
   as 
    
    
    



select Purchase_Date
from "my_db"."dbo"."stg_ecommerce"
where Purchase_Date is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_13278]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_13278]
  ;')
[0m15:59:59.933557 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:59:59.933557 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:59:59.933557 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:59:59.949070 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:59:59.949070 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: ROLLBACK
[0m15:59:59.956242 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: Close
[0m15:59:59.956242 [info ] [Thread-1 (]: 12 of 14 PASS not_null_stg_ecommerce_Purchase_Date ............................. [[32mPASS[0m in 0.06s]
[0m15:59:59.956242 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m15:59:59.956242 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m15:59:59.964524 [info ] [Thread-1 (]: 13 of 14 START test not_null_stg_ecommerce_User_ID ............................. [RUN]
[0m15:59:59.964524 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, now test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf)
[0m15:59:59.964524 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m15:59:59.973900 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m15:59:59.973900 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m15:59:59.981901 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m15:59:59.991653 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m15:59:59.991653 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_13116]
   as 
    
    
    



select User_ID
from "my_db"."dbo"."stg_ecommerce"
where User_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_13116]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_13116]
  ;')
[0m15:59:59.991653 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:59:59.991653 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:59:59.991653 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m16:00:00.015641 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:00:00.015641 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: ROLLBACK
[0m16:00:00.023064 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: Close
[0m16:00:00.023064 [info ] [Thread-1 (]: 13 of 14 PASS not_null_stg_ecommerce_User_ID ................................... [[32mPASS[0m in 0.06s]
[0m16:00:00.023064 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m16:00:00.031072 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m16:00:00.031072 [info ] [Thread-1 (]: 14 of 14 START test unique_stg_ecommerce_Product_ID ............................ [RUN]
[0m16:00:00.031072 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, now test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1)
[0m16:00:00.031072 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m16:00:00.048956 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m16:00:00.056971 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m16:00:00.064996 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m16:00:00.064996 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m16:00:00.064996 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_12274]
   as 
    
    
    

select
    Product_ID as unique_field,
    count(*) as n_records

from "my_db"."dbo"."stg_ecommerce"
where Product_ID is not null
group by Product_ID
having count(*) > 1



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_12274]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_12274]
  ;')
[0m16:00:00.064996 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:00:00.071277 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m16:00:00.074617 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m16:00:00.097536 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m16:00:00.097536 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: ROLLBACK
[0m16:00:00.106130 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: Close
[0m16:00:00.106130 [info ] [Thread-1 (]: 14 of 14 PASS unique_stg_ecommerce_Product_ID .................................. [[32mPASS[0m in 0.08s]
[0m16:00:00.106130 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m16:00:00.114374 [debug] [MainThread]: On master: COMMIT
[0m16:00:00.114374 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:00:00.114374 [debug] [MainThread]: Connection 'list_my_db' was properly closed.
[0m16:00:00.114374 [debug] [MainThread]: Connection 'list_my_db_dbo' was properly closed.
[0m16:00:00.114374 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1' was properly closed.
[0m16:00:00.114374 [info ] [MainThread]: 
[0m16:00:00.122418 [info ] [MainThread]: Finished running 12 data tests, 2 view models in 0 hours 0 minutes and 1.72 seconds (1.72s).
[0m16:00:00.124033 [debug] [MainThread]: Command end result
[0m16:00:00.289276 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m16:00:00.297315 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m16:00:00.305278 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m16:00:00.313515 [info ] [MainThread]: 
[0m16:00:00.313515 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m16:00:00.313515 [info ] [MainThread]: 
[0m16:00:00.321519 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m16:00:00.321519 [error] [MainThread]:   Compilation Error in test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  'esc' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m16:00:00.321519 [info ] [MainThread]: 
[0m16:00:00.321519 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m16:00:00.329558 [error] [MainThread]:   Compilation Error in test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  'esc' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m16:00:00.329558 [info ] [MainThread]: 
[0m16:00:00.329558 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=14
[0m16:00:00.337522 [debug] [MainThread]: Command `dbt build` failed at 16:00:00.337522 after 6.13 seconds
[0m16:00:00.337522 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AD31350D90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AD31350ED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002AD31351290>]}
[0m16:00:00.337522 [debug] [MainThread]: Flushing usage events
[0m16:00:00.940255 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:55:55.098949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002080C304C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002080C35AA10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002080C35BFD0>]}


============================== 11:55:55.098949 | 4414edc5-c13e-47d8-9625-33df6b2ebcdf ==============================
[0m11:55:55.098949 [info ] [MainThread]: Running with dbt=1.10.3
[0m11:55:55.115867 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt build --target sqlserver', 'send_anonymous_usage_stats': 'True'}
[0m11:56:01.229566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4414edc5-c13e-47d8-9625-33df6b2ebcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002080DBDFAD0>]}
[0m11:56:01.356993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4414edc5-c13e-47d8-9625-33df6b2ebcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002080B271FD0>]}
[0m11:56:01.356993 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m11:56:02.501142 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m11:56:02.771664 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m11:56:02.784742 [debug] [MainThread]: previous checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, current checksum: 1bfacb87e6914c9942cfa2c4badfc1df19d859fe8ec086286ef238a7d920f97b
[0m11:56:02.784742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4414edc5-c13e-47d8-9625-33df6b2ebcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002080BA14410>]}
[0m11:56:10.301954 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m11:56:10.301954 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m11:56:10.309616 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m11:56:10.309616 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m11:56:10.313286 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m11:56:10.313286 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m11:56:10.316930 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m11:56:10.316930 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m11:56:10.320542 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m11:56:10.320542 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m11:56:10.320542 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m11:56:10.326311 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m11:56:10.326311 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m11:56:10.329929 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m11:56:10.329929 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m11:56:10.333536 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m11:56:10.333536 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m11:56:10.337156 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m11:56:10.339424 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m11:56:10.341007 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m11:56:10.341007 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m11:56:10.343258 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m11:56:10.343258 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m11:56:10.345442 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m11:56:10.345442 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m11:56:10.347742 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m11:56:10.347742 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m11:56:10.545007 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m11:56:10.596439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4414edc5-c13e-47d8-9625-33df6b2ebcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002080E331990>]}
[0m11:56:10.880446 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m11:56:10.915594 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m11:56:11.097706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4414edc5-c13e-47d8-9625-33df6b2ebcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002080E2AB950>]}
[0m11:56:11.111904 [info ] [MainThread]: Found 2 models, 12 data tests, 1 source, 626 macros
[0m11:56:11.117149 [info ] [MainThread]: 
[0m11:56:11.117149 [info ] [MainThread]: Concurrency: 1 threads (target='sqlserver')
[0m11:56:11.122451 [info ] [MainThread]: 
[0m11:56:11.124128 [debug] [MainThread]: Acquiring new sqlserver connection 'master'
[0m11:56:11.139872 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db'
[0m11:56:11.188120 [debug] [ThreadPool]: dbt-sqlserver
[0m11:56:11.188120 [debug] [ThreadPool]: Using sqlserver connection "list_my_db"
[0m11:56:11.196402 [debug] [ThreadPool]: On list_my_db: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db"} */
USE [my_db];
    select  name as [schema]
    from sys.schemas with (nolock) 
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m11:56:11.196402 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:56:11.198715 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:56:11.378653 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m11:56:11.394278 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m11:56:11.395664 [debug] [ThreadPool]: On list_my_db: Close
[0m11:56:11.400845 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db_dbo'
[0m11:56:11.400845 [debug] [ThreadPool]: dbt-sqlserver
[0m11:56:11.400845 [debug] [ThreadPool]: Using sqlserver connection "list_my_db_dbo"
[0m11:56:11.413636 [debug] [ThreadPool]: On list_my_db_dbo: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db_dbo"} */
USE [my_db];
    with base as (
      select
        DB_NAME() as [database],
        t.name as [name],
        SCHEMA_NAME(t.schema_id) as [schema],
        'table' as table_type
      from sys.tables as t with (nolock)
      union all
      select
        DB_NAME() as [database],
        v.name as [name],
        SCHEMA_NAME(v.schema_id) as [schema],
        'view' as table_type
      from sys.views as v with (nolock)
    )
    select * from base
    where [schema] like 'dbo'
    
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m11:56:11.414891 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:56:11.414891 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:56:11.417114 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m11:56:11.484631 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m11:56:11.489398 [debug] [ThreadPool]: On list_my_db_dbo: ROLLBACK
[0m11:56:11.497535 [debug] [ThreadPool]: On list_my_db_dbo: Close
[0m11:56:11.503464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4414edc5-c13e-47d8-9625-33df6b2ebcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002080E3BE110>]}
[0m11:56:11.505464 [debug] [MainThread]: On master: COMMIT
[0m11:56:11.519887 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m11:56:11.520884 [info ] [Thread-1 (]: 1 of 14 START sql view model dbo.src_ecommerce ................................. [RUN]
[0m11:56:11.523745 [debug] [Thread-1 (]: Acquiring new sqlserver connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m11:56:11.523745 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m11:56:11.544975 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m11:56:11.557493 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m11:56:11.642133 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m11:56:11.642133 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m11:56:11.651506 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."src_ecommerce__dbt_tmp" as 

select * from "my_db"."dbo"."ecommerce";
    ')


[0m11:56:11.651506 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:56:11.653955 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:56:11.659787 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:56:11.659787 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:11.676039 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m11:56:11.676039 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce', 'src_ecommerce__dbt_backup'
[0m11:56:11.863873 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:11.868818 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m11:56:11.868818 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce__dbt_tmp', 'src_ecommerce'
[0m11:56:11.878307 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:11.911485 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: COMMIT
[0m11:56:11.927223 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."src_ecommerce__dbt_backup"
[0m11:56:11.929855 [debug] [Thread-1 (]: dbt-sqlserver
[0m11:56:11.929855 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m11:56:11.944408 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'src_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m11:56:11.960208 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:11.976967 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m11:56:11.979960 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."src_ecommerce__dbt_backup";');

[0m11:56:11.981065 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:11.981065 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: ROLLBACK
[0m11:56:11.981065 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: Close
[0m11:56:11.991071 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4414edc5-c13e-47d8-9625-33df6b2ebcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002080E033550>]}
[0m11:56:11.996245 [info ] [Thread-1 (]: 1 of 14 OK created sql view model dbo.src_ecommerce ............................ [[32mOK[0m in 0.47s]
[0m11:56:11.998665 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m11:56:11.998665 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m11:56:12.002739 [info ] [Thread-1 (]: 2 of 14 START sql view model dbo.stg_ecommerce ................................. [RUN]
[0m11:56:12.006019 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m11:56:12.007062 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m11:56:12.008064 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m11:56:12.016881 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m11:56:12.017881 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m11:56:12.035069 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m11:56:12.038159 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."stg_ecommerce__dbt_tmp" as 

SELECT
    
        CAST(User_ID AS VARCHAR) AS User_ID,
        CAST(Product_ID AS VARCHAR) AS Product_ID,
        CAST(Category AS VARCHAR) AS Category,
        CAST(Price AS FLOAT) AS Price,
        CAST(Discount AS INT) AS Discount,
        CAST(Final_Price AS FLOAT) AS Final_Price,
        CAST(Payment_Method AS VARCHAR) AS Payment_Method,
        CAST(Purchase_Date AS DATE) AS Purchase_Date
    
FROM "my_db"."dbo"."ecommerce";
    ')


[0m11:56:12.039164 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:56:12.040945 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:56:12.040945 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:56:12.044329 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:12.060239 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m11:56:12.062121 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce', 'stg_ecommerce__dbt_backup'
[0m11:56:12.062121 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:12.077791 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m11:56:12.077791 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce__dbt_tmp', 'stg_ecommerce'
[0m11:56:12.087562 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:12.087562 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: COMMIT
[0m11:56:12.103422 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."stg_ecommerce__dbt_backup"
[0m11:56:12.103422 [debug] [Thread-1 (]: dbt-sqlserver
[0m11:56:12.103422 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m11:56:12.103422 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'stg_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m11:56:12.119045 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:12.134846 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m11:56:12.134846 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."stg_ecommerce__dbt_backup";');

[0m11:56:12.134846 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:12.150932 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: ROLLBACK
[0m11:56:12.153738 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: Close
[0m11:56:12.154700 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4414edc5-c13e-47d8-9625-33df6b2ebcdf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002080DA98E10>]}
[0m11:56:12.154700 [info ] [Thread-1 (]: 2 of 14 OK created sql view model dbo.stg_ecommerce ............................ [[32mOK[0m in 0.15s]
[0m11:56:12.157795 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m11:56:12.157795 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m11:56:12.157795 [info ] [Thread-1 (]: 3 of 14 START test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m11:56:12.166022 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6)
[0m11:56:12.166022 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m11:56:12.171779 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m11:56:12.171779 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m11:56:12.214784 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m11:56:12.223736 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m11:56:12.223736 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_9938]
   as 
    
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from "my_db"."dbo"."stg_ecommerce"
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    ''Credit Card'',''Net Banking'',''UPI'',''Debit Card'',''Cash on Delivery''
)



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_9938]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_9938]
  ;')
[0m11:56:12.226287 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:56:12.226287 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:56:12.228733 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:56:12.244509 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:12.244509 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: ROLLBACK
[0m11:56:12.260365 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: Close
[0m11:56:12.262751 [info ] [Thread-1 (]: 3 of 14 PASS accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[32mPASS[0m in 0.10s]
[0m11:56:12.262751 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m11:56:12.262751 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675
[0m11:56:12.270704 [info ] [Thread-1 (]: 4 of 14 START test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0  [RUN]
[0m11:56:12.273134 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675)
[0m11:56:12.274130 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675
[0m11:56:12.440554 [debug] [Thread-1 (]: Compilation Error in test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  'esc' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m11:56:12.457309 [error] [Thread-1 (]: 4 of 14 ERROR dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0  [[31mERROR[0m in 0.19s]
[0m11:56:12.457309 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675
[0m11:56:12.457309 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc
[0m11:56:12.462473 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675' to be skipped because of status 'error'.  Reason: Compilation Error in test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  'esc' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m11:56:12.462473 [info ] [Thread-1 (]: 5 of 14 START test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0  [RUN]
[0m11:56:12.466769 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc)
[0m11:56:12.466769 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc
[0m11:56:12.492400 [debug] [Thread-1 (]: Compilation Error in test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  'esc' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m11:56:12.496402 [error] [Thread-1 (]: 5 of 14 ERROR dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 ... [[31mERROR[0m in 0.03s]
[0m11:56:12.499750 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc
[0m11:56:12.501902 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m11:56:12.503832 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc' to be skipped because of status 'error'.  Reason: Compilation Error in test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  'esc' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m11:56:12.507389 [info ] [Thread-1 (]: 6 of 14 START test not_null_stg_ecommerce_Category ............................. [RUN]
[0m11:56:12.511009 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14)
[0m11:56:12.513086 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m11:56:12.532617 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m11:56:12.532617 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m11:56:12.545457 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m11:56:12.559049 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m11:56:12.559049 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_9459]
   as 
    
    
    



select Category
from "my_db"."dbo"."stg_ecommerce"
where Category is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_9459]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_9459]
  ;')
[0m11:56:12.559049 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:56:12.565363 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:56:12.565363 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:56:12.565363 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:12.582725 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: ROLLBACK
[0m11:56:12.582725 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: Close
[0m11:56:12.585238 [info ] [Thread-1 (]: 6 of 14 PASS not_null_stg_ecommerce_Category ................................... [[32mPASS[0m in 0.08s]
[0m11:56:12.587513 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m11:56:12.587513 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m11:56:12.587513 [info ] [Thread-1 (]: 7 of 14 START test not_null_stg_ecommerce_Discount ............................. [RUN]
[0m11:56:12.595164 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836)
[0m11:56:12.596163 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m11:56:12.599392 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m11:56:12.612543 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m11:56:12.612543 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m11:56:12.620294 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m11:56:12.622471 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_5322]
   as 
    
    
    



select Discount
from "my_db"."dbo"."stg_ecommerce"
where Discount is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_5322]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_5322]
  ;')
[0m11:56:12.622471 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:56:12.625137 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:56:12.625137 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:56:12.629206 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:12.643070 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: ROLLBACK
[0m11:56:12.643070 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: Close
[0m11:56:12.645555 [info ] [Thread-1 (]: 7 of 14 PASS not_null_stg_ecommerce_Discount ................................... [[32mPASS[0m in 0.05s]
[0m11:56:12.645555 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m11:56:12.645555 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m11:56:12.651140 [info ] [Thread-1 (]: 8 of 14 START test not_null_stg_ecommerce_Final_Price .......................... [RUN]
[0m11:56:12.653600 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc)
[0m11:56:12.654611 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m11:56:12.657490 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m11:56:12.673251 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m11:56:12.675313 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m11:56:12.682175 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m11:56:12.682175 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_15023]
   as 
    
    
    



select Final_Price
from "my_db"."dbo"."stg_ecommerce"
where Final_Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_15023]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_15023]
  ;')
[0m11:56:12.684832 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:56:12.684832 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:56:12.687351 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:56:12.687351 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:12.704082 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: ROLLBACK
[0m11:56:12.704082 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: Close
[0m11:56:12.708429 [info ] [Thread-1 (]: 8 of 14 PASS not_null_stg_ecommerce_Final_Price ................................ [[32mPASS[0m in 0.06s]
[0m11:56:12.708429 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m11:56:12.708429 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m11:56:12.714022 [info ] [Thread-1 (]: 9 of 14 START test not_null_stg_ecommerce_Payment_Method ....................... [RUN]
[0m11:56:12.716499 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d)
[0m11:56:12.716499 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m11:56:12.716499 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m11:56:12.733299 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m11:56:12.735758 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m11:56:12.748436 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m11:56:12.751078 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_17396]
   as 
    
    
    



select Payment_Method
from "my_db"."dbo"."stg_ecommerce"
where Payment_Method is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_17396]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_17396]
  ;')
[0m11:56:12.752531 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:56:12.754197 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:56:12.755199 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:56:12.757315 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:12.757315 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: ROLLBACK
[0m11:56:12.773492 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: Close
[0m11:56:12.774496 [info ] [Thread-1 (]: 9 of 14 PASS not_null_stg_ecommerce_Payment_Method ............................. [[32mPASS[0m in 0.06s]
[0m11:56:12.777239 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m11:56:12.777239 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m11:56:12.780467 [info ] [Thread-1 (]: 10 of 14 START test not_null_stg_ecommerce_Price ............................... [RUN]
[0m11:56:12.783238 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a)
[0m11:56:12.783238 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m11:56:12.787809 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m11:56:12.796041 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m11:56:12.798326 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m11:56:12.805957 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m11:56:12.805957 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_6788]
   as 
    
    
    



select Price
from "my_db"."dbo"."stg_ecommerce"
where Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_6788]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_6788]
  ;')
[0m11:56:12.808911 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:56:12.808911 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:56:12.811394 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:56:12.821633 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:12.826005 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: ROLLBACK
[0m11:56:12.826005 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: Close
[0m11:56:12.830201 [info ] [Thread-1 (]: 10 of 14 PASS not_null_stg_ecommerce_Price ..................................... [[32mPASS[0m in 0.05s]
[0m11:56:12.832325 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m11:56:12.832325 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m11:56:12.836060 [info ] [Thread-1 (]: 11 of 14 START test not_null_stg_ecommerce_Product_ID .......................... [RUN]
[0m11:56:12.838840 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c)
[0m11:56:12.840243 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m11:56:12.840243 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m11:56:12.850439 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m11:56:12.852462 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m11:56:12.860400 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m11:56:12.860400 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_17034]
   as 
    
    
    



select Product_ID
from "my_db"."dbo"."stg_ecommerce"
where Product_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_17034]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_17034]
  ;')
[0m11:56:12.862805 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:56:12.862805 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:56:12.865169 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:56:12.874768 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:12.878342 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: ROLLBACK
[0m11:56:12.878342 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: Close
[0m11:56:12.882536 [info ] [Thread-1 (]: 11 of 14 PASS not_null_stg_ecommerce_Product_ID ................................ [[32mPASS[0m in 0.04s]
[0m11:56:12.882536 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m11:56:12.882536 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m11:56:12.889263 [info ] [Thread-1 (]: 12 of 14 START test not_null_stg_ecommerce_Purchase_Date ....................... [RUN]
[0m11:56:12.890263 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307)
[0m11:56:12.892228 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m11:56:12.892228 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m11:56:12.902317 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m11:56:12.905734 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m11:56:12.917066 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m11:56:12.917066 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_12661]
   as 
    
    
    



select Purchase_Date
from "my_db"."dbo"."stg_ecommerce"
where Purchase_Date is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_12661]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_12661]
  ;')
[0m11:56:12.920041 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:56:12.920041 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:56:12.920041 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:56:12.937627 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:12.946135 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: ROLLBACK
[0m11:56:12.946135 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: Close
[0m11:56:12.950323 [info ] [Thread-1 (]: 12 of 14 PASS not_null_stg_ecommerce_Purchase_Date ............................. [[32mPASS[0m in 0.06s]
[0m11:56:12.950323 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m11:56:12.955805 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m11:56:12.956803 [info ] [Thread-1 (]: 13 of 14 START test not_null_stg_ecommerce_User_ID ............................. [RUN]
[0m11:56:12.956803 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, now test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf)
[0m11:56:12.960545 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m11:56:12.961829 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m11:56:12.969995 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m11:56:12.972846 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m11:56:12.979294 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m11:56:12.979294 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_11957]
   as 
    
    
    



select User_ID
from "my_db"."dbo"."stg_ecommerce"
where User_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_11957]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_11957]
  ;')
[0m11:56:12.979294 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:56:12.986668 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:56:12.987672 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:56:13.004394 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:13.008389 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: ROLLBACK
[0m11:56:13.008389 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: Close
[0m11:56:13.011055 [info ] [Thread-1 (]: 13 of 14 PASS not_null_stg_ecommerce_User_ID ................................... [[32mPASS[0m in 0.05s]
[0m11:56:13.011055 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m11:56:13.011055 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m11:56:13.011055 [info ] [Thread-1 (]: 14 of 14 START test unique_stg_ecommerce_Product_ID ............................ [RUN]
[0m11:56:13.021060 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, now test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1)
[0m11:56:13.022757 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m11:56:13.022757 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m11:56:13.036597 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m11:56:13.039597 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m11:56:13.045356 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m11:56:13.045356 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_18644]
   as 
    
    
    

select
    Product_ID as unique_field,
    count(*) as n_records

from "my_db"."dbo"."stg_ecommerce"
where Product_ID is not null
group by Product_ID
having count(*) > 1



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_18644]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_18644]
  ;')
[0m11:56:13.047986 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:56:13.047986 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:56:13.050407 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:56:13.057009 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:56:13.072857 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: ROLLBACK
[0m11:56:13.072857 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: Close
[0m11:56:13.076083 [info ] [Thread-1 (]: 14 of 14 PASS unique_stg_ecommerce_Product_ID .................................. [[32mPASS[0m in 0.06s]
[0m11:56:13.078876 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m11:56:13.082110 [debug] [MainThread]: On master: COMMIT
[0m11:56:13.083111 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:56:13.083111 [debug] [MainThread]: Connection 'list_my_db' was properly closed.
[0m11:56:13.083111 [debug] [MainThread]: Connection 'list_my_db_dbo' was properly closed.
[0m11:56:13.089552 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1' was properly closed.
[0m11:56:13.089552 [info ] [MainThread]: 
[0m11:56:13.092384 [info ] [MainThread]: Finished running 12 data tests, 2 view models in 0 hours 0 minutes and 1.97 seconds (1.97s).
[0m11:56:13.092384 [debug] [MainThread]: Command end result
[0m11:56:13.186189 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m11:56:13.198026 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m11:56:13.225947 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m11:56:13.226948 [info ] [MainThread]: 
[0m11:56:13.230154 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m11:56:13.233218 [info ] [MainThread]: 
[0m11:56:13.235668 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m11:56:13.238177 [error] [MainThread]:   Compilation Error in test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  'esc' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m11:56:13.241416 [info ] [MainThread]: 
[0m11:56:13.242419 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m11:56:13.242419 [error] [MainThread]:   Compilation Error in test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  'esc' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m11:56:13.251801 [info ] [MainThread]: 
[0m11:56:13.256352 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=14
[0m11:56:13.260311 [debug] [MainThread]: Command `dbt build` failed at 11:56:13.258665 after 18.44 seconds
[0m11:56:13.260311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020805903DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002080E2E7450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020805B60550>]}
[0m11:56:13.264298 [debug] [MainThread]: Flushing usage events
[0m11:56:14.984302 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:59:09.295626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023792F87450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023792F87E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023792F84FD0>]}


============================== 11:59:09.295626 | 309d429a-3666-4783-b3e8-dcb14cd2236a ==============================
[0m11:59:09.295626 [info ] [MainThread]: Running with dbt=1.10.3
[0m11:59:09.295626 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt clean', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:59:09.625546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '309d429a-3666-4783-b3e8-dcb14cd2236a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023793086D90>]}
[0m11:59:09.974530 [debug] [MainThread]: Command `dbt clean` succeeded at 11:59:09.974530 after 0.81 seconds
[0m11:59:09.974530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002378C503C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023792FE0590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002378C7E6310>]}
[0m11:59:09.974530 [debug] [MainThread]: Flushing usage events
[0m11:59:10.561405 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:59:30.932137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028B121F45D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028B122DFF90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028B12557A50>]}


============================== 11:59:30.932137 | c5d81577-4ddb-424f-979d-0778a43c8886 ==============================
[0m11:59:30.932137 [info ] [MainThread]: Running with dbt=1.10.3
[0m11:59:30.932137 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt deps', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:59:31.236574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c5d81577-4ddb-424f-979d-0778a43c8886', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028B12620CD0>]}
[0m11:59:31.330209 [debug] [MainThread]: Set downloads directory='C:\Users\diniz\AppData\Local\Temp\dbt-downloads-3a00rj7u'
[0m11:59:31.331214 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m11:59:31.897995 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m11:59:31.913499 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m11:59:31.979691 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m11:59:31.995175 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m11:59:32.800376 [info ] [MainThread]: Installed from version 1.3.0
[0m11:59:32.815199 [info ] [MainThread]: Up to date!
[0m11:59:32.816796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'c5d81577-4ddb-424f-979d-0778a43c8886', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028B0F61A050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028B125093D0>]}
[0m11:59:32.819837 [debug] [MainThread]: Command `dbt deps` succeeded at 11:59:32.819837 after 2.02 seconds
[0m11:59:32.819837 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028B0BA23C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028B0BD06290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028B0BC80210>]}
[0m11:59:32.819837 [debug] [MainThread]: Flushing usage events
[0m11:59:33.399545 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:59:43.844467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E863B53E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E863855310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E863BBBFD0>]}


============================== 11:59:43.844467 | 9bbe39d4-2872-41c6-b353-412b0eb92bca ==============================
[0m11:59:43.844467 [info ] [MainThread]: Running with dbt=1.10.3
[0m11:59:43.844467 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'invocation_command': 'dbt build --target sqlserver', 'send_anonymous_usage_stats': 'True'}
[0m11:59:44.784965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9bbe39d4-2872-41c6-b353-412b0eb92bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8609001D0>]}
[0m11:59:44.898966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9bbe39d4-2872-41c6-b353-412b0eb92bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E862AD1D50>]}
[0m11:59:44.898966 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m11:59:45.703420 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m11:59:45.706280 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:59:45.708176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '9bbe39d4-2872-41c6-b353-412b0eb92bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8653F73D0>]}
[0m11:59:49.386917 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m11:59:49.386917 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m11:59:49.393676 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m11:59:49.393676 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m11:59:49.395924 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m11:59:49.395924 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m11:59:49.398107 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m11:59:49.398107 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m11:59:49.400258 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m11:59:49.400258 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m11:59:49.402638 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m11:59:49.402638 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m11:59:49.404817 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m11:59:49.404817 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m11:59:49.406963 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m11:59:49.406963 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m11:59:49.409150 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m11:59:49.409150 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m11:59:49.411290 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m11:59:49.411290 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m11:59:49.413454 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m11:59:49.413454 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m11:59:49.415610 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m11:59:49.415610 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m11:59:49.417766 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m11:59:49.417766 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m11:59:49.419961 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m11:59:49.590921 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m11:59:49.612744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9bbe39d4-2872-41c6-b353-412b0eb92bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E865BDBF90>]}
[0m11:59:49.881471 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m11:59:49.889456 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m11:59:49.983286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9bbe39d4-2872-41c6-b353-412b0eb92bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E86590EED0>]}
[0m11:59:49.983286 [info ] [MainThread]: Found 2 models, 12 data tests, 1 source, 626 macros
[0m11:59:49.986287 [info ] [MainThread]: 
[0m11:59:49.986287 [info ] [MainThread]: Concurrency: 1 threads (target='sqlserver')
[0m11:59:49.986287 [info ] [MainThread]: 
[0m11:59:49.986287 [debug] [MainThread]: Acquiring new sqlserver connection 'master'
[0m11:59:50.005843 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db'
[0m11:59:50.021699 [debug] [ThreadPool]: dbt-sqlserver
[0m11:59:50.021699 [debug] [ThreadPool]: Using sqlserver connection "list_my_db"
[0m11:59:50.034866 [debug] [ThreadPool]: On list_my_db: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db"} */
USE [my_db];
    select  name as [schema]
    from sys.schemas with (nolock) 
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m11:59:50.034866 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:59:50.037035 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:59:50.136732 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m11:59:50.136732 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m11:59:50.136732 [debug] [ThreadPool]: On list_my_db: Close
[0m11:59:50.136732 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db_dbo'
[0m11:59:50.152952 [debug] [ThreadPool]: dbt-sqlserver
[0m11:59:50.152952 [debug] [ThreadPool]: Using sqlserver connection "list_my_db_dbo"
[0m11:59:50.161744 [debug] [ThreadPool]: On list_my_db_dbo: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db_dbo"} */
USE [my_db];
    with base as (
      select
        DB_NAME() as [database],
        t.name as [name],
        SCHEMA_NAME(t.schema_id) as [schema],
        'table' as table_type
      from sys.tables as t with (nolock)
      union all
      select
        DB_NAME() as [database],
        v.name as [name],
        SCHEMA_NAME(v.schema_id) as [schema],
        'view' as table_type
      from sys.views as v with (nolock)
    )
    select * from base
    where [schema] like 'dbo'
    
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m11:59:50.161744 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:59:50.163999 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:59:50.163999 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m11:59:50.200915 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m11:59:50.200915 [debug] [ThreadPool]: On list_my_db_dbo: ROLLBACK
[0m11:59:50.200915 [debug] [ThreadPool]: On list_my_db_dbo: Close
[0m11:59:50.210697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9bbe39d4-2872-41c6-b353-412b0eb92bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E865B5E490>]}
[0m11:59:50.210697 [debug] [MainThread]: On master: COMMIT
[0m11:59:50.219167 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m11:59:50.219167 [info ] [Thread-1 (]: 1 of 14 START sql view model dbo.src_ecommerce ................................. [RUN]
[0m11:59:50.219167 [debug] [Thread-1 (]: Acquiring new sqlserver connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m11:59:50.226732 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m11:59:50.226732 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m11:59:50.248556 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m11:59:50.299618 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m11:59:50.313732 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m11:59:50.313732 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."src_ecommerce__dbt_tmp" as 

select * from "my_db"."dbo"."ecommerce";
    ')


[0m11:59:50.316981 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m11:59:50.316981 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:59:50.323828 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:59:50.323828 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:50.344412 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m11:59:50.344412 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce', 'src_ecommerce__dbt_backup'
[0m11:59:50.547950 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:50.547950 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m11:59:50.547950 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce__dbt_tmp', 'src_ecommerce'
[0m11:59:50.562538 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:50.594196 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: COMMIT
[0m11:59:50.595900 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."src_ecommerce__dbt_backup"
[0m11:59:50.611653 [debug] [Thread-1 (]: dbt-sqlserver
[0m11:59:50.611653 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m11:59:50.625124 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'src_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m11:59:50.642912 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:50.642912 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m11:59:50.658821 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."src_ecommerce__dbt_backup";');

[0m11:59:50.658821 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:50.658821 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: ROLLBACK
[0m11:59:50.658821 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: Close
[0m11:59:50.673575 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9bbe39d4-2872-41c6-b353-412b0eb92bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8659D18D0>]}
[0m11:59:50.679164 [info ] [Thread-1 (]: 1 of 14 OK created sql view model dbo.src_ecommerce ............................ [[32mOK[0m in 0.45s]
[0m11:59:50.679605 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m11:59:50.682541 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m11:59:50.682541 [info ] [Thread-1 (]: 2 of 14 START sql view model dbo.stg_ecommerce ................................. [RUN]
[0m11:59:50.685560 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m11:59:50.685560 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m11:59:50.688093 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m11:59:50.699329 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m11:59:50.699329 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m11:59:50.710521 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m11:59:50.711777 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."stg_ecommerce__dbt_tmp" as 

SELECT
    
        CAST(User_ID AS VARCHAR) AS User_ID,
        CAST(Product_ID AS VARCHAR) AS Product_ID,
        CAST(Category AS VARCHAR) AS Category,
        CAST(Price AS FLOAT) AS Price,
        CAST(Discount AS INT) AS Discount,
        CAST(Final_Price AS FLOAT) AS Final_Price,
        CAST(Payment_Method AS VARCHAR) AS Payment_Method,
        CAST(Purchase_Date AS DATE) AS Purchase_Date
    
FROM "my_db"."dbo"."ecommerce";
    ')


[0m11:59:50.711777 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:59:50.714379 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:59:50.714379 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:59:50.716951 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:50.716951 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m11:59:50.716951 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce', 'stg_ecommerce__dbt_backup'
[0m11:59:50.782748 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:50.798891 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m11:59:50.798891 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce__dbt_tmp', 'stg_ecommerce'
[0m11:59:50.809861 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:50.809861 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: COMMIT
[0m11:59:50.809861 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."stg_ecommerce__dbt_backup"
[0m11:59:50.809861 [debug] [Thread-1 (]: dbt-sqlserver
[0m11:59:50.824185 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m11:59:50.824185 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'stg_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m11:59:50.827763 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:50.844220 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m11:59:50.844220 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."stg_ecommerce__dbt_backup";');

[0m11:59:50.848260 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:50.848260 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: ROLLBACK
[0m11:59:50.848260 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: Close
[0m11:59:50.855545 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9bbe39d4-2872-41c6-b353-412b0eb92bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8657BB3D0>]}
[0m11:59:50.855545 [info ] [Thread-1 (]: 2 of 14 OK created sql view model dbo.stg_ecommerce ............................ [[32mOK[0m in 0.17s]
[0m11:59:50.859507 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m11:59:50.861580 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m11:59:50.861580 [info ] [Thread-1 (]: 3 of 14 START test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m11:59:50.865718 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6)
[0m11:59:50.865718 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m11:59:50.868185 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m11:59:50.882904 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m11:59:50.915191 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m11:59:50.922196 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m11:59:50.922196 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_18636]
   as 
    
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from "my_db"."dbo"."stg_ecommerce"
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    ''Credit Card'',''Net Banking'',''UPI'',''Debit Card'',''Cash on Delivery''
)



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_18636]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_18636]
  ;')
[0m11:59:50.922196 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:59:50.922196 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:59:50.922196 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:59:50.938375 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:50.938375 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: ROLLBACK
[0m11:59:50.938375 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: Close
[0m11:59:50.938375 [info ] [Thread-1 (]: 3 of 14 PASS accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[32mPASS[0m in 0.07s]
[0m11:59:50.938375 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m11:59:50.954167 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675
[0m11:59:50.955767 [info ] [Thread-1 (]: 4 of 14 START test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0  [RUN]
[0m11:59:50.955767 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675)
[0m11:59:50.955767 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675
[0m11:59:50.974219 [debug] [Thread-1 (]: Compilation Error in test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  'esc' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m11:59:50.974219 [error] [Thread-1 (]: 4 of 14 ERROR dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0  [[31mERROR[0m in 0.02s]
[0m11:59:50.978476 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675
[0m11:59:50.978476 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc
[0m11:59:50.978476 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675' to be skipped because of status 'error'.  Reason: Compilation Error in test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  'esc' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m11:59:50.978476 [info ] [Thread-1 (]: 5 of 14 START test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0  [RUN]
[0m11:59:50.978476 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc)
[0m11:59:50.978476 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc
[0m11:59:50.994302 [debug] [Thread-1 (]: Compilation Error in test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  'esc' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m11:59:50.994302 [error] [Thread-1 (]: 5 of 14 ERROR dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 ... [[31mERROR[0m in 0.02s]
[0m11:59:50.994302 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc
[0m11:59:50.994302 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m11:59:50.994302 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc' to be skipped because of status 'error'.  Reason: Compilation Error in test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  'esc' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m11:59:50.994302 [info ] [Thread-1 (]: 6 of 14 START test not_null_stg_ecommerce_Category ............................. [RUN]
[0m11:59:50.994302 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14)
[0m11:59:51.005314 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m11:59:51.005314 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m11:59:51.005314 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m11:59:51.021332 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m11:59:51.021332 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m11:59:51.021332 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_14791]
   as 
    
    
    



select Category
from "my_db"."dbo"."stg_ecommerce"
where Category is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_14791]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_14791]
  ;')
[0m11:59:51.021332 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:59:51.021332 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:59:51.021332 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:59:51.038521 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:51.038521 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: ROLLBACK
[0m11:59:51.038521 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: Close
[0m11:59:51.038521 [info ] [Thread-1 (]: 6 of 14 PASS not_null_stg_ecommerce_Category ................................... [[32mPASS[0m in 0.04s]
[0m11:59:51.038521 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m11:59:51.055237 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m11:59:51.055237 [info ] [Thread-1 (]: 7 of 14 START test not_null_stg_ecommerce_Discount ............................. [RUN]
[0m11:59:51.059406 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836)
[0m11:59:51.059406 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m11:59:51.059406 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m11:59:51.059406 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m11:59:51.077098 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m11:59:51.081381 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m11:59:51.081381 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_6934]
   as 
    
    
    



select Discount
from "my_db"."dbo"."stg_ecommerce"
where Discount is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_6934]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_6934]
  ;')
[0m11:59:51.081381 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:59:51.081381 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:59:51.081381 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:59:51.097088 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:51.098097 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: ROLLBACK
[0m11:59:51.098097 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: Close
[0m11:59:51.098097 [info ] [Thread-1 (]: 7 of 14 PASS not_null_stg_ecommerce_Discount ................................... [[32mPASS[0m in 0.04s]
[0m11:59:51.098097 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m11:59:51.098097 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m11:59:51.098097 [info ] [Thread-1 (]: 8 of 14 START test not_null_stg_ecommerce_Final_Price .......................... [RUN]
[0m11:59:51.098097 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc)
[0m11:59:51.113765 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m11:59:51.113765 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m11:59:51.113765 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m11:59:51.129402 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m11:59:51.129402 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m11:59:51.129402 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_13733]
   as 
    
    
    



select Final_Price
from "my_db"."dbo"."stg_ecommerce"
where Final_Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_13733]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_13733]
  ;')
[0m11:59:51.129402 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:59:51.129402 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:59:51.129402 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:59:51.145517 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:51.145517 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: ROLLBACK
[0m11:59:51.145517 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: Close
[0m11:59:51.145517 [info ] [Thread-1 (]: 8 of 14 PASS not_null_stg_ecommerce_Final_Price ................................ [[32mPASS[0m in 0.05s]
[0m11:59:51.162535 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m11:59:51.162535 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m11:59:51.162535 [info ] [Thread-1 (]: 9 of 14 START test not_null_stg_ecommerce_Payment_Method ....................... [RUN]
[0m11:59:51.162535 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d)
[0m11:59:51.162535 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m11:59:51.171705 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m11:59:51.171705 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m11:59:51.171705 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m11:59:51.189725 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m11:59:51.191267 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_3310]
   as 
    
    
    



select Payment_Method
from "my_db"."dbo"."stg_ecommerce"
where Payment_Method is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_3310]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_3310]
  ;')
[0m11:59:51.194640 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:59:51.194640 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:59:51.194640 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:59:51.194640 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:51.210389 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: ROLLBACK
[0m11:59:51.210389 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: Close
[0m11:59:51.210389 [info ] [Thread-1 (]: 9 of 14 PASS not_null_stg_ecommerce_Payment_Method ............................. [[32mPASS[0m in 0.05s]
[0m11:59:51.210389 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m11:59:51.210389 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m11:59:51.210389 [info ] [Thread-1 (]: 10 of 14 START test not_null_stg_ecommerce_Price ............................... [RUN]
[0m11:59:51.210389 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a)
[0m11:59:51.210389 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m11:59:51.226299 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m11:59:51.226299 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m11:59:51.241938 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m11:59:51.241938 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m11:59:51.241938 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_15432]
   as 
    
    
    



select Price
from "my_db"."dbo"."stg_ecommerce"
where Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_15432]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_15432]
  ;')
[0m11:59:51.241938 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:59:51.241938 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:59:51.241938 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:59:51.258576 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:51.258576 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: ROLLBACK
[0m11:59:51.258576 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: Close
[0m11:59:51.258576 [info ] [Thread-1 (]: 10 of 14 PASS not_null_stg_ecommerce_Price ..................................... [[32mPASS[0m in 0.05s]
[0m11:59:51.258576 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m11:59:51.258576 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m11:59:51.274362 [info ] [Thread-1 (]: 11 of 14 START test not_null_stg_ecommerce_Product_ID .......................... [RUN]
[0m11:59:51.276075 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c)
[0m11:59:51.276075 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m11:59:51.276075 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m11:59:51.276075 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m11:59:51.288285 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m11:59:51.288285 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m11:59:51.288285 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_17375]
   as 
    
    
    



select Product_ID
from "my_db"."dbo"."stg_ecommerce"
where Product_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_17375]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_17375]
  ;')
[0m11:59:51.288285 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:59:51.288285 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:59:51.288285 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:59:51.308654 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:51.308654 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: ROLLBACK
[0m11:59:51.308654 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: Close
[0m11:59:51.308654 [info ] [Thread-1 (]: 11 of 14 PASS not_null_stg_ecommerce_Product_ID ................................ [[32mPASS[0m in 0.03s]
[0m11:59:51.308654 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m11:59:51.308654 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m11:59:51.324563 [info ] [Thread-1 (]: 12 of 14 START test not_null_stg_ecommerce_Purchase_Date ....................... [RUN]
[0m11:59:51.324563 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307)
[0m11:59:51.324563 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m11:59:51.324563 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m11:59:51.340323 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m11:59:51.347326 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m11:59:51.350350 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m11:59:51.350350 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_5836]
   as 
    
    
    



select Purchase_Date
from "my_db"."dbo"."stg_ecommerce"
where Purchase_Date is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_5836]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_5836]
  ;')
[0m11:59:51.352865 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:59:51.352865 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:59:51.352865 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:59:51.364781 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:51.364781 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: ROLLBACK
[0m11:59:51.364781 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: Close
[0m11:59:51.364781 [info ] [Thread-1 (]: 12 of 14 PASS not_null_stg_ecommerce_Purchase_Date ............................. [[32mPASS[0m in 0.04s]
[0m11:59:51.364781 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m11:59:51.364781 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m11:59:51.380007 [info ] [Thread-1 (]: 13 of 14 START test not_null_stg_ecommerce_User_ID ............................. [RUN]
[0m11:59:51.380007 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, now test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf)
[0m11:59:51.380007 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m11:59:51.384684 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m11:59:51.397129 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m11:59:51.397129 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m11:59:51.405259 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m11:59:51.406286 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_7263]
   as 
    
    
    



select User_ID
from "my_db"."dbo"."stg_ecommerce"
where User_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_7263]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_7263]
  ;')
[0m11:59:51.409227 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:59:51.409227 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:59:51.409227 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:59:51.409227 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:51.426629 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: ROLLBACK
[0m11:59:51.426629 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: Close
[0m11:59:51.426629 [info ] [Thread-1 (]: 13 of 14 PASS not_null_stg_ecommerce_User_ID ................................... [[32mPASS[0m in 0.05s]
[0m11:59:51.426629 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m11:59:51.426629 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m11:59:51.426629 [info ] [Thread-1 (]: 14 of 14 START test unique_stg_ecommerce_Product_ID ............................ [RUN]
[0m11:59:51.426629 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, now test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1)
[0m11:59:51.426629 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m11:59:51.443321 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m11:59:51.443321 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m11:59:51.459704 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m11:59:51.459704 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m11:59:51.459704 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_11774]
   as 
    
    
    

select
    Product_ID as unique_field,
    count(*) as n_records

from "my_db"."dbo"."stg_ecommerce"
where Product_ID is not null
group by Product_ID
having count(*) > 1



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_11774]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_11774]
  ;')
[0m11:59:51.459704 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:59:51.459704 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m11:59:51.459704 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m11:59:51.506342 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m11:59:51.506342 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: ROLLBACK
[0m11:59:51.506342 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: Close
[0m11:59:51.506342 [info ] [Thread-1 (]: 14 of 14 PASS unique_stg_ecommerce_Product_ID .................................. [[32mPASS[0m in 0.08s]
[0m11:59:51.506342 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m11:59:51.506342 [debug] [MainThread]: On master: COMMIT
[0m11:59:51.506342 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:59:51.506342 [debug] [MainThread]: Connection 'list_my_db' was properly closed.
[0m11:59:51.506342 [debug] [MainThread]: Connection 'list_my_db_dbo' was properly closed.
[0m11:59:51.522248 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1' was properly closed.
[0m11:59:51.522248 [info ] [MainThread]: 
[0m11:59:51.522248 [info ] [MainThread]: Finished running 12 data tests, 2 view models in 0 hours 0 minutes and 1.54 seconds (1.54s).
[0m11:59:51.527349 [debug] [MainThread]: Command end result
[0m11:59:51.592779 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m11:59:51.604979 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m11:59:51.604979 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m11:59:51.620854 [info ] [MainThread]: 
[0m11:59:51.623395 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m11:59:51.623395 [info ] [MainThread]: 
[0m11:59:51.623395 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m11:59:51.623395 [error] [MainThread]:   Compilation Error in test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  'esc' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m11:59:51.632722 [info ] [MainThread]: 
[0m11:59:51.632722 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m11:59:51.637331 [error] [MainThread]:   Compilation Error in test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  'esc' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m11:59:51.637331 [info ] [MainThread]: 
[0m11:59:51.643653 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=14
[0m11:59:51.646556 [debug] [MainThread]: Command `dbt build` failed at 11:59:51.646556 after 7.94 seconds
[0m11:59:51.649058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E85D0F3DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E8606BD1D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E85D350550>]}
[0m11:59:51.649058 [debug] [MainThread]: Flushing usage events
[0m11:59:52.238970 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:25:25.348275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB4A9257D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB4A97BFD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB4A927F10>]}


============================== 12:25:25.348275 | 3e8a88fe-9e17-438e-bb17-4fcb5a607c18 ==============================
[0m12:25:25.348275 [info ] [MainThread]: Running with dbt=1.10.3
[0m12:25:25.358508 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt build --target sqlserver', 'send_anonymous_usage_stats': 'True'}
[0m12:25:26.277223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3e8a88fe-9e17-438e-bb17-4fcb5a607c18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB4A9BD850>]}
[0m12:25:26.377564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3e8a88fe-9e17-438e-bb17-4fcb5a607c18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB4C1C5A10>]}
[0m12:25:26.377564 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m12:25:27.137832 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m12:25:27.652740 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m12:25:27.652740 [debug] [MainThread]: Partial parsing: added file: dbt_databricks_cicd://macros\esc.sql
[0m12:25:27.876479 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m12:25:27.892157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3e8a88fe-9e17-438e-bb17-4fcb5a607c18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB4C53FA90>]}
[0m12:25:28.084021 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m12:25:28.084021 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m12:25:28.183648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3e8a88fe-9e17-438e-bb17-4fcb5a607c18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB4C27A250>]}
[0m12:25:28.183648 [info ] [MainThread]: Found 2 models, 12 data tests, 1 source, 627 macros
[0m12:25:28.183648 [info ] [MainThread]: 
[0m12:25:28.183648 [info ] [MainThread]: Concurrency: 1 threads (target='sqlserver')
[0m12:25:28.194942 [info ] [MainThread]: 
[0m12:25:28.194942 [debug] [MainThread]: Acquiring new sqlserver connection 'master'
[0m12:25:28.194942 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db'
[0m12:25:28.227574 [debug] [ThreadPool]: dbt-sqlserver
[0m12:25:28.227574 [debug] [ThreadPool]: Using sqlserver connection "list_my_db"
[0m12:25:28.227574 [debug] [ThreadPool]: On list_my_db: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db"} */
USE [my_db];
    select  name as [schema]
    from sys.schemas with (nolock) 
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m12:25:28.243191 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:25:28.243191 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:28.342513 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m12:25:28.342513 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:25:28.342513 [debug] [ThreadPool]: On list_my_db: Close
[0m12:25:28.342513 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db_dbo'
[0m12:25:28.358673 [debug] [ThreadPool]: dbt-sqlserver
[0m12:25:28.358673 [debug] [ThreadPool]: Using sqlserver connection "list_my_db_dbo"
[0m12:25:28.358673 [debug] [ThreadPool]: On list_my_db_dbo: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db_dbo"} */
USE [my_db];
    with base as (
      select
        DB_NAME() as [database],
        t.name as [name],
        SCHEMA_NAME(t.schema_id) as [schema],
        'table' as table_type
      from sys.tables as t with (nolock)
      union all
      select
        DB_NAME() as [database],
        v.name as [name],
        SCHEMA_NAME(v.schema_id) as [schema],
        'view' as table_type
      from sys.views as v with (nolock)
    )
    select * from base
    where [schema] like 'dbo'
    
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m12:25:28.358673 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:25:28.358673 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:28.358673 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m12:25:28.405552 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:25:28.405552 [debug] [ThreadPool]: On list_my_db_dbo: ROLLBACK
[0m12:25:28.405552 [debug] [ThreadPool]: On list_my_db_dbo: Close
[0m12:25:28.405552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3e8a88fe-9e17-438e-bb17-4fcb5a607c18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB4A927F50>]}
[0m12:25:28.405552 [debug] [MainThread]: On master: COMMIT
[0m12:25:28.420617 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m12:25:28.420617 [info ] [Thread-1 (]: 1 of 14 START sql view model dbo.src_ecommerce ................................. [RUN]
[0m12:25:28.427193 [debug] [Thread-1 (]: Acquiring new sqlserver connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m12:25:28.429035 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m12:25:28.429035 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m12:25:28.444732 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m12:25:28.507627 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m12:25:28.523371 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:25:28.523371 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."src_ecommerce__dbt_tmp" as 

select * from "my_db"."dbo"."ecommerce";
    ')


[0m12:25:28.523371 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:25:28.523371 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:28.534005 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:25:28.534005 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:28.552046 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:25:28.552046 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce', 'src_ecommerce__dbt_backup'
[0m12:25:28.745728 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:28.745728 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:25:28.745728 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce__dbt_tmp', 'src_ecommerce'
[0m12:25:28.745728 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:28.778816 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: COMMIT
[0m12:25:28.794874 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."src_ecommerce__dbt_backup"
[0m12:25:28.810747 [debug] [Thread-1 (]: dbt-sqlserver
[0m12:25:28.810747 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:25:28.810747 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'src_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m12:25:28.826383 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:28.842212 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:25:28.843401 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."src_ecommerce__dbt_backup";');

[0m12:25:28.843401 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:28.843401 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: ROLLBACK
[0m12:25:28.843401 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: Close
[0m12:25:28.859080 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e8a88fe-9e17-438e-bb17-4fcb5a607c18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB4C27A110>]}
[0m12:25:28.860162 [info ] [Thread-1 (]: 1 of 14 OK created sql view model dbo.src_ecommerce ............................ [[32mOK[0m in 0.42s]
[0m12:25:28.862337 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m12:25:28.862337 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m12:25:28.862337 [info ] [Thread-1 (]: 2 of 14 START sql view model dbo.stg_ecommerce ................................. [RUN]
[0m12:25:28.862337 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m12:25:28.862337 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m12:25:28.871175 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:25:28.879732 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m12:25:28.883135 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:25:28.892255 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:25:28.892255 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."stg_ecommerce__dbt_tmp" as 

SELECT
    
        CAST(User_ID AS VARCHAR) AS User_ID,
        CAST(Product_ID AS VARCHAR) AS Product_ID,
        CAST(Category AS VARCHAR) AS Category,
        CAST(Price AS FLOAT) AS Price,
        CAST(Discount AS INT) AS Discount,
        CAST(Final_Price AS FLOAT) AS Final_Price,
        CAST(Payment_Method AS VARCHAR) AS Payment_Method,
        CAST(Purchase_Date AS DATE) AS Purchase_Date
    
FROM "my_db"."dbo"."ecommerce";
    ')


[0m12:25:28.895593 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:25:28.895593 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:28.895593 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:25:28.895593 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:28.911327 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:25:28.911327 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce', 'stg_ecommerce__dbt_backup'
[0m12:25:28.911327 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:28.911327 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:25:28.911327 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce__dbt_tmp', 'stg_ecommerce'
[0m12:25:28.927753 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:28.927753 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: COMMIT
[0m12:25:28.927753 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."stg_ecommerce__dbt_backup"
[0m12:25:28.927753 [debug] [Thread-1 (]: dbt-sqlserver
[0m12:25:28.927753 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:25:28.927753 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'stg_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m12:25:28.959093 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:28.959093 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:25:28.959093 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."stg_ecommerce__dbt_backup";');

[0m12:25:28.964220 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:28.964220 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: ROLLBACK
[0m12:25:28.964220 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: Close
[0m12:25:28.964220 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e8a88fe-9e17-438e-bb17-4fcb5a607c18', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB4C7ECC10>]}
[0m12:25:28.964220 [info ] [Thread-1 (]: 2 of 14 OK created sql view model dbo.stg_ecommerce ............................ [[32mOK[0m in 0.10s]
[0m12:25:28.964220 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m12:25:28.964220 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:25:28.979885 [info ] [Thread-1 (]: 3 of 14 START test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m12:25:28.981481 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6)
[0m12:25:28.981481 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:25:28.999814 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m12:25:28.999814 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:25:29.047344 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m12:25:29.047344 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m12:25:29.047344 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_18092]
   as 
    
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from "my_db"."dbo"."stg_ecommerce"
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    ''Credit Card'',''Net Banking'',''UPI'',''Debit Card'',''Cash on Delivery''
)



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_18092]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_18092]
  ;')
[0m12:25:29.047344 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:25:29.047344 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:29.062965 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:25:29.078652 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:29.078652 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: ROLLBACK
[0m12:25:29.078652 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: Close
[0m12:25:29.078652 [info ] [Thread-1 (]: 3 of 14 PASS accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[32mPASS[0m in 0.10s]
[0m12:25:29.078652 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:25:29.094358 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675
[0m12:25:29.094358 [info ] [Thread-1 (]: 4 of 14 START test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0  [RUN]
[0m12:25:29.099127 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675)
[0m12:25:29.099127 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675
[0m12:25:29.120990 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675"
[0m12:25:29.120990 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675
[0m12:25:29.120990 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675"
[0m12:25:29.120990 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675"
[0m12:25:29.120990 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_eac7153e23b8ffd164a643e36d36a6e9_18801]
   as 
    



select
    1
from "my_db"."dbo"."stg_ecommerce"

where not(Discount 
    
        [Discount]
    
 >= 0)


  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_eac7153e23b8ffd164a643e36d36a6e9_18801]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_eac7153e23b8ffd164a643e36d36a6e9_18801]
  ;')
[0m12:25:29.120990 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:25:29.120990 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:29.137307 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:25:29.137307 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:29.153674 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675: ROLLBACK
[0m12:25:29.153674 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675: Close
[0m12:25:29.153674 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\dbt_utils_expression_is_true_s_3ce755531dc50aaade49c922546eb8f7.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Discount'. (102) (SQLMoreResults)")
[0m12:25:29.246111 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Discount'. (102) (SQLMoreResults)")

[0m12:25:29.246111 [error] [Thread-1 (]: 4 of 14 ERROR dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0  [[31mERROR[0m in 0.15s]
[0m12:25:29.246111 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675
[0m12:25:29.246111 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc
[0m12:25:29.246111 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Discount'. (102) (SQLMoreResults)").
[0m12:25:29.246111 [info ] [Thread-1 (]: 5 of 14 START test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0  [RUN]
[0m12:25:29.262066 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc)
[0m12:25:29.262066 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc
[0m12:25:29.262066 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc"
[0m12:25:29.262066 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc
[0m12:25:29.277844 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc"
[0m12:25:29.277844 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc"
[0m12:25:29.277844 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_2071d09671a293e7587ae78e8806e856_13718]
   as 
    



select
    1
from "my_db"."dbo"."stg_ecommerce"

where not(Price 
    
        [Price]
    
 >= 0)


  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_2071d09671a293e7587ae78e8806e856_13718]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_2071d09671a293e7587ae78e8806e856_13718]
  ;')
[0m12:25:29.277844 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:25:29.277844 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:29.277844 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:25:29.293640 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:29.293640 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc: ROLLBACK
[0m12:25:29.293640 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc: Close
[0m12:25:29.293640 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Price'. (102) (SQLMoreResults)")
[0m12:25:29.293640 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Price'. (102) (SQLMoreResults)")

[0m12:25:29.293640 [error] [Thread-1 (]: 5 of 14 ERROR dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 ... [[31mERROR[0m in 0.03s]
[0m12:25:29.309441 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc
[0m12:25:29.309441 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:25:29.309441 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Price'. (102) (SQLMoreResults)").
[0m12:25:29.309441 [info ] [Thread-1 (]: 6 of 14 START test not_null_stg_ecommerce_Category ............................. [RUN]
[0m12:25:29.315996 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14)
[0m12:25:29.315996 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:25:29.315996 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m12:25:29.333744 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:25:29.339846 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m12:25:29.339846 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m12:25:29.339846 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_5935]
   as 
    
    
    



select Category
from "my_db"."dbo"."stg_ecommerce"
where Category is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_5935]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_5935]
  ;')
[0m12:25:29.339846 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:25:29.339846 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:29.339846 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:25:29.355598 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:29.355598 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: ROLLBACK
[0m12:25:29.372092 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: Close
[0m12:25:29.372092 [info ] [Thread-1 (]: 6 of 14 PASS not_null_stg_ecommerce_Category ................................... [[32mPASS[0m in 0.06s]
[0m12:25:29.372092 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:25:29.372092 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:25:29.372092 [info ] [Thread-1 (]: 7 of 14 START test not_null_stg_ecommerce_Discount ............................. [RUN]
[0m12:25:29.372092 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836)
[0m12:25:29.372092 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:25:29.387847 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m12:25:29.387847 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:25:29.387847 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m12:25:29.404022 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m12:25:29.404022 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_3895]
   as 
    
    
    



select Discount
from "my_db"."dbo"."stg_ecommerce"
where Discount is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_3895]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_3895]
  ;')
[0m12:25:29.404022 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:25:29.404022 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:29.404022 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:25:29.420189 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:29.421955 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: ROLLBACK
[0m12:25:29.421955 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: Close
[0m12:25:29.421955 [info ] [Thread-1 (]: 7 of 14 PASS not_null_stg_ecommerce_Discount ................................... [[32mPASS[0m in 0.05s]
[0m12:25:29.421955 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:25:29.421955 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:25:29.421955 [info ] [Thread-1 (]: 8 of 14 START test not_null_stg_ecommerce_Final_Price .......................... [RUN]
[0m12:25:29.421955 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc)
[0m12:25:29.421955 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:25:29.440809 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m12:25:29.440809 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:25:29.440809 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m12:25:29.457402 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m12:25:29.457402 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_18588]
   as 
    
    
    



select Final_Price
from "my_db"."dbo"."stg_ecommerce"
where Final_Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_18588]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_18588]
  ;')
[0m12:25:29.457402 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:25:29.457402 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:29.457402 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:25:29.475826 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:29.482191 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: ROLLBACK
[0m12:25:29.484614 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: Close
[0m12:25:29.488285 [info ] [Thread-1 (]: 8 of 14 PASS not_null_stg_ecommerce_Final_Price ................................ [[32mPASS[0m in 0.07s]
[0m12:25:29.492368 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:25:29.496020 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:25:29.498536 [info ] [Thread-1 (]: 9 of 14 START test not_null_stg_ecommerce_Payment_Method ....................... [RUN]
[0m12:25:29.502283 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d)
[0m12:25:29.505187 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:25:29.513306 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m12:25:29.513306 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:25:29.513306 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m12:25:29.513306 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m12:25:29.530215 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_4151]
   as 
    
    
    



select Payment_Method
from "my_db"."dbo"."stg_ecommerce"
where Payment_Method is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_4151]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_4151]
  ;')
[0m12:25:29.530215 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:25:29.530215 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:29.530215 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:25:29.547222 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:29.548725 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: ROLLBACK
[0m12:25:29.548725 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: Close
[0m12:25:29.548725 [info ] [Thread-1 (]: 9 of 14 PASS not_null_stg_ecommerce_Payment_Method ............................. [[32mPASS[0m in 0.05s]
[0m12:25:29.548725 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:25:29.548725 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:25:29.548725 [info ] [Thread-1 (]: 10 of 14 START test not_null_stg_ecommerce_Price ............................... [RUN]
[0m12:25:29.548725 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a)
[0m12:25:29.548725 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:25:29.564407 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m12:25:29.564407 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:25:29.580102 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m12:25:29.580102 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m12:25:29.580102 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_16155]
   as 
    
    
    



select Price
from "my_db"."dbo"."stg_ecommerce"
where Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_16155]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_16155]
  ;')
[0m12:25:29.580102 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:25:29.580102 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:29.580102 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:25:29.595863 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:29.595863 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: ROLLBACK
[0m12:25:29.595863 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: Close
[0m12:25:29.595863 [info ] [Thread-1 (]: 10 of 14 PASS not_null_stg_ecommerce_Price ..................................... [[32mPASS[0m in 0.05s]
[0m12:25:29.595863 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:25:29.611756 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:25:29.611966 [info ] [Thread-1 (]: 11 of 14 START test not_null_stg_ecommerce_Product_ID .......................... [RUN]
[0m12:25:29.615503 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c)
[0m12:25:29.615503 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:25:29.615503 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m12:25:29.615503 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:25:29.632363 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m12:25:29.636445 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m12:25:29.636445 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_6693]
   as 
    
    
    



select Product_ID
from "my_db"."dbo"."stg_ecommerce"
where Product_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_6693]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_6693]
  ;')
[0m12:25:29.636445 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:25:29.636445 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:29.636445 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:25:29.653654 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:29.655292 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: ROLLBACK
[0m12:25:29.655292 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: Close
[0m12:25:29.655292 [info ] [Thread-1 (]: 11 of 14 PASS not_null_stg_ecommerce_Product_ID ................................ [[32mPASS[0m in 0.04s]
[0m12:25:29.655292 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:25:29.655292 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:25:29.655292 [info ] [Thread-1 (]: 12 of 14 START test not_null_stg_ecommerce_Purchase_Date ....................... [RUN]
[0m12:25:29.668566 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307)
[0m12:25:29.668566 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:25:29.668566 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m12:25:29.668566 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:25:29.685644 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m12:25:29.685644 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m12:25:29.685644 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_10435]
   as 
    
    
    



select Purchase_Date
from "my_db"."dbo"."stg_ecommerce"
where Purchase_Date is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_10435]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_10435]
  ;')
[0m12:25:29.685644 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:25:29.685644 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:29.685644 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:25:29.703306 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:29.703306 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: ROLLBACK
[0m12:25:29.703306 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: Close
[0m12:25:29.719539 [info ] [Thread-1 (]: 12 of 14 PASS not_null_stg_ecommerce_Purchase_Date ............................. [[32mPASS[0m in 0.05s]
[0m12:25:29.719539 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:25:29.719539 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:25:29.719539 [info ] [Thread-1 (]: 13 of 14 START test not_null_stg_ecommerce_User_ID ............................. [RUN]
[0m12:25:29.726695 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, now test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf)
[0m12:25:29.726695 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:25:29.726695 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m12:25:29.726695 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:25:29.743431 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m12:25:29.749605 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m12:25:29.749605 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_14266]
   as 
    
    
    



select User_ID
from "my_db"."dbo"."stg_ecommerce"
where User_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_14266]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_14266]
  ;')
[0m12:25:29.752603 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:25:29.754387 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:29.754387 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:25:29.754387 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:29.775283 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: ROLLBACK
[0m12:25:29.776282 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: Close
[0m12:25:29.778005 [info ] [Thread-1 (]: 13 of 14 PASS not_null_stg_ecommerce_User_ID ................................... [[32mPASS[0m in 0.05s]
[0m12:25:29.778005 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:25:29.778005 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m12:25:29.778005 [info ] [Thread-1 (]: 14 of 14 START test unique_stg_ecommerce_Product_ID ............................ [RUN]
[0m12:25:29.789026 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, now test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1)
[0m12:25:29.789026 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m12:25:29.805160 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m12:25:29.805160 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m12:25:29.805160 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m12:25:29.819893 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m12:25:29.821895 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_17231]
   as 
    
    
    

select
    Product_ID as unique_field,
    count(*) as n_records

from "my_db"."dbo"."stg_ecommerce"
where Product_ID is not null
group by Product_ID
having count(*) > 1



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_17231]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_17231]
  ;')
[0m12:25:29.821895 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:25:29.821895 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:25:29.821895 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:25:29.837737 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:25:29.837737 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: ROLLBACK
[0m12:25:29.854118 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: Close
[0m12:25:29.854118 [info ] [Thread-1 (]: 14 of 14 PASS unique_stg_ecommerce_Product_ID .................................. [[32mPASS[0m in 0.07s]
[0m12:25:29.857507 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m12:25:29.857507 [debug] [MainThread]: On master: COMMIT
[0m12:25:29.857507 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:25:29.857507 [debug] [MainThread]: Connection 'list_my_db' was properly closed.
[0m12:25:29.857507 [debug] [MainThread]: Connection 'list_my_db_dbo' was properly closed.
[0m12:25:29.857507 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1' was properly closed.
[0m12:25:29.857507 [info ] [MainThread]: 
[0m12:25:29.857507 [info ] [MainThread]: Finished running 12 data tests, 2 view models in 0 hours 0 minutes and 1.66 seconds (1.66s).
[0m12:25:29.873270 [debug] [MainThread]: Command end result
[0m12:25:29.939844 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m12:25:29.956041 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m12:25:29.956041 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m12:25:29.970985 [info ] [MainThread]: 
[0m12:25:29.970985 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m12:25:29.970985 [info ] [MainThread]: 
[0m12:25:29.970985 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m12:25:29.981163 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Discount'. (102) (SQLMoreResults)")
[0m12:25:29.981163 [info ] [MainThread]: 
[0m12:25:29.984899 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\dbt_utils_expression_is_true_s_3ce755531dc50aaade49c922546eb8f7.sql
[0m12:25:29.984899 [info ] [MainThread]: 
[0m12:25:29.984899 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m12:25:29.991724 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Price'. (102) (SQLMoreResults)")
[0m12:25:29.991724 [info ] [MainThread]: 
[0m12:25:29.991724 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.sql
[0m12:25:29.998465 [info ] [MainThread]: 
[0m12:25:29.998465 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=14
[0m12:25:30.002620 [debug] [MainThread]: Command `dbt build` failed at 12:25:30.002620 after 4.79 seconds
[0m12:25:30.002620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB43EC3DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB474C56D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CB44120550>]}
[0m12:25:30.002620 [debug] [MainThread]: Flushing usage events
[0m12:25:31.374303 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:36:21.239905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019EFDA1DE50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E825DB950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E825DBFD0>]}


============================== 12:36:21.239905 | 924144ec-51e1-46ae-9694-a87219f6e0d9 ==============================
[0m12:36:21.239905 [info ] [MainThread]: Running with dbt=1.10.3
[0m12:36:21.239905 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --target sqlserver', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:36:22.396831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '924144ec-51e1-46ae-9694-a87219f6e0d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E82583350>]}
[0m12:36:22.586288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '924144ec-51e1-46ae-9694-a87219f6e0d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E83E45DD0>]}
[0m12:36:22.587898 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m12:36:23.435719 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m12:36:24.110052 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:36:24.110052 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://macros\esc.sql
[0m12:36:24.385083 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m12:36:24.417430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '924144ec-51e1-46ae-9694-a87219f6e0d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E840C0E10>]}
[0m12:36:24.667810 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m12:36:24.681792 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m12:36:24.801869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '924144ec-51e1-46ae-9694-a87219f6e0d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E845ECB90>]}
[0m12:36:24.809995 [info ] [MainThread]: Found 2 models, 12 data tests, 1 source, 627 macros
[0m12:36:24.811798 [info ] [MainThread]: 
[0m12:36:24.811798 [info ] [MainThread]: Concurrency: 1 threads (target='sqlserver')
[0m12:36:24.818379 [info ] [MainThread]: 
[0m12:36:24.819378 [debug] [MainThread]: Acquiring new sqlserver connection 'master'
[0m12:36:24.822095 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db'
[0m12:36:24.856596 [debug] [ThreadPool]: dbt-sqlserver
[0m12:36:24.856596 [debug] [ThreadPool]: Using sqlserver connection "list_my_db"
[0m12:36:24.871771 [debug] [ThreadPool]: On list_my_db: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db"} */
USE [my_db];
    select  name as [schema]
    from sys.schemas with (nolock) 
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m12:36:24.872771 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:36:24.874768 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:24.976145 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m12:36:24.976145 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:36:24.991766 [debug] [ThreadPool]: On list_my_db: Close
[0m12:36:24.996404 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db_dbo'
[0m12:36:24.996404 [debug] [ThreadPool]: dbt-sqlserver
[0m12:36:25.009411 [debug] [ThreadPool]: Using sqlserver connection "list_my_db_dbo"
[0m12:36:25.011244 [debug] [ThreadPool]: On list_my_db_dbo: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db_dbo"} */
USE [my_db];
    with base as (
      select
        DB_NAME() as [database],
        t.name as [name],
        SCHEMA_NAME(t.schema_id) as [schema],
        'table' as table_type
      from sys.tables as t with (nolock)
      union all
      select
        DB_NAME() as [database],
        v.name as [name],
        SCHEMA_NAME(v.schema_id) as [schema],
        'view' as table_type
      from sys.views as v with (nolock)
    )
    select * from base
    where [schema] like 'dbo'
    
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m12:36:25.011244 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:36:25.015103 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:25.015103 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m12:36:25.058174 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m12:36:25.058174 [debug] [ThreadPool]: On list_my_db_dbo: ROLLBACK
[0m12:36:25.058174 [debug] [ThreadPool]: On list_my_db_dbo: Close
[0m12:36:25.070025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '924144ec-51e1-46ae-9694-a87219f6e0d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E83E3C4D0>]}
[0m12:36:25.070025 [debug] [MainThread]: On master: COMMIT
[0m12:36:25.077877 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m12:36:25.077877 [info ] [Thread-1 (]: 1 of 14 START sql view model dbo.src_ecommerce ................................. [RUN]
[0m12:36:25.085625 [debug] [Thread-1 (]: Acquiring new sqlserver connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m12:36:25.086621 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m12:36:25.109974 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m12:36:25.118201 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m12:36:25.187541 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m12:36:25.187541 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:36:25.201076 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."src_ecommerce__dbt_tmp" as 

select * from "my_db"."dbo"."ecommerce";
    ')


[0m12:36:25.201076 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:36:25.205276 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:25.212520 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:36:25.212520 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:25.221172 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:36:25.221172 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce', 'src_ecommerce__dbt_backup'
[0m12:36:25.428510 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:25.444250 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:36:25.445874 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce__dbt_tmp', 'src_ecommerce'
[0m12:36:25.445874 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:25.503768 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: COMMIT
[0m12:36:25.518609 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."src_ecommerce__dbt_backup"
[0m12:36:25.534474 [debug] [Thread-1 (]: dbt-sqlserver
[0m12:36:25.534474 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:36:25.534474 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'src_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m12:36:25.565887 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:25.567341 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:36:25.567341 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."src_ecommerce__dbt_backup";');

[0m12:36:25.573613 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:25.573613 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: ROLLBACK
[0m12:36:25.573613 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: Close
[0m12:36:25.590067 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '924144ec-51e1-46ae-9694-a87219f6e0d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E83EEBC50>]}
[0m12:36:25.593517 [info ] [Thread-1 (]: 1 of 14 OK created sql view model dbo.src_ecommerce ............................ [[32mOK[0m in 0.50s]
[0m12:36:25.597115 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m12:36:25.597115 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m12:36:25.601316 [info ] [Thread-1 (]: 2 of 14 START sql view model dbo.stg_ecommerce ................................. [RUN]
[0m12:36:25.601316 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m12:36:25.601316 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m12:36:25.609329 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:36:25.617261 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m12:36:25.618260 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:36:25.632391 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:36:25.634723 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."stg_ecommerce__dbt_tmp" as 

SELECT
    
        CAST(User_ID AS VARCHAR) AS User_ID,
        CAST(Product_ID AS VARCHAR) AS Product_ID,
        CAST(Category AS VARCHAR) AS Category,
        CAST(Price AS FLOAT) AS Price,
        CAST(Discount AS INT) AS Discount,
        CAST(Final_Price AS FLOAT) AS Final_Price,
        CAST(Payment_Method AS VARCHAR) AS Payment_Method,
        CAST(Purchase_Date AS DATE) AS Purchase_Date
    
FROM "my_db"."dbo"."ecommerce";
    ')


[0m12:36:25.636216 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:36:25.636216 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:25.638839 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:36:25.640742 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:25.640742 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:36:25.640742 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce', 'stg_ecommerce__dbt_backup'
[0m12:36:25.653938 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:25.653938 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:36:25.653938 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce__dbt_tmp', 'stg_ecommerce'
[0m12:36:25.665698 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:25.665698 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: COMMIT
[0m12:36:25.665698 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."stg_ecommerce__dbt_backup"
[0m12:36:25.665698 [debug] [Thread-1 (]: dbt-sqlserver
[0m12:36:25.681175 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:36:25.683176 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'stg_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m12:36:25.703740 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:25.705293 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:36:25.705293 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."stg_ecommerce__dbt_backup";');

[0m12:36:25.710967 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:25.712755 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: ROLLBACK
[0m12:36:25.712755 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: Close
[0m12:36:25.712755 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '924144ec-51e1-46ae-9694-a87219f6e0d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E84D23190>]}
[0m12:36:25.718210 [info ] [Thread-1 (]: 2 of 14 OK created sql view model dbo.stg_ecommerce ............................ [[32mOK[0m in 0.11s]
[0m12:36:25.720513 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m12:36:25.724231 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:36:25.724231 [info ] [Thread-1 (]: 3 of 14 START test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m12:36:25.729530 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6)
[0m12:36:25.729530 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:36:25.752962 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m12:36:25.767349 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:36:25.816954 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m12:36:25.818486 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m12:36:25.820760 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_15099]
   as 
    
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from "my_db"."dbo"."stg_ecommerce"
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    ''Credit Card'',''Net Banking'',''UPI'',''Debit Card'',''Cash on Delivery''
)



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_15099]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_15099]
  ;')
[0m12:36:25.820760 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:36:25.824418 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:25.824418 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:36:25.841414 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:25.857191 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: ROLLBACK
[0m12:36:25.859012 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: Close
[0m12:36:25.860591 [info ] [Thread-1 (]: 3 of 14 PASS accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[32mPASS[0m in 0.13s]
[0m12:36:25.860591 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:36:25.860591 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675
[0m12:36:25.860591 [info ] [Thread-1 (]: 4 of 14 START test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0  [RUN]
[0m12:36:25.871463 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675)
[0m12:36:25.874751 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675
[0m12:36:25.907982 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675"
[0m12:36:25.912290 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675
[0m12:36:25.917714 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675"
[0m12:36:25.922204 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675"
[0m12:36:25.924524 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_3feee64598b3e11c86203428d3233835_11663]
   as 
    



select
    1
from "my_db"."dbo"."stg_ecommerce"

where not(Discount [Discount] >= 0)


  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_3feee64598b3e11c86203428d3233835_11663]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_3feee64598b3e11c86203428d3233835_11663]
  ;')
[0m12:36:25.924524 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:36:25.929363 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:25.929363 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:36:25.929363 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:25.941071 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675: ROLLBACK
[0m12:36:25.941071 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675: Close
[0m12:36:25.943988 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\dbt_utils_expression_is_true_s_3ce755531dc50aaade49c922546eb8f7.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Discount'. (102) (SQLMoreResults)")
[0m12:36:25.956307 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Discount'. (102) (SQLMoreResults)")

[0m12:36:25.956307 [error] [Thread-1 (]: 4 of 14 ERROR dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0  [[31mERROR[0m in 0.09s]
[0m12:36:25.964995 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675
[0m12:36:25.964995 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc
[0m12:36:25.964995 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Discount'. (102) (SQLMoreResults)").
[0m12:36:25.964995 [info ] [Thread-1 (]: 5 of 14 START test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0  [RUN]
[0m12:36:25.976124 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0.f600cd5675, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc)
[0m12:36:25.978126 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc
[0m12:36:25.979496 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc"
[0m12:36:25.989656 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc
[0m12:36:25.990671 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc"
[0m12:36:26.007503 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc"
[0m12:36:26.007503 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_62decf62f91a622cc046af79e15cbad8_1730]
   as 
    



select
    1
from "my_db"."dbo"."stg_ecommerce"

where not(Price [Price] >= 0)


  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_62decf62f91a622cc046af79e15cbad8_1730]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_62decf62f91a622cc046af79e15cbad8_1730]
  ;')
[0m12:36:26.010653 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:36:26.010653 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:26.010653 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:36:26.016099 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:26.016099 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc: ROLLBACK
[0m12:36:26.020942 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc: Close
[0m12:36:26.020942 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Price'. (102) (SQLMoreResults)")
[0m12:36:26.020942 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Price'. (102) (SQLMoreResults)")

[0m12:36:26.020942 [error] [Thread-1 (]: 5 of 14 ERROR dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 ... [[31mERROR[0m in 0.04s]
[0m12:36:26.020942 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc
[0m12:36:26.036724 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:36:26.039165 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Price'. (102) (SQLMoreResults)").
[0m12:36:26.040431 [info ] [Thread-1 (]: 6 of 14 START test not_null_stg_ecommerce_Category ............................. [RUN]
[0m12:36:26.043889 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.0960221acc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14)
[0m12:36:26.043889 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:36:26.058992 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m12:36:26.062351 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:36:26.063362 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m12:36:26.072084 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m12:36:26.073922 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_5400]
   as 
    
    
    



select Category
from "my_db"."dbo"."stg_ecommerce"
where Category is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_5400]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_5400]
  ;')
[0m12:36:26.073922 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:36:26.077360 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:26.077360 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:36:26.081631 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:26.081631 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: ROLLBACK
[0m12:36:26.098360 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: Close
[0m12:36:26.100707 [info ] [Thread-1 (]: 6 of 14 PASS not_null_stg_ecommerce_Category ................................... [[32mPASS[0m in 0.06s]
[0m12:36:26.104405 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:36:26.106984 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:36:26.106984 [info ] [Thread-1 (]: 7 of 14 START test not_null_stg_ecommerce_Discount ............................. [RUN]
[0m12:36:26.110877 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836)
[0m12:36:26.110877 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:36:26.114622 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m12:36:26.129607 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:36:26.129607 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m12:36:26.137278 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m12:36:26.137278 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_14082]
   as 
    
    
    



select Discount
from "my_db"."dbo"."stg_ecommerce"
where Discount is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_14082]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_14082]
  ;')
[0m12:36:26.140150 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:36:26.141223 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:26.144045 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:36:26.144045 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:26.159290 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: ROLLBACK
[0m12:36:26.159290 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: Close
[0m12:36:26.163814 [info ] [Thread-1 (]: 7 of 14 PASS not_null_stg_ecommerce_Discount ................................... [[32mPASS[0m in 0.05s]
[0m12:36:26.163814 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:36:26.163814 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:36:26.172777 [info ] [Thread-1 (]: 8 of 14 START test not_null_stg_ecommerce_Final_Price .......................... [RUN]
[0m12:36:26.176062 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc)
[0m12:36:26.176062 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:36:26.193641 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m12:36:26.196852 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:36:26.199116 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m12:36:26.206188 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m12:36:26.210112 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_3007]
   as 
    
    
    



select Final_Price
from "my_db"."dbo"."stg_ecommerce"
where Final_Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_3007]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_3007]
  ;')
[0m12:36:26.212111 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:36:26.212111 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:26.214392 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:36:26.214392 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:26.230527 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: ROLLBACK
[0m12:36:26.230527 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: Close
[0m12:36:26.234738 [info ] [Thread-1 (]: 8 of 14 PASS not_null_stg_ecommerce_Final_Price ................................ [[32mPASS[0m in 0.06s]
[0m12:36:26.234738 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:36:26.239518 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:36:26.239518 [info ] [Thread-1 (]: 9 of 14 START test not_null_stg_ecommerce_Payment_Method ....................... [RUN]
[0m12:36:26.243711 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d)
[0m12:36:26.245530 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:36:26.257782 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m12:36:26.262798 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:36:26.264750 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m12:36:26.271002 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m12:36:26.272727 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_18817]
   as 
    
    
    



select Payment_Method
from "my_db"."dbo"."stg_ecommerce"
where Payment_Method is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_18817]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_18817]
  ;')
[0m12:36:26.273728 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:36:26.273728 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:26.273728 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:36:26.281096 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:26.296812 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: ROLLBACK
[0m12:36:26.296812 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: Close
[0m12:36:26.296812 [info ] [Thread-1 (]: 9 of 14 PASS not_null_stg_ecommerce_Payment_Method ............................. [[32mPASS[0m in 0.05s]
[0m12:36:26.306612 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:36:26.306612 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:36:26.311303 [info ] [Thread-1 (]: 10 of 14 START test not_null_stg_ecommerce_Price ............................... [RUN]
[0m12:36:26.313289 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a)
[0m12:36:26.315816 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:36:26.324370 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m12:36:26.329722 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:36:26.331810 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m12:36:26.331810 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m12:36:26.347886 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_12970]
   as 
    
    
    



select Price
from "my_db"."dbo"."stg_ecommerce"
where Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_12970]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_12970]
  ;')
[0m12:36:26.349625 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:36:26.352091 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:26.353094 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:36:26.358211 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:26.373964 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: ROLLBACK
[0m12:36:26.373964 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: Close
[0m12:36:26.376595 [info ] [Thread-1 (]: 10 of 14 PASS not_null_stg_ecommerce_Price ..................................... [[32mPASS[0m in 0.06s]
[0m12:36:26.376595 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:36:26.376595 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:36:26.383760 [info ] [Thread-1 (]: 11 of 14 START test not_null_stg_ecommerce_Product_ID .......................... [RUN]
[0m12:36:26.383760 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c)
[0m12:36:26.389229 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:36:26.408558 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m12:36:26.414907 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:36:26.414907 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m12:36:26.430769 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m12:36:26.433333 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_18110]
   as 
    
    
    



select Product_ID
from "my_db"."dbo"."stg_ecommerce"
where Product_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_18110]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_18110]
  ;')
[0m12:36:26.435340 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:36:26.435340 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:26.437783 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:36:26.440219 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:26.457030 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: ROLLBACK
[0m12:36:26.458028 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: Close
[0m12:36:26.459333 [info ] [Thread-1 (]: 11 of 14 PASS not_null_stg_ecommerce_Product_ID ................................ [[32mPASS[0m in 0.08s]
[0m12:36:26.462632 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:36:26.462632 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:36:26.462632 [info ] [Thread-1 (]: 12 of 14 START test not_null_stg_ecommerce_Purchase_Date ....................... [RUN]
[0m12:36:26.470279 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307)
[0m12:36:26.475051 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:36:26.495525 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m12:36:26.499673 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:36:26.513558 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m12:36:26.517746 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m12:36:26.519748 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_9532]
   as 
    
    
    



select Purchase_Date
from "my_db"."dbo"."stg_ecommerce"
where Purchase_Date is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_9532]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_9532]
  ;')
[0m12:36:26.522937 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:36:26.525748 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:26.528044 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:36:26.541345 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:26.541345 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: ROLLBACK
[0m12:36:26.541345 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: Close
[0m12:36:26.554370 [info ] [Thread-1 (]: 12 of 14 PASS not_null_stg_ecommerce_Purchase_Date ............................. [[32mPASS[0m in 0.08s]
[0m12:36:26.558670 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:36:26.558670 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:36:26.558670 [info ] [Thread-1 (]: 13 of 14 START test not_null_stg_ecommerce_User_ID ............................. [RUN]
[0m12:36:26.565321 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, now test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf)
[0m12:36:26.566931 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:36:26.574054 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m12:36:26.578576 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:36:26.578576 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m12:36:26.585845 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m12:36:26.585845 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_3770]
   as 
    
    
    



select User_ID
from "my_db"."dbo"."stg_ecommerce"
where User_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_3770]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_3770]
  ;')
[0m12:36:26.588226 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:36:26.590103 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:26.590103 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:36:26.593841 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:26.609862 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: ROLLBACK
[0m12:36:26.609862 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: Close
[0m12:36:26.616965 [info ] [Thread-1 (]: 13 of 14 PASS not_null_stg_ecommerce_User_ID ................................... [[32mPASS[0m in 0.05s]
[0m12:36:26.616965 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:36:26.622506 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m12:36:26.622506 [info ] [Thread-1 (]: 14 of 14 START test unique_stg_ecommerce_Product_ID ............................ [RUN]
[0m12:36:26.622506 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, now test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1)
[0m12:36:26.628071 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m12:36:26.640973 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m12:36:26.646536 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m12:36:26.651433 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m12:36:26.659718 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m12:36:26.662722 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_4813]
   as 
    
    
    

select
    Product_ID as unique_field,
    count(*) as n_records

from "my_db"."dbo"."stg_ecommerce"
where Product_ID is not null
group by Product_ID
having count(*) > 1



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_4813]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_4813]
  ;')
[0m12:36:26.662722 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:36:26.665442 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m12:36:26.665442 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m12:36:26.686811 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m12:36:26.686811 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: ROLLBACK
[0m12:36:26.686811 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: Close
[0m12:36:26.700556 [info ] [Thread-1 (]: 14 of 14 PASS unique_stg_ecommerce_Product_ID .................................. [[32mPASS[0m in 0.08s]
[0m12:36:26.704854 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m12:36:26.708508 [debug] [MainThread]: On master: COMMIT
[0m12:36:26.708508 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:36:26.710908 [debug] [MainThread]: Connection 'list_my_db' was properly closed.
[0m12:36:26.710908 [debug] [MainThread]: Connection 'list_my_db_dbo' was properly closed.
[0m12:36:26.710908 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1' was properly closed.
[0m12:36:26.713881 [info ] [MainThread]: 
[0m12:36:26.713881 [info ] [MainThread]: Finished running 12 data tests, 2 view models in 0 hours 0 minutes and 1.89 seconds (1.89s).
[0m12:36:26.718184 [debug] [MainThread]: Command end result
[0m12:36:26.823042 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m12:36:26.839988 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m12:36:26.841102 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m12:36:26.841102 [info ] [MainThread]: 
[0m12:36:26.856485 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m12:36:26.861206 [info ] [MainThread]: 
[0m12:36:26.864589 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_stg_ecommerce_Discount___esc_Discount_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m12:36:26.867756 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Discount'. (102) (SQLMoreResults)")
[0m12:36:26.870404 [info ] [MainThread]: 
[0m12:36:26.878194 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\dbt_utils_expression_is_true_s_3ce755531dc50aaade49c922546eb8f7.sql
[0m12:36:26.880501 [info ] [MainThread]: 
[0m12:36:26.880501 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0 (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m12:36:26.880501 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a 'Price'. (102) (SQLMoreResults)")
[0m12:36:26.880501 [info ] [MainThread]: 
[0m12:36:26.880501 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\dbt_utils_expression_is_true_stg_ecommerce_Price___esc_Price_0.sql
[0m12:36:26.891525 [info ] [MainThread]: 
[0m12:36:26.891525 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=14
[0m12:36:26.896103 [debug] [MainThread]: Command `dbt build` failed at 12:36:26.896103 after 5.85 seconds
[0m12:36:26.896103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019EFBAD3DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019E84D41D50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000019EFBD30550>]}
[0m12:36:26.900542 [debug] [MainThread]: Flushing usage events
[0m12:36:27.497126 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:46:29.964291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE2DA8B110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE2DA8BA90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE2DA34210>]}


============================== 12:46:29.964291 | 7a54bf8c-1b42-43f1-beac-c56a5428291e ==============================
[0m12:46:29.964291 [info ] [MainThread]: Running with dbt=1.10.3
[0m12:46:29.980295 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt build --target sqlserver', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:46:31.010183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7a54bf8c-1b42-43f1-beac-c56a5428291e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE2C9F2C90>]}
[0m12:46:31.122184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7a54bf8c-1b42-43f1-beac-c56a5428291e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE2C9A1ED0>]}
[0m12:46:31.122184 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m12:46:31.899176 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m12:46:32.157876 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading dbt_databricks_cicd: staging\databricks\schema.yml - Runtime Error
    Syntax error near line 27
    ------------------------------
    24 |       - name: Price
    25 |         tests:
    26 |           - not_null
    27 |           {% if target.name == 'databricks' %}
    28 |           - dbt_utils.expression_is_true:
    29 |               expression: "{{ esc('Price') }} >= 0"
    30 |           {% endif %}
    
    Raw Error:
    ------------------------------
    while scanning for the next token
    found character that cannot start any token
      in "<unicode string>", line 27, column 12
[0m12:46:32.177191 [debug] [MainThread]: Command `dbt build` failed at 12:46:32.177191 after 2.37 seconds
[0m12:46:32.177191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE2DA379D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE27023DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CE2DA8AE10>]}
[0m12:46:32.177191 [debug] [MainThread]: Flushing usage events
[0m12:46:34.259194 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:46:24.548328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025B22917F90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025B22917AD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025B22915810>]}


============================== 20:46:24.556330 | 7d8f4ae4-30c1-4a6b-9042-6b44f0efc8a3 ==============================
[0m20:46:24.556330 [info ] [MainThread]: Running with dbt=1.10.3
[0m20:46:24.564321 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt build --target sqlserver', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m20:46:25.534620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7d8f4ae4-30c1-4a6b-9042-6b44f0efc8a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025B22907E10>]}
[0m20:46:25.636841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7d8f4ae4-30c1-4a6b-9042-6b44f0efc8a3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025B21871D90>]}
[0m20:46:25.652659 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m20:46:26.398351 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m20:46:26.649945 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading dbt_databricks_cicd: staging\databricks\schema.yml - Runtime Error
    Syntax error near line 27
    ------------------------------
    24 |       - name: Price
    25 |         tests:
    26 |           - not_null
    27 |           {% if target.name == 'databricks' %}
    28 |           - dbt_utils.expression_is_true:
    29 |               expression: "{{ esc('Price') }} >= 0"
    30 |           {% endif %}
    
    Raw Error:
    ------------------------------
    while scanning for the next token
    found character that cannot start any token
      in "<unicode string>", line 27, column 12
[0m20:46:26.649945 [debug] [MainThread]: Command `dbt build` failed at 20:46:26.649945 after 2.25 seconds
[0m20:46:26.657987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025B1BE53DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025B22916710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025B22917C90>]}
[0m20:46:26.657987 [debug] [MainThread]: Flushing usage events
[0m20:46:27.803159 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m08:30:52.461416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002852F5F3E90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002852F5F3650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002852F5F3A90>]}


============================== 08:30:52.461416 | 8e21cf8d-cf8f-4ec5-82ea-d26da14c7b8b ==============================
[0m08:30:52.461416 [info ] [MainThread]: Running with dbt=1.10.3
[0m08:30:52.477081 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt build --target sqlserver', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m08:30:57.648956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8e21cf8d-cf8f-4ec5-82ea-d26da14c7b8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028530D7CB90>]}
[0m08:30:57.758301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8e21cf8d-cf8f-4ec5-82ea-d26da14c7b8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002852E571E10>]}
[0m08:30:57.758301 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m08:30:58.727088 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m08:30:59.102047 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading dbt_databricks_cicd: staging\databricks\schema.yml - Runtime Error
    Syntax error near line 27
    ------------------------------
    24 |       - name: Price
    25 |         tests:
    26 |           - not_null
    27 | {% if target.name == 'databricks' %}
    28 |           - dbt_utils.expression_is_true:
    29 |               expression: "{{ esc('Price') }} >= 0"
    30 | {% endif %}
    
    Raw Error:
    ------------------------------
    while scanning for the next token
    found character that cannot start any token
      in "<unicode string>", line 27, column 2
[0m08:30:59.102047 [debug] [MainThread]: Command `dbt build` failed at 08:30:59.102047 after 6.81 seconds
[0m08:30:59.102047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028528BB3DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002852F65B790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002852F65B690>]}
[0m08:30:59.102047 [debug] [MainThread]: Flushing usage events
[0m08:31:00.274057 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:34:41.741938 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BE47D31ED0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BE47D33710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BE47D30250>]}


============================== 09:34:41.741938 | 67716ad0-30ef-4b2f-b256-4ad5d9bc13a5 ==============================
[0m09:34:41.741938 [info ] [MainThread]: Running with dbt=1.10.3
[0m09:34:41.757565 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt clean', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:34:42.070065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '67716ad0-30ef-4b2f-b256-4ad5d9bc13a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BE47A48C10>]}
[0m09:34:42.257564 [debug] [MainThread]: Command `dbt clean` succeeded at 09:34:42.257564 after 0.65 seconds
[0m09:34:42.257564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BE41243C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BE41526290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002BE4762C250>]}
[0m09:34:42.257564 [debug] [MainThread]: Flushing usage events
[0m09:34:43.273195 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:35:16.196103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023982476CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023982477C50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023982474510>]}


============================== 09:35:16.211731 | a6ce2e81-1909-4f81-9fa1-be735da18c0e ==============================
[0m09:35:16.211731 [info ] [MainThread]: Running with dbt=1.10.3
[0m09:35:16.211731 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt deps', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:35:16.602357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a6ce2e81-1909-4f81-9fa1-be735da18c0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000023982378950>]}
[0m09:35:16.727357 [debug] [MainThread]: Set downloads directory='C:\Users\diniz\AppData\Local\Temp\dbt-downloads-306bbpu7'
[0m09:35:16.727357 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m09:35:17.086728 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m09:35:17.086728 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m09:35:17.164853 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m09:35:17.164853 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m09:35:18.071108 [info ] [MainThread]: Installed from version 1.3.0
[0m09:35:18.071108 [info ] [MainThread]: Up to date!
[0m09:35:18.071108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'a6ce2e81-1909-4f81-9fa1-be735da18c0e', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239825A4610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239825739D0>]}
[0m09:35:18.086736 [debug] [MainThread]: Command `dbt deps` succeeded at 09:35:18.086736 after 2.02 seconds
[0m09:35:18.086736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239FBA13C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239FBCF6310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000239FBC70210>]}
[0m09:35:18.086736 [debug] [MainThread]: Flushing usage events
[0m09:35:18.681739 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:35:38.957213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210024703D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021002470690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021002471F90>]}


============================== 09:35:38.972837 | 5fecb2a2-a939-401a-b020-f5a2e1444f92 ==============================
[0m09:35:38.972837 [info ] [MainThread]: Running with dbt=1.10.3
[0m09:35:38.972837 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --target sqlserver', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m09:35:39.957207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5fecb2a2-a939-401a-b020-f5a2e1444f92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021003D32A50>]}
[0m09:35:40.066618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5fecb2a2-a939-401a-b020-f5a2e1444f92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210013F2010>]}
[0m09:35:40.066618 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m09:35:40.847879 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m09:35:40.863455 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m09:35:40.863455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '5fecb2a2-a939-401a-b020-f5a2e1444f92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021003CDAE50>]}
[0m09:35:46.863515 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m09:35:46.863515 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m09:35:46.863515 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m09:35:46.863515 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m09:35:46.863515 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m09:35:46.863515 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m09:35:46.863515 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m09:35:46.863515 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m09:35:46.863515 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m09:35:46.879081 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m09:35:46.879081 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m09:35:46.879081 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m09:35:46.879081 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m09:35:46.879081 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m09:35:46.879081 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m09:35:46.879081 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m09:35:46.879081 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m09:35:46.879081 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m09:35:46.879081 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m09:35:46.879081 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m09:35:46.879081 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m09:35:46.879081 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m09:35:46.879081 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m09:35:46.894712 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m09:35:46.894712 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m09:35:46.894712 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m09:35:46.894712 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m09:35:47.051014 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m09:35:47.066587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5fecb2a2-a939-401a-b020-f5a2e1444f92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210044EEB10>]}
[0m09:35:47.347832 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m09:35:47.379078 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m09:35:47.504098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5fecb2a2-a939-401a-b020-f5a2e1444f92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021004318DD0>]}
[0m09:35:47.504098 [info ] [MainThread]: Found 2 models, 12 data tests, 1 source, 628 macros
[0m09:35:47.519707 [info ] [MainThread]: 
[0m09:35:47.519707 [info ] [MainThread]: Concurrency: 1 threads (target='sqlserver')
[0m09:35:47.519707 [info ] [MainThread]: 
[0m09:35:47.519707 [debug] [MainThread]: Acquiring new sqlserver connection 'master'
[0m09:35:47.535334 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db'
[0m09:35:47.551013 [debug] [ThreadPool]: dbt-sqlserver
[0m09:35:47.566619 [debug] [ThreadPool]: Using sqlserver connection "list_my_db"
[0m09:35:47.566619 [debug] [ThreadPool]: On list_my_db: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db"} */
USE [my_db];
    select  name as [schema]
    from sys.schemas with (nolock) 
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m09:35:47.566619 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:35:47.566619 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:35:47.660336 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m09:35:47.675964 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m09:35:47.675964 [debug] [ThreadPool]: On list_my_db: Close
[0m09:35:47.675964 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db_dbo'
[0m09:35:47.691627 [debug] [ThreadPool]: dbt-sqlserver
[0m09:35:47.691627 [debug] [ThreadPool]: Using sqlserver connection "list_my_db_dbo"
[0m09:35:47.691627 [debug] [ThreadPool]: On list_my_db_dbo: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db_dbo"} */
USE [my_db];
    with base as (
      select
        DB_NAME() as [database],
        t.name as [name],
        SCHEMA_NAME(t.schema_id) as [schema],
        'table' as table_type
      from sys.tables as t with (nolock)
      union all
      select
        DB_NAME() as [database],
        v.name as [name],
        SCHEMA_NAME(v.schema_id) as [schema],
        'view' as table_type
      from sys.views as v with (nolock)
    )
    select * from base
    where [schema] like 'dbo'
    
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m09:35:47.691627 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:35:47.691627 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:35:47.691627 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m09:35:47.738465 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m09:35:47.738465 [debug] [ThreadPool]: On list_my_db_dbo: ROLLBACK
[0m09:35:47.738465 [debug] [ThreadPool]: On list_my_db_dbo: Close
[0m09:35:47.738465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5fecb2a2-a939-401a-b020-f5a2e1444f92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210043C2990>]}
[0m09:35:47.738465 [debug] [MainThread]: On master: COMMIT
[0m09:35:47.754077 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m09:35:47.754077 [info ] [Thread-1 (]: 1 of 14 START sql view model dbo.src_ecommerce ................................. [RUN]
[0m09:35:47.754077 [debug] [Thread-1 (]: Acquiring new sqlserver connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m09:35:47.754077 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m09:35:47.769743 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m09:35:47.769743 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m09:35:47.832207 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m09:35:47.832207 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m09:35:47.847840 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."src_ecommerce__dbt_tmp" as 

select * from "my_db"."dbo"."ecommerce";
    ')


[0m09:35:47.847840 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m09:35:47.847840 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:35:47.847840 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m09:35:47.863504 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:47.863504 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m09:35:47.863504 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce', 'src_ecommerce__dbt_backup'
[0m09:35:48.051019 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.051019 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m09:35:48.066632 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce__dbt_tmp', 'src_ecommerce'
[0m09:35:48.066632 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.097879 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: COMMIT
[0m09:35:48.097879 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."src_ecommerce__dbt_backup"
[0m09:35:48.113497 [debug] [Thread-1 (]: dbt-sqlserver
[0m09:35:48.113497 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m09:35:48.113497 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'src_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m09:35:48.144746 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.144746 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m09:35:48.144746 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."src_ecommerce__dbt_backup";');

[0m09:35:48.160337 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.160337 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: ROLLBACK
[0m09:35:48.160337 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: Close
[0m09:35:48.160337 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5fecb2a2-a939-401a-b020-f5a2e1444f92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000210044E1F50>]}
[0m09:35:48.176003 [info ] [Thread-1 (]: 1 of 14 OK created sql view model dbo.src_ecommerce ............................ [[32mOK[0m in 0.41s]
[0m09:35:48.176003 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m09:35:48.176003 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m09:35:48.176003 [info ] [Thread-1 (]: 2 of 14 START sql view model dbo.stg_ecommerce ................................. [RUN]
[0m09:35:48.176003 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m09:35:48.176003 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m09:35:48.176003 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:35:48.191627 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m09:35:48.191627 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:35:48.191627 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:35:48.191627 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."stg_ecommerce__dbt_tmp" as 

SELECT
    
        CAST(User_ID AS VARCHAR) AS User_ID,
        CAST(Product_ID AS VARCHAR) AS Product_ID,
        CAST(Category AS VARCHAR) AS Category,
        CAST(Price AS FLOAT) AS Price,
        CAST(Discount AS INT) AS Discount,
        CAST(Final_Price AS FLOAT) AS Final_Price,
        CAST(Payment_Method AS VARCHAR) AS Payment_Method,
        CAST(Purchase_Date AS DATE) AS Purchase_Date
    
FROM "my_db"."dbo"."ecommerce";
    ')


[0m09:35:48.207213 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:35:48.207213 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:35:48.207213 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m09:35:48.207213 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.207213 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:35:48.207213 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce', 'stg_ecommerce__dbt_backup'
[0m09:35:48.222870 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.222870 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:35:48.222870 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce__dbt_tmp', 'stg_ecommerce'
[0m09:35:48.238516 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.238516 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: COMMIT
[0m09:35:48.254081 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."stg_ecommerce__dbt_backup"
[0m09:35:48.254081 [debug] [Thread-1 (]: dbt-sqlserver
[0m09:35:48.254081 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:35:48.254081 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'stg_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m09:35:48.300956 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.300956 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:35:48.300956 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."stg_ecommerce__dbt_backup";');

[0m09:35:48.300956 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.316583 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: ROLLBACK
[0m09:35:48.316583 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: Close
[0m09:35:48.316583 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5fecb2a2-a939-401a-b020-f5a2e1444f92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021003DE5890>]}
[0m09:35:48.316583 [info ] [Thread-1 (]: 2 of 14 OK created sql view model dbo.stg_ecommerce ............................ [[32mOK[0m in 0.14s]
[0m09:35:48.316583 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m09:35:48.316583 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m09:35:48.316583 [info ] [Thread-1 (]: 3 of 14 START test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m09:35:48.316583 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6)
[0m09:35:48.316583 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m09:35:48.332207 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m09:35:48.332207 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m09:35:48.379082 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m09:35:48.379082 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m09:35:48.379082 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_8716]
   as 
    
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from "my_db"."dbo"."stg_ecommerce"
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    ''Credit Card'',''Net Banking'',''UPI'',''Debit Card'',''Cash on Delivery''
)



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_8716]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_8716]
  ;')
[0m09:35:48.379082 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:35:48.379082 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:35:48.379082 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m09:35:48.394704 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.410331 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: ROLLBACK
[0m09:35:48.410331 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: Close
[0m09:35:48.410331 [info ] [Thread-1 (]: 3 of 14 PASS accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[32mPASS[0m in 0.09s]
[0m09:35:48.410331 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m09:35:48.410331 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m09:35:48.410331 [info ] [Thread-1 (]: 4 of 14 START test non_negative_stg_ecommerce_Discount ......................... [RUN]
[0m09:35:48.410331 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb)
[0m09:35:48.410331 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m09:35:48.425955 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m09:35:48.425955 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m09:35:48.425955 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m09:35:48.441587 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m09:35:48.441587 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_19281ffd652b733be2e28145e70fc0a4_4419]
   as 
    
select *
from "my_db"."dbo"."stg_ecommerce"
where [Discount] < 0

  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_19281ffd652b733be2e28145e70fc0a4_4419]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_19281ffd652b733be2e28145e70fc0a4_4419]
  ;')
[0m09:35:48.441587 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:35:48.441587 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:35:48.441587 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m09:35:48.457229 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.457229 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb: ROLLBACK
[0m09:35:48.457229 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb: Close
[0m09:35:48.457229 [info ] [Thread-1 (]: 4 of 14 PASS non_negative_stg_ecommerce_Discount ............................... [[32mPASS[0m in 0.05s]
[0m09:35:48.457229 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m09:35:48.457229 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m09:35:48.457229 [info ] [Thread-1 (]: 5 of 14 START test non_negative_stg_ecommerce_Price ............................ [RUN]
[0m09:35:48.472832 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d)
[0m09:35:48.472832 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m09:35:48.472832 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m09:35:48.472832 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m09:35:48.488463 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m09:35:48.488463 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m09:35:48.488463 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_f555c6c76d3ad7acca32da9ff350f089_17677]
   as 
    
select *
from "my_db"."dbo"."stg_ecommerce"
where [Price] < 0

  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_f555c6c76d3ad7acca32da9ff350f089_17677]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_f555c6c76d3ad7acca32da9ff350f089_17677]
  ;')
[0m09:35:48.488463 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:35:48.488463 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:35:48.488463 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m09:35:48.504083 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.504083 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d: ROLLBACK
[0m09:35:48.504083 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d: Close
[0m09:35:48.504083 [info ] [Thread-1 (]: 5 of 14 PASS non_negative_stg_ecommerce_Price .................................. [[32mPASS[0m in 0.05s]
[0m09:35:48.504083 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m09:35:48.504083 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m09:35:48.519746 [info ] [Thread-1 (]: 6 of 14 START test not_null_stg_ecommerce_Category ............................. [RUN]
[0m09:35:48.519746 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14)
[0m09:35:48.519746 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m09:35:48.535345 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m09:35:48.535345 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m09:35:48.535345 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m09:35:48.551013 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m09:35:48.551013 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_10027]
   as 
    
    
    



select Category
from "my_db"."dbo"."stg_ecommerce"
where Category is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_10027]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_10027]
  ;')
[0m09:35:48.551013 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:35:48.551013 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:35:48.551013 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m09:35:48.566587 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.566587 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: ROLLBACK
[0m09:35:48.566587 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: Close
[0m09:35:48.566587 [info ] [Thread-1 (]: 6 of 14 PASS not_null_stg_ecommerce_Category ................................... [[32mPASS[0m in 0.05s]
[0m09:35:48.566587 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m09:35:48.566587 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m09:35:48.566587 [info ] [Thread-1 (]: 7 of 14 START test not_null_stg_ecommerce_Discount ............................. [RUN]
[0m09:35:48.582210 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836)
[0m09:35:48.582210 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m09:35:48.582210 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m09:35:48.582210 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m09:35:48.597837 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m09:35:48.597837 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m09:35:48.597837 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_11638]
   as 
    
    
    



select Discount
from "my_db"."dbo"."stg_ecommerce"
where Discount is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_11638]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_11638]
  ;')
[0m09:35:48.597837 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:35:48.597837 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:35:48.597837 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m09:35:48.613493 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.613493 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: ROLLBACK
[0m09:35:48.613493 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: Close
[0m09:35:48.613493 [info ] [Thread-1 (]: 7 of 14 PASS not_null_stg_ecommerce_Discount ................................... [[32mPASS[0m in 0.03s]
[0m09:35:48.629084 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m09:35:48.629084 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m09:35:48.629084 [info ] [Thread-1 (]: 8 of 14 START test not_null_stg_ecommerce_Final_Price .......................... [RUN]
[0m09:35:48.629084 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc)
[0m09:35:48.629084 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m09:35:48.644707 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m09:35:48.644707 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m09:35:48.644707 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m09:35:48.644707 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m09:35:48.644707 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_15244]
   as 
    
    
    



select Final_Price
from "my_db"."dbo"."stg_ecommerce"
where Final_Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_15244]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_15244]
  ;')
[0m09:35:48.660369 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:35:48.660369 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:35:48.660369 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m09:35:48.660369 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.675995 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: ROLLBACK
[0m09:35:48.675995 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: Close
[0m09:35:48.675995 [info ] [Thread-1 (]: 8 of 14 PASS not_null_stg_ecommerce_Final_Price ................................ [[32mPASS[0m in 0.05s]
[0m09:35:48.675995 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m09:35:48.675995 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m09:35:48.675995 [info ] [Thread-1 (]: 9 of 14 START test not_null_stg_ecommerce_Payment_Method ....................... [RUN]
[0m09:35:48.675995 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d)
[0m09:35:48.675995 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m09:35:48.691585 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m09:35:48.691585 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m09:35:48.691585 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m09:35:48.691585 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m09:35:48.707214 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_4386]
   as 
    
    
    



select Payment_Method
from "my_db"."dbo"."stg_ecommerce"
where Payment_Method is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_4386]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_4386]
  ;')
[0m09:35:48.707214 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:35:48.707214 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:35:48.707214 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m09:35:48.707214 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.722868 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: ROLLBACK
[0m09:35:48.722868 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: Close
[0m09:35:48.722868 [info ] [Thread-1 (]: 9 of 14 PASS not_null_stg_ecommerce_Payment_Method ............................. [[32mPASS[0m in 0.05s]
[0m09:35:48.722868 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m09:35:48.722868 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m09:35:48.722868 [info ] [Thread-1 (]: 10 of 14 START test not_null_stg_ecommerce_Price ............................... [RUN]
[0m09:35:48.722868 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a)
[0m09:35:48.722868 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m09:35:48.738456 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m09:35:48.738456 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m09:35:48.754116 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m09:35:48.754116 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m09:35:48.754116 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_7940]
   as 
    
    
    



select Price
from "my_db"."dbo"."stg_ecommerce"
where Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_7940]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_7940]
  ;')
[0m09:35:48.754116 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:35:48.754116 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:35:48.754116 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m09:35:48.769715 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.769715 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: ROLLBACK
[0m09:35:48.769715 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: Close
[0m09:35:48.769715 [info ] [Thread-1 (]: 10 of 14 PASS not_null_stg_ecommerce_Price ..................................... [[32mPASS[0m in 0.05s]
[0m09:35:48.769715 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m09:35:48.769715 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m09:35:48.769715 [info ] [Thread-1 (]: 11 of 14 START test not_null_stg_ecommerce_Product_ID .......................... [RUN]
[0m09:35:48.785331 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c)
[0m09:35:48.785331 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m09:35:48.785331 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m09:35:48.785331 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m09:35:48.800958 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m09:35:48.800958 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m09:35:48.800958 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_12784]
   as 
    
    
    



select Product_ID
from "my_db"."dbo"."stg_ecommerce"
where Product_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_12784]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_12784]
  ;')
[0m09:35:48.800958 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:35:48.800958 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:35:48.800958 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m09:35:48.816582 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.816582 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: ROLLBACK
[0m09:35:48.816582 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: Close
[0m09:35:48.816582 [info ] [Thread-1 (]: 11 of 14 PASS not_null_stg_ecommerce_Product_ID ................................ [[32mPASS[0m in 0.03s]
[0m09:35:48.816582 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m09:35:48.816582 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m09:35:48.832208 [info ] [Thread-1 (]: 12 of 14 START test not_null_stg_ecommerce_Purchase_Date ....................... [RUN]
[0m09:35:48.832208 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307)
[0m09:35:48.832208 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m09:35:48.832208 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m09:35:48.847861 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m09:35:48.847861 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m09:35:48.847861 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m09:35:48.847861 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_4170]
   as 
    
    
    



select Purchase_Date
from "my_db"."dbo"."stg_ecommerce"
where Purchase_Date is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_4170]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_4170]
  ;')
[0m09:35:48.847861 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:35:48.847861 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:35:48.847861 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m09:35:48.863460 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.863460 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: ROLLBACK
[0m09:35:48.863460 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: Close
[0m09:35:48.863460 [info ] [Thread-1 (]: 12 of 14 PASS not_null_stg_ecommerce_Purchase_Date ............................. [[32mPASS[0m in 0.03s]
[0m09:35:48.879081 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m09:35:48.879081 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m09:35:48.879081 [info ] [Thread-1 (]: 13 of 14 START test not_null_stg_ecommerce_User_ID ............................. [RUN]
[0m09:35:48.879081 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, now test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf)
[0m09:35:48.879081 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m09:35:48.894711 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m09:35:48.894711 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m09:35:48.894711 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m09:35:48.894711 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m09:35:48.894711 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_12828]
   as 
    
    
    



select User_ID
from "my_db"."dbo"."stg_ecommerce"
where User_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_12828]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_12828]
  ;')
[0m09:35:48.910329 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:35:48.910329 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:35:48.910329 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m09:35:48.910329 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.926010 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: ROLLBACK
[0m09:35:48.926010 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: Close
[0m09:35:48.926010 [info ] [Thread-1 (]: 13 of 14 PASS not_null_stg_ecommerce_User_ID ................................... [[32mPASS[0m in 0.05s]
[0m09:35:48.926010 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m09:35:48.926010 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m09:35:48.926010 [info ] [Thread-1 (]: 14 of 14 START test unique_stg_ecommerce_Product_ID ............................ [RUN]
[0m09:35:48.926010 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, now test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1)
[0m09:35:48.926010 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m09:35:48.941585 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m09:35:48.941585 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m09:35:48.957210 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m09:35:48.957210 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m09:35:48.957210 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_18666]
   as 
    
    
    

select
    Product_ID as unique_field,
    count(*) as n_records

from "my_db"."dbo"."stg_ecommerce"
where Product_ID is not null
group by Product_ID
having count(*) > 1



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_18666]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_18666]
  ;')
[0m09:35:48.957210 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:35:48.957210 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:35:48.957210 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m09:35:48.972831 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:35:48.988457 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: ROLLBACK
[0m09:35:48.988457 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: Close
[0m09:35:48.988457 [info ] [Thread-1 (]: 14 of 14 PASS unique_stg_ecommerce_Product_ID .................................. [[32mPASS[0m in 0.06s]
[0m09:35:48.988457 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m09:35:48.988457 [debug] [MainThread]: On master: COMMIT
[0m09:35:48.988457 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:35:48.988457 [debug] [MainThread]: Connection 'list_my_db' was properly closed.
[0m09:35:48.988457 [debug] [MainThread]: Connection 'list_my_db_dbo' was properly closed.
[0m09:35:48.988457 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1' was properly closed.
[0m09:35:49.004080 [info ] [MainThread]: 
[0m09:35:49.004080 [info ] [MainThread]: Finished running 12 data tests, 2 view models in 0 hours 0 minutes and 1.48 seconds (1.48s).
[0m09:35:49.004080 [debug] [MainThread]: Command end result
[0m09:35:49.113462 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m09:35:49.113462 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m09:35:49.129095 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m09:35:49.129095 [info ] [MainThread]: 
[0m09:35:49.129095 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:35:49.129095 [info ] [MainThread]: 
[0m09:35:49.129095 [info ] [MainThread]: Done. PASS=14 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=14
[0m09:35:49.129095 [debug] [MainThread]: Command `dbt build` succeeded at 09:35:49.129095 after 10.31 seconds
[0m09:35:49.129095 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002107B953DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002107BBB10D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002107BBB04D0>]}
[0m09:35:49.129095 [debug] [MainThread]: Flushing usage events
[0m09:35:49.738573 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:36:27.342052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C6AB41910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C6AB43090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C6AB43610>]}


============================== 09:36:27.357676 | bf4543b4-b661-4ecb-86ed-debc6f5dfb68 ==============================
[0m09:36:27.357676 [info ] [MainThread]: Running with dbt=1.10.3
[0m09:36:27.357676 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --target databricks', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m09:36:29.342047 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m09:36:29.342047 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m09:36:29.342047 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m09:36:35.842054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bf4543b4-b661-4ecb-86ed-debc6f5dfb68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C75DE12D0>]}
[0m09:36:35.951431 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bf4543b4-b661-4ecb-86ed-debc6f5dfb68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C6A2B9C90>]}
[0m09:36:35.951431 [info ] [MainThread]: Registered adapter: databricks=1.10.4
[0m09:36:37.076498 [debug] [MainThread]: checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, vars: {}, profile: , target: databricks, version: 1.10.3
[0m09:36:37.295173 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m09:36:37.295173 [debug] [MainThread]: previous checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, current checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331
[0m09:36:37.295173 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m09:36:37.295173 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m09:36:37.310797 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'bf4543b4-b661-4ecb-86ed-debc6f5dfb68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C75C05D50>]}
[0m09:36:42.576439 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m09:36:42.592062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bf4543b4-b661-4ecb-86ed-debc6f5dfb68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C770F3890>]}
[0m09:36:42.779557 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m09:36:42.779557 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m09:36:42.873308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bf4543b4-b661-4ecb-86ed-debc6f5dfb68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C77802310>]}
[0m09:36:42.873308 [info ] [MainThread]: Found 9 models, 39 data tests, 1 source, 800 macros
[0m09:36:42.888926 [info ] [MainThread]: 
[0m09:36:42.888926 [info ] [MainThread]: Concurrency: 1 threads (target='databricks')
[0m09:36:42.888926 [info ] [MainThread]: 
[0m09:36:42.888926 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=0s, language=None, compute-name=) - Creating connection
[0m09:36:42.888926 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m09:36:42.904553 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace, idle-time=0s, language=None, compute-name=) - Creating connection
[0m09:36:42.904553 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace'
[0m09:36:42.904553 [debug] [ThreadPool]: Using databricks connection "list_workspace"
[0m09:36:42.904553 [debug] [ThreadPool]: On list_workspace: GetSchemas(database=workspace, schema=None)
[0m09:36:42.920173 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:36:44.310944 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f07779-0101-1f1c-9669-e6e38cc2a569) - Created
[0m09:37:47.173324 [debug] [ThreadPool]: SQL status: OK in 64.250 seconds
[0m09:37:47.188949 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f07779-0101-1f1c-9669-e6e38cc2a569, command-id=01f07779-2531-1521-96e0-1cd4beb68f32) - Closing
[0m09:37:47.188949 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace_default, idle-time=0s, language=None, compute-name=) - Creating connection
[0m09:37:47.188949 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace_default'
[0m09:37:47.204574 [debug] [ThreadPool]: Using databricks connection "list_workspace_default"
[0m09:37:47.204574 [debug] [ThreadPool]: On list_workspace_default: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "connection_name": "list_workspace_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'workspace' 
  AND table_schema = 'default'

  
[0m09:37:47.204574 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:37:48.017208 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f07779-2715-19f0-90a6-7a5dc15224be) - Created
[0m09:37:52.642079 [debug] [ThreadPool]: SQL status: OK in 5.440 seconds
[0m09:37:52.673345 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f07779-2715-19f0-90a6-7a5dc15224be, command-id=01f07779-273f-1828-8bab-4fe447d30408) - Closing
[0m09:37:52.673345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bf4543b4-b661-4ecb-86ed-debc6f5dfb68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C7739AA90>]}
[0m09:37:52.673345 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m09:37:52.688947 [info ] [Thread-1 (]: 1 of 48 START sql view model default.src_ecommerce ............................. [RUN]
[0m09:37:52.688947 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_cicd.src_ecommerce, idle-time=0s, language=None, compute-name=) - Creating connection
[0m09:37:52.688947 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m09:37:52.688947 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m09:37:52.704607 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m09:37:52.704607 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m09:37:52.735819 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m09:37:52.735819 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m09:37:52.735819 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'bf4543b4-b661-4ecb-86ed-debc6f5dfb68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C6770C5D0>]}
[0m09:37:52.767068 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`src_ecommerce`
[0m09:37:52.782694 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m09:37:52.782694 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.src_ecommerce"
[0m09:37:52.782694 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`src_ecommerce`
  
  as (
    SELECT * FROM default.sales_ecommerce
  )

[0m09:37:52.782694 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m09:37:53.501583 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a) - Created
[0m09:37:56.251444 [debug] [Thread-1 (]: SQL status: OK in 3.470 seconds
[0m09:37:56.251444 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-2a7f-1045-b30d-9781b22a1102) - Closing
[0m09:37:56.298323 [debug] [Thread-1 (]: Applying tags to relation None
[0m09:37:56.298323 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf4543b4-b661-4ecb-86ed-debc6f5dfb68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C7783E810>]}
[0m09:37:56.298323 [info ] [Thread-1 (]: 1 of 48 OK created sql view model default.src_ecommerce ........................ [[32mOK[0m in 3.61s]
[0m09:37:56.298323 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m09:37:56.298323 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m09:37:56.313941 [info ] [Thread-1 (]: 2 of 48 START sql view model default.stg_ecommerce ............................. [RUN]
[0m09:37:56.313941 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m09:37:56.313941 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=model.dbt_databricks_cicd.stg_ecommerce, idle-time=0.01561737060546875s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.src_ecommerce
[0m09:37:56.313941 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m09:37:56.313941 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:37:56.313941 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m09:37:56.329566 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m09:37:56.329566 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`stg_ecommerce`
[0m09:37:56.329566 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:37:56.329566 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:37:56.329566 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`stg_ecommerce`
  
  as (
    SELECT
  User_ID,
  Product_ID,
  Category,
  Price,
  Discount,
  Final_Price,
  Payment_Method,
  Purchase_Date
FROM `workspace`.`default`.`src_ecommerce`
  )

[0m09:37:57.267070 [debug] [Thread-1 (]: SQL status: OK in 0.940 seconds
[0m09:37:57.282693 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-2c2e-1728-83ba-e2251743f782) - Closing
[0m09:37:57.282693 [debug] [Thread-1 (]: Applying tags to relation None
[0m09:37:57.282693 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf4543b4-b661-4ecb-86ed-debc6f5dfb68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C778350D0>]}
[0m09:37:57.282693 [info ] [Thread-1 (]: 2 of 48 OK created sql view model default.stg_ecommerce ........................ [[32mOK[0m in 0.97s]
[0m09:37:57.282693 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m09:37:57.282693 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m09:37:57.298321 [info ] [Thread-1 (]: 3 of 48 START test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m09:37:57.298321 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6)
[0m09:37:57.298321 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, idle-time=0.015628576278686523s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.stg_ecommerce
[0m09:37:57.298321 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m09:37:57.298321 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m09:37:57.298321 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m09:37:57.345194 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m09:37:57.345194 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m09:37:57.345194 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from `workspace`.`default`.`stg_ecommerce`
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    'Credit Card','Net Banking','UPI','Debit Card','Cash on Delivery'
)



  
  
      
    ) dbt_internal_test
[0m09:38:02.095197 [debug] [Thread-1 (]: SQL status: OK in 4.750 seconds
[0m09:38:02.095197 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-2cc9-1600-93f7-1efc69457e13) - Closing
[0m09:38:02.110825 [info ] [Thread-1 (]: 3 of 48 PASS accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[32mPASS[0m in 4.81s]
[0m09:38:02.110825 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m09:38:02.110825 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m09:38:02.110825 [info ] [Thread-1 (]: 4 of 48 START test non_negative_stg_ecommerce_Discount ......................... [RUN]
[0m09:38:02.110825 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb)
[0m09:38:02.110825 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m09:38:02.110825 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m09:38:02.126448 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m09:38:02.126448 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m09:38:02.142121 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m09:38:02.142121 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m09:38:02.142121 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`stg_ecommerce`
where `Discount` < 0

  
  
      
    ) dbt_internal_test
[0m09:38:03.470194 [debug] [Thread-1 (]: SQL status: OK in 1.330 seconds
[0m09:38:03.470194 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-2fa5-11c6-9382-19863b0a752b) - Closing
[0m09:38:03.470194 [info ] [Thread-1 (]: 4 of 48 PASS non_negative_stg_ecommerce_Discount ............................... [[32mPASS[0m in 1.36s]
[0m09:38:03.470194 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m09:38:03.470194 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m09:38:03.470194 [info ] [Thread-1 (]: 5 of 48 START test non_negative_stg_ecommerce_Price ............................ [RUN]
[0m09:38:03.485821 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d)
[0m09:38:03.485821 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d, idle-time=0.015626192092895508s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m09:38:03.485821 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m09:38:03.501447 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m09:38:03.501447 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m09:38:03.517079 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m09:38:03.517079 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m09:38:03.517079 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`stg_ecommerce`
where `Price` < 0

  
  
      
    ) dbt_internal_test
[0m09:38:04.313960 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m09:38:04.329572 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-3076-162d-9003-87c73f46fba7) - Closing
[0m09:38:04.329572 [info ] [Thread-1 (]: 5 of 48 PASS non_negative_stg_ecommerce_Price .................................. [[32mPASS[0m in 0.84s]
[0m09:38:04.329572 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m09:38:04.329572 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m09:38:04.329572 [info ] [Thread-1 (]: 6 of 48 START test not_null_stg_ecommerce_Category ............................. [RUN]
[0m09:38:04.329572 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14)
[0m09:38:04.329572 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m09:38:04.329572 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m09:38:04.345198 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m09:38:04.360821 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m09:38:04.360821 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m09:38:04.360821 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m09:38:04.360821 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`stg_ecommerce`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:38:05.110822 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m09:38:05.110822 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-30fa-184b-8719-781eff8499c9) - Closing
[0m09:38:05.110822 [info ] [Thread-1 (]: 6 of 48 PASS not_null_stg_ecommerce_Category ................................... [[32mPASS[0m in 0.78s]
[0m09:38:05.110822 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m09:38:05.110822 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m09:38:05.110822 [info ] [Thread-1 (]: 7 of 48 START test not_null_stg_ecommerce_Discount ............................. [RUN]
[0m09:38:05.110822 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836)
[0m09:38:05.126445 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, idle-time=0.015623807907104492s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m09:38:05.126445 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m09:38:05.126445 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m09:38:05.126445 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m09:38:05.142068 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m09:38:05.142068 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m09:38:05.142068 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Discount
from `workspace`.`default`.`stg_ecommerce`
where Discount is null



  
  
      
    ) dbt_internal_test
[0m09:38:06.017210 [debug] [Thread-1 (]: SQL status: OK in 0.880 seconds
[0m09:38:06.032700 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-316f-16aa-a0c7-80421d5531d6) - Closing
[0m09:38:06.032700 [info ] [Thread-1 (]: 7 of 48 PASS not_null_stg_ecommerce_Discount ................................... [[32mPASS[0m in 0.92s]
[0m09:38:06.032700 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m09:38:06.032700 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m09:38:06.032700 [info ] [Thread-1 (]: 8 of 48 START test not_null_stg_ecommerce_Final_Price .......................... [RUN]
[0m09:38:06.032700 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc)
[0m09:38:06.032700 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m09:38:06.032700 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m09:38:06.048317 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m09:38:06.048317 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m09:38:06.063955 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m09:38:06.063955 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m09:38:06.063955 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Final_Price
from `workspace`.`default`.`stg_ecommerce`
where Final_Price is null



  
  
      
    ) dbt_internal_test
[0m09:38:06.892205 [debug] [Thread-1 (]: SQL status: OK in 0.830 seconds
[0m09:38:06.907695 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-31fb-1d2c-8db4-93c21fedd3d7) - Closing
[0m09:38:06.907695 [info ] [Thread-1 (]: 8 of 48 PASS not_null_stg_ecommerce_Final_Price ................................ [[32mPASS[0m in 0.87s]
[0m09:38:06.907695 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m09:38:06.907695 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m09:38:06.907695 [info ] [Thread-1 (]: 9 of 48 START test not_null_stg_ecommerce_Payment_Method ....................... [RUN]
[0m09:38:06.907695 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d)
[0m09:38:06.907695 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m09:38:06.907695 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m09:38:06.923323 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m09:38:06.923323 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m09:38:06.938944 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m09:38:06.938944 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m09:38:06.938944 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`stg_ecommerce`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m09:38:08.579688 [debug] [Thread-1 (]: SQL status: OK in 1.640 seconds
[0m09:38:08.579688 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-3280-17f6-a8ee-98b8ad81d0e3) - Closing
[0m09:38:08.579688 [info ] [Thread-1 (]: 9 of 48 PASS not_null_stg_ecommerce_Payment_Method ............................. [[32mPASS[0m in 1.67s]
[0m09:38:08.595197 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m09:38:08.595197 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m09:38:08.595197 [info ] [Thread-1 (]: 10 of 48 START test not_null_stg_ecommerce_Price ............................... [RUN]
[0m09:38:08.595197 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a)
[0m09:38:08.595197 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, idle-time=0.015509843826293945s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m09:38:08.595197 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m09:38:08.610820 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m09:38:08.610820 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m09:38:08.610820 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m09:38:08.610820 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m09:38:08.626450 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Price
from `workspace`.`default`.`stg_ecommerce`
where Price is null



  
  
      
    ) dbt_internal_test
[0m09:38:09.516707 [debug] [Thread-1 (]: SQL status: OK in 0.890 seconds
[0m09:38:09.516707 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-3381-1464-b3a3-8d5d20c82c9d) - Closing
[0m09:38:09.516707 [info ] [Thread-1 (]: 10 of 48 PASS not_null_stg_ecommerce_Price ..................................... [[32mPASS[0m in 0.92s]
[0m09:38:09.516707 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m09:38:09.516707 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m09:38:09.516707 [info ] [Thread-1 (]: 11 of 48 START test not_null_stg_ecommerce_Product_ID .......................... [RUN]
[0m09:38:09.516707 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c)
[0m09:38:09.532325 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, idle-time=0.015618562698364258s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m09:38:09.532325 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m09:38:09.532325 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m09:38:09.532325 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m09:38:09.547960 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m09:38:09.547960 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m09:38:09.547960 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Product_ID
from `workspace`.`default`.`stg_ecommerce`
where Product_ID is null



  
  
      
    ) dbt_internal_test
[0m09:38:10.329217 [debug] [Thread-1 (]: SQL status: OK in 0.780 seconds
[0m09:38:10.344828 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-3410-199c-bf19-737a0dceb932) - Closing
[0m09:38:10.344828 [info ] [Thread-1 (]: 11 of 48 PASS not_null_stg_ecommerce_Product_ID ................................ [[32mPASS[0m in 0.83s]
[0m09:38:10.344828 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m09:38:10.344828 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m09:38:10.344828 [info ] [Thread-1 (]: 12 of 48 START test not_null_stg_ecommerce_Purchase_Date ....................... [RUN]
[0m09:38:10.344828 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307)
[0m09:38:10.344828 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m09:38:10.360452 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m09:38:10.360452 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m09:38:10.360452 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m09:38:10.376124 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m09:38:10.376124 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m09:38:10.376124 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Purchase_Date
from `workspace`.`default`.`stg_ecommerce`
where Purchase_Date is null



  
  
      
    ) dbt_internal_test
[0m09:38:11.188575 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m09:38:11.188575 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-348d-1b4a-b84d-8ca8eea577ad) - Closing
[0m09:38:11.188575 [info ] [Thread-1 (]: 12 of 48 PASS not_null_stg_ecommerce_Purchase_Date ............................. [[32mPASS[0m in 0.84s]
[0m09:38:11.188575 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m09:38:11.188575 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m09:38:11.188575 [info ] [Thread-1 (]: 13 of 48 START test not_null_stg_ecommerce_User_ID ............................. [RUN]
[0m09:38:11.204199 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, now test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf)
[0m09:38:11.204199 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, idle-time=0.015624523162841797s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m09:38:11.204199 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m09:38:11.204199 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m09:38:11.219828 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m09:38:11.219828 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m09:38:11.219828 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m09:38:11.235454 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`stg_ecommerce`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m09:38:12.266703 [debug] [Thread-1 (]: SQL status: OK in 1.030 seconds
[0m09:38:12.282328 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-3510-15c8-89fd-529d048aec1b) - Closing
[0m09:38:12.282328 [info ] [Thread-1 (]: 13 of 48 PASS not_null_stg_ecommerce_User_ID ................................... [[32mPASS[0m in 1.09s]
[0m09:38:12.282328 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m09:38:12.282328 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m09:38:12.297951 [info ] [Thread-1 (]: 14 of 48 START test unique_stg_ecommerce_Product_ID ............................ [RUN]
[0m09:38:12.297951 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, now test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1)
[0m09:38:12.297951 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1, idle-time=0.015623092651367188s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m09:38:12.297951 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m09:38:12.313582 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m09:38:12.313582 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m09:38:12.313582 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m09:38:12.313582 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m09:38:12.329203 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    Product_ID as unique_field,
    count(*) as n_records

from `workspace`.`default`.`stg_ecommerce`
where Product_ID is not null
group by Product_ID
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m09:38:13.298055 [debug] [Thread-1 (]: SQL status: OK in 0.970 seconds
[0m09:38:13.298055 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-35b6-1053-8813-02fb5f9ce12b) - Closing
[0m09:38:13.313618 [info ] [Thread-1 (]: 14 of 48 PASS unique_stg_ecommerce_Product_ID .................................. [[32mPASS[0m in 1.02s]
[0m09:38:13.313618 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m09:38:13.313618 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_discount_by_category
[0m09:38:13.313618 [info ] [Thread-1 (]: 15 of 48 START sql view model default.avg_discount_by_category ................. [RUN]
[0m09:38:13.313618 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1, now model.dbt_databricks_cicd.avg_discount_by_category)
[0m09:38:13.313618 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=model.dbt_databricks_cicd.avg_discount_by_category, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m09:38:13.313618 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_discount_by_category
[0m09:38:13.329210 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m09:38:13.329210 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_discount_by_category
[0m09:38:13.344864 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m09:38:13.344864 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`avg_discount_by_category`
[0m09:38:13.344864 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m09:38:13.344864 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.avg_discount_by_category"
[0m09:38:13.344864 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_discount_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.avg_discount_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`avg_discount_by_category`
  
  as (
    SELECT
  Category,
  ROUND(AVG(CAST(`Discount` AS DOUBLE)), 2) AS avg_discount_percent
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY avg_discount_percent DESC
  )

[0m09:38:14.032463 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m09:38:14.032463 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-3653-15bb-94ac-4f027d0e11ef) - Closing
[0m09:38:14.032463 [debug] [Thread-1 (]: Applying tags to relation None
[0m09:38:14.032463 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf4543b4-b661-4ecb-86ed-debc6f5dfb68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C6A632C50>]}
[0m09:38:14.047961 [info ] [Thread-1 (]: 15 of 48 OK created sql view model default.avg_discount_by_category ............ [[32mOK[0m in 0.72s]
[0m09:38:14.047961 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_discount_by_category
[0m09:38:14.047961 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m09:38:14.047961 [info ] [Thread-1 (]: 16 of 48 START sql view model default.avg_ticket_by_category ................... [RUN]
[0m09:38:14.047961 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_discount_by_category, now model.dbt_databricks_cicd.avg_ticket_by_category)
[0m09:38:14.047961 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=model.dbt_databricks_cicd.avg_ticket_by_category, idle-time=0.015498161315917969s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.avg_discount_by_category
[0m09:38:14.047961 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_ticket_by_category
[0m09:38:14.063583 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m09:38:14.063583 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_ticket_by_category
[0m09:38:14.079200 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m09:38:14.079200 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`avg_ticket_by_category`
[0m09:38:14.079200 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m09:38:14.079200 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m09:38:14.094877 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_ticket_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.avg_ticket_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`avg_ticket_by_category`
  
  as (
    SELECT
  Category,
  ROUND(AVG(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS avg_ticket
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY avg_ticket DESC
  )

[0m09:38:14.751220 [debug] [Thread-1 (]: SQL status: OK in 0.660 seconds
[0m09:38:14.751220 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-36c4-15e7-ab19-816aee86a138) - Closing
[0m09:38:14.751220 [debug] [Thread-1 (]: Applying tags to relation None
[0m09:38:14.751220 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf4543b4-b661-4ecb-86ed-debc6f5dfb68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C7782DD50>]}
[0m09:38:14.751220 [info ] [Thread-1 (]: 16 of 48 OK created sql view model default.avg_ticket_by_category .............. [[32mOK[0m in 0.70s]
[0m09:38:14.766700 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m09:38:14.766700 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.monthly_revenue
[0m09:38:14.766700 [info ] [Thread-1 (]: 17 of 48 START sql view model default.monthly_revenue .......................... [RUN]
[0m09:38:14.766700 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_ticket_by_category, now model.dbt_databricks_cicd.monthly_revenue)
[0m09:38:14.766700 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=model.dbt_databricks_cicd.monthly_revenue, idle-time=0.015480279922485352s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.avg_ticket_by_category
[0m09:38:14.766700 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.monthly_revenue
[0m09:38:14.782341 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.monthly_revenue"
[0m09:38:14.782341 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.monthly_revenue
[0m09:38:14.782341 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m09:38:14.782341 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`monthly_revenue`
[0m09:38:14.782341 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.monthly_revenue"
[0m09:38:14.797952 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.monthly_revenue"
[0m09:38:14.797952 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.monthly_revenue: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.monthly_revenue"} */

  
  
  
  create or replace view `workspace`.`default`.`monthly_revenue`
  
  as (
    SELECT
  CAST(DATE_TRUNC('month', CAST(Purchase_Date AS DATE)) AS DATE) AS month,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS monthly_revenue
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY 1
ORDER BY 1
  )

[0m09:38:15.469969 [debug] [Thread-1 (]: SQL status: OK in 0.670 seconds
[0m09:38:15.469969 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-372e-1fa0-affe-4b18958fffc0) - Closing
[0m09:38:15.485458 [debug] [Thread-1 (]: Applying tags to relation None
[0m09:38:15.485458 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf4543b4-b661-4ecb-86ed-debc6f5dfb68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C6A61B690>]}
[0m09:38:15.485458 [info ] [Thread-1 (]: 17 of 48 OK created sql view model default.monthly_revenue ..................... [[32mOK[0m in 0.72s]
[0m09:38:15.485458 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.monthly_revenue
[0m09:38:15.485458 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.payment_distribution
[0m09:38:15.485458 [info ] [Thread-1 (]: 18 of 48 START sql view model default.payment_distribution ..................... [RUN]
[0m09:38:15.485458 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.monthly_revenue, now model.dbt_databricks_cicd.payment_distribution)
[0m09:38:15.485458 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=model.dbt_databricks_cicd.payment_distribution, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.monthly_revenue
[0m09:38:15.485458 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.payment_distribution
[0m09:38:15.501082 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.payment_distribution"
[0m09:38:15.501082 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.payment_distribution
[0m09:38:15.516712 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m09:38:15.516712 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`payment_distribution`
[0m09:38:15.516712 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.payment_distribution"
[0m09:38:15.516712 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.payment_distribution"
[0m09:38:15.516712 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.payment_distribution: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.payment_distribution"} */

  
  
  
  create or replace view `workspace`.`default`.`payment_distribution`
  
  as (
    SELECT
  Payment_Method,
  COUNT(*) AS total_transactions,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_value
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Payment_Method
ORDER BY total_value DESC
  )

[0m09:38:16.266704 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m09:38:16.266704 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-379e-16e3-82a8-39eae06cc69a) - Closing
[0m09:38:16.266704 [debug] [Thread-1 (]: Applying tags to relation None
[0m09:38:16.266704 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf4543b4-b661-4ecb-86ed-debc6f5dfb68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C6A632AD0>]}
[0m09:38:16.282329 [info ] [Thread-1 (]: 18 of 48 OK created sql view model default.payment_distribution ................ [[32mOK[0m in 0.78s]
[0m09:38:16.282329 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.payment_distribution
[0m09:38:16.282329 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.sales_by_category
[0m09:38:16.282329 [info ] [Thread-1 (]: 19 of 48 START sql view model default.sales_by_category ........................ [RUN]
[0m09:38:16.297951 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.payment_distribution, now model.dbt_databricks_cicd.sales_by_category)
[0m09:38:16.297951 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=model.dbt_databricks_cicd.sales_by_category, idle-time=0.03124713897705078s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.payment_distribution
[0m09:38:16.297951 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.sales_by_category
[0m09:38:16.313575 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.sales_by_category"
[0m09:38:16.313575 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.sales_by_category
[0m09:38:16.329203 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m09:38:16.329203 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`sales_by_category`
[0m09:38:16.329203 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.sales_by_category"
[0m09:38:16.329203 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.sales_by_category"
[0m09:38:16.329203 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.sales_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.sales_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`sales_by_category`
  
  as (
    SELECT
  Category,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_revenue
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY total_revenue DESC
  )

[0m09:38:17.047960 [debug] [Thread-1 (]: SQL status: OK in 0.720 seconds
[0m09:38:17.047960 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-381a-1057-91d8-f36dff2219ca) - Closing
[0m09:38:17.047960 [debug] [Thread-1 (]: Applying tags to relation None
[0m09:38:17.047960 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf4543b4-b661-4ecb-86ed-debc6f5dfb68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C778034D0>]}
[0m09:38:17.047960 [info ] [Thread-1 (]: 19 of 48 OK created sql view model default.sales_by_category ................... [[32mOK[0m in 0.75s]
[0m09:38:17.063581 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.sales_by_category
[0m09:38:17.063581 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_5_products
[0m09:38:17.063581 [info ] [Thread-1 (]: 20 of 48 START sql view model default.top_5_products ........................... [RUN]
[0m09:38:17.063581 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.sales_by_category, now model.dbt_databricks_cicd.top_5_products)
[0m09:38:17.063581 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=model.dbt_databricks_cicd.top_5_products, idle-time=0.015621423721313477s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.sales_by_category
[0m09:38:17.063581 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_5_products
[0m09:38:17.079204 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_5_products"
[0m09:38:17.094832 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_5_products
[0m09:38:17.094832 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m09:38:17.094832 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`top_5_products`
[0m09:38:17.094832 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_5_products"
[0m09:38:17.110455 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.top_5_products"
[0m09:38:17.110455 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_5_products: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.top_5_products"} */

  
  
  
  create or replace view `workspace`.`default`.`top_5_products`
  
  as (
    WITH base AS (
    SELECT
        product_id,
        ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_sales
    FROM `workspace`.`default`.`stg_ecommerce`
    GROUP BY product_id
)

SELECT
    product_id,
    total_sales
FROM base
ORDER BY total_sales DESC
LIMIT 5
  )

[0m09:38:17.954341 [debug] [Thread-1 (]: SQL status: OK in 0.840 seconds
[0m09:38:17.969836 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-388f-1ba3-a88a-3233f43fac9a) - Closing
[0m09:38:17.969836 [debug] [Thread-1 (]: Applying tags to relation None
[0m09:38:17.969836 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf4543b4-b661-4ecb-86ed-debc6f5dfb68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C778A0E10>]}
[0m09:38:17.969836 [info ] [Thread-1 (]: 20 of 48 OK created sql view model default.top_5_products ...................... [[32mOK[0m in 0.91s]
[0m09:38:17.969836 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_5_products
[0m09:38:17.969836 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_customers
[0m09:38:17.969836 [info ] [Thread-1 (]: 21 of 48 START sql view model default.top_customers ............................ [RUN]
[0m09:38:17.985457 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_5_products, now model.dbt_databricks_cicd.top_customers)
[0m09:38:17.985457 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=model.dbt_databricks_cicd.top_customers, idle-time=0.015620946884155273s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.top_5_products
[0m09:38:17.985457 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_customers
[0m09:38:17.985457 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_customers"
[0m09:38:17.985457 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_customers
[0m09:38:18.001115 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m09:38:18.001115 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`top_customers`
[0m09:38:18.001115 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_customers"
[0m09:38:18.001115 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.top_customers"
[0m09:38:18.001115 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_customers: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.top_customers"} */

  
  
  
  create or replace view `workspace`.`default`.`top_customers`
  
  as (
    SELECT
  User_ID,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_spent
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY User_ID
ORDER BY total_spent DESC
LIMIT 10
  )

[0m09:38:18.688696 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m09:38:18.688696 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-3919-1d65-ae6a-86ef156af6e2) - Closing
[0m09:38:18.688696 [debug] [Thread-1 (]: Applying tags to relation None
[0m09:38:18.688696 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf4543b4-b661-4ecb-86ed-debc6f5dfb68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C77FC1E90>]}
[0m09:38:18.688696 [info ] [Thread-1 (]: 21 of 48 OK created sql view model default.top_customers ....................... [[32mOK[0m in 0.72s]
[0m09:38:18.704201 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_customers
[0m09:38:18.704201 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6
[0m09:38:18.704201 [info ] [Thread-1 (]: 22 of 48 START test dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0  [RUN]
[0m09:38:18.704201 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_customers, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6)
[0m09:38:18.704201 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6, idle-time=0.015505075454711914s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.top_customers
[0m09:38:18.704201 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6
[0m09:38:18.719835 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"
[0m09:38:18.719835 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6
[0m09:38:18.719835 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"
[0m09:38:18.735473 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"
[0m09:38:18.735473 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_discount_by_category`

where not(avg_discount_percent avg_discount_percent >= 0)


  
  
      
    ) dbt_internal_test
[0m09:38:19.173092 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_discount_by_category`

where not(avg_discount_percent avg_discount_percent >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 52)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_discount_by_category`

where not(avg_discount_percent avg_discount_percent >= 0)
----------------------------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 52)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_discount_by_category`

where not(avg_discount_percent avg_discount_percent >= 0)
----------------------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 52)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_discount_by_category`

where not(avg_discount_percent avg_discount_percent >= 0)
----------------------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f07779-3988-15bd-bebf-e9ea76abd5b7
[0m09:38:19.422967 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 52)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`avg_discount_by_category`
  
  where not(avg_discount_percent avg_discount_percent >= 0)
  ----------------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5b124626a971bfcac535904f1039d3eb.sql
[0m09:38:19.438579 [error] [Thread-1 (]: 22 of 48 ERROR dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0  [[31mERROR[0m in 0.72s]
[0m09:38:19.438579 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6
[0m09:38:19.438579 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:38:19.438579 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 52)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`avg_discount_by_category`
  
  where not(avg_discount_percent avg_discount_percent >= 0)
  ----------------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5b124626a971bfcac535904f1039d3eb.sql.
[0m09:38:19.438579 [info ] [Thread-1 (]: 23 of 48 START test not_null_avg_discount_by_category_Category ................. [RUN]
[0m09:38:19.438579 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b)
[0m09:38:19.438579 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, idle-time=0.015611886978149414s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6
[0m09:38:19.438579 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:38:19.454209 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m09:38:19.454209 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:38:19.469859 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m09:38:19.469859 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m09:38:19.469859 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_discount_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:38:20.291628 [debug] [Thread-1 (]: SQL status: OK in 0.820 seconds
[0m09:38:20.307250 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-39f9-10a1-9ae9-fdb7093a5ca7) - Closing
[0m09:38:20.307250 [info ] [Thread-1 (]: 23 of 48 PASS not_null_avg_discount_by_category_Category ....................... [[32mPASS[0m in 0.87s]
[0m09:38:20.307250 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:38:20.322886 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:38:20.322886 [info ] [Thread-1 (]: 24 of 48 START test not_null_avg_discount_by_category_avg_discount_percent ..... [RUN]
[0m09:38:20.322886 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101)
[0m09:38:20.322886 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, idle-time=0.015636205673217773s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:38:20.322886 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:38:20.354125 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m09:38:20.354125 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:38:20.369748 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m09:38:20.369748 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m09:38:20.369748 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_discount_percent
from `workspace`.`default`.`avg_discount_by_category`
where avg_discount_percent is null



  
  
      
    ) dbt_internal_test
[0m09:38:21.771327 [debug] [Thread-1 (]: SQL status: OK in 1.400 seconds
[0m09:38:21.771327 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-3a83-1811-85c9-36fb380967fa) - Closing
[0m09:38:21.771327 [info ] [Thread-1 (]: 24 of 48 PASS not_null_avg_discount_by_category_avg_discount_percent ........... [[32mPASS[0m in 1.45s]
[0m09:38:21.786817 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:38:21.786817 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301
[0m09:38:21.786817 [info ] [Thread-1 (]: 25 of 48 START test dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0  [RUN]
[0m09:38:21.786817 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301)
[0m09:38:21.786817 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301, idle-time=0.015489816665649414s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:38:21.786817 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301
[0m09:38:21.802448 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"
[0m09:38:21.802448 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301
[0m09:38:21.818066 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"
[0m09:38:21.818066 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"
[0m09:38:21.818066 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_ticket_by_category`

where not(avg_ticket avg_ticket >= 0)


  
  
      
    ) dbt_internal_test
[0m09:38:22.224451 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_ticket_by_category`

where not(avg_ticket avg_ticket >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 32)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_ticket_by_category`

where not(avg_ticket avg_ticket >= 0)
--------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 32)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_ticket_by_category`

where not(avg_ticket avg_ticket >= 0)
--------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 32)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_ticket_by_category`

where not(avg_ticket avg_ticket >= 0)
--------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f07779-3b5f-10a4-b757-b1ca1f49696d
[0m09:38:22.239947 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 32)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`avg_ticket_by_category`
  
  where not(avg_ticket avg_ticket >= 0)
  --------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5328046ff58f0d97fcb998395932ee40.sql
[0m09:38:22.255566 [error] [Thread-1 (]: 25 of 48 ERROR dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0  [[31mERROR[0m in 0.47s]
[0m09:38:22.255566 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301
[0m09:38:22.255566 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:38:22.255566 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 32)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`avg_ticket_by_category`
  
  where not(avg_ticket avg_ticket >= 0)
  --------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5328046ff58f0d97fcb998395932ee40.sql.
[0m09:38:22.255566 [info ] [Thread-1 (]: 26 of 48 START test not_null_avg_ticket_by_category_Category ................... [RUN]
[0m09:38:22.271202 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f)
[0m09:38:22.271202 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, idle-time=0.01563572883605957s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301
[0m09:38:22.271202 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:38:22.286817 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m09:38:22.302440 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:38:22.302440 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m09:38:22.318064 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m09:38:22.318064 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_ticket_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:38:23.365082 [debug] [Thread-1 (]: SQL status: OK in 1.050 seconds
[0m09:38:23.380569 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-3baa-1a8a-bb0b-84b2ded5dc65) - Closing
[0m09:38:23.380569 [info ] [Thread-1 (]: 26 of 48 PASS not_null_avg_ticket_by_category_Category ......................... [[32mPASS[0m in 1.11s]
[0m09:38:23.380569 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:38:23.380569 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:38:23.380569 [info ] [Thread-1 (]: 27 of 48 START test not_null_avg_ticket_by_category_avg_ticket ................. [RUN]
[0m09:38:23.380569 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41)
[0m09:38:23.380569 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:38:23.380569 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:38:23.396193 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m09:38:23.396193 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:38:23.411849 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m09:38:23.411849 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m09:38:23.427439 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_ticket
from `workspace`.`default`.`avg_ticket_by_category`
where avg_ticket is null



  
  
      
    ) dbt_internal_test
[0m09:38:24.717462 [debug] [Thread-1 (]: SQL status: OK in 1.290 seconds
[0m09:38:24.722162 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-3c54-120a-ba17-0c01a1ead0f7) - Closing
[0m09:38:24.724164 [info ] [Thread-1 (]: 27 of 48 PASS not_null_avg_ticket_by_category_avg_ticket ....................... [[32mPASS[0m in 1.34s]
[0m09:38:24.727253 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:38:24.728110 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14
[0m09:38:24.730116 [info ] [Thread-1 (]: 28 of 48 START test dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0  [RUN]
[0m09:38:24.731864 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14)
[0m09:38:24.732862 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14, idle-time=0.009700536727905273s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:38:24.733867 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14
[0m09:38:24.745551 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"
[0m09:38:24.748557 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14
[0m09:38:24.753831 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"
[0m09:38:24.756790 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"
[0m09:38:24.757788 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`monthly_revenue`

where not(monthly_revenue monthly_revenue >= 0)


  
  
      
    ) dbt_internal_test
[0m09:38:25.189332 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`monthly_revenue`

where not(monthly_revenue monthly_revenue >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 42)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`monthly_revenue`

where not(monthly_revenue monthly_revenue >= 0)
------------------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 42)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`monthly_revenue`

where not(monthly_revenue monthly_revenue >= 0)
------------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 42)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`monthly_revenue`

where not(monthly_revenue monthly_revenue >= 0)
------------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f07779-3d1f-1232-95b8-7dff3a83c286
[0m09:38:25.196836 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 42)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`monthly_revenue`
  
  where not(monthly_revenue monthly_revenue >= 0)
  ------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_m_f3c6f8ea5d3985ba2e05e7b0666775b9.sql
[0m09:38:25.199002 [error] [Thread-1 (]: 28 of 48 ERROR dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0  [[31mERROR[0m in 0.47s]
[0m09:38:25.201009 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14
[0m09:38:25.202009 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:38:25.203010 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 42)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`monthly_revenue`
  
  where not(monthly_revenue monthly_revenue >= 0)
  ------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_m_f3c6f8ea5d3985ba2e05e7b0666775b9.sql.
[0m09:38:25.205010 [info ] [Thread-1 (]: 29 of 48 START test not_null_monthly_revenue_month ............................. [RUN]
[0m09:38:25.206965 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14, now test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b)
[0m09:38:25.207972 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, idle-time=0.008970260620117188s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14
[0m09:38:25.210893 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:38:25.220033 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m09:38:25.222894 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:38:25.236872 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m09:38:25.240871 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m09:38:25.244893 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select month
from `workspace`.`default`.`monthly_revenue`
where month is null



  
  
      
    ) dbt_internal_test
[0m09:38:26.128348 [debug] [Thread-1 (]: SQL status: OK in 0.880 seconds
[0m09:38:26.128348 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-3d69-1086-bfa9-4d34024486ce) - Closing
[0m09:38:26.128348 [info ] [Thread-1 (]: 29 of 48 PASS not_null_monthly_revenue_month ................................... [[32mPASS[0m in 0.92s]
[0m09:38:26.145624 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:38:26.145624 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:38:26.145624 [info ] [Thread-1 (]: 30 of 48 START test not_null_monthly_revenue_monthly_revenue ................... [RUN]
[0m09:38:26.145624 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, now test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b)
[0m09:38:26.145624 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, idle-time=0.017276287078857422s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:38:26.145624 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:38:26.162063 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m09:38:26.162063 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:38:26.178458 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m09:38:26.178458 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m09:38:26.178458 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select monthly_revenue
from `workspace`.`default`.`monthly_revenue`
where monthly_revenue is null



  
  
      
    ) dbt_internal_test
[0m09:38:27.068543 [debug] [Thread-1 (]: SQL status: OK in 0.890 seconds
[0m09:38:27.068543 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-3dfa-13b1-8abc-764ab73da597) - Closing
[0m09:38:27.068543 [info ] [Thread-1 (]: 30 of 48 PASS not_null_monthly_revenue_monthly_revenue ......................... [[32mPASS[0m in 0.92s]
[0m09:38:27.068543 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:38:27.068543 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147
[0m09:38:27.084032 [info ] [Thread-1 (]: 31 of 48 START test dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0  [RUN]
[0m09:38:27.084032 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147)
[0m09:38:27.084032 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147, idle-time=0.015489339828491211s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:38:27.084032 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147
[0m09:38:27.084032 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"
[0m09:38:27.099654 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147
[0m09:38:27.099654 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"
[0m09:38:27.099654 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"
[0m09:38:27.099654 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_transactions total_transactions > 0)


  
  
      
    ) dbt_internal_test
[0m09:38:27.490303 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_transactions total_transactions > 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 48)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_transactions total_transactions > 0)
------------------------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 48)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_transactions total_transactions > 0)
------------------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 48)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_transactions total_transactions > 0)
------------------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f07779-3e86-1c4c-a477-a625b3fa6216
[0m09:38:27.490303 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 48)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`payment_distribution`
  
  where not(total_transactions total_transactions > 0)
  ------------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_fc379226623eb21c1aee5952042cbcd4.sql
[0m09:38:27.505909 [error] [Thread-1 (]: 31 of 48 ERROR dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0  [[31mERROR[0m in 0.42s]
[0m09:38:27.505909 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147
[0m09:38:27.505909 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97
[0m09:38:27.505909 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 48)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`payment_distribution`
  
  where not(total_transactions total_transactions > 0)
  ------------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_fc379226623eb21c1aee5952042cbcd4.sql.
[0m09:38:27.505909 [info ] [Thread-1 (]: 32 of 48 START test dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0  [RUN]
[0m09:38:27.505909 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97)
[0m09:38:27.505909 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147
[0m09:38:27.505909 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97
[0m09:38:27.521535 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"
[0m09:38:27.521535 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97
[0m09:38:27.537193 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"
[0m09:38:27.537193 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"
[0m09:38:27.537193 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_value total_value >= 0)


  
  
      
    ) dbt_internal_test
[0m09:38:27.756043 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_value total_value >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_value total_value >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_value total_value >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_value total_value >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f07779-3ec8-152f-b756-f9d00a42c51d
[0m09:38:27.771546 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`payment_distribution`
  
  where not(total_value total_value >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_5ed37f769e6a283e088dfae7f31ac751.sql
[0m09:38:27.771546 [error] [Thread-1 (]: 32 of 48 ERROR dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0  [[31mERROR[0m in 0.27s]
[0m09:38:27.771546 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97
[0m09:38:27.771546 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:38:27.771546 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`payment_distribution`
  
  where not(total_value total_value >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_5ed37f769e6a283e088dfae7f31ac751.sql.
[0m09:38:27.771546 [info ] [Thread-1 (]: 33 of 48 START test not_null_payment_distribution_Payment_Method ............... [RUN]
[0m09:38:27.771546 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97, now test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae)
[0m09:38:27.771546 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97
[0m09:38:27.787158 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:38:27.787158 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m09:38:27.787158 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:38:27.802777 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m09:38:27.802777 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m09:38:27.802777 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`payment_distribution`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m09:38:28.599800 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m09:38:28.615286 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-3ef0-1679-b1a3-5cf0db3f835a) - Closing
[0m09:38:28.615286 [info ] [Thread-1 (]: 33 of 48 PASS not_null_payment_distribution_Payment_Method ..................... [[32mPASS[0m in 0.84s]
[0m09:38:28.615286 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:38:28.615286 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:38:28.615286 [info ] [Thread-1 (]: 34 of 48 START test not_null_payment_distribution_total_transactions ........... [RUN]
[0m09:38:28.615286 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, now test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8)
[0m09:38:28.615286 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:38:28.630910 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:38:28.630910 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m09:38:28.630910 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:38:28.646569 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m09:38:28.646569 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m09:38:28.646569 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_transactions
from `workspace`.`default`.`payment_distribution`
where total_transactions is null



  
  
      
    ) dbt_internal_test
[0m09:38:29.380911 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m09:38:29.380911 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-3f72-1d94-a8b4-1983a37eedea) - Closing
[0m09:38:29.380911 [info ] [Thread-1 (]: 34 of 48 PASS not_null_payment_distribution_total_transactions ................. [[32mPASS[0m in 0.77s]
[0m09:38:29.380911 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:38:29.380911 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:38:29.380911 [info ] [Thread-1 (]: 35 of 48 START test not_null_payment_distribution_total_value .................. [RUN]
[0m09:38:29.380911 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, now test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03)
[0m09:38:29.380911 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:38:29.380911 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:38:29.396534 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m09:38:29.396534 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:38:29.412195 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m09:38:29.412195 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m09:38:29.412195 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_value
from `workspace`.`default`.`payment_distribution`
where total_value is null



  
  
      
    ) dbt_internal_test
[0m09:38:30.271528 [debug] [Thread-1 (]: SQL status: OK in 0.860 seconds
[0m09:38:30.271528 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-3fe7-1238-9c20-e41e9bb7a588) - Closing
[0m09:38:30.271528 [info ] [Thread-1 (]: 35 of 48 PASS not_null_payment_distribution_total_value ........................ [[32mPASS[0m in 0.89s]
[0m09:38:30.287153 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:38:30.287153 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7
[0m09:38:30.287153 [info ] [Thread-1 (]: 36 of 48 START test dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0  [RUN]
[0m09:38:30.287153 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7)
[0m09:38:30.287153 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7, idle-time=0.0156252384185791s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:38:30.287153 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7
[0m09:38:30.302781 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"
[0m09:38:30.302781 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7
[0m09:38:30.302781 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"
[0m09:38:30.318402 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"
[0m09:38:30.318402 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_orders total_orders > 0)


  
  
      
    ) dbt_internal_test
[0m09:38:30.740287 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_orders total_orders > 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_orders total_orders > 0)
------------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_orders total_orders > 0)
------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_orders total_orders > 0)
------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f07779-406f-175d-b488-3e46096cb02d
[0m09:38:30.740287 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`sales_by_category`
  
  where not(total_orders total_orders > 0)
  ------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_89c32efc0957beac212198ac47c17269.sql
[0m09:38:30.740287 [error] [Thread-1 (]: 36 of 48 ERROR dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0  [[31mERROR[0m in 0.45s]
[0m09:38:30.740287 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7
[0m09:38:30.740287 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd
[0m09:38:30.740287 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`sales_by_category`
  
  where not(total_orders total_orders > 0)
  ------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_89c32efc0957beac212198ac47c17269.sql.
[0m09:38:30.740287 [info ] [Thread-1 (]: 37 of 48 START test dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0  [RUN]
[0m09:38:30.755949 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd)
[0m09:38:30.755949 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd, idle-time=0.01566147804260254s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7
[0m09:38:30.755949 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd
[0m09:38:30.771573 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"
[0m09:38:30.771573 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd
[0m09:38:30.771573 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"
[0m09:38:30.771573 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"
[0m09:38:30.771573 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_revenue total_revenue >= 0)


  
  
      
    ) dbt_internal_test
[0m09:38:31.021659 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_revenue total_revenue >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 38)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_revenue total_revenue >= 0)
--------------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 38)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_revenue total_revenue >= 0)
--------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 38)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_revenue total_revenue >= 0)
--------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f07779-40b6-190a-bced-218996508dae
[0m09:38:31.037158 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 38)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`sales_by_category`
  
  where not(total_revenue total_revenue >= 0)
  --------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_a42e1924275d2ea59b3d9b718bc54aee.sql
[0m09:38:31.037158 [error] [Thread-1 (]: 37 of 48 ERROR dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0  [[31mERROR[0m in 0.28s]
[0m09:38:31.037158 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd
[0m09:38:31.037158 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:38:31.037158 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 38)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`sales_by_category`
  
  where not(total_revenue total_revenue >= 0)
  --------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_a42e1924275d2ea59b3d9b718bc54aee.sql.
[0m09:38:31.037158 [info ] [Thread-1 (]: 38 of 48 START test not_null_sales_by_category_Category ........................ [RUN]
[0m09:38:31.037158 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd, now test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507)
[0m09:38:31.037158 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd
[0m09:38:31.037158 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:38:31.052785 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m09:38:31.052785 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:38:31.068446 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m09:38:31.068446 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m09:38:31.068446 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`sales_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:38:31.865415 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m09:38:31.865415 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-40e2-11d2-a40c-fd2bb9d5bd8d) - Closing
[0m09:38:31.880910 [info ] [Thread-1 (]: 38 of 48 PASS not_null_sales_by_category_Category .............................. [[32mPASS[0m in 0.84s]
[0m09:38:31.880910 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:38:31.880910 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:38:31.880910 [info ] [Thread-1 (]: 39 of 48 START test not_null_sales_by_category_total_orders .................... [RUN]
[0m09:38:31.880910 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, now test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e)
[0m09:38:31.880910 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:38:31.880910 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:38:31.896541 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m09:38:31.896541 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:38:31.896541 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m09:38:31.896541 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m09:38:31.912158 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`sales_by_category`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m09:38:32.552917 [debug] [Thread-1 (]: SQL status: OK in 0.640 seconds
[0m09:38:32.552917 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-4162-171a-b4e4-6a343f9a9234) - Closing
[0m09:38:32.552917 [info ] [Thread-1 (]: 39 of 48 PASS not_null_sales_by_category_total_orders .......................... [[32mPASS[0m in 0.67s]
[0m09:38:32.552917 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:38:32.568406 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:38:32.568406 [info ] [Thread-1 (]: 40 of 48 START test not_null_sales_by_category_total_revenue ................... [RUN]
[0m09:38:32.568406 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, now test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd)
[0m09:38:32.568406 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, idle-time=0.015489339828491211s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:38:32.568406 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:38:32.568406 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m09:38:32.584032 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:38:32.584032 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m09:38:32.584032 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m09:38:32.584032 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_revenue
from `workspace`.`default`.`sales_by_category`
where total_revenue is null



  
  
      
    ) dbt_internal_test
[0m09:38:33.474656 [debug] [Thread-1 (]: SQL status: OK in 0.890 seconds
[0m09:38:33.474656 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-41ca-1529-8b59-ac1d09a66380) - Closing
[0m09:38:33.474656 [info ] [Thread-1 (]: 40 of 48 PASS not_null_sales_by_category_total_revenue ......................... [[32mPASS[0m in 0.91s]
[0m09:38:33.474656 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:38:33.474656 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57
[0m09:38:33.474656 [info ] [Thread-1 (]: 41 of 48 START test dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0  [RUN]
[0m09:38:33.474656 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57)
[0m09:38:33.490285 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57, idle-time=0.015628337860107422s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:38:33.490285 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57
[0m09:38:33.490285 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"
[0m09:38:33.490285 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57
[0m09:38:33.505908 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"
[0m09:38:33.505908 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"
[0m09:38:33.505908 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_5_products`

where not(total_sales total_sales >= 0)


  
  
      
    ) dbt_internal_test
[0m09:38:33.896524 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_5_products`

where not(total_sales total_sales >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_5_products`

where not(total_sales total_sales >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_5_products`

where not(total_sales total_sales >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_5_products`

where not(total_sales total_sales >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f07779-4257-1e55-b5c4-c4fb8e70220a
[0m09:38:33.896524 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_5_products`
  
  where not(total_sales total_sales >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_53d9d0761651e2acd9611a042b182945.sql
[0m09:38:33.896524 [error] [Thread-1 (]: 41 of 48 ERROR dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0  [[31mERROR[0m in 0.42s]
[0m09:38:33.896524 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57
[0m09:38:33.896524 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:38:33.912169 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_5_products`
  
  where not(total_sales total_sales >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_53d9d0761651e2acd9611a042b182945.sql.
[0m09:38:33.912169 [info ] [Thread-1 (]: 42 of 48 START test not_null_top_5_products_product_id ......................... [RUN]
[0m09:38:33.912169 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57, now test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe)
[0m09:38:33.912169 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, idle-time=0.01564478874206543s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57
[0m09:38:33.912169 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:38:33.927821 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m09:38:33.927821 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:38:33.927821 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m09:38:33.927821 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m09:38:33.943403 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select product_id
from `workspace`.`default`.`top_5_products`
where product_id is null



  
  
      
    ) dbt_internal_test
[0m09:38:34.881023 [debug] [Thread-1 (]: SQL status: OK in 0.940 seconds
[0m09:38:34.896538 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-4299-12cb-b141-f296850d54ca) - Closing
[0m09:38:34.896538 [info ] [Thread-1 (]: 42 of 48 PASS not_null_top_5_products_product_id ............................... [[32mPASS[0m in 0.98s]
[0m09:38:34.896538 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:38:34.896538 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:38:34.896538 [info ] [Thread-1 (]: 43 of 48 START test not_null_top_5_products_total_sales ........................ [RUN]
[0m09:38:34.896538 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, now test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818)
[0m09:38:34.896538 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:38:34.896538 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:38:34.912159 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m09:38:34.912159 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:38:35.037165 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m09:38:35.052783 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m09:38:35.052783 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_sales
from `workspace`.`default`.`top_5_products`
where total_sales is null



  
  
      
    ) dbt_internal_test
[0m09:38:35.912157 [debug] [Thread-1 (]: SQL status: OK in 0.860 seconds
[0m09:38:35.912157 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-4342-1a2b-bc03-4a14b65b3694) - Closing
[0m09:38:35.912157 [info ] [Thread-1 (]: 43 of 48 PASS not_null_top_5_products_total_sales .............................. [[32mPASS[0m in 1.02s]
[0m09:38:35.912157 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:38:35.912157 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4
[0m09:38:35.912157 [info ] [Thread-1 (]: 44 of 48 START test dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0  [RUN]
[0m09:38:35.927785 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4)
[0m09:38:35.927785 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4, idle-time=0.015627622604370117s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:38:35.927785 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4
[0m09:38:35.927785 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"
[0m09:38:35.927785 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4
[0m09:38:35.943407 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"
[0m09:38:35.943407 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"
[0m09:38:35.959065 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_orders total_orders > 0)


  
  
      
    ) dbt_internal_test
[0m09:38:36.334126 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_orders total_orders > 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_orders total_orders > 0)
------------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_orders total_orders > 0)
------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_orders total_orders > 0)
------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f07779-43cc-1686-954e-879750f923e4
[0m09:38:36.349664 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_customers`
  
  where not(total_orders total_orders > 0)
  ------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_837145e0920d813dbd0319ae1c97969b.sql
[0m09:38:36.349664 [error] [Thread-1 (]: 44 of 48 ERROR dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0  [[31mERROR[0m in 0.42s]
[0m09:38:36.349664 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4
[0m09:38:36.349664 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343
[0m09:38:36.349664 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_customers`
  
  where not(total_orders total_orders > 0)
  ------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_837145e0920d813dbd0319ae1c97969b.sql.
[0m09:38:36.349664 [info ] [Thread-1 (]: 45 of 48 START test dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0  [RUN]
[0m09:38:36.349664 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343)
[0m09:38:36.349664 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4
[0m09:38:36.365319 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343
[0m09:38:36.365319 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"
[0m09:38:36.365319 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343
[0m09:38:36.380916 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"
[0m09:38:36.380916 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"
[0m09:38:36.380916 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_spent total_spent >= 0)


  
  
      
    ) dbt_internal_test
[0m09:38:36.615418 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_spent total_spent >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_spent total_spent >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_spent total_spent >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_spent total_spent >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f07779-440e-152c-b427-e7122ae1a7af
[0m09:38:36.615418 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_customers`
  
  where not(total_spent total_spent >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_2a6b4bf5f333b9ab281e1669bb988c44.sql
[0m09:38:36.615418 [error] [Thread-1 (]: 45 of 48 ERROR dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0  [[31mERROR[0m in 0.27s]
[0m09:38:36.630907 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343
[0m09:38:36.630907 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:38:36.630907 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_customers`
  
  where not(total_spent total_spent >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_2a6b4bf5f333b9ab281e1669bb988c44.sql.
[0m09:38:36.630907 [info ] [Thread-1 (]: 46 of 48 START test not_null_top_customers_User_ID ............................. [RUN]
[0m09:38:36.630907 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343, now test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0)
[0m09:38:36.630907 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, idle-time=0.015488147735595703s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343
[0m09:38:36.630907 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:38:36.646573 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m09:38:36.646573 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:38:36.646573 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m09:38:36.646573 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m09:38:36.662153 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`top_customers`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m09:38:37.677782 [debug] [Thread-1 (]: SQL status: OK in 1.020 seconds
[0m09:38:37.677782 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-4436-1a22-aab6-94ec55d699da) - Closing
[0m09:38:37.677782 [info ] [Thread-1 (]: 46 of 48 PASS not_null_top_customers_User_ID ................................... [[32mPASS[0m in 1.05s]
[0m09:38:37.677782 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:38:37.677782 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:38:37.677782 [info ] [Thread-1 (]: 47 of 48 START test not_null_top_customers_total_orders ........................ [RUN]
[0m09:38:37.693413 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, now test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746)
[0m09:38:37.693413 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, idle-time=0.015630483627319336s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:38:37.693413 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:38:37.693413 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m09:38:37.693413 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:38:37.709033 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m09:38:37.709033 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m09:38:37.709033 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`top_customers`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m09:38:38.427782 [debug] [Thread-1 (]: SQL status: OK in 0.720 seconds
[0m09:38:38.427782 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-44e2-1fde-b7f1-27f3d7b78094) - Closing
[0m09:38:38.427782 [info ] [Thread-1 (]: 47 of 48 PASS not_null_top_customers_total_orders .............................. [[32mPASS[0m in 0.73s]
[0m09:38:38.427782 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:38:38.427782 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:38:38.443407 [info ] [Thread-1 (]: 48 of 48 START test not_null_top_customers_total_spent ......................... [RUN]
[0m09:38:38.443407 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, now test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73)
[0m09:38:38.443407 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, name=test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73, idle-time=0.015625476837158203s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:38:38.443407 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:38:38.443407 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m09:38:38.459037 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:38:38.459037 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m09:38:38.459037 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m09:38:38.459037 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_spent
from `workspace`.`default`.`top_customers`
where total_spent is null



  
  
      
    ) dbt_internal_test
[0m09:38:39.459032 [debug] [Thread-1 (]: SQL status: OK in 1.000 seconds
[0m09:38:39.459032 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a, command-id=01f07779-454c-18af-aabe-417ee5b55d18) - Closing
[0m09:38:39.459032 [info ] [Thread-1 (]: 48 of 48 PASS not_null_top_customers_total_spent ............................... [[32mPASS[0m in 1.02s]
[0m09:38:39.459032 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:38:39.459032 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=46.78568696975708s, language=None, compute-name=) - Reusing connection previously named master
[0m09:38:39.459032 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:38:39.474661 [debug] [MainThread]: Connection 'list_workspace' was properly closed.
[0m09:38:39.474661 [debug] [MainThread]: On list_workspace: Close
[0m09:38:39.474661 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07779-0101-1f1c-9669-e6e38cc2a569) - Closing
[0m09:38:39.677917 [debug] [MainThread]: Connection 'list_workspace_default' was properly closed.
[0m09:38:39.677917 [debug] [MainThread]: On list_workspace_default: Close
[0m09:38:39.677917 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07779-2715-19f0-90a6-7a5dc15224be) - Closing
[0m09:38:39.881022 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73' was properly closed.
[0m09:38:39.881022 [debug] [MainThread]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: Close
[0m09:38:39.881022 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07779-2a61-1279-8ac2-e4799a4d539a) - Closing
[0m09:38:40.099774 [info ] [MainThread]: 
[0m09:38:40.115281 [info ] [MainThread]: Finished running 39 data tests, 9 view models in 0 hours 1 minutes and 57.21 seconds (117.21s).
[0m09:38:40.130945 [debug] [MainThread]: Command end result
[0m09:38:40.209069 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m09:38:40.209069 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m09:38:40.224695 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m09:38:40.224695 [info ] [MainThread]: 
[0m09:38:40.240284 [info ] [MainThread]: [31mCompleted with 10 errors, 0 partial successes, and 0 warnings:[0m
[0m09:38:40.240284 [info ] [MainThread]: 
[0m09:38:40.240284 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m09:38:40.240284 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 52)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`avg_discount_by_category`
  
  where not(avg_discount_percent avg_discount_percent >= 0)
  ----------------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5b124626a971bfcac535904f1039d3eb.sql
[0m09:38:40.255904 [info ] [MainThread]: 
[0m09:38:40.255904 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5b124626a971bfcac535904f1039d3eb.sql
[0m09:38:40.255904 [info ] [MainThread]: 
[0m09:38:40.271527 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m09:38:40.271527 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 32)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`avg_ticket_by_category`
  
  where not(avg_ticket avg_ticket >= 0)
  --------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5328046ff58f0d97fcb998395932ee40.sql
[0m09:38:40.271527 [info ] [MainThread]: 
[0m09:38:40.271527 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5328046ff58f0d97fcb998395932ee40.sql
[0m09:38:40.287153 [info ] [MainThread]: 
[0m09:38:40.287153 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m09:38:40.302778 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 42)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`monthly_revenue`
  
  where not(monthly_revenue monthly_revenue >= 0)
  ------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_m_f3c6f8ea5d3985ba2e05e7b0666775b9.sql
[0m09:38:40.302778 [info ] [MainThread]: 
[0m09:38:40.302778 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_m_f3c6f8ea5d3985ba2e05e7b0666775b9.sql
[0m09:38:40.302778 [info ] [MainThread]: 
[0m09:38:40.302778 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m09:38:40.318406 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 48)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`payment_distribution`
  
  where not(total_transactions total_transactions > 0)
  ------------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_fc379226623eb21c1aee5952042cbcd4.sql
[0m09:38:40.318406 [info ] [MainThread]: 
[0m09:38:40.334030 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_fc379226623eb21c1aee5952042cbcd4.sql
[0m09:38:40.334030 [info ] [MainThread]: 
[0m09:38:40.334030 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m09:38:40.334030 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`payment_distribution`
  
  where not(total_value total_value >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_5ed37f769e6a283e088dfae7f31ac751.sql
[0m09:38:40.349652 [info ] [MainThread]: 
[0m09:38:40.349652 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_5ed37f769e6a283e088dfae7f31ac751.sql
[0m09:38:40.349652 [info ] [MainThread]: 
[0m09:38:40.349652 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m09:38:40.349652 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`sales_by_category`
  
  where not(total_orders total_orders > 0)
  ------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_89c32efc0957beac212198ac47c17269.sql
[0m09:38:40.365281 [info ] [MainThread]: 
[0m09:38:40.365281 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_89c32efc0957beac212198ac47c17269.sql
[0m09:38:40.365281 [info ] [MainThread]: 
[0m09:38:40.365281 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m09:38:40.365281 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 38)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`sales_by_category`
  
  where not(total_revenue total_revenue >= 0)
  --------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_a42e1924275d2ea59b3d9b718bc54aee.sql
[0m09:38:40.365281 [info ] [MainThread]: 
[0m09:38:40.380903 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_a42e1924275d2ea59b3d9b718bc54aee.sql
[0m09:38:40.380903 [info ] [MainThread]: 
[0m09:38:40.380903 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m09:38:40.380903 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_5_products`
  
  where not(total_sales total_sales >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_53d9d0761651e2acd9611a042b182945.sql
[0m09:38:40.380903 [info ] [MainThread]: 
[0m09:38:40.396529 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_53d9d0761651e2acd9611a042b182945.sql
[0m09:38:40.396529 [info ] [MainThread]: 
[0m09:38:40.396529 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m09:38:40.396529 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_customers`
  
  where not(total_orders total_orders > 0)
  ------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_837145e0920d813dbd0319ae1c97969b.sql
[0m09:38:40.396529 [info ] [MainThread]: 
[0m09:38:40.412184 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_837145e0920d813dbd0319ae1c97969b.sql
[0m09:38:40.412184 [info ] [MainThread]: 
[0m09:38:40.412184 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m09:38:40.412184 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_customers`
  
  where not(total_spent total_spent >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_2a6b4bf5f333b9ab281e1669bb988c44.sql
[0m09:38:40.412184 [info ] [MainThread]: 
[0m09:38:40.427779 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_2a6b4bf5f333b9ab281e1669bb988c44.sql
[0m09:38:40.427779 [info ] [MainThread]: 
[0m09:38:40.427779 [info ] [MainThread]: Done. PASS=38 WARN=0 ERROR=10 SKIP=0 NO-OP=0 TOTAL=48
[0m09:38:40.427779 [debug] [MainThread]: Command `dbt build` failed at 09:38:40.427779 after 133.26 seconds
[0m09:38:40.427779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C640E3DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C64340550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000026C76F25350>]}
[0m09:38:40.443409 [debug] [MainThread]: Flushing usage events
[0m09:38:41.177918 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:17:14.485748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF1CBA8150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF1CBA8E10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF1CBA80D0>]}


============================== 10:17:14.485748 | bed9b0c4-da6d-4082-a04c-1840ca3566e5 ==============================
[0m10:17:14.485748 [info ] [MainThread]: Running with dbt=1.10.3
[0m10:17:14.485748 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt build --target databricks', 'send_anonymous_usage_stats': 'True'}
[0m10:17:16.142036 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m10:17:16.142036 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m10:17:16.157635 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m10:17:17.907667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bed9b0c4-da6d-4082-a04c-1840ca3566e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF273E3AD0>]}
[0m10:17:18.032673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bed9b0c4-da6d-4082-a04c-1840ca3566e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF1C2E9B90>]}
[0m10:17:18.032673 [info ] [MainThread]: Registered adapter: databricks=1.10.4
[0m10:17:19.157637 [debug] [MainThread]: checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, vars: {}, profile: , target: databricks, version: 1.10.3
[0m10:17:19.720165 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m10:17:19.720165 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://dbt_databricks_cicd/models\staging\databricks\schema.yml
[0m10:17:19.720165 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://macros\esc.sql
[0m10:17:19.735749 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://macros\tests\non_negative.sql
[0m10:17:20.704498 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m10:17:20.735755 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bed9b0c4-da6d-4082-a04c-1840ca3566e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF29315990>]}
[0m10:17:20.938875 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m10:17:20.938875 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m10:17:21.048255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bed9b0c4-da6d-4082-a04c-1840ca3566e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF291A76D0>]}
[0m10:17:21.048255 [info ] [MainThread]: Found 9 models, 40 data tests, 1 source, 800 macros
[0m10:17:21.063919 [info ] [MainThread]: 
[0m10:17:21.063919 [info ] [MainThread]: Concurrency: 1 threads (target='databricks')
[0m10:17:21.063919 [info ] [MainThread]: 
[0m10:17:21.063919 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:17:21.063919 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:17:21.079544 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:17:21.079544 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace'
[0m10:17:21.079544 [debug] [ThreadPool]: Using databricks connection "list_workspace"
[0m10:17:21.079544 [debug] [ThreadPool]: On list_workspace: GetSchemas(database=workspace, schema=None)
[0m10:17:21.079544 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:17:21.892118 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0777e-ae08-10b2-b8f4-4c5b2e9030f6) - Created
[0m10:17:22.782764 [debug] [ThreadPool]: SQL status: OK in 1.700 seconds
[0m10:17:22.798248 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0777e-ae08-10b2-b8f4-4c5b2e9030f6, command-id=01f0777e-ae31-1e54-81be-a1632d8ad3db) - Closing
[0m10:17:22.798248 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace_default, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:17:22.798248 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace_default'
[0m10:17:22.813878 [debug] [ThreadPool]: Using databricks connection "list_workspace_default"
[0m10:17:22.813878 [debug] [ThreadPool]: On list_workspace_default: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "connection_name": "list_workspace_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'workspace' 
  AND table_schema = 'default'

  
[0m10:17:22.813878 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:17:23.548368 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0777e-af06-1f52-90da-59538c9ad06e) - Created
[0m10:17:27.279401 [debug] [ThreadPool]: SQL status: OK in 4.470 seconds
[0m10:17:27.294951 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0777e-af06-1f52-90da-59538c9ad06e, command-id=01f0777e-af27-1375-979e-210bd57f3356) - Closing
[0m10:17:27.310529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bed9b0c4-da6d-4082-a04c-1840ca3566e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF29317210>]}
[0m10:17:27.310529 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m10:17:27.310529 [info ] [Thread-1 (]: 1 of 49 START sql view model default.src_ecommerce ............................. [RUN]
[0m10:17:27.310529 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_cicd.src_ecommerce, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:17:27.310529 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m10:17:27.310529 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m10:17:27.326160 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m10:17:27.341821 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m10:17:27.357406 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:17:27.373077 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m10:17:27.373077 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'bed9b0c4-da6d-4082-a04c-1840ca3566e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF297E6850>]}
[0m10:17:27.404322 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`src_ecommerce`
[0m10:17:27.419943 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m10:17:27.419943 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.src_ecommerce"
[0m10:17:27.419943 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`src_ecommerce`
  
  as (
    SELECT * FROM default.sales_ecommerce
  )

[0m10:17:27.419943 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:17:28.169908 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a) - Created
[0m10:17:31.607528 [debug] [Thread-1 (]: SQL status: OK in 4.190 seconds
[0m10:17:31.607528 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, command-id=01f0777e-b1ec-10d2-a2c5-ceb4b522ea87) - Closing
[0m10:17:31.623034 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:17:31.638660 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bed9b0c4-da6d-4082-a04c-1840ca3566e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF297DEB90>]}
[0m10:17:31.638660 [info ] [Thread-1 (]: 1 of 49 OK created sql view model default.src_ecommerce ........................ [[32mOK[0m in 4.31s]
[0m10:17:31.638660 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m10:17:31.638660 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m10:17:31.638660 [info ] [Thread-1 (]: 2 of 49 START sql view model default.stg_ecommerce ............................. [RUN]
[0m10:17:31.638660 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m10:17:31.638660 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, name=model.dbt_databricks_cicd.stg_ecommerce, idle-time=0.01562666893005371s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.src_ecommerce
[0m10:17:31.638660 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m10:17:31.654324 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:17:31.654324 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m10:17:31.669950 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:17:31.669950 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`stg_ecommerce`
[0m10:17:31.669950 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:17:31.669950 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:17:31.669950 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`stg_ecommerce`
  
  as (
    SELECT
  User_ID,
  Product_ID,
  Category,
  Price,
  Discount,
  Final_Price,
  Payment_Method,
  Purchase_Date
FROM `workspace`.`default`.`src_ecommerce`
  )

[0m10:17:32.638655 [debug] [Thread-1 (]: SQL status: OK in 0.970 seconds
[0m10:17:32.638655 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, command-id=01f0777e-b3fe-1e41-9034-bf7f30e579f1) - Closing
[0m10:17:32.638655 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:17:32.638655 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bed9b0c4-da6d-4082-a04c-1840ca3566e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF29B934D0>]}
[0m10:17:32.638655 [info ] [Thread-1 (]: 2 of 49 OK created sql view model default.stg_ecommerce ........................ [[32mOK[0m in 1.00s]
[0m10:17:32.638655 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m10:17:32.638655 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__PayPal__Bank_Transfer.e4d027c10e
[0m10:17:32.638655 [info ] [Thread-1 (]: 3 of 49 START test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__PayPal__Bank_Transfer  [RUN]
[0m10:17:32.654324 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__PayPal__Bank_Transfer.e4d027c10e)
[0m10:17:32.654324 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, name=test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__PayPal__Bank_Transfer.e4d027c10e, idle-time=0.015668392181396484s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.stg_ecommerce
[0m10:17:32.654324 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__PayPal__Bank_Transfer.e4d027c10e
[0m10:17:32.654324 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__PayPal__Bank_Transfer.e4d027c10e"
[0m10:17:32.654324 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__PayPal__Bank_Transfer.e4d027c10e
[0m10:17:32.701185 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__PayPal__Bank_Transfer.e4d027c10e"
[0m10:17:32.701185 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__PayPal__Bank_Transfer.e4d027c10e"
[0m10:17:32.701185 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__PayPal__Bank_Transfer.e4d027c10e: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__PayPal__Bank_Transfer.e4d027c10e"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from `workspace`.`default`.`stg_ecommerce`
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    'Credit Card','PayPal','Bank Transfer'
)



  
  
      
    ) dbt_internal_test
[0m10:17:37.779280 [debug] [Thread-1 (]: SQL status: OK in 5.080 seconds
[0m10:17:37.794915 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, command-id=01f0777e-b49d-15a7-b5a6-2fa562356119) - Closing
[0m10:17:37.794915 [error] [Thread-1 (]: 3 of 49 FAIL 4 accepted_values_stg_ecommerce_Payment_Method__Credit_Card__PayPal__Bank_Transfer  [[31mFAIL 4[0m in 5.14s]
[0m10:17:37.794915 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__PayPal__Bank_Transfer.e4d027c10e
[0m10:17:37.794915 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m10:17:37.794915 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__PayPal__Bank_Transfer.e4d027c10e' to be skipped because of status 'fail'.  Reason: Got 4 results, configured to fail if != 0.
[0m10:17:37.794915 [info ] [Thread-1 (]: 4 of 49 START test non_negative_stg_ecommerce_Discount ......................... [RUN]
[0m10:17:37.810539 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__PayPal__Bank_Transfer.e4d027c10e, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb)
[0m10:17:37.810539 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb, idle-time=0.015623807907104492s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__PayPal__Bank_Transfer.e4d027c10e
[0m10:17:37.810539 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m10:17:37.810539 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m10:17:37.826155 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m10:17:37.826155 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m10:17:37.826155 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m10:17:37.826155 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    select *
    from `workspace`.`default`.`stg_ecommerce`
    where Discount < 0

  
  
      
    ) dbt_internal_test
[0m10:17:38.545047 [debug] [Thread-1 (]: SQL status: OK in 0.720 seconds
[0m10:17:38.545047 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, command-id=01f0777e-b7aa-103a-af1c-14e61a094f87) - Closing
[0m10:17:38.545047 [info ] [Thread-1 (]: 4 of 49 PASS non_negative_stg_ecommerce_Discount ............................... [[32mPASS[0m in 0.73s]
[0m10:17:38.560530 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m10:17:38.560530 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m10:17:38.560530 [info ] [Thread-1 (]: 5 of 49 START test non_negative_stg_ecommerce_Final_Price ...................... [RUN]
[0m10:17:38.560530 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7)
[0m10:17:38.560530 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7, idle-time=0.015483617782592773s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m10:17:38.560530 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m10:17:38.576158 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m10:17:38.576158 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m10:17:38.591787 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m10:17:38.591787 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m10:17:38.591787 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    select *
    from `workspace`.`default`.`stg_ecommerce`
    where Final_Price < 0

  
  
      
    ) dbt_internal_test
[0m10:17:40.045053 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    select *
    from `workspace`.`default`.`stg_ecommerce`
    where Final_Price < 0

  
  
      
    ) dbt_internal_test
: [CAST_INVALID_INPUT] The value '31,05' of the type "STRING" cannot be cast to "BIGINT" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [CAST_INVALID_INPUT] org.apache.spark.SparkNumberFormatException: [CAST_INVALID_INPUT] The value '31,05' of the type "STRING" cannot be cast to "BIGINT" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.SparkNumberFormatException: [CAST_INVALID_INPUT] The value '31,05' of the type "STRING" cannot be cast to "BIGINT" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018
	at org.apache.spark.sql.errors.QueryExecutionErrors$.invalidInputInCastToNumberError(QueryExecutionErrors.scala:188)
	at com.databricks.photon.PhotonException$.getSparkException(PhotonException.scala:205)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:487)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:777)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:344)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:213)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:714)
	at org.apache.spark.sql.Dataset.withAction(Dataset.scala:5011)
	at org.apache.spark.sql.Dataset.collectToHybridCloudStoreResults(Dataset.scala:4102)
	at org.apache.spark.sql.hive.thriftserver.HybridCloudStoreResultHandler.computeResult(HybridCloudStoreResultHandler.scala:61)
	at org.apache.spark.sql.hive.thriftserver.HybridCloudStoreResultHandler.computeResult(HybridCloudStoreResultHandler.scala:32)
	at org.apache.spark.sql.hive.thriftserver.ResultCollector.$anonfun$collectResult$13(ResultCollector.scala:170)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at org.apache.spark.sql.hive.thriftserver.ResultCollector.collectResult(ResultCollector.scala:170)
	at org.apache.spark.sql.hive.thriftserver.ResultCollector.collectResult$(ResultCollector.scala:88)
	at org.apache.spark.sql.hive.thriftserver.HybridCloudStoreResultHandler.collectResult(HybridCloudStoreResultHandler.scala:32)
	at org.apache.spark.sql.hive.thriftserver.HybridCloudStoreResultHandler.org$apache$spark$sql$hive$thriftserver$HybridCloudStoreResultHandler$$initFromDataFrame(HybridCloudStoreResultHandler.scala:84)
	at org.apache.spark.sql.hive.thriftserver.HybridCloudStoreResultHandler$.createFromDataFrame(HybridCloudStoreResultHandler.scala:213)
	at org.apache.spark.sql.hive.thriftserver.ResultHandlerFactory.getCollectorHandler(ResultHandlerFactory.scala:473)
	at org.apache.spark.sql.hive.thriftserver.ResultHandlerFactory.createResultHandler(ResultHandlerFactory.scala:446)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$12(SparkExecuteStatementOperation.scala:921)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withSuspendedQueryHangingDetection(SparkExecuteStatementOperation.scala:180)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:918)
	... 43 more
	Suppressed: org.apache.spark.SparkException: Job aborted due to stage failure: com.databricks.photon.PhotonException: Error class: InvalidInputSyntaxForNumericError. Parameters: long,31,05
	at 0xbcad333 <photon>.InvalidInputSyntaxForNumericError(external/workspace_spark_3_5/photon/common/status.cc:343)
	at 0x87462eb <photon>.OnInvalidInput(external/workspace_spark_3_5/photon/exprs/cast-functions.h:673)
	at 0x8745f33 <photon>.ProjectBatch(external/workspace_spark_3_5/photon/exprs/compute-function.h:1125)
	at 0x87458eb <photon>.Eval(external/workspace_spark_3_5/photon/exprs/unary-expr.h:120)
	at 0x8a22763 <photon>.EvalImpl(external/workspace_spark_3_5/photon/exprs/binary-expr.h:202)
	at 0xb714047 <photon>.EvalImpl(external/workspace_spark_3_5/photon/exprs/logical-functions.cc:290)
	at 0xb714047 <photon>.Eval(external/workspace_spark_3_5/photon/io/parquet-reader/data-filter.cc:142)
	at 0x7155cc7 <photon>.EvalAllFilters(external/workspace_spark_3_5/photon/io/parquet-reader/data-filter.cc:407)
	at 0x718d29f <photon>.ScanAndFilterRowsUntilNonEmptyBatch(external/workspace_spark_3_5/photon/io/parquet-reader/row-group-reader.cc:1505)
	at 0x718dc63 <photon>.YieldRowsWithFilter(external/workspace_spark_3_5/photon/io/parquet-reader/row-group-reader.cc:1564)
	at 0x718f363 <photon>.operator()(external/workspace_spark_3_5/photon/io/parquet-reader/row-group-reader.cc:1756)
	at 0x718e90b <photon>.Next(external/workspace_spark_3_5/photon/io/parquet-reader/row-group-reader.cc:1655)
	at 0x717eff3 <photon>.Next(external/workspace_spark_3_5/photon/io/parquet-reader/file-reader.cc:396)
	at 0x6e0f59b <photon>.operator()(external/workspace_spark_3_5/photon/exec-nodes/file-scan-node.cc:849)
	at 0x6e0d537 <photon>.TryPullNextBatch(external/workspace_spark_3_5/photon/exec-nodes/file-scan-node.cc:849)
	at 0x6e0d537 <photon>.DoHasNextImpl(external/workspace_spark_3_5/photon/exec-nodes/file-scan-node.cc:704)
	at 0x6e0cbd3 <photon>.HasNextImpl(external/workspace_spark_3_5/photon/exec-nodes/file-scan-node.cc:466)
	at 0x6d7c5e7 <photon>.OpenImpl(external/workspace_spark_3_5/photon/exec-nodes/agg-node.cc:80)
	at 0x6d7c3cf <photon>.OpenImpl(external/workspace_spark_3_5/photon/exec-nodes/shuffle-sink-node.cc:171)
	at com.databricks.photon.JniApiImpl.open(Native Method)
	at com.databricks.photon.JniApi.open(JniApi.scala)
	at com.databricks.photon.JniExecNode.open(JniExecNode.java:73)
	at com.databricks.photon.PhotonPreShuffleResultHandler.$anonfun$getResult$1(PhotonExec.scala:1041)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.photon.PhotonResultHandler.timeit(PhotonResultHandler.scala:30)
	at com.databricks.photon.PhotonResultHandler.timeit$(PhotonResultHandler.scala:28)
	at com.databricks.photon.PhotonPreShuffleResultHandler.timeit(PhotonExec.scala:1034)
	at com.databricks.photon.PhotonPreShuffleResultHandler.getResult(PhotonExec.scala:1041)
	at com.databricks.photon.PhotonBasicEvaluatorFactory$PhotonBasicEvaluator$$anon$1.open(PhotonBasicEvaluatorFactory.scala:252)
	at com.databricks.photon.PhotonBasicEvaluatorFactory$PhotonBasicEvaluator$$anon$1.hasNextImpl(PhotonBasicEvaluatorFactory.scala:257)
	at com.databricks.photon.PhotonBasicEvaluatorFactory$PhotonBasicEvaluator$$anon$1.$anonfun$hasNext$1(PhotonBasicEvaluatorFactory.scala:275)
	at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
	at org.apache.spark.TaskContext.runFuncAsBillable(TaskContext.scala:268)
	at com.databricks.photon.PhotonBasicEvaluatorFactory$PhotonBasicEvaluator$$anon$1.hasNext(PhotonBasicEvaluatorFactory.scala:275)
	at com.databricks.photon.CloseableIterator$$anon$10.hasNext(CloseableIterator.scala:211)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
	at com.databricks.photon.MetadataOnlyShuffleWriter.write(MetadataOnlyShuffleWriter.scala:50)
	at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:56)
	at org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$3(ShuffleMapTask.scala:87)
	at com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)
	at org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$1(ShuffleMapTask.scala:82)
	at com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:58)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:39)
	at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:227)
	at org.apache.spark.scheduler.Task.doRunTask(Task.scala:204)
	at org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:166)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:160)
	at com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)
	at org.apache.spark.scheduler.Task.run(Task.scala:105)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$11(Executor.scala:1224)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)
	at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:112)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:1228)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:1080)
	at com.databricks.aether.RDDTask.run(RDDTask.scala:194)
	at com.databricks.aether.worker.WorkerTaskAttemptThread.$anonfun$runInternal$1(AetherWorkerImpl.scala:254)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.aether.AetherInt64Gauge.scopedAdd(AetherServiceMetricImpls.scala:129)
	at com.databricks.aether.worker.WorkerTaskAttemptThread.runInternal(AetherWorkerImpl.scala:244)
	at com.databricks.aether.worker.WorkerTaskAttemptThread.run(AetherWorkerImpl.scala:222)
	at com.databricks.aether.FairBlockingQueue$SlotCountingRunnable.run(FairBlockingQueue.java:425)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)

		at org.apache.spark.scheduler.DAGScheduler.$anonfun$failJobAndIndependentStages$1(DAGScheduler.scala:4511)
		at scala.Option.getOrElse(Option.scala:189)
		at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:4509)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3(DAGScheduler.scala:4421)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$3$adapted(DAGScheduler.scala:4408)
		at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)
		at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)
		at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$1(DAGScheduler.scala:4408)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
		at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:4399)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$2(DAGScheduler.scala:1882)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$2$adapted(DAGScheduler.scala:1869)
		at scala.Option.foreach(Option.scala:407)
		at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1869)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
		at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1869)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:4775)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.liftedTree1$1(DAGScheduler.scala:4673)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:4672)
		at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:4658)
		at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:55)
	Caused by: com.databricks.photon.PhotonException: Error class: InvalidInputSyntaxForNumericError. Parameters: long,31,05
		at 0xbcad333 <photon>.InvalidInputSyntaxForNumericError(external/workspace_spark_3_5/photon/common/status.cc:343)
		at 0x87462eb <photon>.OnInvalidInput(external/workspace_spark_3_5/photon/exprs/cast-functions.h:673)
		at 0x8745f33 <photon>.ProjectBatch(external/workspace_spark_3_5/photon/exprs/compute-function.h:1125)
		at 0x87458eb <photon>.Eval(external/workspace_spark_3_5/photon/exprs/unary-expr.h:120)
		at 0x8a22763 <photon>.EvalImpl(external/workspace_spark_3_5/photon/exprs/binary-expr.h:202)
		at 0xb714047 <photon>.EvalImpl(external/workspace_spark_3_5/photon/exprs/logical-functions.cc:290)
		at 0xb714047 <photon>.Eval(external/workspace_spark_3_5/photon/io/parquet-reader/data-filter.cc:142)
		at 0x7155cc7 <photon>.EvalAllFilters(external/workspace_spark_3_5/photon/io/parquet-reader/data-filter.cc:407)
		at 0x718d29f <photon>.ScanAndFilterRowsUntilNonEmptyBatch(external/workspace_spark_3_5/photon/io/parquet-reader/row-group-reader.cc:1505)
		at 0x718dc63 <photon>.YieldRowsWithFilter(external/workspace_spark_3_5/photon/io/parquet-reader/row-group-reader.cc:1564)
		at 0x718f363 <photon>.operator()(external/workspace_spark_3_5/photon/io/parquet-reader/row-group-reader.cc:1756)
		at 0x718e90b <photon>.Next(external/workspace_spark_3_5/photon/io/parquet-reader/row-group-reader.cc:1655)
		at 0x717eff3 <photon>.Next(external/workspace_spark_3_5/photon/io/parquet-reader/file-reader.cc:396)
		at 0x6e0f59b <photon>.operator()(external/workspace_spark_3_5/photon/exec-nodes/file-scan-node.cc:849)
		at 0x6e0d537 <photon>.TryPullNextBatch(external/workspace_spark_3_5/photon/exec-nodes/file-scan-node.cc:849)
		at 0x6e0d537 <photon>.DoHasNextImpl(external/workspace_spark_3_5/photon/exec-nodes/file-scan-node.cc:704)
		at 0x6e0cbd3 <photon>.HasNextImpl(external/workspace_spark_3_5/photon/exec-nodes/file-scan-node.cc:466)
		at 0x6d7c5e7 <photon>.OpenImpl(external/workspace_spark_3_5/photon/exec-nodes/agg-node.cc:80)
		at 0x6d7c3cf <photon>.OpenImpl(external/workspace_spark_3_5/photon/exec-nodes/shuffle-sink-node.cc:171)
		at com.databricks.photon.JniApiImpl.open(Native Method)
		at com.databricks.photon.JniApi.open(JniApi.scala)
		at com.databricks.photon.JniExecNode.open(JniExecNode.java:73)
		at com.databricks.photon.PhotonPreShuffleResultHandler.$anonfun$getResult$1(PhotonExec.scala:1041)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at com.databricks.photon.PhotonResultHandler.timeit(PhotonResultHandler.scala:30)
		at com.databricks.photon.PhotonResultHandler.timeit$(PhotonResultHandler.scala:28)
		at com.databricks.photon.PhotonPreShuffleResultHandler.timeit(PhotonExec.scala:1034)
		at com.databricks.photon.PhotonPreShuffleResultHandler.getResult(PhotonExec.scala:1041)
		at com.databricks.photon.PhotonBasicEvaluatorFactory$PhotonBasicEvaluator$$anon$1.open(PhotonBasicEvaluatorFactory.scala:252)
		at com.databricks.photon.PhotonBasicEvaluatorFactory$PhotonBasicEvaluator$$anon$1.hasNextImpl(PhotonBasicEvaluatorFactory.scala:257)
		at com.databricks.photon.PhotonBasicEvaluatorFactory$PhotonBasicEvaluator$$anon$1.$anonfun$hasNext$1(PhotonBasicEvaluatorFactory.scala:275)
		at scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)
		at org.apache.spark.TaskContext.runFuncAsBillable(TaskContext.scala:268)
		at com.databricks.photon.PhotonBasicEvaluatorFactory$PhotonBasicEvaluator$$anon$1.hasNext(PhotonBasicEvaluatorFactory.scala:275)
		at com.databricks.photon.CloseableIterator$$anon$10.hasNext(CloseableIterator.scala:211)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)
		at com.databricks.photon.MetadataOnlyShuffleWriter.write(MetadataOnlyShuffleWriter.scala:50)
		at org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:56)
		at org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$3(ShuffleMapTask.scala:87)
		at com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)
		at org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$1(ShuffleMapTask.scala:82)
		at com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)
		at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:58)
		at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:39)
		at org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:227)
		at org.apache.spark.scheduler.Task.doRunTask(Task.scala:204)
		at org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:166)
		at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
		at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
		at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
		at scala.util.Using$.resource(Using.scala:269)
		at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
		at org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:160)
		at com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)
		at org.apache.spark.scheduler.Task.run(Task.scala:105)
		at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$11(Executor.scala:1224)
		at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:80)
		at org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:77)
		at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:112)
		at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:1228)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)
		at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:1080)
		at com.databricks.aether.RDDTask.run(RDDTask.scala:194)
		at com.databricks.aether.worker.WorkerTaskAttemptThread.$anonfun$runInternal$1(AetherWorkerImpl.scala:254)
		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
		at com.databricks.aether.AetherInt64Gauge.scopedAdd(AetherServiceMetricImpls.scala:129)
		at com.databricks.aether.worker.WorkerTaskAttemptThread.runInternal(AetherWorkerImpl.scala:244)
		at com.databricks.aether.worker.WorkerTaskAttemptThread.run(AetherWorkerImpl.scala:222)
		at com.databricks.aether.FairBlockingQueue$SlotCountingRunnable.run(FairBlockingQueue.java:425)
		at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
		at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
		at java.base/java.lang.Thread.run(Thread.java:840)
, operation-id=01f0777e-b81e-1e9e-9902-e495be473c52
[0m10:17:40.060531 [debug] [Thread-1 (]: Database Error in test non_negative_stg_ecommerce_Final_Price (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  [CAST_INVALID_INPUT] The value '31,05' of the type "STRING" cannot be cast to "BIGINT" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\non_negative_stg_ecommerce_Final_Price.sql
[0m10:17:40.060531 [error] [Thread-1 (]: 5 of 49 ERROR non_negative_stg_ecommerce_Final_Price ........................... [[31mERROR[0m in 1.50s]
[0m10:17:40.076161 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m10:17:40.076161 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m10:17:40.076161 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7' to be skipped because of status 'error'.  Reason: Database Error in test non_negative_stg_ecommerce_Final_Price (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  [CAST_INVALID_INPUT] The value '31,05' of the type "STRING" cannot be cast to "BIGINT" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\non_negative_stg_ecommerce_Final_Price.sql.
[0m10:17:40.076161 [info ] [Thread-1 (]: 6 of 49 START test non_negative_stg_ecommerce_Price ............................ [RUN]
[0m10:17:40.076161 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d)
[0m10:17:40.076161 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d, idle-time=0.015630006790161133s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m10:17:40.076161 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m10:17:40.091827 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m10:17:40.091827 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m10:17:40.091827 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m10:17:40.107409 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m10:17:40.107409 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    select *
    from `workspace`.`default`.`stg_ecommerce`
    where Price < 0

  
  
      
    ) dbt_internal_test
[0m10:17:40.857523 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m10:17:40.873030 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, command-id=01f0777e-b905-1da2-b3be-8e997b70bf66) - Closing
[0m10:17:40.873030 [info ] [Thread-1 (]: 6 of 49 PASS non_negative_stg_ecommerce_Price .................................. [[32mPASS[0m in 0.80s]
[0m10:17:40.873030 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m10:17:40.873030 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m10:17:40.873030 [info ] [Thread-1 (]: 7 of 49 START test not_null_stg_ecommerce_Category ............................. [RUN]
[0m10:17:40.873030 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14)
[0m10:17:40.888656 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m10:17:40.888656 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m10:17:40.904319 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m10:17:40.904319 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m10:17:40.919906 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m10:17:40.919906 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m10:17:40.919906 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`stg_ecommerce`
where Category is null



  
  
      
    ) dbt_internal_test
[0m10:17:41.607405 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m10:17:41.607405 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, command-id=01f0777e-b982-1066-94be-df568e723c2e) - Closing
[0m10:17:41.623030 [info ] [Thread-1 (]: 7 of 49 PASS not_null_stg_ecommerce_Category ................................... [[32mPASS[0m in 0.75s]
[0m10:17:41.623030 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m10:17:41.623030 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m10:17:41.623030 [info ] [Thread-1 (]: 8 of 49 START test not_null_stg_ecommerce_Discount ............................. [RUN]
[0m10:17:41.623030 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836)
[0m10:17:41.623030 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m10:17:41.623030 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m10:17:41.638656 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m10:17:41.638656 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m10:17:41.654280 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m10:17:41.654280 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m10:17:41.654280 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Discount
from `workspace`.`default`.`stg_ecommerce`
where Discount is null



  
  
      
    ) dbt_internal_test
[0m10:17:42.404281 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m10:17:42.404281 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, command-id=01f0777e-b9f2-1041-bbac-c6f6ed26eec5) - Closing
[0m10:17:42.404281 [info ] [Thread-1 (]: 8 of 49 PASS not_null_stg_ecommerce_Discount ................................... [[32mPASS[0m in 0.78s]
[0m10:17:42.404281 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m10:17:42.404281 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m10:17:42.404281 [info ] [Thread-1 (]: 9 of 49 START test not_null_stg_ecommerce_Final_Price .......................... [RUN]
[0m10:17:42.404281 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc)
[0m10:17:42.419906 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m10:17:42.419906 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m10:17:42.419906 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m10:17:42.419906 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m10:17:42.435530 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m10:17:42.435530 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m10:17:42.435530 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Final_Price
from `workspace`.`default`.`stg_ecommerce`
where Final_Price is null



  
  
      
    ) dbt_internal_test
[0m10:17:43.154403 [debug] [Thread-1 (]: SQL status: OK in 0.720 seconds
[0m10:17:43.154403 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, command-id=01f0777e-ba69-1292-ab9e-9d9cd5c99659) - Closing
[0m10:17:43.169950 [info ] [Thread-1 (]: 9 of 49 PASS not_null_stg_ecommerce_Final_Price ................................ [[32mPASS[0m in 0.77s]
[0m10:17:43.169950 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m10:17:43.169950 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m10:17:43.169950 [info ] [Thread-1 (]: 10 of 49 START test not_null_stg_ecommerce_Payment_Method ...................... [RUN]
[0m10:17:43.169950 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d)
[0m10:17:43.169950 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m10:17:43.169950 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m10:17:43.185540 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m10:17:43.185540 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m10:17:43.185540 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m10:17:43.185540 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m10:17:43.185540 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`stg_ecommerce`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m10:17:43.810674 [debug] [Thread-1 (]: SQL status: OK in 0.610 seconds
[0m10:17:43.810674 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, command-id=01f0777e-badc-17a0-8327-007170cbc663) - Closing
[0m10:17:43.810674 [info ] [Thread-1 (]: 10 of 49 PASS not_null_stg_ecommerce_Payment_Method ............................ [[32mPASS[0m in 0.64s]
[0m10:17:43.826160 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m10:17:43.826160 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m10:17:43.826160 [info ] [Thread-1 (]: 11 of 49 START test not_null_stg_ecommerce_Price ............................... [RUN]
[0m10:17:43.826160 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a)
[0m10:17:43.826160 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, idle-time=0.01548624038696289s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m10:17:43.826160 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m10:17:43.841831 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m10:17:43.841831 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m10:17:43.841831 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m10:17:43.841831 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m10:17:43.841831 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Price
from `workspace`.`default`.`stg_ecommerce`
where Price is null



  
  
      
    ) dbt_internal_test
[0m10:17:44.560676 [debug] [Thread-1 (]: SQL status: OK in 0.720 seconds
[0m10:17:44.576158 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, command-id=01f0777e-bb40-1ab4-b106-9d5ff3427ce9) - Closing
[0m10:17:44.576158 [info ] [Thread-1 (]: 11 of 49 PASS not_null_stg_ecommerce_Price ..................................... [[32mPASS[0m in 0.75s]
[0m10:17:44.576158 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m10:17:44.576158 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m10:17:44.576158 [info ] [Thread-1 (]: 12 of 49 START test not_null_stg_ecommerce_Product_ID .......................... [RUN]
[0m10:17:44.576158 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c)
[0m10:17:44.576158 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m10:17:44.576158 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m10:17:44.591823 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m10:17:44.591823 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m10:17:44.591823 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m10:17:44.607448 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m10:17:44.607448 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Product_ID
from `workspace`.`default`.`stg_ecommerce`
where Product_ID is null



  
  
      
    ) dbt_internal_test
[0m10:17:45.279401 [debug] [Thread-1 (]: SQL status: OK in 0.670 seconds
[0m10:17:45.279401 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, command-id=01f0777e-bbb4-1170-be36-36d1e7cd5381) - Closing
[0m10:17:45.294905 [info ] [Thread-1 (]: 12 of 49 PASS not_null_stg_ecommerce_Product_ID ................................ [[32mPASS[0m in 0.72s]
[0m10:17:45.294905 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m10:17:45.294905 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m10:17:45.294905 [info ] [Thread-1 (]: 13 of 49 START test not_null_stg_ecommerce_Purchase_Date ....................... [RUN]
[0m10:17:45.294905 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307)
[0m10:17:45.294905 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m10:17:45.294905 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m10:17:45.310574 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m10:17:45.310574 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m10:17:45.310574 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m10:17:45.326156 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m10:17:45.326156 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Purchase_Date
from `workspace`.`default`.`stg_ecommerce`
where Purchase_Date is null



  
  
      
    ) dbt_internal_test
[0m10:17:46.029399 [debug] [Thread-1 (]: SQL status: OK in 0.700 seconds
[0m10:17:46.029399 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, command-id=01f0777e-bc21-1049-9371-ef2008617a2e) - Closing
[0m10:17:46.044905 [info ] [Thread-1 (]: 13 of 49 PASS not_null_stg_ecommerce_Purchase_Date ............................. [[32mPASS[0m in 0.75s]
[0m10:17:46.044905 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m10:17:46.044905 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m10:17:46.044905 [info ] [Thread-1 (]: 14 of 49 START test not_null_stg_ecommerce_User_ID ............................. [RUN]
[0m10:17:46.044905 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, now test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf)
[0m10:17:46.044905 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m10:17:46.044905 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m10:17:46.060542 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m10:17:46.060542 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m10:17:46.060542 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m10:17:46.060542 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m10:17:46.060542 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`stg_ecommerce`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m10:17:46.810531 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m10:17:46.810531 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, command-id=01f0777e-bc93-1600-8d1c-e0816f83cb84) - Closing
[0m10:17:46.810531 [info ] [Thread-1 (]: 14 of 49 PASS not_null_stg_ecommerce_User_ID ................................... [[32mPASS[0m in 0.77s]
[0m10:17:46.810531 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m10:17:46.810531 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m10:17:46.810531 [info ] [Thread-1 (]: 15 of 49 START test unique_stg_ecommerce_Product_ID ............................ [RUN]
[0m10:17:46.826153 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, now test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1)
[0m10:17:46.826153 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, name=test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1, idle-time=0.015622138977050781s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m10:17:46.826153 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m10:17:46.826153 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m10:17:46.841828 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m10:17:46.841828 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m10:17:46.841828 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m10:17:46.841828 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    Product_ID as unique_field,
    count(*) as n_records

from `workspace`.`default`.`stg_ecommerce`
where Product_ID is not null
group by Product_ID
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m10:17:47.591904 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m10:17:47.591904 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a, command-id=01f0777e-bd0a-1b23-b100-a183f6501b15) - Closing
[0m10:17:47.607409 [info ] [Thread-1 (]: 15 of 49 PASS unique_stg_ecommerce_Product_ID .................................. [[32mPASS[0m in 0.78s]
[0m10:17:47.607409 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m10:17:47.607409 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_discount_by_category
[0m10:17:47.607409 [info ] [Thread-1 (]: 16 of 49 SKIP relation default.avg_discount_by_category ........................ [[33mSKIP[0m]
[0m10:17:47.607409 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_discount_by_category
[0m10:17:47.607409 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:17:47.607409 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.avg_discount_by_category' to be skipped because of status 'skipped'. 
[0m10:17:47.607409 [info ] [Thread-1 (]: 17 of 49 SKIP relation default.avg_ticket_by_category .......................... [[33mSKIP[0m]
[0m10:17:47.607409 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:17:47.623041 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.monthly_revenue
[0m10:17:47.623041 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.avg_ticket_by_category' to be skipped because of status 'skipped'. 
[0m10:17:47.623041 [info ] [Thread-1 (]: 18 of 49 SKIP relation default.monthly_revenue ................................. [[33mSKIP[0m]
[0m10:17:47.623041 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.monthly_revenue
[0m10:17:47.623041 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.payment_distribution
[0m10:17:47.623041 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.monthly_revenue' to be skipped because of status 'skipped'. 
[0m10:17:47.623041 [info ] [Thread-1 (]: 19 of 49 SKIP relation default.payment_distribution ............................ [[33mSKIP[0m]
[0m10:17:47.623041 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.payment_distribution
[0m10:17:47.623041 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.sales_by_category
[0m10:17:47.623041 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.payment_distribution' to be skipped because of status 'skipped'. 
[0m10:17:47.623041 [info ] [Thread-1 (]: 20 of 49 SKIP relation default.sales_by_category ............................... [[33mSKIP[0m]
[0m10:17:47.638660 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.sales_by_category
[0m10:17:47.638660 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_5_products
[0m10:17:47.638660 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.sales_by_category' to be skipped because of status 'skipped'. 
[0m10:17:47.638660 [info ] [Thread-1 (]: 21 of 49 SKIP relation default.top_5_products .................................. [[33mSKIP[0m]
[0m10:17:47.638660 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_5_products
[0m10:17:47.638660 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_customers
[0m10:17:47.638660 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.top_5_products' to be skipped because of status 'skipped'. 
[0m10:17:47.638660 [info ] [Thread-1 (]: 22 of 49 SKIP relation default.top_customers ................................... [[33mSKIP[0m]
[0m10:17:47.638660 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_customers
[0m10:17:47.638660 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6
[0m10:17:47.638660 [debug] [Thread-4 (]: Marking all children of 'model.dbt_databricks_cicd.top_customers' to be skipped because of status 'skipped'. 
[0m10:17:47.654279 [info ] [Thread-1 (]: 23 of 49 SKIP test dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0  [[33mSKIP[0m]
[0m10:17:47.654279 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6
[0m10:17:47.654279 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:17:47.654279 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6' to be skipped because of status 'skipped'. 
[0m10:17:47.654279 [info ] [Thread-1 (]: 24 of 49 SKIP test not_null_avg_discount_by_category_Category .................. [[33mSKIP[0m]
[0m10:17:47.654279 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:17:47.654279 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:17:47.654279 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b' to be skipped because of status 'skipped'. 
[0m10:17:47.654279 [info ] [Thread-1 (]: 25 of 49 SKIP test not_null_avg_discount_by_category_avg_discount_percent ...... [[33mSKIP[0m]
[0m10:17:47.654279 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:17:47.669905 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101' to be skipped because of status 'skipped'. 
[0m10:17:47.654279 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301
[0m10:17:47.669905 [info ] [Thread-1 (]: 26 of 49 SKIP test dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0  [[33mSKIP[0m]
[0m10:17:47.669905 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301
[0m10:17:47.669905 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:17:47.669905 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301' to be skipped because of status 'skipped'. 
[0m10:17:47.669905 [info ] [Thread-1 (]: 27 of 49 SKIP test not_null_avg_ticket_by_category_Category .................... [[33mSKIP[0m]
[0m10:17:47.669905 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:17:47.669905 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:17:47.669905 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f' to be skipped because of status 'skipped'. 
[0m10:17:47.669905 [info ] [Thread-1 (]: 28 of 49 SKIP test not_null_avg_ticket_by_category_avg_ticket .................. [[33mSKIP[0m]
[0m10:17:47.685530 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:17:47.685530 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14
[0m10:17:47.685530 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41' to be skipped because of status 'skipped'. 
[0m10:17:47.685530 [info ] [Thread-1 (]: 29 of 49 SKIP test dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0  [[33mSKIP[0m]
[0m10:17:47.685530 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14
[0m10:17:47.685530 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:17:47.685530 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14' to be skipped because of status 'skipped'. 
[0m10:17:47.685530 [info ] [Thread-1 (]: 30 of 49 SKIP test not_null_monthly_revenue_month .............................. [[33mSKIP[0m]
[0m10:17:47.685530 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:17:47.685530 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:17:47.685530 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b' to be skipped because of status 'skipped'. 
[0m10:17:47.685530 [info ] [Thread-1 (]: 31 of 49 SKIP test not_null_monthly_revenue_monthly_revenue .................... [[33mSKIP[0m]
[0m10:17:47.701163 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:17:47.701163 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147
[0m10:17:47.701163 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b' to be skipped because of status 'skipped'. 
[0m10:17:47.701163 [info ] [Thread-1 (]: 32 of 49 SKIP test dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0  [[33mSKIP[0m]
[0m10:17:47.701163 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147
[0m10:17:47.701163 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97
[0m10:17:47.701163 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147' to be skipped because of status 'skipped'. 
[0m10:17:47.701163 [info ] [Thread-1 (]: 33 of 49 SKIP test dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0  [[33mSKIP[0m]
[0m10:17:47.716780 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97
[0m10:17:47.716780 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:17:47.716780 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97' to be skipped because of status 'skipped'. 
[0m10:17:47.716780 [info ] [Thread-1 (]: 34 of 49 SKIP test not_null_payment_distribution_Payment_Method ................ [[33mSKIP[0m]
[0m10:17:47.716780 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:17:47.716780 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:17:47.716780 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae' to be skipped because of status 'skipped'. 
[0m10:17:47.716780 [info ] [Thread-1 (]: 35 of 49 SKIP test not_null_payment_distribution_total_transactions ............ [[33mSKIP[0m]
[0m10:17:47.732406 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:17:47.732406 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:17:47.732406 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8' to be skipped because of status 'skipped'. 
[0m10:17:47.732406 [info ] [Thread-1 (]: 36 of 49 SKIP test not_null_payment_distribution_total_value ................... [[33mSKIP[0m]
[0m10:17:47.732406 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:17:47.732406 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7
[0m10:17:47.732406 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03' to be skipped because of status 'skipped'. 
[0m10:17:47.732406 [info ] [Thread-1 (]: 37 of 49 SKIP test dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0  [[33mSKIP[0m]
[0m10:17:47.732406 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7
[0m10:17:47.748031 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd
[0m10:17:47.748031 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7' to be skipped because of status 'skipped'. 
[0m10:17:47.748031 [info ] [Thread-1 (]: 38 of 49 SKIP test dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0  [[33mSKIP[0m]
[0m10:17:47.748031 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd
[0m10:17:47.748031 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:17:47.748031 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd' to be skipped because of status 'skipped'. 
[0m10:17:47.748031 [info ] [Thread-1 (]: 39 of 49 SKIP test not_null_sales_by_category_Category ......................... [[33mSKIP[0m]
[0m10:17:47.748031 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:17:47.748031 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:17:47.748031 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507' to be skipped because of status 'skipped'. 
[0m10:17:47.763698 [info ] [Thread-1 (]: 40 of 49 SKIP test not_null_sales_by_category_total_orders ..................... [[33mSKIP[0m]
[0m10:17:47.763698 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:17:47.763698 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:17:47.763698 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e' to be skipped because of status 'skipped'. 
[0m10:17:47.763698 [info ] [Thread-1 (]: 41 of 49 SKIP test not_null_sales_by_category_total_revenue .................... [[33mSKIP[0m]
[0m10:17:47.763698 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:17:47.763698 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57
[0m10:17:47.763698 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd' to be skipped because of status 'skipped'. 
[0m10:17:47.763698 [info ] [Thread-1 (]: 42 of 49 SKIP test dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0  [[33mSKIP[0m]
[0m10:17:47.779280 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57
[0m10:17:47.779280 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:17:47.779280 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57' to be skipped because of status 'skipped'. 
[0m10:17:47.779280 [info ] [Thread-1 (]: 43 of 49 SKIP test not_null_top_5_products_product_id .......................... [[33mSKIP[0m]
[0m10:17:47.779280 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:17:47.779280 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:17:47.779280 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe' to be skipped because of status 'skipped'. 
[0m10:17:47.779280 [info ] [Thread-1 (]: 44 of 49 SKIP test not_null_top_5_products_total_sales ......................... [[33mSKIP[0m]
[0m10:17:47.779280 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:17:47.794905 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818' to be skipped because of status 'skipped'. 
[0m10:17:47.794905 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4
[0m10:17:47.794905 [info ] [Thread-1 (]: 45 of 49 SKIP test dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0  [[33mSKIP[0m]
[0m10:17:47.794905 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4
[0m10:17:47.794905 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343
[0m10:17:47.794905 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4' to be skipped because of status 'skipped'. 
[0m10:17:47.794905 [info ] [Thread-1 (]: 46 of 49 SKIP test dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0  [[33mSKIP[0m]
[0m10:17:47.794905 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343
[0m10:17:47.794905 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:17:47.794905 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343' to be skipped because of status 'skipped'. 
[0m10:17:47.810540 [info ] [Thread-1 (]: 47 of 49 SKIP test not_null_top_customers_User_ID .............................. [[33mSKIP[0m]
[0m10:17:47.810540 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:17:47.810540 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:17:47.810540 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0' to be skipped because of status 'skipped'. 
[0m10:17:47.810540 [info ] [Thread-1 (]: 48 of 49 SKIP test not_null_top_customers_total_orders ......................... [[33mSKIP[0m]
[0m10:17:47.810540 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:17:47.810540 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m10:17:47.810540 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746' to be skipped because of status 'skipped'. 
[0m10:17:47.826156 [info ] [Thread-1 (]: 49 of 49 SKIP test not_null_top_customers_total_spent .......................... [[33mSKIP[0m]
[0m10:17:47.826156 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m10:17:47.826156 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73' to be skipped because of status 'skipped'. 
[0m10:17:47.826156 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=20.515626907348633s, language=None, compute-name=) - Reusing connection previously named master
[0m10:17:47.826156 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:17:47.826156 [debug] [MainThread]: Connection 'list_workspace' was properly closed.
[0m10:17:47.826156 [debug] [MainThread]: On list_workspace: Close
[0m10:17:47.826156 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0777e-ae08-10b2-b8f4-4c5b2e9030f6) - Closing
[0m10:17:48.045046 [debug] [MainThread]: Connection 'list_workspace_default' was properly closed.
[0m10:17:48.045046 [debug] [MainThread]: On list_workspace_default: Close
[0m10:17:48.045046 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0777e-af06-1f52-90da-59538c9ad06e) - Closing
[0m10:17:48.263664 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1' was properly closed.
[0m10:17:48.263664 [debug] [MainThread]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: Close
[0m10:17:48.263664 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0777e-b1c6-1902-838c-7b6ed297bd7a) - Closing
[0m10:17:48.482441 [info ] [MainThread]: 
[0m10:17:48.482441 [info ] [MainThread]: Finished running 40 data tests, 9 view models in 0 hours 0 minutes and 27.42 seconds (27.42s).
[0m10:17:48.482441 [debug] [MainThread]: Command end result
[0m10:17:48.576195 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m10:17:48.576195 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m10:17:48.591822 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m10:17:48.607405 [info ] [MainThread]: 
[0m10:17:48.607405 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m10:17:48.607405 [info ] [MainThread]: 
[0m10:17:48.607405 [error] [MainThread]: [31mFailure in test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__PayPal__Bank_Transfer (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m10:17:48.607405 [error] [MainThread]:   Got 4 results, configured to fail if != 0
[0m10:17:48.607405 [info ] [MainThread]: 
[0m10:17:48.623033 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\accepted_values_stg_ecommerce_83561dad4e5293008a04b564ae169f5f.sql
[0m10:17:48.623033 [info ] [MainThread]: 
[0m10:17:48.623033 [error] [MainThread]: [31mFailure in test non_negative_stg_ecommerce_Final_Price (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m10:17:48.623033 [error] [MainThread]:   Database Error in test non_negative_stg_ecommerce_Final_Price (dbt_databricks_cicd/models\staging\databricks\schema.yml)
  [CAST_INVALID_INPUT] The value '31,05' of the type "STRING" cannot be cast to "BIGINT" because it is malformed. Correct the value as per the syntax, or change its target type. Use `try_cast` to tolerate malformed input and return NULL instead. SQLSTATE: 22018
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\non_negative_stg_ecommerce_Final_Price.sql
[0m10:17:48.623033 [info ] [MainThread]: 
[0m10:17:48.623033 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\non_negative_stg_ecommerce_Final_Price.sql
[0m10:17:48.638694 [info ] [MainThread]: 
[0m10:17:48.638694 [info ] [MainThread]: Done. PASS=13 WARN=0 ERROR=2 SKIP=34 NO-OP=0 TOTAL=49
[0m10:17:48.638694 [debug] [MainThread]: Command `dbt build` failed at 10:17:48.638694 after 34.29 seconds
[0m10:17:48.638694 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF160D3DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF1CBCAE10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FF16330550>]}
[0m10:17:48.638694 [debug] [MainThread]: Flushing usage events
[0m10:17:49.794906 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:10:34.711849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002239C68B110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002239C68A690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002239C668750>]}


============================== 12:10:34.719856 | 48d0787c-4ef3-4c17-8933-9030159e66d2 ==============================
[0m12:10:34.719856 [info ] [MainThread]: Running with dbt=1.10.3
[0m12:10:34.721813 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt build --target databricks', 'send_anonymous_usage_stats': 'True'}
[0m12:10:38.521784 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m12:10:38.524788 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m12:10:38.525788 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m12:10:44.221787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '48d0787c-4ef3-4c17-8933-9030159e66d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002239C668F90>]}
[0m12:10:44.412781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '48d0787c-4ef3-4c17-8933-9030159e66d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002239BDA9B90>]}
[0m12:10:44.414781 [info ] [MainThread]: Registered adapter: databricks=1.10.4
[0m12:10:46.003317 [debug] [MainThread]: checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, vars: {}, profile: , target: databricks, version: 1.10.3
[0m12:10:48.443312 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 3 files changed.
[0m12:10:48.445311 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://dbt_databricks_cicd/models\staging\databricks\schema.yml
[0m12:10:48.447312 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://dbt_databricks_cicd/models\staging\sqlserver\stg_ecommerce.sql
[0m12:10:48.448311 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://macros\tests\non_negative.sql
[0m12:10:49.420315 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m12:10:49.453350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '48d0787c-4ef3-4c17-8933-9030159e66d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000223A8FA6A90>]}
[0m12:10:49.667315 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m12:10:49.675347 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m12:10:49.827676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '48d0787c-4ef3-4c17-8933-9030159e66d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000223A926A210>]}
[0m12:10:49.829678 [info ] [MainThread]: Found 9 models, 40 data tests, 1 source, 800 macros
[0m12:10:49.840677 [info ] [MainThread]: 
[0m12:10:49.841677 [info ] [MainThread]: Concurrency: 1 threads (target='databricks')
[0m12:10:49.843675 [info ] [MainThread]: 
[0m12:10:49.844676 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=0s, language=None, compute-name=) - Creating connection
[0m12:10:49.845675 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m12:10:49.862676 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace, idle-time=0s, language=None, compute-name=) - Creating connection
[0m12:10:49.863678 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace'
[0m12:10:49.865677 [debug] [ThreadPool]: Using databricks connection "list_workspace"
[0m12:10:49.866676 [debug] [ThreadPool]: On list_workspace: GetSchemas(database=workspace, schema=None)
[0m12:10:49.867676 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:10:50.829592 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0778e-8879-1cd2-90b6-6e8fb4bb2bae) - Created
[0m12:10:53.222844 [debug] [ThreadPool]: SQL status: OK in 3.360 seconds
[0m12:10:53.224847 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0778e-8879-1cd2-90b6-6e8fb4bb2bae, command-id=01f0778e-889b-19b4-8266-95696ab2ff9a) - Closing
[0m12:10:53.228870 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace_default, idle-time=0s, language=None, compute-name=) - Creating connection
[0m12:10:53.229924 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace_default'
[0m12:10:53.277885 [debug] [ThreadPool]: Using databricks connection "list_workspace_default"
[0m12:10:53.278887 [debug] [ThreadPool]: On list_workspace_default: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "connection_name": "list_workspace_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'workspace' 
  AND table_schema = 'default'

  
[0m12:10:53.280886 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:10:54.014482 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0778e-8a60-13d5-b1b2-e533c28e9831) - Created
[0m12:10:58.364692 [debug] [ThreadPool]: SQL status: OK in 5.080 seconds
[0m12:10:58.376590 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0778e-8a60-13d5-b1b2-e533c28e9831, command-id=01f0778e-8a82-14f2-9975-ff0a36d3c33e) - Closing
[0m12:10:58.382588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '48d0787c-4ef3-4c17-8933-9030159e66d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002239EB86990>]}
[0m12:10:58.390640 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m12:10:58.392645 [info ] [Thread-1 (]: 1 of 49 START sql view model default.src_ecommerce ............................. [RUN]
[0m12:10:58.394641 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_cicd.src_ecommerce, idle-time=0s, language=None, compute-name=) - Creating connection
[0m12:10:58.395684 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m12:10:58.397638 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m12:10:58.411678 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m12:10:58.414642 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m12:10:58.443643 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:10:58.447645 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m12:10:58.449641 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '48d0787c-4ef3-4c17-8933-9030159e66d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000223A9268250>]}
[0m12:10:58.483640 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`src_ecommerce`
[0m12:10:58.501638 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m12:10:58.503642 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:10:58.504642 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`src_ecommerce`
  
  as (
    SELECT * FROM default.sales_ecommerce
  )

[0m12:10:58.506640 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:10:59.236196 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410) - Created
[0m12:11:02.916807 [debug] [Thread-1 (]: SQL status: OK in 4.410 seconds
[0m12:11:02.918811 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-8d9c-1dee-8f31-f6becd9d66cb) - Closing
[0m12:11:02.937814 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:11:02.945821 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48d0787c-4ef3-4c17-8933-9030159e66d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000223A8EB0250>]}
[0m12:11:02.947850 [info ] [Thread-1 (]: 1 of 49 OK created sql view model default.src_ecommerce ........................ [[32mOK[0m in 4.55s]
[0m12:11:02.949815 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m12:11:02.951185 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m12:11:02.953207 [info ] [Thread-1 (]: 2 of 49 START sql view model default.stg_ecommerce ............................. [RUN]
[0m12:11:02.955227 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m12:11:02.956220 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=model.dbt_databricks_cicd.stg_ecommerce, idle-time=0.014407634735107422s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.src_ecommerce
[0m12:11:02.957229 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m12:11:02.965219 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:11:02.968223 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m12:11:02.973219 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:11:02.977266 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`stg_ecommerce`
[0m12:11:02.979270 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:11:02.981262 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:11:02.982263 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`stg_ecommerce`
  
  as (
    SELECT
  User_ID,
  Product_ID,
  Category,
  Price,
  Discount,
  Final_Price,
  Payment_Method,
  Purchase_Date
FROM `workspace`.`default`.`src_ecommerce`
  )

[0m12:11:03.757343 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m12:11:03.759345 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-8fd8-1d3b-9cd2-aa8a600c7031) - Closing
[0m12:11:03.761343 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:11:03.763344 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48d0787c-4ef3-4c17-8933-9030159e66d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000223A95F2F90>]}
[0m12:11:03.765354 [info ] [Thread-1 (]: 2 of 49 OK created sql view model default.stg_ecommerce ........................ [[32mOK[0m in 0.81s]
[0m12:11:03.767135 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m12:11:03.769754 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:11:03.770788 [info ] [Thread-1 (]: 3 of 49 START test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m12:11:03.773301 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6)
[0m12:11:03.774299 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, idle-time=0.010955333709716797s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.stg_ecommerce
[0m12:11:03.776301 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:11:03.784299 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m12:11:03.786300 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:11:03.821305 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m12:11:03.823299 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m12:11:03.825301 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from `workspace`.`default`.`stg_ecommerce`
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    'Credit Card','Net Banking','UPI','Debit Card','Cash on Delivery'
)



  
  
      
    ) dbt_internal_test
[0m12:11:05.008876 [debug] [Thread-1 (]: SQL status: OK in 1.180 seconds
[0m12:11:05.013889 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9059-1dac-b4f1-b8cc21d6d031) - Closing
[0m12:11:05.017879 [info ] [Thread-1 (]: 3 of 49 PASS accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[32mPASS[0m in 1.25s]
[0m12:11:05.020209 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:11:05.021208 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m12:11:05.023209 [info ] [Thread-1 (]: 4 of 49 START test non_negative_stg_ecommerce_Discount ......................... [RUN]
[0m12:11:05.025128 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb)
[0m12:11:05.026138 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb, idle-time=0.00825953483581543s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:11:05.027128 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m12:11:05.036127 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m12:11:05.039086 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m12:11:05.047088 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m12:11:05.049100 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m12:11:05.051090 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`stg_ecommerce`
where TRY_CAST(REPLACE(Discount, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m12:11:09.122410 [debug] [Thread-1 (]: SQL status: OK in 4.070 seconds
[0m12:11:09.127412 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9114-179a-ab0f-86919e460b1d) - Closing
[0m12:11:09.129414 [info ] [Thread-1 (]: 4 of 49 PASS non_negative_stg_ecommerce_Discount ............................... [[32mPASS[0m in 4.11s]
[0m12:11:09.131413 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m12:11:09.132410 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m12:11:09.133412 [info ] [Thread-1 (]: 5 of 49 START test non_negative_stg_ecommerce_Final_Price ...................... [RUN]
[0m12:11:09.135411 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7)
[0m12:11:09.137412 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7, idle-time=0.006997585296630859s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m12:11:09.138411 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m12:11:09.149411 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m12:11:09.151412 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m12:11:09.158410 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m12:11:09.160414 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m12:11:09.161412 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`stg_ecommerce`
where TRY_CAST(REPLACE(Final_Price, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m12:11:10.037027 [debug] [Thread-1 (]: SQL status: OK in 0.870 seconds
[0m12:11:10.041022 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9388-12bd-9490-db2db5024cb5) - Closing
[0m12:11:10.043024 [info ] [Thread-1 (]: 5 of 49 PASS non_negative_stg_ecommerce_Final_Price ............................ [[32mPASS[0m in 0.91s]
[0m12:11:10.044813 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m12:11:10.045860 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m12:11:10.047853 [info ] [Thread-1 (]: 6 of 49 START test non_negative_stg_ecommerce_Price ............................ [RUN]
[0m12:11:10.049437 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d)
[0m12:11:10.050436 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d, idle-time=0.00841522216796875s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m12:11:10.051437 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m12:11:10.060436 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m12:11:10.062436 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m12:11:10.069437 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m12:11:10.071436 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m12:11:10.073435 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`stg_ecommerce`
where TRY_CAST(REPLACE(Price, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m12:11:11.111085 [debug] [Thread-1 (]: SQL status: OK in 1.040 seconds
[0m12:11:11.115087 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9413-1284-93f5-1f3934986dda) - Closing
[0m12:11:11.117088 [info ] [Thread-1 (]: 6 of 49 PASS non_negative_stg_ecommerce_Price .................................. [[32mPASS[0m in 1.07s]
[0m12:11:11.119364 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m12:11:11.120406 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:11:11.122405 [info ] [Thread-1 (]: 7 of 49 START test not_null_stg_ecommerce_Category ............................. [RUN]
[0m12:11:11.124003 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14)
[0m12:11:11.125001 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, idle-time=0.007912635803222656s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m12:11:11.126002 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:11:11.139001 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m12:11:11.141000 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:11:11.148040 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m12:11:11.151004 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m12:11:11.153003 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`stg_ecommerce`
where Category is null



  
  
      
    ) dbt_internal_test
[0m12:11:11.835925 [debug] [Thread-1 (]: SQL status: OK in 0.680 seconds
[0m12:11:11.839928 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-94b8-13eb-aeb0-d19b34e67279) - Closing
[0m12:11:11.841929 [info ] [Thread-1 (]: 7 of 49 PASS not_null_stg_ecommerce_Category ................................... [[32mPASS[0m in 0.72s]
[0m12:11:11.844087 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:11:11.845125 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:11:11.847138 [info ] [Thread-1 (]: 8 of 49 START test not_null_stg_ecommerce_Discount ............................. [RUN]
[0m12:11:11.848745 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836)
[0m12:11:11.849742 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, idle-time=0.007813215255737305s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:11:11.851744 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:11:11.859743 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m12:11:11.861747 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:11:11.869741 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m12:11:11.872745 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m12:11:11.873743 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Discount
from `workspace`.`default`.`stg_ecommerce`
where Discount is null



  
  
      
    ) dbt_internal_test
[0m12:11:12.654876 [debug] [Thread-1 (]: SQL status: OK in 0.780 seconds
[0m12:11:12.658917 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9525-1bd4-af14-6eb0f2952766) - Closing
[0m12:11:12.660920 [info ] [Thread-1 (]: 8 of 49 PASS not_null_stg_ecommerce_Discount ................................... [[32mPASS[0m in 0.81s]
[0m12:11:12.662883 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:11:12.663883 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:11:12.665881 [info ] [Thread-1 (]: 9 of 49 START test not_null_stg_ecommerce_Final_Price .......................... [RUN]
[0m12:11:12.667916 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc)
[0m12:11:12.668881 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, idle-time=0.007961511611938477s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:11:12.669921 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:11:12.679915 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m12:11:12.681917 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:11:12.688875 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m12:11:12.690882 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m12:11:12.692883 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Final_Price
from `workspace`.`default`.`stg_ecommerce`
where Final_Price is null



  
  
      
    ) dbt_internal_test
[0m12:11:13.414609 [debug] [Thread-1 (]: SQL status: OK in 0.720 seconds
[0m12:11:13.417611 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-95a2-1f63-b0dd-fa4d3e39b5ce) - Closing
[0m12:11:13.420610 [info ] [Thread-1 (]: 9 of 49 PASS not_null_stg_ecommerce_Final_Price ................................ [[32mPASS[0m in 0.75s]
[0m12:11:13.422627 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:11:13.423649 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:11:13.424649 [info ] [Thread-1 (]: 10 of 49 START test not_null_stg_ecommerce_Payment_Method ...................... [RUN]
[0m12:11:13.427128 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d)
[0m12:11:13.428127 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, idle-time=0.008518218994140625s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:11:13.429126 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:11:13.437168 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m12:11:13.439128 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:11:13.445125 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m12:11:13.447127 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m12:11:13.449129 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`stg_ecommerce`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m12:11:14.240685 [debug] [Thread-1 (]: SQL status: OK in 0.790 seconds
[0m12:11:14.247688 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9615-1c53-a203-c18bc1d88c7a) - Closing
[0m12:11:14.251688 [info ] [Thread-1 (]: 10 of 49 PASS not_null_stg_ecommerce_Payment_Method ............................ [[32mPASS[0m in 0.82s]
[0m12:11:14.254685 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:11:14.257686 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:11:14.259684 [info ] [Thread-1 (]: 11 of 49 START test not_null_stg_ecommerce_Price ............................... [RUN]
[0m12:11:14.262687 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a)
[0m12:11:14.265687 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, idle-time=0.013998270034790039s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:11:14.267701 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:11:14.282685 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m12:11:14.284687 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:11:14.290683 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m12:11:14.292686 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m12:11:14.294693 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Price
from `workspace`.`default`.`stg_ecommerce`
where Price is null



  
  
      
    ) dbt_internal_test
[0m12:11:15.016630 [debug] [Thread-1 (]: SQL status: OK in 0.720 seconds
[0m12:11:15.020635 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9696-1acc-b5a5-e9924f29e8e2) - Closing
[0m12:11:15.022636 [info ] [Thread-1 (]: 11 of 49 PASS not_null_stg_ecommerce_Price ..................................... [[32mPASS[0m in 0.76s]
[0m12:11:15.024596 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:11:15.025595 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:11:15.026595 [info ] [Thread-1 (]: 12 of 49 START test not_null_stg_ecommerce_Product_ID .......................... [RUN]
[0m12:11:15.028589 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c)
[0m12:11:15.030604 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, idle-time=0.00695490837097168s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:11:15.031590 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:11:15.039589 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m12:11:15.041589 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:11:15.049588 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m12:11:15.051590 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m12:11:15.052591 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Product_ID
from `workspace`.`default`.`stg_ecommerce`
where Product_ID is null



  
  
      
    ) dbt_internal_test
[0m12:11:15.737526 [debug] [Thread-1 (]: SQL status: OK in 0.680 seconds
[0m12:11:15.741528 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-970a-19f1-9bbf-2b61378883c0) - Closing
[0m12:11:15.743531 [info ] [Thread-1 (]: 12 of 49 PASS not_null_stg_ecommerce_Product_ID ................................ [[32mPASS[0m in 0.71s]
[0m12:11:15.746526 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:11:15.747526 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:11:15.748526 [info ] [Thread-1 (]: 13 of 49 START test not_null_stg_ecommerce_Purchase_Date ....................... [RUN]
[0m12:11:15.750525 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307)
[0m12:11:15.751526 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, idle-time=0.007995367050170898s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:11:15.752527 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:11:15.764526 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m12:11:15.766525 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:11:15.773525 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m12:11:15.775526 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m12:11:15.776527 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Purchase_Date
from `workspace`.`default`.`stg_ecommerce`
where Purchase_Date is null



  
  
      
    ) dbt_internal_test
[0m12:11:16.468197 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m12:11:16.472202 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9779-11aa-b191-0ea425507f8c) - Closing
[0m12:11:16.474207 [info ] [Thread-1 (]: 13 of 49 PASS not_null_stg_ecommerce_Purchase_Date ............................. [[32mPASS[0m in 0.72s]
[0m12:11:16.476199 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:11:16.478198 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:11:16.480203 [info ] [Thread-1 (]: 14 of 49 START test not_null_stg_ecommerce_User_ID ............................. [RUN]
[0m12:11:16.481203 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, now test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf)
[0m12:11:16.483202 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, idle-time=0.008994817733764648s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:11:16.484196 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:11:16.492201 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m12:11:16.494202 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:11:16.503196 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m12:11:16.505198 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m12:11:16.507202 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`stg_ecommerce`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m12:11:17.205571 [debug] [Thread-1 (]: SQL status: OK in 0.700 seconds
[0m12:11:17.208574 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-97e9-1501-a058-0c178609691b) - Closing
[0m12:11:17.211572 [info ] [Thread-1 (]: 14 of 49 PASS not_null_stg_ecommerce_User_ID ................................... [[32mPASS[0m in 0.73s]
[0m12:11:17.213201 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:11:17.214241 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m12:11:17.216239 [info ] [Thread-1 (]: 15 of 49 START test unique_stg_ecommerce_Product_ID ............................ [RUN]
[0m12:11:17.217814 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, now test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1)
[0m12:11:17.218813 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1, idle-time=0.008240461349487305s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:11:17.219813 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m12:11:17.234832 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m12:11:17.238815 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m12:11:17.251815 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m12:11:17.255814 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m12:11:17.257814 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    Product_ID as unique_field,
    count(*) as n_records

from `workspace`.`default`.`stg_ecommerce`
where Product_ID is not null
group by Product_ID
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m12:11:18.055494 [debug] [Thread-1 (]: SQL status: OK in 0.790 seconds
[0m12:11:18.059496 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-985c-131c-923e-c4368a7b9071) - Closing
[0m12:11:18.061498 [info ] [Thread-1 (]: 15 of 49 PASS unique_stg_ecommerce_Product_ID .................................. [[32mPASS[0m in 0.84s]
[0m12:11:18.063738 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m12:11:18.065736 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_discount_by_category
[0m12:11:18.067777 [info ] [Thread-1 (]: 16 of 49 START sql view model default.avg_discount_by_category ................. [RUN]
[0m12:11:18.069503 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1, now model.dbt_databricks_cicd.avg_discount_by_category)
[0m12:11:18.070500 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=model.dbt_databricks_cicd.avg_discount_by_category, idle-time=0.009001731872558594s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m12:11:18.071503 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_discount_by_category
[0m12:11:18.079501 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m12:11:18.081501 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_discount_by_category
[0m12:11:18.088499 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:11:18.090501 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`avg_discount_by_category`
[0m12:11:18.092510 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m12:11:18.095501 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.avg_discount_by_category"
[0m12:11:18.096503 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_discount_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.avg_discount_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`avg_discount_by_category`
  
  as (
    SELECT
  Category,
  ROUND(AVG(CAST(`Discount` AS DOUBLE)), 2) AS avg_discount_percent
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY avg_discount_percent DESC
  )

[0m12:11:18.739912 [debug] [Thread-1 (]: SQL status: OK in 0.640 seconds
[0m12:11:18.742911 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-98da-18d4-a362-06c8def0f233) - Closing
[0m12:11:18.743912 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:11:18.746911 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48d0787c-4ef3-4c17-8933-9030159e66d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002239C1035D0>]}
[0m12:11:18.747911 [info ] [Thread-1 (]: 16 of 49 OK created sql view model default.avg_discount_by_category ............ [[32mOK[0m in 0.68s]
[0m12:11:18.749942 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_discount_by_category
[0m12:11:18.750981 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m12:11:18.752980 [info ] [Thread-1 (]: 17 of 49 START sql view model default.avg_ticket_by_category ................... [RUN]
[0m12:11:18.754887 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_discount_by_category, now model.dbt_databricks_cicd.avg_ticket_by_category)
[0m12:11:18.755886 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=model.dbt_databricks_cicd.avg_ticket_by_category, idle-time=0.009974241256713867s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.avg_discount_by_category
[0m12:11:18.756886 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_ticket_by_category
[0m12:11:18.763885 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m12:11:18.765886 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_ticket_by_category
[0m12:11:18.771889 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:11:18.773892 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`avg_ticket_by_category`
[0m12:11:18.775899 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m12:11:18.778891 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m12:11:18.779891 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_ticket_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.avg_ticket_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`avg_ticket_by_category`
  
  as (
    SELECT
  Category,
  ROUND(AVG(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS avg_ticket
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY avg_ticket DESC
  )

[0m12:11:19.403676 [debug] [Thread-1 (]: SQL status: OK in 0.620 seconds
[0m12:11:19.405678 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9944-1e10-9b79-50de8562e0e9) - Closing
[0m12:11:19.407679 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:11:19.409641 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48d0787c-4ef3-4c17-8933-9030159e66d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002239C0CD0D0>]}
[0m12:11:19.411683 [info ] [Thread-1 (]: 17 of 49 OK created sql view model default.avg_ticket_by_category .............. [[32mOK[0m in 0.66s]
[0m12:11:19.413640 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m12:11:19.414680 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.monthly_revenue
[0m12:11:19.416680 [info ] [Thread-1 (]: 18 of 49 START sql view model default.monthly_revenue .......................... [RUN]
[0m12:11:19.418628 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_ticket_by_category, now model.dbt_databricks_cicd.monthly_revenue)
[0m12:11:19.419626 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=model.dbt_databricks_cicd.monthly_revenue, idle-time=0.009985208511352539s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.avg_ticket_by_category
[0m12:11:19.420625 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.monthly_revenue
[0m12:11:19.427625 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.monthly_revenue"
[0m12:11:19.430628 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.monthly_revenue
[0m12:11:19.436623 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:11:19.438627 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`monthly_revenue`
[0m12:11:19.440626 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.monthly_revenue"
[0m12:11:19.444626 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.monthly_revenue"
[0m12:11:19.445625 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.monthly_revenue: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.monthly_revenue"} */

  
  
  
  create or replace view `workspace`.`default`.`monthly_revenue`
  
  as (
    SELECT
  CAST(DATE_TRUNC('month', CAST(Purchase_Date AS DATE)) AS DATE) AS month,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS monthly_revenue
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY 1
ORDER BY 1
  )

[0m12:11:20.138508 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m12:11:20.140512 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-99a8-16f8-84d7-af34b22695a4) - Closing
[0m12:11:20.142512 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:11:20.145514 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48d0787c-4ef3-4c17-8933-9030159e66d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000223A9686890>]}
[0m12:11:20.147512 [info ] [Thread-1 (]: 18 of 49 OK created sql view model default.monthly_revenue ..................... [[32mOK[0m in 0.73s]
[0m12:11:20.149271 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.monthly_revenue
[0m12:11:20.150322 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.payment_distribution
[0m12:11:20.152309 [info ] [Thread-1 (]: 19 of 49 START sql view model default.payment_distribution ..................... [RUN]
[0m12:11:20.154208 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.monthly_revenue, now model.dbt_databricks_cicd.payment_distribution)
[0m12:11:20.155206 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=model.dbt_databricks_cicd.payment_distribution, idle-time=0.00969243049621582s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.monthly_revenue
[0m12:11:20.156205 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.payment_distribution
[0m12:11:20.163204 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.payment_distribution"
[0m12:11:20.166208 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.payment_distribution
[0m12:11:20.171203 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:11:20.173207 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`payment_distribution`
[0m12:11:20.176216 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.payment_distribution"
[0m12:11:20.178206 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.payment_distribution"
[0m12:11:20.180205 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.payment_distribution: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.payment_distribution"} */

  
  
  
  create or replace view `workspace`.`default`.`payment_distribution`
  
  as (
    SELECT
  Payment_Method,
  COUNT(*) AS total_transactions,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_value
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Payment_Method
ORDER BY total_value DESC
  )

[0m12:11:20.837704 [debug] [Thread-1 (]: SQL status: OK in 0.660 seconds
[0m12:11:20.839708 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9a18-1d63-8c07-6c0ad52d2a0b) - Closing
[0m12:11:20.842713 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:11:20.844709 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48d0787c-4ef3-4c17-8933-9030159e66d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000223A926BAD0>]}
[0m12:11:20.846707 [info ] [Thread-1 (]: 19 of 49 OK created sql view model default.payment_distribution ................ [[32mOK[0m in 0.69s]
[0m12:11:20.848377 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.payment_distribution
[0m12:11:20.849375 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.sales_by_category
[0m12:11:20.851378 [info ] [Thread-1 (]: 20 of 49 START sql view model default.sales_by_category ........................ [RUN]
[0m12:11:20.853377 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.payment_distribution, now model.dbt_databricks_cicd.sales_by_category)
[0m12:11:20.854392 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=model.dbt_databricks_cicd.sales_by_category, idle-time=0.009682893753051758s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.payment_distribution
[0m12:11:20.855417 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.sales_by_category
[0m12:11:20.863413 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.sales_by_category"
[0m12:11:20.865378 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.sales_by_category
[0m12:11:20.872416 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:11:20.876376 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`sales_by_category`
[0m12:11:20.878416 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.sales_by_category"
[0m12:11:20.880400 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.sales_by_category"
[0m12:11:20.881383 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.sales_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.sales_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`sales_by_category`
  
  as (
    SELECT
  Category,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_revenue
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY total_revenue DESC
  )

[0m12:11:21.582119 [debug] [Thread-1 (]: SQL status: OK in 0.700 seconds
[0m12:11:21.584120 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9a84-18c1-9423-991f32a83f90) - Closing
[0m12:11:21.585119 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:11:21.588120 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48d0787c-4ef3-4c17-8933-9030159e66d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000223A964B810>]}
[0m12:11:21.590123 [info ] [Thread-1 (]: 20 of 49 OK created sql view model default.sales_by_category ................... [[32mOK[0m in 0.73s]
[0m12:11:21.592220 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.sales_by_category
[0m12:11:21.593249 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_5_products
[0m12:11:21.595208 [info ] [Thread-1 (]: 21 of 49 START sql view model default.top_5_products ........................... [RUN]
[0m12:11:21.597249 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.sales_by_category, now model.dbt_databricks_cicd.top_5_products)
[0m12:11:21.598208 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=model.dbt_databricks_cicd.top_5_products, idle-time=0.011088371276855469s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.sales_by_category
[0m12:11:21.599250 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_5_products
[0m12:11:21.606255 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_5_products"
[0m12:11:21.609210 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_5_products
[0m12:11:21.614248 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:11:21.616257 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`top_5_products`
[0m12:11:21.618248 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_5_products"
[0m12:11:21.620208 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.top_5_products"
[0m12:11:21.621208 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_5_products: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.top_5_products"} */

  
  
  
  create or replace view `workspace`.`default`.`top_5_products`
  
  as (
    WITH base AS (
    SELECT
        product_id,
        ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_sales
    FROM `workspace`.`default`.`stg_ecommerce`
    GROUP BY product_id
)

SELECT
    product_id,
    total_sales
FROM base
ORDER BY total_sales DESC
LIMIT 5
  )

[0m12:11:22.281117 [debug] [Thread-1 (]: SQL status: OK in 0.660 seconds
[0m12:11:22.283121 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9af4-1cef-b97b-2049b7b457be) - Closing
[0m12:11:22.285121 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:11:22.287120 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48d0787c-4ef3-4c17-8933-9030159e66d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000223A96E9110>]}
[0m12:11:22.289121 [info ] [Thread-1 (]: 21 of 49 OK created sql view model default.top_5_products ...................... [[32mOK[0m in 0.69s]
[0m12:11:22.291123 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_5_products
[0m12:11:22.292124 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_customers
[0m12:11:22.294122 [info ] [Thread-1 (]: 22 of 49 START sql view model default.top_customers ............................ [RUN]
[0m12:11:22.295121 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_5_products, now model.dbt_databricks_cicd.top_customers)
[0m12:11:22.297119 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=model.dbt_databricks_cicd.top_customers, idle-time=0.008999824523925781s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.top_5_products
[0m12:11:22.298119 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_customers
[0m12:11:22.304119 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_customers"
[0m12:11:22.306129 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_customers
[0m12:11:22.312120 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:11:22.314123 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`top_customers`
[0m12:11:22.316123 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_customers"
[0m12:11:22.318124 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.top_customers"
[0m12:11:22.319124 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_customers: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.top_customers"} */

  
  
  
  create or replace view `workspace`.`default`.`top_customers`
  
  as (
    SELECT
  User_ID,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_spent
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY User_ID
ORDER BY total_spent DESC
LIMIT 10
  )

[0m12:11:23.000395 [debug] [Thread-1 (]: SQL status: OK in 0.680 seconds
[0m12:11:23.002397 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9b5f-178c-a4e5-6175e76321ca) - Closing
[0m12:11:23.004397 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:11:23.006398 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48d0787c-4ef3-4c17-8933-9030159e66d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000223A9273450>]}
[0m12:11:23.007395 [info ] [Thread-1 (]: 22 of 49 OK created sql view model default.top_customers ....................... [[32mOK[0m in 0.71s]
[0m12:11:23.009402 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_customers
[0m12:11:23.011400 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6
[0m12:11:23.012402 [info ] [Thread-1 (]: 23 of 49 START test dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0  [RUN]
[0m12:11:23.014933 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_customers, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6)
[0m12:11:23.015932 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6, idle-time=0.009534120559692383s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.top_customers
[0m12:11:23.016932 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6
[0m12:11:23.032938 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"
[0m12:11:23.035932 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6
[0m12:11:23.042970 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"
[0m12:11:23.044938 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"
[0m12:11:23.045938 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_discount_by_category`

where not(avg_discount_percent avg_discount_percent >= 0)


  
  
      
    ) dbt_internal_test
[0m12:11:23.491554 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_discount_by_category`

where not(avg_discount_percent avg_discount_percent >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 52)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_discount_by_category`

where not(avg_discount_percent avg_discount_percent >= 0)
----------------------------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 52)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_discount_by_category`

where not(avg_discount_percent avg_discount_percent >= 0)
----------------------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 52)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_discount_by_category`

where not(avg_discount_percent avg_discount_percent >= 0)
----------------------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778e-9bce-1611-baec-4d1b9af2f4b3
[0m12:11:23.697671 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 52)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`avg_discount_by_category`
  
  where not(avg_discount_percent avg_discount_percent >= 0)
  ----------------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5b124626a971bfcac535904f1039d3eb.sql
[0m12:11:23.699672 [error] [Thread-1 (]: 23 of 49 ERROR dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0  [[31mERROR[0m in 0.68s]
[0m12:11:23.702712 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6
[0m12:11:23.703675 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m12:11:23.704671 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 52)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`avg_discount_by_category`
  
  where not(avg_discount_percent avg_discount_percent >= 0)
  ----------------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5b124626a971bfcac535904f1039d3eb.sql.
[0m12:11:23.706673 [info ] [Thread-1 (]: 24 of 49 START test not_null_avg_discount_by_category_Category ................. [RUN]
[0m12:11:23.708676 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b)
[0m12:11:23.709713 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, idle-time=0.011043548583984375s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6
[0m12:11:23.710711 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m12:11:23.723671 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m12:11:23.725671 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m12:11:23.731669 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m12:11:23.733678 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m12:11:23.735679 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_discount_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m12:11:24.406068 [debug] [Thread-1 (]: SQL status: OK in 0.670 seconds
[0m12:11:24.410105 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9c36-1f25-a6f1-d356d7fc4f57) - Closing
[0m12:11:24.412107 [info ] [Thread-1 (]: 24 of 49 PASS not_null_avg_discount_by_category_Category ....................... [[32mPASS[0m in 0.70s]
[0m12:11:24.414074 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m12:11:24.415074 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m12:11:24.416074 [info ] [Thread-1 (]: 25 of 49 START test not_null_avg_discount_by_category_avg_discount_percent ..... [RUN]
[0m12:11:24.418068 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101)
[0m12:11:24.419069 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, idle-time=0.007962226867675781s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m12:11:24.421068 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m12:11:24.429071 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m12:11:24.431068 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m12:11:24.437066 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m12:11:24.440068 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m12:11:24.441075 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_discount_percent
from `workspace`.`default`.`avg_discount_by_category`
where avg_discount_percent is null



  
  
      
    ) dbt_internal_test
[0m12:11:25.108605 [debug] [Thread-1 (]: SQL status: OK in 0.670 seconds
[0m12:11:25.112604 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9ca3-1579-a7a0-7c546c229568) - Closing
[0m12:11:25.114608 [info ] [Thread-1 (]: 25 of 49 PASS not_null_avg_discount_by_category_avg_discount_percent ........... [[32mPASS[0m in 0.70s]
[0m12:11:25.116704 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m12:11:25.117750 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301
[0m12:11:25.119745 [info ] [Thread-1 (]: 26 of 49 START test dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0  [RUN]
[0m12:11:25.121705 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301)
[0m12:11:25.122702 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301, idle-time=0.008093833923339844s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m12:11:25.123703 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301
[0m12:11:25.133702 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"
[0m12:11:25.136705 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301
[0m12:11:25.142705 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"
[0m12:11:25.145712 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"
[0m12:11:25.146712 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_ticket_by_category`

where not(avg_ticket avg_ticket >= 0)


  
  
      
    ) dbt_internal_test
[0m12:11:25.526552 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_ticket_by_category`

where not(avg_ticket avg_ticket >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 32)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_ticket_by_category`

where not(avg_ticket avg_ticket >= 0)
--------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 32)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_ticket_by_category`

where not(avg_ticket avg_ticket >= 0)
--------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 32)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_ticket_by_category`

where not(avg_ticket avg_ticket >= 0)
--------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778e-9d0f-158b-a377-47a10d89e101
[0m12:11:25.533553 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 32)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`avg_ticket_by_category`
  
  where not(avg_ticket avg_ticket >= 0)
  --------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5328046ff58f0d97fcb998395932ee40.sql
[0m12:11:25.535553 [error] [Thread-1 (]: 26 of 49 ERROR dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0  [[31mERROR[0m in 0.41s]
[0m12:11:25.537596 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301
[0m12:11:25.539556 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m12:11:25.540554 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 32)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`avg_ticket_by_category`
  
  where not(avg_ticket avg_ticket >= 0)
  --------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5328046ff58f0d97fcb998395932ee40.sql.
[0m12:11:25.541678 [info ] [Thread-1 (]: 27 of 49 START test not_null_avg_ticket_by_category_Category ................... [RUN]
[0m12:11:25.543573 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f)
[0m12:11:25.545589 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, idle-time=0.010036468505859375s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301
[0m12:11:25.546589 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m12:11:25.555628 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m12:11:25.557631 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m12:11:25.566629 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m12:11:25.568588 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m12:11:25.570594 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_ticket_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m12:11:26.312744 [debug] [Thread-1 (]: SQL status: OK in 0.740 seconds
[0m12:11:26.316744 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9d4f-1118-94a0-6fdbeb2d82be) - Closing
[0m12:11:26.318746 [info ] [Thread-1 (]: 27 of 49 PASS not_null_avg_ticket_by_category_Category ......................... [[32mPASS[0m in 0.78s]
[0m12:11:26.320747 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m12:11:26.322751 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m12:11:26.323750 [info ] [Thread-1 (]: 28 of 49 START test not_null_avg_ticket_by_category_avg_ticket ................. [RUN]
[0m12:11:26.324744 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41)
[0m12:11:26.326746 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, idle-time=0.007000446319580078s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m12:11:26.327744 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m12:11:26.340787 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m12:11:26.342751 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m12:11:26.348781 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m12:11:26.350785 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m12:11:26.352748 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_ticket
from `workspace`.`default`.`avg_ticket_by_category`
where avg_ticket is null



  
  
      
    ) dbt_internal_test
[0m12:11:27.027070 [debug] [Thread-1 (]: SQL status: OK in 0.670 seconds
[0m12:11:27.031076 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9dc7-16e9-9e33-92b20a1f84fa) - Closing
[0m12:11:27.033073 [info ] [Thread-1 (]: 28 of 49 PASS not_null_avg_ticket_by_category_avg_ticket ....................... [[32mPASS[0m in 0.71s]
[0m12:11:27.035480 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m12:11:27.037479 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14
[0m12:11:27.038519 [info ] [Thread-1 (]: 29 of 49 START test dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0  [RUN]
[0m12:11:27.040266 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14)
[0m12:11:27.041264 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14, idle-time=0.00819087028503418s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m12:11:27.042266 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14
[0m12:11:27.052270 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"
[0m12:11:27.054269 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14
[0m12:11:27.061268 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"
[0m12:11:27.063263 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"
[0m12:11:27.064270 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`monthly_revenue`

where not(monthly_revenue monthly_revenue >= 0)


  
  
      
    ) dbt_internal_test
[0m12:11:27.432976 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`monthly_revenue`

where not(monthly_revenue monthly_revenue >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 42)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`monthly_revenue`

where not(monthly_revenue monthly_revenue >= 0)
------------------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 42)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`monthly_revenue`

where not(monthly_revenue monthly_revenue >= 0)
------------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 42)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`monthly_revenue`

where not(monthly_revenue monthly_revenue >= 0)
------------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778e-9e33-1c54-9910-6e13e48b547b
[0m12:11:27.439974 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 42)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`monthly_revenue`
  
  where not(monthly_revenue monthly_revenue >= 0)
  ------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_m_f3c6f8ea5d3985ba2e05e7b0666775b9.sql
[0m12:11:27.441982 [error] [Thread-1 (]: 29 of 49 ERROR dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0  [[31mERROR[0m in 0.40s]
[0m12:11:27.443640 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14
[0m12:11:27.444678 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m12:11:27.446643 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 42)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`monthly_revenue`
  
  where not(monthly_revenue monthly_revenue >= 0)
  ------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_m_f3c6f8ea5d3985ba2e05e7b0666775b9.sql.
[0m12:11:27.447208 [info ] [Thread-1 (]: 30 of 49 START test not_null_monthly_revenue_month ............................. [RUN]
[0m12:11:27.449223 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14, now test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b)
[0m12:11:27.451223 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, idle-time=0.009248733520507812s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14
[0m12:11:27.452226 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m12:11:27.461261 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m12:11:27.463229 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m12:11:27.470228 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m12:11:27.472229 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m12:11:27.474229 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select month
from `workspace`.`default`.`monthly_revenue`
where month is null



  
  
      
    ) dbt_internal_test
[0m12:11:28.308691 [debug] [Thread-1 (]: SQL status: OK in 0.830 seconds
[0m12:11:28.311698 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9e72-1734-a0b6-80861f4f7d20) - Closing
[0m12:11:28.313692 [info ] [Thread-1 (]: 30 of 49 PASS not_null_monthly_revenue_month ................................... [[32mPASS[0m in 0.86s]
[0m12:11:28.316049 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m12:11:28.318047 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m12:11:28.319046 [info ] [Thread-1 (]: 31 of 49 START test not_null_monthly_revenue_monthly_revenue ................... [RUN]
[0m12:11:28.320898 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, now test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b)
[0m12:11:28.321899 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, idle-time=0.008206605911254883s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m12:11:28.322896 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m12:11:28.331896 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m12:11:28.333898 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m12:11:28.343896 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m12:11:28.345892 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m12:11:28.346909 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select monthly_revenue
from `workspace`.`default`.`monthly_revenue`
where monthly_revenue is null



  
  
      
    ) dbt_internal_test
[0m12:11:29.173357 [debug] [Thread-1 (]: SQL status: OK in 0.830 seconds
[0m12:11:29.177359 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9ef7-12ee-9fe3-ca991399776e) - Closing
[0m12:11:29.179364 [info ] [Thread-1 (]: 31 of 49 PASS not_null_monthly_revenue_monthly_revenue ......................... [[32mPASS[0m in 0.86s]
[0m12:11:29.181362 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m12:11:29.182318 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147
[0m12:11:29.184361 [info ] [Thread-1 (]: 32 of 49 START test dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0  [RUN]
[0m12:11:29.185359 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147)
[0m12:11:29.187361 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147, idle-time=0.008040666580200195s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m12:11:29.188321 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147
[0m12:11:29.197359 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"
[0m12:11:29.199369 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147
[0m12:11:29.207359 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"
[0m12:11:29.209366 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"
[0m12:11:29.210362 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_transactions total_transactions > 0)


  
  
      
    ) dbt_internal_test
[0m12:11:29.579141 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_transactions total_transactions > 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 48)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_transactions total_transactions > 0)
------------------------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 48)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_transactions total_transactions > 0)
------------------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 48)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_transactions total_transactions > 0)
------------------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778e-9f7b-1bfe-b662-1da7120b58d2
[0m12:11:29.588137 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 48)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`payment_distribution`
  
  where not(total_transactions total_transactions > 0)
  ------------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_fc379226623eb21c1aee5952042cbcd4.sql
[0m12:11:29.590139 [error] [Thread-1 (]: 32 of 49 ERROR dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0  [[31mERROR[0m in 0.40s]
[0m12:11:29.593139 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147
[0m12:11:29.594140 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97
[0m12:11:29.596140 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 48)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`payment_distribution`
  
  where not(total_transactions total_transactions > 0)
  ------------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_fc379226623eb21c1aee5952042cbcd4.sql.
[0m12:11:29.597137 [info ] [Thread-1 (]: 33 of 49 START test dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0  [RUN]
[0m12:11:29.599137 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97)
[0m12:11:29.601179 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97, idle-time=0.011043071746826172s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147
[0m12:11:29.602166 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97
[0m12:11:29.612179 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"
[0m12:11:29.614181 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97
[0m12:11:29.621141 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"
[0m12:11:29.623145 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"
[0m12:11:29.624144 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_value total_value >= 0)


  
  
      
    ) dbt_internal_test
[0m12:11:29.890273 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_value total_value >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_value total_value >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_value total_value >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_value total_value >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778e-9fba-1275-b413-efe1e70ae0ce
[0m12:11:29.897272 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`payment_distribution`
  
  where not(total_value total_value >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_5ed37f769e6a283e088dfae7f31ac751.sql
[0m12:11:29.898273 [error] [Thread-1 (]: 33 of 49 ERROR dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0  [[31mERROR[0m in 0.30s]
[0m12:11:29.901280 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97
[0m12:11:29.902277 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m12:11:29.903279 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`payment_distribution`
  
  where not(total_value total_value >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_5ed37f769e6a283e088dfae7f31ac751.sql.
[0m12:11:29.904272 [info ] [Thread-1 (]: 34 of 49 START test not_null_payment_distribution_Payment_Method ............... [RUN]
[0m12:11:29.906273 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97, now test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae)
[0m12:11:29.907275 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, idle-time=0.009002447128295898s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97
[0m12:11:29.909274 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m12:11:29.917274 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m12:11:29.919273 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m12:11:29.926310 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m12:11:29.928275 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m12:11:29.929318 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`payment_distribution`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m12:11:30.779930 [debug] [Thread-1 (]: SQL status: OK in 0.850 seconds
[0m12:11:30.782969 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-9fe8-1fb4-86dd-f5b1acb45929) - Closing
[0m12:11:30.784970 [info ] [Thread-1 (]: 34 of 49 PASS not_null_payment_distribution_Payment_Method ..................... [[32mPASS[0m in 0.88s]
[0m12:11:30.786937 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m12:11:30.788936 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m12:11:30.789935 [info ] [Thread-1 (]: 35 of 49 START test not_null_payment_distribution_total_transactions ........... [RUN]
[0m12:11:30.791761 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, now test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8)
[0m12:11:30.792759 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, idle-time=0.007789134979248047s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m12:11:30.793760 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m12:11:30.802759 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m12:11:30.804760 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m12:11:30.813798 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m12:11:30.816765 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m12:11:30.818763 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_transactions
from `workspace`.`default`.`payment_distribution`
where total_transactions is null



  
  
      
    ) dbt_internal_test
[0m12:11:31.549798 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m12:11:31.553805 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-a070-145f-830b-f83fc8604c89) - Closing
[0m12:11:31.555806 [info ] [Thread-1 (]: 35 of 49 PASS not_null_payment_distribution_total_transactions ................. [[32mPASS[0m in 0.76s]
[0m12:11:31.557275 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m12:11:31.559277 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m12:11:31.560277 [info ] [Thread-1 (]: 36 of 49 START test not_null_payment_distribution_total_value .................. [RUN]
[0m12:11:31.562451 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, now test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03)
[0m12:11:31.563453 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, idle-time=0.00864863395690918s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m12:11:31.565451 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m12:11:31.572448 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m12:11:31.575449 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m12:11:31.583485 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m12:11:31.585488 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m12:11:31.586455 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_value
from `workspace`.`default`.`payment_distribution`
where total_value is null



  
  
      
    ) dbt_internal_test
[0m12:11:32.291604 [debug] [Thread-1 (]: SQL status: OK in 0.700 seconds
[0m12:11:32.295605 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-a0e6-13ad-9fe4-df69a7e9cc51) - Closing
[0m12:11:32.297608 [info ] [Thread-1 (]: 36 of 49 PASS not_null_payment_distribution_total_value ........................ [[32mPASS[0m in 0.74s]
[0m12:11:32.299615 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m12:11:32.300653 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7
[0m12:11:32.302652 [info ] [Thread-1 (]: 37 of 49 START test dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0  [RUN]
[0m12:11:32.303657 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7)
[0m12:11:32.304660 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7, idle-time=0.0070514678955078125s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m12:11:32.306654 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7
[0m12:11:32.316653 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"
[0m12:11:32.318657 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7
[0m12:11:32.324652 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"
[0m12:11:32.326660 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"
[0m12:11:32.327657 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_orders total_orders > 0)


  
  
      
    ) dbt_internal_test
[0m12:11:32.688911 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_orders total_orders > 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_orders total_orders > 0)
------------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_orders total_orders > 0)
------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_orders total_orders > 0)
------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778e-a156-1750-9b5b-19a743683f32
[0m12:11:32.696914 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`sales_by_category`
  
  where not(total_orders total_orders > 0)
  ------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_89c32efc0957beac212198ac47c17269.sql
[0m12:11:32.698915 [error] [Thread-1 (]: 37 of 49 ERROR dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0  [[31mERROR[0m in 0.39s]
[0m12:11:32.700418 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7
[0m12:11:32.701459 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd
[0m12:11:32.702457 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`sales_by_category`
  
  where not(total_orders total_orders > 0)
  ------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_89c32efc0957beac212198ac47c17269.sql.
[0m12:11:32.704418 [info ] [Thread-1 (]: 38 of 49 START test dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0  [RUN]
[0m12:11:32.706456 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd)
[0m12:11:32.707464 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd, idle-time=0.009552240371704102s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7
[0m12:11:32.708458 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd
[0m12:11:32.718455 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"
[0m12:11:32.721417 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd
[0m12:11:32.729414 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"
[0m12:11:32.732469 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"
[0m12:11:32.733459 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_revenue total_revenue >= 0)


  
  
      
    ) dbt_internal_test
[0m12:11:32.952287 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_revenue total_revenue >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 38)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_revenue total_revenue >= 0)
--------------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 38)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_revenue total_revenue >= 0)
--------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 38)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_revenue total_revenue >= 0)
--------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778e-a194-1eaa-b5d9-a655af26f2ce
[0m12:11:32.959326 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 38)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`sales_by_category`
  
  where not(total_revenue total_revenue >= 0)
  --------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_a42e1924275d2ea59b3d9b718bc54aee.sql
[0m12:11:32.960293 [error] [Thread-1 (]: 38 of 49 ERROR dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0  [[31mERROR[0m in 0.25s]
[0m12:11:32.963294 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd
[0m12:11:32.964296 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m12:11:32.965296 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 38)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`sales_by_category`
  
  where not(total_revenue total_revenue >= 0)
  --------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_a42e1924275d2ea59b3d9b718bc54aee.sql.
[0m12:11:32.966330 [info ] [Thread-1 (]: 39 of 49 START test not_null_sales_by_category_Category ........................ [RUN]
[0m12:11:32.968290 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd, now test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507)
[0m12:11:32.970291 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, idle-time=0.008997917175292969s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd
[0m12:11:32.971291 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m12:11:32.979290 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m12:11:32.982291 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m12:11:32.990292 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m12:11:32.992294 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m12:11:32.994290 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`sales_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m12:11:33.819789 [debug] [Thread-1 (]: SQL status: OK in 0.820 seconds
[0m12:11:33.823789 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-a1bf-1393-a437-83c45f89db4f) - Closing
[0m12:11:33.825788 [info ] [Thread-1 (]: 39 of 49 PASS not_null_sales_by_category_Category .............................. [[32mPASS[0m in 0.86s]
[0m12:11:33.827790 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m12:11:33.829750 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m12:11:33.830749 [info ] [Thread-1 (]: 40 of 49 START test not_null_sales_by_category_total_orders .................... [RUN]
[0m12:11:33.831789 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, now test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e)
[0m12:11:33.833790 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, idle-time=0.007006168365478516s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m12:11:33.834748 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m12:11:33.843751 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m12:11:33.845748 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m12:11:33.852745 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m12:11:33.854749 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m12:11:33.856749 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`sales_by_category`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m12:11:34.580507 [debug] [Thread-1 (]: SQL status: OK in 0.720 seconds
[0m12:11:34.584507 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-a23f-1936-8869-a7c116741b03) - Closing
[0m12:11:34.586512 [info ] [Thread-1 (]: 40 of 49 PASS not_null_sales_by_category_total_orders .......................... [[32mPASS[0m in 0.75s]
[0m12:11:34.588516 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m12:11:34.590515 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m12:11:34.591514 [info ] [Thread-1 (]: 41 of 49 START test not_null_sales_by_category_total_revenue ................... [RUN]
[0m12:11:34.592509 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, now test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd)
[0m12:11:34.594512 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, idle-time=0.00800013542175293s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m12:11:34.595509 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m12:11:34.606548 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m12:11:34.608550 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m12:11:34.615513 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m12:11:34.617516 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m12:11:34.619516 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_revenue
from `workspace`.`default`.`sales_by_category`
where total_revenue is null



  
  
      
    ) dbt_internal_test
[0m12:11:35.457426 [debug] [Thread-1 (]: SQL status: OK in 0.840 seconds
[0m12:11:35.461428 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-a2b4-19f3-bb39-1b5532d29db9) - Closing
[0m12:11:35.463428 [info ] [Thread-1 (]: 41 of 49 PASS not_null_sales_by_category_total_revenue ......................... [[32mPASS[0m in 0.87s]
[0m12:11:35.465867 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m12:11:35.466906 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57
[0m12:11:35.468907 [info ] [Thread-1 (]: 42 of 49 START test dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0  [RUN]
[0m12:11:35.469908 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57)
[0m12:11:35.470907 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57, idle-time=0.007479429244995117s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m12:11:35.472866 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57
[0m12:11:35.482864 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"
[0m12:11:35.484863 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57
[0m12:11:35.491867 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"
[0m12:11:35.495865 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"
[0m12:11:35.496864 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_5_products`

where not(total_sales total_sales >= 0)


  
  
      
    ) dbt_internal_test
[0m12:11:35.858666 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_5_products`

where not(total_sales total_sales >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_5_products`

where not(total_sales total_sales >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_5_products`

where not(total_sales total_sales >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_5_products`

where not(total_sales total_sales >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778e-a33a-17f4-9962-b5dba76458a6
[0m12:11:35.866668 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_5_products`
  
  where not(total_sales total_sales >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_53d9d0761651e2acd9611a042b182945.sql
[0m12:11:35.867666 [error] [Thread-1 (]: 42 of 49 ERROR dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0  [[31mERROR[0m in 0.40s]
[0m12:11:35.870106 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57
[0m12:11:35.871147 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m12:11:35.872148 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_5_products`
  
  where not(total_sales total_sales >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_53d9d0761651e2acd9611a042b182945.sql.
[0m12:11:35.873610 [info ] [Thread-1 (]: 43 of 49 START test not_null_top_5_products_product_id ......................... [RUN]
[0m12:11:35.875625 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57, now test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe)
[0m12:11:35.878629 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, idle-time=0.010001897811889648s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57
[0m12:11:35.879625 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m12:11:35.887625 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m12:11:35.889637 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m12:11:35.899625 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m12:11:35.901626 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m12:11:35.902627 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select product_id
from `workspace`.`default`.`top_5_products`
where product_id is null



  
  
      
    ) dbt_internal_test
[0m12:11:36.645244 [debug] [Thread-1 (]: SQL status: OK in 0.740 seconds
[0m12:11:36.649246 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-a378-177a-a6d3-616b027551d7) - Closing
[0m12:11:36.651248 [info ] [Thread-1 (]: 43 of 49 PASS not_null_top_5_products_product_id ............................... [[32mPASS[0m in 0.78s]
[0m12:11:36.653212 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m12:11:36.654212 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m12:11:36.655212 [info ] [Thread-1 (]: 44 of 49 START test not_null_top_5_products_total_sales ........................ [RUN]
[0m12:11:36.657206 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, now test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818)
[0m12:11:36.659212 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, idle-time=0.007964372634887695s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m12:11:36.660244 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m12:11:36.668251 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m12:11:36.670262 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m12:11:36.677207 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m12:11:36.679208 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m12:11:36.681207 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_sales
from `workspace`.`default`.`top_5_products`
where total_sales is null



  
  
      
    ) dbt_internal_test
[0m12:11:37.380996 [debug] [Thread-1 (]: SQL status: OK in 0.700 seconds
[0m12:11:37.384996 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-a3ee-1c1c-9fd7-ab006fcaf0c3) - Closing
[0m12:11:37.386997 [info ] [Thread-1 (]: 44 of 49 PASS not_null_top_5_products_total_sales .............................. [[32mPASS[0m in 0.73s]
[0m12:11:37.388518 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m12:11:37.389518 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4
[0m12:11:37.390518 [info ] [Thread-1 (]: 45 of 49 START test dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0  [RUN]
[0m12:11:37.393410 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4)
[0m12:11:37.394408 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4, idle-time=0.008412599563598633s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m12:11:37.395410 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4
[0m12:11:37.403409 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"
[0m12:11:37.405410 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4
[0m12:11:37.413446 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"
[0m12:11:37.415414 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"
[0m12:11:37.416409 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_orders total_orders > 0)


  
  
      
    ) dbt_internal_test
[0m12:11:37.780752 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_orders total_orders > 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_orders total_orders > 0)
------------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_orders total_orders > 0)
------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_orders total_orders > 0)
------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778e-a45f-19a3-a13f-47d015e1f07c
[0m12:11:37.786754 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_customers`
  
  where not(total_orders total_orders > 0)
  ------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_837145e0920d813dbd0319ae1c97969b.sql
[0m12:11:37.788754 [error] [Thread-1 (]: 45 of 49 ERROR dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0  [[31mERROR[0m in 0.40s]
[0m12:11:37.790763 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4
[0m12:11:37.792762 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343
[0m12:11:37.793762 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_customers`
  
  where not(total_orders total_orders > 0)
  ------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_837145e0920d813dbd0319ae1c97969b.sql.
[0m12:11:37.794799 [info ] [Thread-1 (]: 46 of 49 START test dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0  [RUN]
[0m12:11:37.796755 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343)
[0m12:11:37.798795 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343, idle-time=0.009042024612426758s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4
[0m12:11:37.799755 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343
[0m12:11:37.809793 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"
[0m12:11:37.811794 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343
[0m12:11:37.818758 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"
[0m12:11:37.820760 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"
[0m12:11:37.822761 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_spent total_spent >= 0)


  
  
      
    ) dbt_internal_test
[0m12:11:38.046443 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_spent total_spent >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_spent total_spent >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_spent total_spent >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_spent total_spent >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778e-a49d-1b10-8cb5-40c298b6fda4
[0m12:11:38.053443 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_customers`
  
  where not(total_spent total_spent >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_2a6b4bf5f333b9ab281e1669bb988c44.sql
[0m12:11:38.054443 [error] [Thread-1 (]: 46 of 49 ERROR dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0  [[31mERROR[0m in 0.26s]
[0m12:11:38.056783 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343
[0m12:11:38.058788 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m12:11:38.059785 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_customers`
  
  where not(total_spent total_spent >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_2a6b4bf5f333b9ab281e1669bb988c44.sql.
[0m12:11:38.060823 [info ] [Thread-1 (]: 47 of 49 START test not_null_top_customers_User_ID ............................. [RUN]
[0m12:11:38.062783 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343, now test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0)
[0m12:11:38.063825 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, idle-time=0.009381294250488281s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343
[0m12:11:38.064823 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m12:11:38.072822 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m12:11:38.075824 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m12:11:38.083821 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m12:11:38.085827 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m12:11:38.086785 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`top_customers`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m12:11:38.865865 [debug] [Thread-1 (]: SQL status: OK in 0.780 seconds
[0m12:11:38.869866 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-a4c6-14e6-aa90-2be75d19da25) - Closing
[0m12:11:38.870866 [info ] [Thread-1 (]: 47 of 49 PASS not_null_top_customers_User_ID ................................... [[32mPASS[0m in 0.81s]
[0m12:11:38.873505 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m12:11:38.875503 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m12:11:38.876502 [info ] [Thread-1 (]: 48 of 49 START test not_null_top_customers_total_orders ........................ [RUN]
[0m12:11:38.878376 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, now test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746)
[0m12:11:38.879376 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, idle-time=0.008509397506713867s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m12:11:38.880375 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m12:11:38.889375 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m12:11:38.891374 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m12:11:38.897373 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m12:11:38.899376 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m12:11:38.900378 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`top_customers`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m12:11:39.586200 [debug] [Thread-1 (]: SQL status: OK in 0.680 seconds
[0m12:11:39.590205 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-a541-18fc-8337-07f010bf2fa9) - Closing
[0m12:11:39.593202 [info ] [Thread-1 (]: 48 of 49 PASS not_null_top_customers_total_orders .............................. [[32mPASS[0m in 0.71s]
[0m12:11:39.594704 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m12:11:39.595746 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m12:11:39.597744 [info ] [Thread-1 (]: 49 of 49 START test not_null_top_customers_total_spent ......................... [RUN]
[0m12:11:39.598746 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, now test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73)
[0m12:11:39.599744 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, name=test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73, idle-time=0.007543087005615234s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m12:11:39.601741 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m12:11:39.609702 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m12:11:39.612703 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m12:11:39.617700 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m12:11:39.619703 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m12:11:39.621703 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_spent
from `workspace`.`default`.`top_customers`
where total_spent is null



  
  
      
    ) dbt_internal_test
[0m12:11:40.392625 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m12:11:40.395624 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778e-8d7a-1f29-ac23-d851685af410, command-id=01f0778e-a5af-162d-8324-62e5ae0f381b) - Closing
[0m12:11:40.397627 [info ] [Thread-1 (]: 49 of 49 PASS not_null_top_customers_total_spent ............................... [[32mPASS[0m in 0.80s]
[0m12:11:40.400595 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m12:11:40.404634 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=42.02104640007019s, language=None, compute-name=) - Reusing connection previously named master
[0m12:11:40.407587 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:11:40.408586 [debug] [MainThread]: Connection 'list_workspace' was properly closed.
[0m12:11:40.410586 [debug] [MainThread]: On list_workspace: Close
[0m12:11:40.411587 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0778e-8879-1cd2-90b6-6e8fb4bb2bae) - Closing
[0m12:11:40.620818 [debug] [MainThread]: Connection 'list_workspace_default' was properly closed.
[0m12:11:40.621832 [debug] [MainThread]: On list_workspace_default: Close
[0m12:11:40.622872 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0778e-8a60-13d5-b1b2-e533c28e9831) - Closing
[0m12:11:40.833837 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73' was properly closed.
[0m12:11:40.835852 [debug] [MainThread]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: Close
[0m12:11:40.836851 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0778e-8d7a-1f29-ac23-d851685af410) - Closing
[0m12:11:41.045911 [info ] [MainThread]: 
[0m12:11:41.047490 [info ] [MainThread]: Finished running 40 data tests, 9 view models in 0 hours 0 minutes and 51.20 seconds (51.20s).
[0m12:11:41.063195 [debug] [MainThread]: Command end result
[0m12:11:41.304199 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m12:11:41.309199 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m12:11:41.324197 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m12:11:41.325200 [info ] [MainThread]: 
[0m12:11:41.327200 [info ] [MainThread]: [31mCompleted with 10 errors, 0 partial successes, and 0 warnings:[0m
[0m12:11:41.328195 [info ] [MainThread]: 
[0m12:11:41.330198 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:11:41.331197 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 52)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`avg_discount_by_category`
  
  where not(avg_discount_percent avg_discount_percent >= 0)
  ----------------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5b124626a971bfcac535904f1039d3eb.sql
[0m12:11:41.334198 [info ] [MainThread]: 
[0m12:11:41.335201 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5b124626a971bfcac535904f1039d3eb.sql
[0m12:11:41.337211 [info ] [MainThread]: 
[0m12:11:41.339200 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:11:41.347208 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 32)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`avg_ticket_by_category`
  
  where not(avg_ticket avg_ticket >= 0)
  --------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5328046ff58f0d97fcb998395932ee40.sql
[0m12:11:41.349199 [info ] [MainThread]: 
[0m12:11:41.351199 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5328046ff58f0d97fcb998395932ee40.sql
[0m12:11:41.353198 [info ] [MainThread]: 
[0m12:11:41.356220 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:11:41.362196 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 42)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`monthly_revenue`
  
  where not(monthly_revenue monthly_revenue >= 0)
  ------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_m_f3c6f8ea5d3985ba2e05e7b0666775b9.sql
[0m12:11:41.364199 [info ] [MainThread]: 
[0m12:11:41.367207 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_m_f3c6f8ea5d3985ba2e05e7b0666775b9.sql
[0m12:11:41.369205 [info ] [MainThread]: 
[0m12:11:41.371200 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:11:41.379234 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 48)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`payment_distribution`
  
  where not(total_transactions total_transactions > 0)
  ------------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_fc379226623eb21c1aee5952042cbcd4.sql
[0m12:11:41.381199 [info ] [MainThread]: 
[0m12:11:41.383198 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_fc379226623eb21c1aee5952042cbcd4.sql
[0m12:11:41.385207 [info ] [MainThread]: 
[0m12:11:41.387205 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:11:41.396241 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`payment_distribution`
  
  where not(total_value total_value >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_5ed37f769e6a283e088dfae7f31ac751.sql
[0m12:11:41.399205 [info ] [MainThread]: 
[0m12:11:41.401205 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_5ed37f769e6a283e088dfae7f31ac751.sql
[0m12:11:41.402197 [info ] [MainThread]: 
[0m12:11:41.406255 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:11:41.412233 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`sales_by_category`
  
  where not(total_orders total_orders > 0)
  ------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_89c32efc0957beac212198ac47c17269.sql
[0m12:11:41.415199 [info ] [MainThread]: 
[0m12:11:41.417202 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_89c32efc0957beac212198ac47c17269.sql
[0m12:11:41.419201 [info ] [MainThread]: 
[0m12:11:41.421209 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:11:41.428212 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 38)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`sales_by_category`
  
  where not(total_revenue total_revenue >= 0)
  --------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_a42e1924275d2ea59b3d9b718bc54aee.sql
[0m12:11:41.430196 [info ] [MainThread]: 
[0m12:11:41.432198 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_a42e1924275d2ea59b3d9b718bc54aee.sql
[0m12:11:41.434201 [info ] [MainThread]: 
[0m12:11:41.436199 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:11:41.443204 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_5_products`
  
  where not(total_sales total_sales >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_53d9d0761651e2acd9611a042b182945.sql
[0m12:11:41.446201 [info ] [MainThread]: 
[0m12:11:41.448200 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_53d9d0761651e2acd9611a042b182945.sql
[0m12:11:41.449199 [info ] [MainThread]: 
[0m12:11:41.451197 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:11:41.453199 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_customers`
  
  where not(total_orders total_orders > 0)
  ------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_837145e0920d813dbd0319ae1c97969b.sql
[0m12:11:41.459198 [info ] [MainThread]: 
[0m12:11:41.462200 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_837145e0920d813dbd0319ae1c97969b.sql
[0m12:11:41.463208 [info ] [MainThread]: 
[0m12:11:41.465198 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:11:41.467202 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_customers`
  
  where not(total_spent total_spent >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_2a6b4bf5f333b9ab281e1669bb988c44.sql
[0m12:11:41.475200 [info ] [MainThread]: 
[0m12:11:41.478201 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_2a6b4bf5f333b9ab281e1669bb988c44.sql
[0m12:11:41.480201 [info ] [MainThread]: 
[0m12:11:41.481198 [info ] [MainThread]: Done. PASS=39 WARN=0 ERROR=10 SKIP=0 NO-OP=0 TOTAL=49
[0m12:11:41.485203 [debug] [MainThread]: Command `dbt build` failed at 12:11:41.485203 after 66.94 seconds
[0m12:11:41.486203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022395BB3DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002239B738850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022395E10550>]}
[0m12:11:41.489203 [debug] [MainThread]: Flushing usage events
[0m12:11:42.644694 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:14:14.079944 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FFDDCBE50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FFDDCAC90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FFDDCBA50>]}


============================== 12:14:14.087943 | eb8d27f7-317c-4eef-8736-3e0a9f4df950 ==============================
[0m12:14:14.087943 [info ] [MainThread]: Running with dbt=1.10.3
[0m12:14:14.089946 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt build --target databricks', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:14:15.782922 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m12:14:15.783923 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m12:14:15.785924 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m12:14:17.575359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eb8d27f7-317c-4eef-8736-3e0a9f4df950', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F86CEE390>]}
[0m12:14:17.687360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eb8d27f7-317c-4eef-8736-3e0a9f4df950', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FFD4E9C10>]}
[0m12:14:17.688362 [info ] [MainThread]: Registered adapter: databricks=1.10.4
[0m12:14:18.772320 [debug] [MainThread]: checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, vars: {}, profile: , target: databricks, version: 1.10.3
[0m12:14:19.322318 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:14:19.323321 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://macros\tests\non_negative.sql
[0m12:14:19.327363 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two macros named "test_non_negative" in the project
  "dbt_databricks_cicd".
   To fix this error, rename or remove one of the following macros:
      - macros\tests\non_negative.sql
      - macros\tests\non_negative.sql
[0m12:14:19.331322 [debug] [MainThread]: Command `dbt build` failed at 12:14:19.331322 after 5.38 seconds
[0m12:14:19.333342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FFDD78C10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025F8A24AD10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000025FF7353DD0>]}
[0m12:14:19.335323 [debug] [MainThread]: Flushing usage events
[0m12:14:19.936066 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:14:52.242139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1C189FAD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1C18CBFD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1C1874410>]}


============================== 12:14:52.254141 | fdd125b1-ec46-476c-95e6-7cc36c15ad33 ==============================
[0m12:14:52.254141 [info ] [MainThread]: Running with dbt=1.10.3
[0m12:14:52.257139 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt build --target databricks', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:14:53.926642 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m12:14:53.928643 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m12:14:53.929642 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m12:14:55.704732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fdd125b1-ec46-476c-95e6-7cc36c15ad33', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1CCB20A50>]}
[0m12:14:55.813726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fdd125b1-ec46-476c-95e6-7cc36c15ad33', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1C0FE9C50>]}
[0m12:14:55.815728 [info ] [MainThread]: Registered adapter: databricks=1.10.4
[0m12:14:56.984729 [debug] [MainThread]: checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, vars: {}, profile: , target: databricks, version: 1.10.3
[0m12:14:57.544731 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:14:57.546734 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://macros\tests\non_negative.sql
[0m12:14:57.549734 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two macros named "test_non_negative" in the project
  "dbt_databricks_cicd".
   To fix this error, rename or remove one of the following macros:
      - macros\tests\non_negative.sql
      - macros\tests\non_negative.sql
[0m12:14:57.553733 [debug] [MainThread]: Command `dbt build` failed at 12:14:57.552737 after 5.44 seconds
[0m12:14:57.554727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1BAE33DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1C18CBFD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C1C18CB9D0>]}
[0m12:14:57.555737 [debug] [MainThread]: Flushing usage events
[0m12:14:58.123370 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:17:07.328343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E42FBC4310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E42F4E6650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E42EE39750>]}


============================== 12:17:07.336344 | c8b6c892-55e5-4180-b9ff-e34bf5893022 ==============================
[0m12:17:07.336344 [info ] [MainThread]: Running with dbt=1.10.3
[0m12:17:07.338353 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'debug': 'True', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --target databricks --debug', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:17:08.997028 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m12:17:08.999032 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m12:17:09.002030 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m12:17:10.864219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c8b6c892-55e5-4180-b9ff-e34bf5893022', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E4389EDD90>]}
[0m12:17:11.035221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c8b6c892-55e5-4180-b9ff-e34bf5893022', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E42F549D90>]}
[0m12:17:11.038224 [info ] [MainThread]: Registered adapter: databricks=1.10.4
[0m12:17:12.183226 [debug] [MainThread]: checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, vars: {}, profile: , target: databricks, version: 1.10.3
[0m12:17:12.783220 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:17:12.787223 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://macros\tests\non_negative.sql
[0m12:17:12.793221 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two macros named "test_non_negative" in the project
  "dbt_databricks_cicd".
   To fix this error, rename or remove one of the following macros:
      - macros\tests\non_negative.sql
      - macros\tests\non_negative.sql
[0m12:17:12.797223 [debug] [MainThread]: Command `dbt build` failed at 12:17:12.797223 after 5.62 seconds
[0m12:17:12.800242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E42FE2BBD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E429353DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E42FDFFFD0>]}
[0m12:17:12.803233 [debug] [MainThread]: Flushing usage events
[0m12:17:13.421457 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:17:29.235516 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F4886EBD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F48848550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F48848350>]}


============================== 12:17:29.246522 | 3d73ac85-915f-4e15-b8e8-7ea23253ec0e ==============================
[0m12:17:29.246522 [info ] [MainThread]: Running with dbt=1.10.3
[0m12:17:29.248521 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'debug': 'True', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt build --target databricks --debug', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:17:30.949494 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m12:17:30.951496 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m12:17:30.953510 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m12:17:32.727253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3d73ac85-915f-4e15-b8e8-7ea23253ec0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F48604490>]}
[0m12:17:32.842212 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3d73ac85-915f-4e15-b8e8-7ea23253ec0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F47F89C50>]}
[0m12:17:32.845215 [info ] [MainThread]: Registered adapter: databricks=1.10.4
[0m12:17:33.927251 [debug] [MainThread]: checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, vars: {}, profile: , target: databricks, version: 1.10.3
[0m12:17:34.474994 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:17:34.475965 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:17:34.492970 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m12:17:34.694994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3d73ac85-915f-4e15-b8e8-7ea23253ec0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F47312E90>]}
[0m12:17:34.885992 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m12:17:34.892955 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m12:17:34.989953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3d73ac85-915f-4e15-b8e8-7ea23253ec0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F45FC0D10>]}
[0m12:17:34.992957 [info ] [MainThread]: Found 9 models, 40 data tests, 1 source, 800 macros
[0m12:17:35.001950 [info ] [MainThread]: 
[0m12:17:35.003954 [info ] [MainThread]: Concurrency: 1 threads (target='databricks')
[0m12:17:35.006997 [info ] [MainThread]: 
[0m12:17:35.008953 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=0s, language=None, compute-name=) - Creating connection
[0m12:17:35.010954 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m12:17:35.026953 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace, idle-time=0s, language=None, compute-name=) - Creating connection
[0m12:17:35.028962 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace'
[0m12:17:35.031958 [debug] [ThreadPool]: Using databricks connection "list_workspace"
[0m12:17:35.035955 [debug] [ThreadPool]: On list_workspace: GetSchemas(database=workspace, schema=None)
[0m12:17:35.036953 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:17:35.971130 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0778f-79f4-1761-863c-95a978049724) - Created
[0m12:17:36.564618 [debug] [ThreadPool]: SQL status: OK in 1.530 seconds
[0m12:17:36.567624 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0778f-79f4-1761-863c-95a978049724, command-id=01f0778f-7a17-1107-8b85-61aeed2bfb7f) - Closing
[0m12:17:36.574619 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace_default, idle-time=0s, language=None, compute-name=) - Creating connection
[0m12:17:36.576621 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace_default'
[0m12:17:36.603619 [debug] [ThreadPool]: Using databricks connection "list_workspace_default"
[0m12:17:36.605624 [debug] [ThreadPool]: On list_workspace_default: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "connection_name": "list_workspace_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'workspace' 
  AND table_schema = 'default'

  
[0m12:17:36.611623 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:17:37.343104 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f0778f-7ac9-190d-95c6-c2546870ae6c) - Created
[0m12:17:37.906733 [debug] [ThreadPool]: SQL status: OK in 1.300 seconds
[0m12:17:37.920747 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f0778f-7ac9-190d-95c6-c2546870ae6c, command-id=01f0778f-7ae8-127d-ae12-9db2b20a9c28) - Closing
[0m12:17:37.926742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3d73ac85-915f-4e15-b8e8-7ea23253ec0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F5384B990>]}
[0m12:17:37.936663 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m12:17:37.940651 [info ] [Thread-1 (]: 1 of 49 START sql view model default.src_ecommerce ............................. [RUN]
[0m12:17:37.943653 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_cicd.src_ecommerce, idle-time=0s, language=None, compute-name=) - Creating connection
[0m12:17:37.945652 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m12:17:37.947697 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m12:17:37.964818 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m12:17:37.970801 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m12:17:37.997779 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:17:38.007781 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m12:17:38.009782 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '3d73ac85-915f-4e15-b8e8-7ea23253ec0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F5553C750>]}
[0m12:17:38.043777 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`src_ecommerce`
[0m12:17:38.066818 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m12:17:38.070803 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:17:38.072808 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`src_ecommerce`
  
  as (
    SELECT * FROM default.sales_ecommerce
  )

[0m12:17:38.074801 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:17:38.791333 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192) - Created
[0m12:17:39.534281 [debug] [Thread-1 (]: SQL status: OK in 1.460 seconds
[0m12:17:39.537107 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-7bce-1827-af7d-b727be534b22) - Closing
[0m12:17:39.559738 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:17:39.569164 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3d73ac85-915f-4e15-b8e8-7ea23253ec0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F54FFEF90>]}
[0m12:17:39.570967 [info ] [Thread-1 (]: 1 of 49 OK created sql view model default.src_ecommerce ........................ [[32mOK[0m in 1.62s]
[0m12:17:39.573591 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m12:17:39.577584 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m12:17:39.579592 [info ] [Thread-1 (]: 2 of 49 START sql view model default.stg_ecommerce ............................. [RUN]
[0m12:17:39.582592 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m12:17:39.585619 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=model.dbt_databricks_cicd.stg_ecommerce, idle-time=0.019429922103881836s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.src_ecommerce
[0m12:17:39.587585 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m12:17:39.597583 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:17:39.601593 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m12:17:39.610027 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:17:39.613033 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`stg_ecommerce`
[0m12:17:39.617027 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:17:39.619991 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:17:39.621989 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`stg_ecommerce`
  
  as (
    SELECT
  User_ID,
  Product_ID,
  Category,
  Price,
  Discount,
  Final_Price,
  Payment_Method,
  Purchase_Date
FROM `workspace`.`default`.`src_ecommerce`
  )

[0m12:17:40.248933 [debug] [Thread-1 (]: SQL status: OK in 0.620 seconds
[0m12:17:40.253940 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-7c44-13d9-b869-d0ca8746a208) - Closing
[0m12:17:40.256928 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:17:40.261931 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3d73ac85-915f-4e15-b8e8-7ea23253ec0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F5558B8D0>]}
[0m12:17:40.265931 [info ] [Thread-1 (]: 2 of 49 OK created sql view model default.stg_ecommerce ........................ [[32mOK[0m in 0.68s]
[0m12:17:40.271932 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m12:17:40.276928 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:17:40.279930 [info ] [Thread-1 (]: 3 of 49 START test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m12:17:40.283933 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6)
[0m12:17:40.288929 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, idle-time=0.027054548263549805s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.stg_ecommerce
[0m12:17:40.291931 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:17:40.354932 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m12:17:40.359934 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:17:40.409926 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m12:17:40.412934 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m12:17:40.415931 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from `workspace`.`default`.`stg_ecommerce`
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    'Credit Card','Net Banking','UPI','Debit Card','Cash on Delivery'
)



  
  
      
    ) dbt_internal_test
[0m12:17:40.871773 [debug] [Thread-1 (]: SQL status: OK in 0.450 seconds
[0m12:17:40.877781 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-7cbc-1f13-a943-54c76436caa4) - Closing
[0m12:17:40.883708 [info ] [Thread-1 (]: 3 of 49 PASS accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[32mPASS[0m in 0.60s]
[0m12:17:40.886715 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:17:40.888707 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m12:17:40.890714 [info ] [Thread-1 (]: 4 of 49 START test non_negative_stg_ecommerce_Discount ......................... [RUN]
[0m12:17:40.893717 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb)
[0m12:17:40.896708 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb, idle-time=0.013012170791625977s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:17:40.898509 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m12:17:40.910510 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m12:17:40.913576 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m12:17:40.922962 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m12:17:40.925978 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m12:17:40.928970 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`stg_ecommerce`
where TRY_CAST(REPLACE(Discount, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m12:17:41.338197 [debug] [Thread-1 (]: SQL status: OK in 0.410 seconds
[0m12:17:41.343206 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-7d0b-188c-988c-506f3ba582cf) - Closing
[0m12:17:41.346193 [info ] [Thread-1 (]: 4 of 49 PASS non_negative_stg_ecommerce_Discount ............................... [[32mPASS[0m in 0.45s]
[0m12:17:41.349189 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m12:17:41.351192 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m12:17:41.353193 [info ] [Thread-1 (]: 5 of 49 START test non_negative_stg_ecommerce_Final_Price ...................... [RUN]
[0m12:17:41.355190 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7)
[0m12:17:41.358191 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7, idle-time=0.010997533798217773s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m12:17:41.360191 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m12:17:41.371189 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m12:17:41.374363 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m12:17:41.381116 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m12:17:41.385296 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m12:17:41.388340 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`stg_ecommerce`
where TRY_CAST(REPLACE(Final_Price, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m12:17:41.826477 [debug] [Thread-1 (]: SQL status: OK in 0.440 seconds
[0m12:17:41.831113 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-7d51-127a-a36b-7cfdf1331326) - Closing
[0m12:17:41.835050 [info ] [Thread-1 (]: 5 of 49 PASS non_negative_stg_ecommerce_Final_Price ............................ [[32mPASS[0m in 0.48s]
[0m12:17:41.836776 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m12:17:41.838774 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m12:17:41.840775 [info ] [Thread-1 (]: 6 of 49 START test non_negative_stg_ecommerce_Price ............................ [RUN]
[0m12:17:41.842775 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d)
[0m12:17:41.844774 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d, idle-time=0.010725021362304688s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m12:17:41.847782 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m12:17:41.859811 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m12:17:41.861773 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m12:17:41.873776 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m12:17:41.876659 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m12:17:41.879662 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`stg_ecommerce`
where TRY_CAST(REPLACE(Price, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m12:17:42.276460 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m12:17:42.282513 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-7d9c-1af2-9d1e-faa184885874) - Closing
[0m12:17:42.286459 [info ] [Thread-1 (]: 6 of 49 PASS non_negative_stg_ecommerce_Price .................................. [[32mPASS[0m in 0.44s]
[0m12:17:42.288216 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m12:17:42.290498 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:17:42.292495 [info ] [Thread-1 (]: 7 of 49 START test not_null_stg_ecommerce_Category ............................. [RUN]
[0m12:17:42.294199 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14)
[0m12:17:42.296200 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, idle-time=0.010738611221313477s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m12:17:42.298195 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:17:42.315198 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m12:17:42.320218 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:17:42.327194 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m12:17:42.330195 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m12:17:42.335201 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`stg_ecommerce`
where Category is null



  
  
      
    ) dbt_internal_test
[0m12:17:42.728783 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m12:17:42.733788 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-7de2-14bd-a5a1-a2a57aaf94dc) - Closing
[0m12:17:42.737790 [info ] [Thread-1 (]: 7 of 49 PASS not_null_stg_ecommerce_Category ................................... [[32mPASS[0m in 0.44s]
[0m12:17:42.739445 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:17:42.741899 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:17:42.743913 [info ] [Thread-1 (]: 8 of 49 START test not_null_stg_ecommerce_Discount ............................. [RUN]
[0m12:17:42.745900 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836)
[0m12:17:42.747901 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, idle-time=0.011113882064819336s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:17:42.750900 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:17:42.761897 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m12:17:42.764830 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:17:42.772819 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m12:17:42.775873 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m12:17:42.778821 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Discount
from `workspace`.`default`.`stg_ecommerce`
where Discount is null



  
  
      
    ) dbt_internal_test
[0m12:17:43.157039 [debug] [Thread-1 (]: SQL status: OK in 0.380 seconds
[0m12:17:43.163049 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-7e25-180d-90ae-744f54799ee9) - Closing
[0m12:17:43.165824 [info ] [Thread-1 (]: 8 of 49 PASS not_null_stg_ecommerce_Discount ................................... [[32mPASS[0m in 0.42s]
[0m12:17:43.167908 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:17:43.169984 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:17:43.171978 [info ] [Thread-1 (]: 9 of 49 START test not_null_stg_ecommerce_Final_Price .......................... [RUN]
[0m12:17:43.173975 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc)
[0m12:17:43.175975 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, idle-time=0.010150909423828125s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:17:43.179067 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:17:43.188981 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m12:17:43.191886 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:17:43.200056 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m12:17:43.203073 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m12:17:43.205073 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Final_Price
from `workspace`.`default`.`stg_ecommerce`
where Final_Price is null



  
  
      
    ) dbt_internal_test
[0m12:17:43.635129 [debug] [Thread-1 (]: SQL status: OK in 0.430 seconds
[0m12:17:43.639816 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-7e66-1ae3-8dde-fcdaee342d3c) - Closing
[0m12:17:43.642853 [info ] [Thread-1 (]: 9 of 49 PASS not_null_stg_ecommerce_Final_Price ................................ [[32mPASS[0m in 0.47s]
[0m12:17:43.645187 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:17:43.648695 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:17:43.650648 [info ] [Thread-1 (]: 10 of 49 START test not_null_stg_ecommerce_Payment_Method ...................... [RUN]
[0m12:17:43.652654 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d)
[0m12:17:43.654653 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, idle-time=0.010794878005981445s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:17:43.656661 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:17:43.667686 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m12:17:43.670675 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:17:43.681783 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m12:17:43.685719 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m12:17:43.687721 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`stg_ecommerce`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m12:17:44.086831 [debug] [Thread-1 (]: SQL status: OK in 0.400 seconds
[0m12:17:44.091381 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-7eb0-13cd-9ead-568dc5369088) - Closing
[0m12:17:44.094417 [info ] [Thread-1 (]: 10 of 49 PASS not_null_stg_ecommerce_Payment_Method ............................ [[32mPASS[0m in 0.44s]
[0m12:17:44.097646 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:17:44.100487 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:17:44.102488 [info ] [Thread-1 (]: 11 of 49 START test not_null_stg_ecommerce_Price ............................... [RUN]
[0m12:17:44.104490 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a)
[0m12:17:44.107526 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, idle-time=0.012071371078491211s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:17:44.109487 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:17:44.119524 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m12:17:44.122710 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:17:44.132271 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m12:17:44.135860 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m12:17:44.137845 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Price
from `workspace`.`default`.`stg_ecommerce`
where Price is null



  
  
      
    ) dbt_internal_test
[0m12:17:44.486782 [debug] [Thread-1 (]: SQL status: OK in 0.350 seconds
[0m12:17:44.494776 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-7ef4-14fe-bde4-37fe61fc478b) - Closing
[0m12:17:44.498817 [info ] [Thread-1 (]: 11 of 49 PASS not_null_stg_ecommerce_Price ..................................... [[32mPASS[0m in 0.39s]
[0m12:17:44.501778 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:17:44.503777 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:17:44.506777 [info ] [Thread-1 (]: 12 of 49 START test not_null_stg_ecommerce_Product_ID .......................... [RUN]
[0m12:17:44.509778 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c)
[0m12:17:44.513773 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, idle-time=0.014873266220092773s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:17:44.516777 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:17:44.529777 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m12:17:44.534776 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:17:44.545772 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m12:17:44.550782 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m12:17:44.552775 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Product_ID
from `workspace`.`default`.`stg_ecommerce`
where Product_ID is null



  
  
      
    ) dbt_internal_test
[0m12:17:44.969597 [debug] [Thread-1 (]: SQL status: OK in 0.410 seconds
[0m12:17:44.974418 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-7f33-174e-a83e-b46ff2850042) - Closing
[0m12:17:44.978348 [info ] [Thread-1 (]: 12 of 49 PASS not_null_stg_ecommerce_Product_ID ................................ [[32mPASS[0m in 0.47s]
[0m12:17:44.981349 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:17:44.983348 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:17:44.985350 [info ] [Thread-1 (]: 13 of 49 START test not_null_stg_ecommerce_Purchase_Date ....................... [RUN]
[0m12:17:44.987390 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307)
[0m12:17:44.989347 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, idle-time=0.012001752853393555s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:17:44.992389 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:17:45.003487 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m12:17:45.006492 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:17:45.016050 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m12:17:45.018681 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m12:17:45.020344 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Purchase_Date
from `workspace`.`default`.`stg_ecommerce`
where Purchase_Date is null



  
  
      
    ) dbt_internal_test
[0m12:17:45.428557 [debug] [Thread-1 (]: SQL status: OK in 0.410 seconds
[0m12:17:45.433608 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-7f7b-1694-8998-afd93c06c101) - Closing
[0m12:17:45.436598 [info ] [Thread-1 (]: 13 of 49 PASS not_null_stg_ecommerce_Purchase_Date ............................. [[32mPASS[0m in 0.45s]
[0m12:17:45.438565 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:17:45.440687 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:17:45.442676 [info ] [Thread-1 (]: 14 of 49 START test not_null_stg_ecommerce_User_ID ............................. [RUN]
[0m12:17:45.444332 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, now test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf)
[0m12:17:45.448330 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, idle-time=0.012768268585205078s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:17:45.451389 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:17:45.459365 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m12:17:45.464347 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:17:45.474362 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m12:17:45.478361 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m12:17:45.482359 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`stg_ecommerce`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m12:17:45.830179 [debug] [Thread-1 (]: SQL status: OK in 0.340 seconds
[0m12:17:45.835238 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-7fc1-163e-b244-2db99b473c41) - Closing
[0m12:17:45.838177 [info ] [Thread-1 (]: 14 of 49 PASS not_null_stg_ecommerce_User_ID ................................... [[32mPASS[0m in 0.39s]
[0m12:17:45.840398 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:17:45.842690 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m12:17:45.844690 [info ] [Thread-1 (]: 15 of 49 START test unique_stg_ecommerce_Product_ID ............................ [RUN]
[0m12:17:45.847691 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, now test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1)
[0m12:17:45.849697 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1, idle-time=0.011520147323608398s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:17:45.851690 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m12:17:45.866727 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m12:17:45.869689 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m12:17:45.876689 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m12:17:45.880692 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m12:17:45.882690 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    Product_ID as unique_field,
    count(*) as n_records

from `workspace`.`default`.`stg_ecommerce`
where Product_ID is not null
group by Product_ID
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m12:17:46.258892 [debug] [Thread-1 (]: SQL status: OK in 0.370 seconds
[0m12:17:46.266892 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-7fff-14e1-8819-9049136021dc) - Closing
[0m12:17:46.269897 [info ] [Thread-1 (]: 15 of 49 PASS unique_stg_ecommerce_Product_ID .................................. [[32mPASS[0m in 0.42s]
[0m12:17:46.273894 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m12:17:46.277891 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_discount_by_category
[0m12:17:46.280892 [info ] [Thread-1 (]: 16 of 49 START sql view model default.avg_discount_by_category ................. [RUN]
[0m12:17:46.282890 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1, now model.dbt_databricks_cicd.avg_discount_by_category)
[0m12:17:46.284892 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=model.dbt_databricks_cicd.avg_discount_by_category, idle-time=0.01399374008178711s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m12:17:46.285891 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_discount_by_category
[0m12:17:46.292890 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m12:17:46.295895 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_discount_by_category
[0m12:17:46.300890 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:17:46.303893 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`avg_discount_by_category`
[0m12:17:46.305892 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m12:17:46.307892 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.avg_discount_by_category"
[0m12:17:46.309892 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_discount_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.avg_discount_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`avg_discount_by_category`
  
  as (
    SELECT
  Category,
  ROUND(AVG(CAST(`Discount` AS DOUBLE)), 2) AS avg_discount_percent
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY avg_discount_percent DESC
  )

[0m12:17:47.131104 [debug] [Thread-1 (]: SQL status: OK in 0.820 seconds
[0m12:17:47.133991 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-8040-13c1-8853-1d3eabbeed23) - Closing
[0m12:17:47.137002 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:17:47.140525 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3d73ac85-915f-4e15-b8e8-7ea23253ec0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F54FFF1D0>]}
[0m12:17:47.142489 [info ] [Thread-1 (]: 16 of 49 OK created sql view model default.avg_discount_by_category ............ [[32mOK[0m in 0.86s]
[0m12:17:47.145485 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_discount_by_category
[0m12:17:47.147478 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m12:17:47.149485 [info ] [Thread-1 (]: 17 of 49 START sql view model default.avg_ticket_by_category ................... [RUN]
[0m12:17:47.152487 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_discount_by_category, now model.dbt_databricks_cicd.avg_ticket_by_category)
[0m12:17:47.155553 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=model.dbt_databricks_cicd.avg_ticket_by_category, idle-time=0.014989137649536133s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.avg_discount_by_category
[0m12:17:47.157483 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_ticket_by_category
[0m12:17:47.165480 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m12:17:47.169486 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_ticket_by_category
[0m12:17:47.176632 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:17:47.180639 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`avg_ticket_by_category`
[0m12:17:47.183638 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m12:17:47.186649 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m12:17:47.189640 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_ticket_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.avg_ticket_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`avg_ticket_by_category`
  
  as (
    SELECT
  Category,
  ROUND(AVG(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS avg_ticket
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY avg_ticket DESC
  )

[0m12:17:47.925117 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m12:17:47.928117 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-80c7-18e2-a6bc-9b4e20bbbf8c) - Closing
[0m12:17:47.931183 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:17:47.935151 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3d73ac85-915f-4e15-b8e8-7ea23253ec0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F5563B9D0>]}
[0m12:17:47.937156 [info ] [Thread-1 (]: 17 of 49 OK created sql view model default.avg_ticket_by_category .............. [[32mOK[0m in 0.78s]
[0m12:17:47.939584 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m12:17:47.941583 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.monthly_revenue
[0m12:17:47.944577 [info ] [Thread-1 (]: 18 of 49 START sql view model default.monthly_revenue .......................... [RUN]
[0m12:17:47.946586 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_ticket_by_category, now model.dbt_databricks_cicd.monthly_revenue)
[0m12:17:47.948967 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=model.dbt_databricks_cicd.monthly_revenue, idle-time=0.013815641403198242s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.avg_ticket_by_category
[0m12:17:47.950968 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.monthly_revenue
[0m12:17:47.964354 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.monthly_revenue"
[0m12:17:47.969354 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.monthly_revenue
[0m12:17:47.977599 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:17:47.980563 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`monthly_revenue`
[0m12:17:47.983574 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.monthly_revenue"
[0m12:17:47.987151 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.monthly_revenue"
[0m12:17:47.990149 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.monthly_revenue: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.monthly_revenue"} */

  
  
  
  create or replace view `workspace`.`default`.`monthly_revenue`
  
  as (
    SELECT
  CAST(DATE_TRUNC('month', CAST(Purchase_Date AS DATE)) AS DATE) AS month,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS monthly_revenue
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY 1
ORDER BY 1
  )

[0m12:17:48.742611 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m12:17:48.745617 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-8140-1479-b594-47999cd0bafd) - Closing
[0m12:17:48.749136 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:17:48.752075 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3d73ac85-915f-4e15-b8e8-7ea23253ec0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F555A2A50>]}
[0m12:17:48.754080 [info ] [Thread-1 (]: 18 of 49 OK created sql view model default.monthly_revenue ..................... [[32mOK[0m in 0.81s]
[0m12:17:48.757071 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.monthly_revenue
[0m12:17:48.760113 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.payment_distribution
[0m12:17:48.762077 [info ] [Thread-1 (]: 19 of 49 START sql view model default.payment_distribution ..................... [RUN]
[0m12:17:48.765077 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.monthly_revenue, now model.dbt_databricks_cicd.payment_distribution)
[0m12:17:48.767445 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=model.dbt_databricks_cicd.payment_distribution, idle-time=0.01537013053894043s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.monthly_revenue
[0m12:17:48.769371 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.payment_distribution
[0m12:17:48.779546 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.payment_distribution"
[0m12:17:48.782525 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.payment_distribution
[0m12:17:48.788522 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:17:48.793546 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`payment_distribution`
[0m12:17:48.797557 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.payment_distribution"
[0m12:17:48.799529 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.payment_distribution"
[0m12:17:48.802045 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.payment_distribution: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.payment_distribution"} */

  
  
  
  create or replace view `workspace`.`default`.`payment_distribution`
  
  as (
    SELECT
  Payment_Method,
  COUNT(*) AS total_transactions,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_value
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Payment_Method
ORDER BY total_value DESC
  )

[0m12:17:49.490512 [debug] [Thread-1 (]: SQL status: OK in 0.680 seconds
[0m12:17:49.493149 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-81bc-1611-88e3-8329f3f567a4) - Closing
[0m12:17:49.496812 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:17:49.499752 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3d73ac85-915f-4e15-b8e8-7ea23253ec0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F55559E10>]}
[0m12:17:49.501759 [info ] [Thread-1 (]: 19 of 49 OK created sql view model default.payment_distribution ................ [[32mOK[0m in 0.73s]
[0m12:17:49.504785 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.payment_distribution
[0m12:17:49.506785 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.sales_by_category
[0m12:17:49.509756 [info ] [Thread-1 (]: 20 of 49 START sql view model default.sales_by_category ........................ [RUN]
[0m12:17:49.512791 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.payment_distribution, now model.dbt_databricks_cicd.sales_by_category)
[0m12:17:49.514748 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=model.dbt_databricks_cicd.sales_by_category, idle-time=0.014995336532592773s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.payment_distribution
[0m12:17:49.516743 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.sales_by_category
[0m12:17:49.528125 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.sales_by_category"
[0m12:17:49.530157 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.sales_by_category
[0m12:17:49.537120 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:17:49.541120 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`sales_by_category`
[0m12:17:49.545153 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.sales_by_category"
[0m12:17:49.548125 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.sales_by_category"
[0m12:17:49.550123 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.sales_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.sales_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`sales_by_category`
  
  as (
    SELECT
  Category,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_revenue
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY total_revenue DESC
  )

[0m12:17:50.323511 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m12:17:50.326581 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-822f-1211-924d-0107668fab49) - Closing
[0m12:17:50.329573 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:17:50.332581 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3d73ac85-915f-4e15-b8e8-7ea23253ec0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F5518BA50>]}
[0m12:17:50.335588 [info ] [Thread-1 (]: 20 of 49 OK created sql view model default.sales_by_category ................... [[32mOK[0m in 0.82s]
[0m12:17:50.337349 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.sales_by_category
[0m12:17:50.340377 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_5_products
[0m12:17:50.343351 [info ] [Thread-1 (]: 21 of 49 START sql view model default.top_5_products ........................... [RUN]
[0m12:17:50.345354 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.sales_by_category, now model.dbt_databricks_cicd.top_5_products)
[0m12:17:50.347348 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=model.dbt_databricks_cicd.top_5_products, idle-time=0.01476740837097168s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.sales_by_category
[0m12:17:50.349348 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_5_products
[0m12:17:50.360388 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_5_products"
[0m12:17:50.363088 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_5_products
[0m12:17:50.373007 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:17:50.377983 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`top_5_products`
[0m12:17:50.381060 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_5_products"
[0m12:17:50.384048 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.top_5_products"
[0m12:17:50.386029 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_5_products: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.top_5_products"} */

  
  
  
  create or replace view `workspace`.`default`.`top_5_products`
  
  as (
    WITH base AS (
    SELECT
        product_id,
        ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_sales
    FROM `workspace`.`default`.`stg_ecommerce`
    GROUP BY product_id
)

SELECT
    product_id,
    total_sales
FROM base
ORDER BY total_sales DESC
LIMIT 5
  )

[0m12:17:51.019272 [debug] [Thread-1 (]: SQL status: OK in 0.630 seconds
[0m12:17:51.023288 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-82ad-1c20-84c6-0935ccf9609b) - Closing
[0m12:17:51.027315 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:17:51.029273 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3d73ac85-915f-4e15-b8e8-7ea23253ec0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F556756D0>]}
[0m12:17:51.031492 [info ] [Thread-1 (]: 21 of 49 OK created sql view model default.top_5_products ...................... [[32mOK[0m in 0.68s]
[0m12:17:51.034139 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_5_products
[0m12:17:51.036579 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_customers
[0m12:17:51.038573 [info ] [Thread-1 (]: 22 of 49 START sql view model default.top_customers ............................ [RUN]
[0m12:17:51.042586 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_5_products, now model.dbt_databricks_cicd.top_customers)
[0m12:17:51.045578 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=model.dbt_databricks_cicd.top_customers, idle-time=0.016304969787597656s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.top_5_products
[0m12:17:51.047572 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_customers
[0m12:17:51.056645 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_customers"
[0m12:17:51.060614 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_customers
[0m12:17:51.066573 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:17:51.070627 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`top_customers`
[0m12:17:51.073853 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_customers"
[0m12:17:51.077825 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.top_customers"
[0m12:17:51.079826 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_customers: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.top_customers"} */

  
  
  
  create or replace view `workspace`.`default`.`top_customers`
  
  as (
    SELECT
  User_ID,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_spent
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY User_ID
ORDER BY total_spent DESC
LIMIT 10
  )

[0m12:17:51.689192 [debug] [Thread-1 (]: SQL status: OK in 0.610 seconds
[0m12:17:51.691955 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-8317-1ef0-87e0-a9ebebe3f466) - Closing
[0m12:17:51.695958 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:17:51.698964 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3d73ac85-915f-4e15-b8e8-7ea23253ec0e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F55674310>]}
[0m12:17:51.700956 [info ] [Thread-1 (]: 22 of 49 OK created sql view model default.top_customers ....................... [[32mOK[0m in 0.66s]
[0m12:17:51.703992 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_customers
[0m12:17:51.705973 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6
[0m12:17:51.708954 [info ] [Thread-1 (]: 23 of 49 START test dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0  [RUN]
[0m12:17:51.711965 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_customers, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6)
[0m12:17:51.713954 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6, idle-time=0.014990091323852539s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.top_customers
[0m12:17:51.716583 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6
[0m12:17:51.734701 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"
[0m12:17:51.737715 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6
[0m12:17:51.746782 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"
[0m12:17:51.750787 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"
[0m12:17:51.752801 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_discount_by_category`

where not(avg_discount_percent avg_discount_percent >= 0)


  
  
      
    ) dbt_internal_test
[0m12:17:52.128516 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_discount_by_category`

where not(avg_discount_percent avg_discount_percent >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 52)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_discount_by_category`

where not(avg_discount_percent avg_discount_percent >= 0)
----------------------------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 52)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_discount_by_category`

where not(avg_discount_percent avg_discount_percent >= 0)
----------------------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 52)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_discount_by_category`

where not(avg_discount_percent avg_discount_percent >= 0)
----------------------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778f-837e-1ec0-9e61-778b1a82091a
[0m12:17:52.150553 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 52)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`avg_discount_by_category`
  
  where not(avg_discount_percent avg_discount_percent >= 0)
  ----------------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5b124626a971bfcac535904f1039d3eb.sql
[0m12:17:52.153523 [error] [Thread-1 (]: 23 of 49 ERROR dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0  [[31mERROR[0m in 0.44s]
[0m12:17:52.156849 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6
[0m12:17:52.158732 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m12:17:52.160762 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 52)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`avg_discount_by_category`
  
  where not(avg_discount_percent avg_discount_percent >= 0)
  ----------------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5b124626a971bfcac535904f1039d3eb.sql.
[0m12:17:52.162718 [info ] [Thread-1 (]: 24 of 49 START test not_null_avg_discount_by_category_Category ................. [RUN]
[0m12:17:52.169724 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b)
[0m12:17:52.173388 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, idle-time=0.019864797592163086s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6
[0m12:17:52.175267 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m12:17:52.186706 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m12:17:52.189625 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m12:17:52.199596 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m12:17:52.202597 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m12:17:52.205600 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_discount_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m12:17:52.572670 [debug] [Thread-1 (]: SQL status: OK in 0.370 seconds
[0m12:17:52.577740 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-83c3-1a4e-a1d2-e9266f8893a1) - Closing
[0m12:17:52.580698 [info ] [Thread-1 (]: 24 of 49 PASS not_null_avg_discount_by_category_Category ....................... [[32mPASS[0m in 0.41s]
[0m12:17:52.583697 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m12:17:52.585691 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m12:17:52.587693 [info ] [Thread-1 (]: 25 of 49 START test not_null_avg_discount_by_category_avg_discount_percent ..... [RUN]
[0m12:17:52.590732 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101)
[0m12:17:52.591698 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, idle-time=0.011000633239746094s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m12:17:52.594077 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m12:17:52.609187 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m12:17:52.611910 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m12:17:52.618905 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m12:17:52.621919 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m12:17:52.625907 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_discount_percent
from `workspace`.`default`.`avg_discount_by_category`
where avg_discount_percent is null



  
  
      
    ) dbt_internal_test
[0m12:17:53.040667 [debug] [Thread-1 (]: SQL status: OK in 0.410 seconds
[0m12:17:53.046000 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-8403-1fc6-86a7-a3e96e1d9dba) - Closing
[0m12:17:53.049996 [info ] [Thread-1 (]: 25 of 49 PASS not_null_avg_discount_by_category_avg_discount_percent ........... [[32mPASS[0m in 0.46s]
[0m12:17:53.052000 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m12:17:53.053998 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301
[0m12:17:53.056998 [info ] [Thread-1 (]: 26 of 49 START test dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0  [RUN]
[0m12:17:53.059001 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301)
[0m12:17:53.060901 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301, idle-time=0.011905670166015625s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m12:17:53.063129 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301
[0m12:17:53.077044 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"
[0m12:17:53.080040 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301
[0m12:17:53.087038 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"
[0m12:17:53.092076 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"
[0m12:17:53.095042 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_ticket_by_category`

where not(avg_ticket avg_ticket >= 0)


  
  
      
    ) dbt_internal_test
[0m12:17:53.510126 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_ticket_by_category`

where not(avg_ticket avg_ticket >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 32)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_ticket_by_category`

where not(avg_ticket avg_ticket >= 0)
--------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 32)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_ticket_by_category`

where not(avg_ticket avg_ticket >= 0)
--------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 32)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`avg_ticket_by_category`

where not(avg_ticket avg_ticket >= 0)
--------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778f-8453-1385-9e26-dafb696fa497
[0m12:17:53.524165 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 32)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`avg_ticket_by_category`
  
  where not(avg_ticket avg_ticket >= 0)
  --------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5328046ff58f0d97fcb998395932ee40.sql
[0m12:17:53.527134 [error] [Thread-1 (]: 26 of 49 ERROR dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0  [[31mERROR[0m in 0.47s]
[0m12:17:53.530214 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301
[0m12:17:53.531798 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m12:17:53.533792 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 32)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`avg_ticket_by_category`
  
  where not(avg_ticket avg_ticket >= 0)
  --------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5328046ff58f0d97fcb998395932ee40.sql.
[0m12:17:53.535792 [info ] [Thread-1 (]: 27 of 49 START test not_null_avg_ticket_by_category_Category ................... [RUN]
[0m12:17:53.540791 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f)
[0m12:17:53.545798 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, idle-time=0.018665075302124023s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301
[0m12:17:53.547802 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m12:17:53.560794 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m12:17:53.563765 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m12:17:53.572769 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m12:17:53.576766 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m12:17:53.578765 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_ticket_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m12:17:53.975827 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m12:17:53.980814 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-8495-19ad-a927-5412ef74e572) - Closing
[0m12:17:53.983854 [info ] [Thread-1 (]: 27 of 49 PASS not_null_avg_ticket_by_category_Category ......................... [[32mPASS[0m in 0.44s]
[0m12:17:53.986818 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m12:17:53.988814 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m12:17:53.991815 [info ] [Thread-1 (]: 28 of 49 START test not_null_avg_ticket_by_category_avg_ticket ................. [RUN]
[0m12:17:53.994167 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41)
[0m12:17:53.997167 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, idle-time=0.013313770294189453s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m12:17:53.999162 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m12:17:54.010834 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m12:17:54.013563 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m12:17:54.023518 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m12:17:54.026568 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m12:17:54.029520 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_ticket
from `workspace`.`default`.`avg_ticket_by_category`
where avg_ticket is null



  
  
      
    ) dbt_internal_test
[0m12:17:54.400571 [debug] [Thread-1 (]: SQL status: OK in 0.370 seconds
[0m12:17:54.405401 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-84da-126c-8d71-7f9f1da5c71d) - Closing
[0m12:17:54.408957 [info ] [Thread-1 (]: 28 of 49 PASS not_null_avg_ticket_by_category_avg_ticket ....................... [[32mPASS[0m in 0.41s]
[0m12:17:54.410856 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m12:17:54.413862 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14
[0m12:17:54.415859 [info ] [Thread-1 (]: 29 of 49 START test dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0  [RUN]
[0m12:17:54.417858 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14)
[0m12:17:54.420889 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14, idle-time=0.011931180953979492s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m12:17:54.423853 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14
[0m12:17:54.437902 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"
[0m12:17:54.441899 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14
[0m12:17:54.448850 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"
[0m12:17:54.451672 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"
[0m12:17:54.455702 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`monthly_revenue`

where not(monthly_revenue monthly_revenue >= 0)


  
  
      
    ) dbt_internal_test
[0m12:17:54.829176 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`monthly_revenue`

where not(monthly_revenue monthly_revenue >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 42)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`monthly_revenue`

where not(monthly_revenue monthly_revenue >= 0)
------------------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 42)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`monthly_revenue`

where not(monthly_revenue monthly_revenue >= 0)
------------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 42)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`monthly_revenue`

where not(monthly_revenue monthly_revenue >= 0)
------------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778f-851b-1184-a5e1-42e3dc1875c7
[0m12:17:56.195779 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 42)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`monthly_revenue`
  
  where not(monthly_revenue monthly_revenue >= 0)
  ------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_m_f3c6f8ea5d3985ba2e05e7b0666775b9.sql
[0m12:17:56.199075 [error] [Thread-1 (]: 29 of 49 ERROR dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0  [[31mERROR[0m in 1.78s]
[0m12:17:56.201663 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14
[0m12:17:56.208888 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m12:17:56.210920 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 42)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`monthly_revenue`
  
  where not(monthly_revenue monthly_revenue >= 0)
  ------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_m_f3c6f8ea5d3985ba2e05e7b0666775b9.sql.
[0m12:17:56.212883 [info ] [Thread-1 (]: 30 of 49 START test not_null_monthly_revenue_month ............................. [RUN]
[0m12:17:56.215882 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14, now test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b)
[0m12:17:56.219882 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, idle-time=0.019808530807495117s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14
[0m12:17:56.225957 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m12:17:56.238825 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m12:17:56.243746 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m12:17:56.261747 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m12:17:56.266779 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m12:17:56.271748 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select month
from `workspace`.`default`.`monthly_revenue`
where month is null



  
  
      
    ) dbt_internal_test
[0m12:17:56.652299 [debug] [Thread-1 (]: SQL status: OK in 0.380 seconds
[0m12:17:56.657116 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-8631-1a26-8916-d61543f46abe) - Closing
[0m12:17:56.660378 [info ] [Thread-1 (]: 30 of 49 PASS not_null_monthly_revenue_month ................................... [[32mPASS[0m in 0.44s]
[0m12:17:56.662375 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m12:17:56.664369 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m12:17:56.666372 [info ] [Thread-1 (]: 31 of 49 START test not_null_monthly_revenue_monthly_revenue ................... [RUN]
[0m12:17:56.669374 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, now test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b)
[0m12:17:56.671382 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, idle-time=0.011003732681274414s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m12:17:56.673368 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m12:17:56.684373 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m12:17:56.688171 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m12:17:56.696167 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m12:17:56.698989 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m12:17:56.702047 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select monthly_revenue
from `workspace`.`default`.`monthly_revenue`
where monthly_revenue is null



  
  
      
    ) dbt_internal_test
[0m12:17:57.096100 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m12:17:57.102645 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-8672-1023-89e6-a89453936d30) - Closing
[0m12:17:57.104500 [info ] [Thread-1 (]: 31 of 49 PASS not_null_monthly_revenue_monthly_revenue ......................... [[32mPASS[0m in 0.44s]
[0m12:17:57.106892 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m12:17:57.108891 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147
[0m12:17:57.109889 [info ] [Thread-1 (]: 32 of 49 START test dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0  [RUN]
[0m12:17:57.111890 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147)
[0m12:17:57.113891 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147, idle-time=0.008394479751586914s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m12:17:57.114889 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147
[0m12:17:57.127897 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"
[0m12:17:57.129760 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147
[0m12:17:57.137285 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"
[0m12:17:57.140297 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"
[0m12:17:57.143327 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_transactions total_transactions > 0)


  
  
      
    ) dbt_internal_test
[0m12:17:57.505325 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_transactions total_transactions > 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 48)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_transactions total_transactions > 0)
------------------------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 48)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_transactions total_transactions > 0)
------------------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 48)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_transactions total_transactions > 0)
------------------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778f-86b5-13e4-943c-f8092c057f64
[0m12:17:57.521340 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 48)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`payment_distribution`
  
  where not(total_transactions total_transactions > 0)
  ------------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_fc379226623eb21c1aee5952042cbcd4.sql
[0m12:17:57.523800 [error] [Thread-1 (]: 32 of 49 ERROR dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0  [[31mERROR[0m in 0.41s]
[0m12:17:57.526798 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147
[0m12:17:57.528797 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97
[0m12:17:57.529792 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 48)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`payment_distribution`
  
  where not(total_transactions total_transactions > 0)
  ------------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_fc379226623eb21c1aee5952042cbcd4.sql.
[0m12:17:57.531796 [info ] [Thread-1 (]: 33 of 49 START test dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0  [RUN]
[0m12:17:57.537794 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97)
[0m12:17:57.543930 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97, idle-time=0.01909327507019043s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147
[0m12:17:57.545890 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97
[0m12:17:57.560664 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"
[0m12:17:57.564015 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97
[0m12:17:57.571964 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"
[0m12:17:57.575017 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"
[0m12:17:57.577974 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_value total_value >= 0)


  
  
      
    ) dbt_internal_test
[0m12:17:57.796893 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_value total_value >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_value total_value >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_value total_value >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`payment_distribution`

where not(total_value total_value >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778f-86f7-151e-84fc-d6757aaa3bde
[0m12:17:57.813935 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`payment_distribution`
  
  where not(total_value total_value >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_5ed37f769e6a283e088dfae7f31ac751.sql
[0m12:17:57.817936 [error] [Thread-1 (]: 33 of 49 ERROR dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0  [[31mERROR[0m in 0.28s]
[0m12:17:57.820898 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97
[0m12:17:57.822918 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m12:17:57.824901 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`payment_distribution`
  
  where not(total_value total_value >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_5ed37f769e6a283e088dfae7f31ac751.sql.
[0m12:17:57.826901 [info ] [Thread-1 (]: 34 of 49 START test not_null_payment_distribution_Payment_Method ............... [RUN]
[0m12:17:57.829897 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97, now test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae)
[0m12:17:57.831765 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, idle-time=0.014760017395019531s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97
[0m12:17:57.839767 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m12:17:57.850389 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m12:17:57.854663 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m12:17:57.861677 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m12:17:57.864695 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m12:17:57.867672 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`payment_distribution`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m12:17:58.224477 [debug] [Thread-1 (]: SQL status: OK in 0.350 seconds
[0m12:17:58.231516 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-8723-1cdf-96ff-857be1a64cd3) - Closing
[0m12:17:58.236487 [info ] [Thread-1 (]: 34 of 49 PASS not_null_payment_distribution_Payment_Method ..................... [[32mPASS[0m in 0.41s]
[0m12:17:58.238477 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m12:17:58.241489 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m12:17:58.245479 [info ] [Thread-1 (]: 35 of 49 START test not_null_payment_distribution_total_transactions ........... [RUN]
[0m12:17:58.249480 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, now test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8)
[0m12:17:58.253477 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, idle-time=0.018001079559326172s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m12:17:58.259479 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m12:17:58.280480 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m12:17:58.285499 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m12:17:58.302482 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m12:17:58.308480 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m12:17:58.312484 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_transactions
from `workspace`.`default`.`payment_distribution`
where total_transactions is null



  
  
      
    ) dbt_internal_test
[0m12:17:58.684082 [debug] [Thread-1 (]: SQL status: OK in 0.370 seconds
[0m12:17:58.688086 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-8767-1e22-947c-cfc02dcfe717) - Closing
[0m12:17:58.690083 [info ] [Thread-1 (]: 35 of 49 PASS not_null_payment_distribution_total_transactions ................. [[32mPASS[0m in 0.44s]
[0m12:17:58.692140 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m12:17:58.694044 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m12:17:58.695042 [info ] [Thread-1 (]: 36 of 49 START test not_null_payment_distribution_total_value .................. [RUN]
[0m12:17:58.697044 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, now test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03)
[0m12:17:58.698042 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, idle-time=0.007959604263305664s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m12:17:58.701043 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m12:17:58.709042 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m12:17:58.711608 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m12:17:58.720211 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m12:17:58.722216 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m12:17:58.724169 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_value
from `workspace`.`default`.`payment_distribution`
where total_value is null



  
  
      
    ) dbt_internal_test
[0m12:17:59.102687 [debug] [Thread-1 (]: SQL status: OK in 0.380 seconds
[0m12:17:59.110742 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-87a6-1886-b5cf-99c10735de19) - Closing
[0m12:17:59.113686 [info ] [Thread-1 (]: 36 of 49 PASS not_null_payment_distribution_total_value ........................ [[32mPASS[0m in 0.42s]
[0m12:17:59.116819 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m12:17:59.118830 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7
[0m12:17:59.121824 [info ] [Thread-1 (]: 37 of 49 START test dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0  [RUN]
[0m12:17:59.125606 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7)
[0m12:17:59.127605 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7, idle-time=0.012913942337036133s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m12:17:59.129610 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7
[0m12:17:59.141639 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"
[0m12:17:59.143606 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7
[0m12:17:59.153457 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"
[0m12:17:59.156408 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"
[0m12:17:59.159380 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_orders total_orders > 0)


  
  
      
    ) dbt_internal_test
[0m12:17:59.527409 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_orders total_orders > 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_orders total_orders > 0)
------------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_orders total_orders > 0)
------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_orders total_orders > 0)
------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778f-87e9-1310-81c6-63d584c47cbd
[0m12:17:59.543414 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`sales_by_category`
  
  where not(total_orders total_orders > 0)
  ------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_89c32efc0957beac212198ac47c17269.sql
[0m12:17:59.545807 [error] [Thread-1 (]: 37 of 49 ERROR dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0  [[31mERROR[0m in 0.42s]
[0m12:17:59.549125 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7
[0m12:17:59.551084 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd
[0m12:17:59.553093 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`sales_by_category`
  
  where not(total_orders total_orders > 0)
  ------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_89c32efc0957beac212198ac47c17269.sql.
[0m12:17:59.554084 [info ] [Thread-1 (]: 38 of 49 START test dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0  [RUN]
[0m12:17:59.562134 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd)
[0m12:17:59.564213 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd, idle-time=0.018406152725219727s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7
[0m12:17:59.567212 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd
[0m12:17:59.578211 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"
[0m12:17:59.581656 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd
[0m12:17:59.590641 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"
[0m12:17:59.593731 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"
[0m12:17:59.596723 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_revenue total_revenue >= 0)


  
  
      
    ) dbt_internal_test
[0m12:17:59.832971 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_revenue total_revenue >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 38)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_revenue total_revenue >= 0)
--------------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 38)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_revenue total_revenue >= 0)
--------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 38)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`sales_by_category`

where not(total_revenue total_revenue >= 0)
--------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778f-882c-1248-83ad-57f54266170e
[0m12:17:59.847972 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 38)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`sales_by_category`
  
  where not(total_revenue total_revenue >= 0)
  --------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_a42e1924275d2ea59b3d9b718bc54aee.sql
[0m12:17:59.850979 [error] [Thread-1 (]: 38 of 49 ERROR dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0  [[31mERROR[0m in 0.29s]
[0m12:17:59.853247 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd
[0m12:17:59.855621 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m12:17:59.856623 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 38)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`sales_by_category`
  
  where not(total_revenue total_revenue >= 0)
  --------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_a42e1924275d2ea59b3d9b718bc54aee.sql.
[0m12:17:59.858622 [info ] [Thread-1 (]: 39 of 49 START test not_null_sales_by_category_Category ........................ [RUN]
[0m12:17:59.861620 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd, now test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507)
[0m12:17:59.864630 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, idle-time=0.01264333724975586s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd
[0m12:17:59.867628 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m12:17:59.880625 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m12:17:59.884689 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m12:17:59.891620 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m12:17:59.894619 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m12:17:59.896490 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`sales_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m12:18:00.292302 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m12:18:00.298312 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-8859-1e12-a8c3-2d860617cdf6) - Closing
[0m12:18:00.301305 [info ] [Thread-1 (]: 39 of 49 PASS not_null_sales_by_category_Category .............................. [[32mPASS[0m in 0.44s]
[0m12:18:00.303305 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m12:18:00.305307 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m12:18:00.307303 [info ] [Thread-1 (]: 40 of 49 START test not_null_sales_by_category_total_orders .................... [RUN]
[0m12:18:00.309305 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, now test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e)
[0m12:18:00.311304 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, idle-time=0.009996891021728516s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m12:18:00.313305 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m12:18:00.323305 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m12:18:00.326306 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m12:18:00.338341 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m12:18:00.341308 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m12:18:00.343313 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`sales_by_category`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m12:18:00.770036 [debug] [Thread-1 (]: SQL status: OK in 0.420 seconds
[0m12:18:00.776036 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-889f-14a5-8174-5501f4ce78b8) - Closing
[0m12:18:00.780038 [info ] [Thread-1 (]: 40 of 49 PASS not_null_sales_by_category_total_orders .......................... [[32mPASS[0m in 0.47s]
[0m12:18:00.784041 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m12:18:00.786036 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m12:18:00.790042 [info ] [Thread-1 (]: 41 of 49 START test not_null_sales_by_category_total_revenue ................... [RUN]
[0m12:18:00.793043 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, now test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd)
[0m12:18:00.796048 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, idle-time=0.016010046005249023s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m12:18:00.800039 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m12:18:00.814036 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m12:18:00.819036 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m12:18:00.831037 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m12:18:00.837041 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m12:18:00.840038 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_revenue
from `workspace`.`default`.`sales_by_category`
where total_revenue is null



  
  
      
    ) dbt_internal_test
[0m12:18:01.199035 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m12:18:01.205039 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-88e8-1f1b-8226-bb87952876e3) - Closing
[0m12:18:01.208040 [info ] [Thread-1 (]: 41 of 49 PASS not_null_sales_by_category_total_revenue ......................... [[32mPASS[0m in 0.42s]
[0m12:18:01.210037 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m12:18:01.212040 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57
[0m12:18:01.215045 [info ] [Thread-1 (]: 42 of 49 START test dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0  [RUN]
[0m12:18:01.218034 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57)
[0m12:18:01.222038 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57, idle-time=0.014017820358276367s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m12:18:01.224035 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57
[0m12:18:01.243035 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"
[0m12:18:01.251036 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57
[0m12:18:01.267042 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"
[0m12:18:01.273042 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"
[0m12:18:01.277040 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_5_products`

where not(total_sales total_sales >= 0)


  
  
      
    ) dbt_internal_test
[0m12:18:01.649036 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_5_products`

where not(total_sales total_sales >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_5_products`

where not(total_sales total_sales >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_5_products`

where not(total_sales total_sales >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_5_products`

where not(total_sales total_sales >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778f-892d-11ab-8ae9-38c0a088eb8a
[0m12:18:01.669031 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_5_products`
  
  where not(total_sales total_sales >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_53d9d0761651e2acd9611a042b182945.sql
[0m12:18:01.672034 [error] [Thread-1 (]: 42 of 49 ERROR dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0  [[31mERROR[0m in 0.45s]
[0m12:18:01.675035 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57
[0m12:18:01.678040 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m12:18:01.680038 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_5_products`
  
  where not(total_sales total_sales >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_53d9d0761651e2acd9611a042b182945.sql.
[0m12:18:01.684046 [info ] [Thread-1 (]: 43 of 49 START test not_null_top_5_products_product_id ......................... [RUN]
[0m12:18:01.688035 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57, now test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe)
[0m12:18:01.690082 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, idle-time=0.017002344131469727s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57
[0m12:18:01.693035 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m12:18:01.709047 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m12:18:01.713039 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m12:18:01.721032 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m12:18:01.724038 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m12:18:01.728079 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select product_id
from `workspace`.`default`.`top_5_products`
where product_id is null



  
  
      
    ) dbt_internal_test
[0m12:18:02.113037 [debug] [Thread-1 (]: SQL status: OK in 0.380 seconds
[0m12:18:02.120041 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-8971-18d8-afe8-2e52f0b33f03) - Closing
[0m12:18:02.123037 [info ] [Thread-1 (]: 43 of 49 PASS not_null_top_5_products_product_id ............................... [[32mPASS[0m in 0.44s]
[0m12:18:02.125044 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m12:18:02.127039 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m12:18:02.130084 [info ] [Thread-1 (]: 44 of 49 START test not_null_top_5_products_total_sales ........................ [RUN]
[0m12:18:02.133036 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, now test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818)
[0m12:18:02.135037 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, idle-time=0.010999441146850586s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m12:18:02.139042 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m12:18:02.150041 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m12:18:02.153055 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m12:18:02.165041 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m12:18:02.168041 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m12:18:02.171044 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_sales
from `workspace`.`default`.`top_5_products`
where total_sales is null



  
  
      
    ) dbt_internal_test
[0m12:18:02.539761 [debug] [Thread-1 (]: SQL status: OK in 0.370 seconds
[0m12:18:02.545759 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-89b4-14b0-adc3-e940b1519e24) - Closing
[0m12:18:02.548727 [info ] [Thread-1 (]: 44 of 49 PASS not_null_top_5_products_total_sales .............................. [[32mPASS[0m in 0.42s]
[0m12:18:02.550759 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m12:18:02.552989 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4
[0m12:18:02.555227 [info ] [Thread-1 (]: 45 of 49 START test dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0  [RUN]
[0m12:18:02.557237 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4)
[0m12:18:02.559232 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4, idle-time=0.010504484176635742s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m12:18:02.562237 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4
[0m12:18:02.574230 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"
[0m12:18:02.577025 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4
[0m12:18:02.587023 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"
[0m12:18:02.589922 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"
[0m12:18:02.592938 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_orders total_orders > 0)


  
  
      
    ) dbt_internal_test
[0m12:18:02.958191 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_orders total_orders > 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_orders total_orders > 0)
------------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_orders total_orders > 0)
------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_orders total_orders > 0)
------------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778f-89f4-1912-ae7f-f0f18dd3fd8e
[0m12:18:02.973195 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_customers`
  
  where not(total_orders total_orders > 0)
  ------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_837145e0920d813dbd0319ae1c97969b.sql
[0m12:18:02.976370 [error] [Thread-1 (]: 45 of 49 ERROR dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0  [[31mERROR[0m in 0.42s]
[0m12:18:02.979676 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4
[0m12:18:02.982123 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343
[0m12:18:02.984127 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_customers`
  
  where not(total_orders total_orders > 0)
  ------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_837145e0920d813dbd0319ae1c97969b.sql.
[0m12:18:02.986119 [info ] [Thread-1 (]: 46 of 49 START test dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0  [RUN]
[0m12:18:02.993125 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4, now test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343)
[0m12:18:02.995124 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343, idle-time=0.018754243850708008s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4
[0m12:18:02.998123 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343
[0m12:18:03.010122 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"
[0m12:18:03.014666 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343
[0m12:18:03.021705 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"
[0m12:18:03.024661 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"
[0m12:18:03.027679 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_spent total_spent >= 0)


  
  
      
    ) dbt_internal_test
[0m12:18:03.251597 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_spent total_spent >= 0)


  
  
      
    ) dbt_internal_test
: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_spent total_spent >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [PARSE_SYNTAX_ERROR] org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_spent total_spent >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:764)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:688)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:558)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:234)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:73)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:521)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1899)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:571)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.parser.ParseException: 
[PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)

== SQL ==
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  



select
    1
from `workspace`.`default`.`top_customers`

where not(total_spent total_spent >= 0)
----------------------------------^^^


  
  
      
    ) dbt_internal_test

	at org.apache.spark.sql.catalyst.parser.ParseException.withCommand(parsers.scala:487)
	at org.apache.spark.sql.catalyst.parser.AbstractParser.parse(parsers.scala:118)
	at org.apache.spark.sql.execution.SparkSqlParser.parse(SparkSqlParser.scala:150)
	at org.apache.spark.sql.catalyst.parser.AbstractSqlParser.parsePlan(AbstractSqlParser.scala:117)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$4(QueryRuntimePrediction.scala:422)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:548)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$3(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:219)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$2(QueryRuntimePrediction.scala:421)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:151)
	at com.databricks.sql.QueryRuntimePredictionUtils$.$anonfun$getParsedPlanWithTracking$1(QueryRuntimePrediction.scala:420)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:80)
	at com.databricks.sql.QueryRuntimePredictionUtils$.getParsedPlanWithTracking(QueryRuntimePrediction.scala:416)
	at com.databricks.sql.QueryRuntimePrediction.$anonfun$getQueryExecutionWithParsedPlan$1(QueryRuntimePrediction.scala:766)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:1462)
	at com.databricks.sql.QueryRuntimePrediction.getQueryExecutionWithParsedPlan(QueryRuntimePrediction.scala:757)
	at com.databricks.sql.QueryRuntimePrediction.getRuntimeCategory(QueryRuntimePrediction.scala:545)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$3(ClusterLoadMonitor.scala:818)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at com.databricks.unity.HandleImpl.$anonfun$runWithAndClose$1(UCSHandle.scala:109)
	at scala.util.Using$.resource(Using.scala:269)
	at com.databricks.unity.HandleImpl.runWithAndClose(UCSHandle.scala:108)
	at com.databricks.sql.ClusterLoadMonitor.$anonfun$getRuntimeCategory$2(ClusterLoadMonitor.scala:813)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1768)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.$anonfun$run$1(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$6(SparkThreadLocalForwardingThreadPoolExecutor.scala:119)
	at com.databricks.sql.transaction.tahoe.mst.MSTThreadHelper$.runWithMstTxnId(MSTThreadHelper.scala:57)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$5(SparkThreadLocalForwardingThreadPoolExecutor.scala:118)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.$anonfun$runWithCaptured$4(SparkThreadLocalForwardingThreadPoolExecutor.scala:117)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:116)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingHelper.runWithCaptured$(SparkThreadLocalForwardingThreadPoolExecutor.scala:93)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.runWithCaptured(SparkThreadLocalForwardingThreadPoolExecutor.scala:162)
	at org.apache.spark.util.threads.SparkThreadLocalCapturingRunnable.run(SparkThreadLocalForwardingThreadPoolExecutor.scala:165)
	... 3 more
, operation-id=01f0778f-8a37-1808-86e5-daa0f50b8e7f
[0m12:18:03.275601 [debug] [Thread-1 (]: Database Error in test dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_customers`
  
  where not(total_spent total_spent >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_2a6b4bf5f333b9ab281e1669bb988c44.sql
[0m12:18:03.280598 [error] [Thread-1 (]: 46 of 49 ERROR dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0  [[31mERROR[0m in 0.29s]
[0m12:18:03.283601 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343
[0m12:18:03.288633 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m12:18:03.289599 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343' to be skipped because of status 'error'.  Reason: Database Error in test dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_customers`
  
  where not(total_spent total_spent >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_2a6b4bf5f333b9ab281e1669bb988c44.sql.
[0m12:18:03.291598 [info ] [Thread-1 (]: 47 of 49 START test not_null_top_customers_User_ID ............................. [RUN]
[0m12:18:03.295683 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343, now test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0)
[0m12:18:03.298599 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, idle-time=0.017998456954956055s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343
[0m12:18:03.303600 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m12:18:03.316597 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m12:18:03.319601 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m12:18:03.326594 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m12:18:03.331597 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m12:18:03.333617 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`top_customers`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m12:18:03.730866 [debug] [Thread-1 (]: SQL status: OK in 0.400 seconds
[0m12:18:03.736128 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-8a65-1b82-aeb2-fc31371cb978) - Closing
[0m12:18:03.739382 [info ] [Thread-1 (]: 47 of 49 PASS not_null_top_customers_User_ID ................................... [[32mPASS[0m in 0.44s]
[0m12:18:03.741349 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m12:18:03.743397 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m12:18:03.746428 [info ] [Thread-1 (]: 48 of 49 START test not_null_top_customers_total_orders ........................ [RUN]
[0m12:18:03.748397 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, now test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746)
[0m12:18:03.751404 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, idle-time=0.011013507843017578s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m12:18:03.753398 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m12:18:03.764395 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m12:18:03.768398 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m12:18:03.779398 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m12:18:03.782396 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m12:18:03.785408 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`top_customers`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m12:18:04.217795 [debug] [Thread-1 (]: SQL status: OK in 0.430 seconds
[0m12:18:04.222801 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-8aaa-17a6-a47d-9f75e9383951) - Closing
[0m12:18:04.225795 [info ] [Thread-1 (]: 48 of 49 PASS not_null_top_customers_total_orders .............................. [[32mPASS[0m in 0.48s]
[0m12:18:04.228761 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m12:18:04.231235 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m12:18:04.233242 [info ] [Thread-1 (]: 49 of 49 START test not_null_top_customers_total_spent ......................... [RUN]
[0m12:18:04.235240 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, now test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73)
[0m12:18:04.238245 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, name=test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73, idle-time=0.012449264526367188s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m12:18:04.242237 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m12:18:04.265237 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m12:18:04.270239 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m12:18:04.287234 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m12:18:04.291265 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m12:18:04.296235 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_spent
from `workspace`.`default`.`top_customers`
where total_spent is null



  
  
      
    ) dbt_internal_test
[0m12:18:04.695313 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m12:18:04.699991 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192, command-id=01f0778f-8af8-1a93-a3cf-4bcff9f0e45b) - Closing
[0m12:18:04.702958 [info ] [Thread-1 (]: 49 of 49 PASS not_null_top_customers_total_spent ............................... [[32mPASS[0m in 0.47s]
[0m12:18:04.704913 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m12:18:04.708917 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=26.780170440673828s, language=None, compute-name=) - Reusing connection previously named master
[0m12:18:04.711916 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:18:04.713921 [debug] [MainThread]: Connection 'list_workspace' was properly closed.
[0m12:18:04.714913 [debug] [MainThread]: On list_workspace: Close
[0m12:18:04.716914 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0778f-79f4-1761-863c-95a978049724) - Closing
[0m12:18:04.941910 [debug] [MainThread]: Connection 'list_workspace_default' was properly closed.
[0m12:18:04.943913 [debug] [MainThread]: On list_workspace_default: Close
[0m12:18:04.947912 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0778f-7ac9-190d-95c6-c2546870ae6c) - Closing
[0m12:18:05.157393 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73' was properly closed.
[0m12:18:05.161391 [debug] [MainThread]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: Close
[0m12:18:05.165384 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f0778f-7ba6-19af-873e-d5e17bf0c192) - Closing
[0m12:18:05.383713 [info ] [MainThread]: 
[0m12:18:05.385720 [info ] [MainThread]: Finished running 40 data tests, 9 view models in 0 hours 0 minutes and 30.37 seconds (30.37s).
[0m12:18:05.405715 [debug] [MainThread]: Command end result
[0m12:18:05.499861 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m12:18:05.507866 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m12:18:05.533865 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m12:18:05.535869 [info ] [MainThread]: 
[0m12:18:05.537870 [info ] [MainThread]: [31mCompleted with 10 errors, 0 partial successes, and 0 warnings:[0m
[0m12:18:05.540864 [info ] [MainThread]: 
[0m12:18:05.545866 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:18:05.548863 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 52)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_discount_by_category_avg_discount_percent__avg_discount_percent_0.6056ce52e6"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`avg_discount_by_category`
  
  where not(avg_discount_percent avg_discount_percent >= 0)
  ----------------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5b124626a971bfcac535904f1039d3eb.sql
[0m12:18:05.551863 [info ] [MainThread]: 
[0m12:18:05.553864 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5b124626a971bfcac535904f1039d3eb.sql
[0m12:18:05.554867 [info ] [MainThread]: 
[0m12:18:05.556871 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:18:05.565882 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 32)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_avg_ticket_by_category_avg_ticket__avg_ticket_0.dc5a5b1301"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`avg_ticket_by_category`
  
  where not(avg_ticket avg_ticket >= 0)
  --------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5328046ff58f0d97fcb998395932ee40.sql
[0m12:18:05.567868 [info ] [MainThread]: 
[0m12:18:05.569865 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_a_5328046ff58f0d97fcb998395932ee40.sql
[0m12:18:05.571875 [info ] [MainThread]: 
[0m12:18:05.574866 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:18:05.581867 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 42)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_monthly_revenue_monthly_revenue__monthly_revenue_0.f3c39d0a14"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`monthly_revenue`
  
  where not(monthly_revenue monthly_revenue >= 0)
  ------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_m_f3c6f8ea5d3985ba2e05e7b0666775b9.sql
[0m12:18:05.584868 [info ] [MainThread]: 
[0m12:18:05.586865 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_m_f3c6f8ea5d3985ba2e05e7b0666775b9.sql
[0m12:18:05.588868 [info ] [MainThread]: 
[0m12:18:05.597881 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:18:05.599862 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 48)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_transactions__total_transactions_0.0c63b16147"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`payment_distribution`
  
  where not(total_transactions total_transactions > 0)
  ------------------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_fc379226623eb21c1aee5952042cbcd4.sql
[0m12:18:05.601884 [info ] [MainThread]: 
[0m12:18:05.603864 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_fc379226623eb21c1aee5952042cbcd4.sql
[0m12:18:05.605865 [info ] [MainThread]: 
[0m12:18:05.613866 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:18:05.616863 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_payment_distribution_total_value__total_value_0.a082f6ba97"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`payment_distribution`
  
  where not(total_value total_value >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_5ed37f769e6a283e088dfae7f31ac751.sql
[0m12:18:05.618862 [info ] [MainThread]: 
[0m12:18:05.620871 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_p_5ed37f769e6a283e088dfae7f31ac751.sql
[0m12:18:05.628865 [info ] [MainThread]: 
[0m12:18:05.630865 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:18:05.632863 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_orders__total_orders_0.89435423b7"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`sales_by_category`
  
  where not(total_orders total_orders > 0)
  ------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_89c32efc0957beac212198ac47c17269.sql
[0m12:18:05.635872 [info ] [MainThread]: 
[0m12:18:05.637864 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_89c32efc0957beac212198ac47c17269.sql
[0m12:18:05.645886 [info ] [MainThread]: 
[0m12:18:05.647864 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:18:05.649864 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 38)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_sales_by_category_total_revenue__total_revenue_0.c600e04fdd"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`sales_by_category`
  
  where not(total_revenue total_revenue >= 0)
  --------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_a42e1924275d2ea59b3d9b718bc54aee.sql
[0m12:18:05.652862 [info ] [MainThread]: 
[0m12:18:05.654880 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_s_a42e1924275d2ea59b3d9b718bc54aee.sql
[0m12:18:05.661867 [info ] [MainThread]: 
[0m12:18:05.663862 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:18:05.665864 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_5_products_total_sales__total_sales_0.d3462b3b57"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_5_products`
  
  where not(total_sales total_sales >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_53d9d0761651e2acd9611a042b182945.sql
[0m12:18:05.667863 [info ] [MainThread]: 
[0m12:18:05.669871 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_53d9d0761651e2acd9611a042b182945.sql
[0m12:18:05.676892 [info ] [MainThread]: 
[0m12:18:05.678862 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:18:05.680878 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>'. SQLSTATE: 42601 (line 18, pos 36)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_orders__total_orders_0.08d7bb49d4"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_customers`
  
  where not(total_orders total_orders > 0)
  ------------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_837145e0920d813dbd0319ae1c97969b.sql
[0m12:18:05.683862 [info ] [MainThread]: 
[0m12:18:05.684860 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_837145e0920d813dbd0319ae1c97969b.sql
[0m12:18:05.691893 [info ] [MainThread]: 
[0m12:18:05.694866 [error] [MainThread]: [31mFailure in test dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)[0m
[0m12:18:05.697863 [error] [MainThread]:   Database Error in test dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0 (dbt_databricks_cicd/models\mart\databricks\schema.yml)
  
  [PARSE_SYNTAX_ERROR] Syntax error at or near '>='. SQLSTATE: 42601 (line 18, pos 34)
  
  == SQL ==
  /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.dbt_utils_expression_is_true_top_customers_total_spent__total_spent_0.9290dc4343"} */
  
      select
        count(*) as failures,
        count(*) != 0 as should_warn,
        count(*) != 0 as should_error
      from (
        
      
    
  
  
  
  select
      1
  from `workspace`.`default`.`top_customers`
  
  where not(total_spent total_spent >= 0)
  ----------------------------------^^^
  
  
    
    
        
      ) dbt_internal_test
  
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_2a6b4bf5f333b9ab281e1669bb988c44.sql
[0m12:18:05.700866 [info ] [MainThread]: 
[0m12:18:05.703872 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\mart\databricks\schema.yml\dbt_utils_expression_is_true_t_2a6b4bf5f333b9ab281e1669bb988c44.sql
[0m12:18:05.708885 [info ] [MainThread]: 
[0m12:18:05.711866 [info ] [MainThread]: Done. PASS=39 WARN=0 ERROR=10 SKIP=0 NO-OP=0 TOTAL=49
[0m12:18:05.715860 [debug] [MainThread]: Command `dbt build` failed at 12:18:05.715860 after 36.61 seconds
[0m12:18:05.717863 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F41DC3DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F41DC3D10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000011F420210D0>]}
[0m12:18:05.721868 [debug] [MainThread]: Flushing usage events
[0m12:18:06.446817 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:56:05.367099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DB1AB7F50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DB1AB4CD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DB1AB5810>]}


============================== 12:56:05.375236 | 57947df1-e203-4795-954a-ff7dc7f7f8c4 ==============================
[0m12:56:05.375236 [info ] [MainThread]: Running with dbt=1.10.3
[0m12:56:05.377815 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --target databricks', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:56:07.092901 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m12:56:07.093902 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m12:56:07.095902 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m12:56:08.947985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '57947df1-e203-4795-954a-ff7dc7f7f8c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DBB10C6D0>]}
[0m12:56:09.073985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '57947df1-e203-4795-954a-ff7dc7f7f8c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DB1229A50>]}
[0m12:56:09.076982 [info ] [MainThread]: Registered adapter: databricks=1.10.4
[0m12:56:10.232977 [debug] [MainThread]: checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, vars: {}, profile: , target: databricks, version: 1.10.3
[0m12:56:10.766900 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:56:10.768905 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://dbt_databricks_cicd/models\mart\databricks\schema.yml
[0m12:56:11.726982 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m12:56:11.751980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '57947df1-e203-4795-954a-ff7dc7f7f8c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DBE23C0D0>]}
[0m12:56:11.932980 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m12:56:11.937979 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m12:56:12.030945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '57947df1-e203-4795-954a-ff7dc7f7f8c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DBE6EBED0>]}
[0m12:56:12.031947 [info ] [MainThread]: Found 9 models, 37 data tests, 1 source, 800 macros
[0m12:56:12.041945 [info ] [MainThread]: 
[0m12:56:12.043942 [info ] [MainThread]: Concurrency: 1 threads (target='databricks')
[0m12:56:12.044941 [info ] [MainThread]: 
[0m12:56:12.046846 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=0s, language=None, compute-name=) - Creating connection
[0m12:56:12.047844 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m12:56:12.062188 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace, idle-time=0s, language=None, compute-name=) - Creating connection
[0m12:56:12.063186 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace'
[0m12:56:12.064188 [debug] [ThreadPool]: Using databricks connection "list_workspace"
[0m12:56:12.065188 [debug] [ThreadPool]: On list_workspace: GetSchemas(database=workspace, schema=None)
[0m12:56:12.066188 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:56:13.431803 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f07794-df2a-1136-93ef-089a51f56a0b) - Created
[0m12:57:16.336869 [debug] [ThreadPool]: SQL status: OK in 64.270 seconds
[0m12:57:16.336869 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f07794-df2a-1136-93ef-089a51f56a0b, command-id=01f07795-035c-1b0d-9585-ea17d34a7385) - Closing
[0m12:57:16.336869 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace_default, idle-time=0s, language=None, compute-name=) - Creating connection
[0m12:57:16.336869 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace_default'
[0m12:57:16.368120 [debug] [ThreadPool]: Using databricks connection "list_workspace_default"
[0m12:57:16.383787 [debug] [ThreadPool]: On list_workspace_default: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "connection_name": "list_workspace_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'workspace' 
  AND table_schema = 'default'

  
[0m12:57:16.383787 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:57:17.102490 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f07795-0539-18a4-99b0-712fc1717806) - Created
[0m12:57:21.633055 [debug] [ThreadPool]: SQL status: OK in 5.250 seconds
[0m12:57:21.648544 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f07795-0539-18a4-99b0-712fc1717806, command-id=01f07795-055b-1158-964c-433d66ad4384) - Closing
[0m12:57:21.648544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '57947df1-e203-4795-954a-ff7dc7f7f8c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DBE3E0B90>]}
[0m12:57:21.664177 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m12:57:21.664177 [info ] [Thread-1 (]: 1 of 46 START sql view model default.src_ecommerce ............................. [RUN]
[0m12:59:45.018315 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_cicd.src_ecommerce, idle-time=0s, language=None, compute-name=) - Creating connection
[0m12:59:45.018315 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m12:59:45.033938 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m12:59:45.065192 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m12:59:45.080809 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m12:59:45.096433 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:59:45.096433 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m12:59:45.096433 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '57947df1-e203-4795-954a-ff7dc7f7f8c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DBE6F4410>]}
[0m12:59:45.143309 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`src_ecommerce`
[0m12:59:45.158937 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m12:59:45.158937 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.src_ecommerce"
[0m12:59:45.158937 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`src_ecommerce`
  
  as (
    SELECT * FROM default.sales_ecommerce
  )

[0m12:59:45.158937 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m12:59:45.909075 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca) - Created
[0m12:59:49.549558 [debug] [Thread-1 (]: SQL status: OK in 4.390 seconds
[0m12:59:49.549558 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-5e0d-1740-b416-77a882e204f5) - Closing
[0m12:59:49.565187 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:59:49.580827 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57947df1-e203-4795-954a-ff7dc7f7f8c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DBE6B1350>]}
[0m12:59:49.580827 [info ] [Thread-1 (]: 1 of 46 OK created sql view model default.src_ecommerce ........................ [[32mOK[0m in 4.56s]
[0m12:59:49.580827 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m12:59:49.580827 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m12:59:49.580827 [info ] [Thread-1 (]: 2 of 46 START sql view model default.stg_ecommerce ............................. [RUN]
[0m12:59:49.580827 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m12:59:49.596439 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=model.dbt_databricks_cicd.stg_ecommerce, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.src_ecommerce
[0m12:59:49.596439 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m12:59:49.596439 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:59:49.596439 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m12:59:49.612065 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m12:59:49.612065 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`stg_ecommerce`
[0m12:59:49.612065 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:59:49.612065 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m12:59:49.612065 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`stg_ecommerce`
  
  as (
    SELECT
  User_ID,
  Product_ID,
  Category,
  Price,
  Discount,
  Final_Price,
  Payment_Method,
  Purchase_Date
FROM `workspace`.`default`.`src_ecommerce`
  )

[0m12:59:50.377687 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m12:59:50.377687 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-6043-13da-bc7a-55dbd488e45b) - Closing
[0m12:59:50.393311 [debug] [Thread-1 (]: Applying tags to relation None
[0m12:59:50.393311 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57947df1-e203-4795-954a-ff7dc7f7f8c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DBEAE7F90>]}
[0m12:59:50.393311 [info ] [Thread-1 (]: 2 of 46 OK created sql view model default.stg_ecommerce ........................ [[32mOK[0m in 0.81s]
[0m12:59:50.393311 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m12:59:50.393311 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:59:50.393311 [info ] [Thread-1 (]: 3 of 46 START test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m12:59:50.393311 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6)
[0m12:59:50.393311 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.stg_ecommerce
[0m12:59:50.408971 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:59:50.424599 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m12:59:50.424599 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:59:50.471435 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m12:59:50.471435 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m12:59:50.471435 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from `workspace`.`default`.`stg_ecommerce`
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    'Credit Card','Net Banking','UPI','Debit Card','Cash on Delivery'
)



  
  
      
    ) dbt_internal_test
[0m12:59:51.846575 [debug] [Thread-1 (]: SQL status: OK in 1.380 seconds
[0m12:59:51.846575 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-60c4-1f7d-b55b-78866f89688c) - Closing
[0m12:59:51.846575 [info ] [Thread-1 (]: 3 of 46 PASS accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[32mPASS[0m in 1.45s]
[0m12:59:51.862072 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:59:51.862072 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m12:59:51.862072 [info ] [Thread-1 (]: 4 of 46 START test non_negative_stg_ecommerce_Discount ......................... [RUN]
[0m12:59:51.862072 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb)
[0m12:59:51.862072 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb, idle-time=0.015496015548706055s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m12:59:51.862072 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m12:59:51.877688 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m12:59:51.877688 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m12:59:51.877688 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m12:59:51.877688 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m12:59:51.877688 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`stg_ecommerce`
where TRY_CAST(REPLACE(Discount, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m12:59:52.659076 [debug] [Thread-1 (]: SQL status: OK in 0.780 seconds
[0m12:59:52.659076 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-619d-135b-84fd-7dec4f98c0ea) - Closing
[0m12:59:52.659076 [info ] [Thread-1 (]: 4 of 46 PASS non_negative_stg_ecommerce_Discount ............................... [[32mPASS[0m in 0.80s]
[0m12:59:52.674578 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m12:59:52.674578 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m12:59:52.674578 [info ] [Thread-1 (]: 5 of 46 START test non_negative_stg_ecommerce_Final_Price ...................... [RUN]
[0m12:59:52.674578 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7)
[0m12:59:52.674578 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7, idle-time=0.015502214431762695s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m12:59:52.674578 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m12:59:52.690187 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m12:59:52.690187 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m12:59:52.705819 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m12:59:52.705819 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m12:59:52.705819 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`stg_ecommerce`
where TRY_CAST(REPLACE(Final_Price, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m12:59:53.596577 [debug] [Thread-1 (]: SQL status: OK in 0.890 seconds
[0m12:59:53.596577 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-621a-12af-a8c4-90316c45713b) - Closing
[0m12:59:53.612064 [info ] [Thread-1 (]: 5 of 46 PASS non_negative_stg_ecommerce_Final_Price ............................ [[32mPASS[0m in 0.94s]
[0m12:59:53.612064 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m12:59:53.612064 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m12:59:53.612064 [info ] [Thread-1 (]: 6 of 46 START test non_negative_stg_ecommerce_Price ............................ [RUN]
[0m12:59:53.612064 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d)
[0m12:59:53.612064 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m12:59:53.612064 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m12:59:53.627690 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m12:59:53.627690 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m12:59:53.627690 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m12:59:53.627690 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m12:59:53.627690 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`stg_ecommerce`
where TRY_CAST(REPLACE(Price, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m12:59:54.533939 [debug] [Thread-1 (]: SQL status: OK in 0.880 seconds
[0m12:59:54.533939 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-62a7-1eee-a1b8-ce5645cd1422) - Closing
[0m12:59:54.533939 [info ] [Thread-1 (]: 6 of 46 PASS non_negative_stg_ecommerce_Price .................................. [[32mPASS[0m in 0.92s]
[0m12:59:54.533939 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m12:59:54.533939 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:59:54.533939 [info ] [Thread-1 (]: 7 of 46 START test not_null_stg_ecommerce_Category ............................. [RUN]
[0m12:59:54.533939 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14)
[0m12:59:54.533939 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m12:59:54.533939 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:59:54.549566 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m12:59:54.549566 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:59:54.565189 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m12:59:54.565189 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m12:59:54.565189 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`stg_ecommerce`
where Category is null



  
  
      
    ) dbt_internal_test
[0m12:59:55.284081 [debug] [Thread-1 (]: SQL status: OK in 0.720 seconds
[0m12:59:55.299560 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-6336-144a-ae15-94a2fa90d97f) - Closing
[0m12:59:55.299560 [info ] [Thread-1 (]: 7 of 46 PASS not_null_stg_ecommerce_Category ................................... [[32mPASS[0m in 0.77s]
[0m12:59:55.299560 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:59:55.299560 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:59:55.299560 [info ] [Thread-1 (]: 8 of 46 START test not_null_stg_ecommerce_Discount ............................. [RUN]
[0m12:59:55.299560 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836)
[0m12:59:55.299560 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m12:59:55.299560 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:59:55.315192 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m12:59:55.315192 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:59:55.315192 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m12:59:55.330824 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m12:59:55.330824 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Discount
from `workspace`.`default`.`stg_ecommerce`
where Discount is null



  
  
      
    ) dbt_internal_test
[0m12:59:56.096432 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m12:59:56.096432 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-63aa-123b-923c-c7fff5f03f06) - Closing
[0m12:59:56.096432 [info ] [Thread-1 (]: 8 of 46 PASS not_null_stg_ecommerce_Discount ................................... [[32mPASS[0m in 0.80s]
[0m12:59:56.096432 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:59:56.096432 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:59:56.096432 [info ] [Thread-1 (]: 9 of 46 START test not_null_stg_ecommerce_Final_Price .......................... [RUN]
[0m12:59:56.096432 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc)
[0m12:59:56.112065 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, idle-time=0.01563239097595215s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m12:59:56.112065 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:59:56.112065 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m12:59:56.112065 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:59:56.127683 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m12:59:56.127683 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m12:59:56.127683 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Final_Price
from `workspace`.`default`.`stg_ecommerce`
where Final_Price is null



  
  
      
    ) dbt_internal_test
[0m12:59:56.877826 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m12:59:56.877826 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-6423-1e13-8f24-ec187823bfca) - Closing
[0m12:59:56.877826 [info ] [Thread-1 (]: 9 of 46 PASS not_null_stg_ecommerce_Final_Price ................................ [[32mPASS[0m in 0.78s]
[0m12:59:56.877826 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:59:56.877826 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:59:56.893315 [info ] [Thread-1 (]: 10 of 46 START test not_null_stg_ecommerce_Payment_Method ...................... [RUN]
[0m12:59:56.893315 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d)
[0m12:59:56.893315 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, idle-time=0.015489339828491211s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m12:59:56.893315 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:59:56.893315 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m12:59:56.893315 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:59:56.908936 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m12:59:56.908936 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m12:59:56.908936 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`stg_ecommerce`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m12:59:57.659073 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m12:59:57.659073 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-649c-1af4-a095-b35372a9a717) - Closing
[0m12:59:57.674558 [info ] [Thread-1 (]: 10 of 46 PASS not_null_stg_ecommerce_Payment_Method ............................ [[32mPASS[0m in 0.78s]
[0m12:59:57.674558 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:59:57.674558 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:59:57.674558 [info ] [Thread-1 (]: 11 of 46 START test not_null_stg_ecommerce_Price ............................... [RUN]
[0m12:59:57.674558 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a)
[0m12:59:57.674558 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m12:59:57.674558 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:59:57.690197 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m12:59:57.690197 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:59:57.690197 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m12:59:57.690197 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m12:59:57.705827 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Price
from `workspace`.`default`.`stg_ecommerce`
where Price is null



  
  
      
    ) dbt_internal_test
[0m12:59:58.392901 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m12:59:58.392901 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-6514-1bd2-a2de-8592361cf5f8) - Closing
[0m12:59:58.392901 [info ] [Thread-1 (]: 11 of 46 PASS not_null_stg_ecommerce_Price ..................................... [[32mPASS[0m in 0.72s]
[0m12:59:58.392901 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:59:58.392901 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:59:58.392901 [info ] [Thread-1 (]: 12 of 46 START test not_null_stg_ecommerce_Product_ID .......................... [RUN]
[0m12:59:58.392901 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c)
[0m12:59:58.392901 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m12:59:58.392901 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:59:58.408524 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m12:59:58.408524 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:59:58.424153 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m12:59:58.424153 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m12:59:58.424153 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Product_ID
from `workspace`.`default`.`stg_ecommerce`
where Product_ID is null



  
  
      
    ) dbt_internal_test
[0m12:59:59.111643 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m12:59:59.111643 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-6583-127b-b388-b437b55b41d0) - Closing
[0m12:59:59.111643 [info ] [Thread-1 (]: 12 of 46 PASS not_null_stg_ecommerce_Product_ID ................................ [[32mPASS[0m in 0.72s]
[0m12:59:59.127271 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:59:59.127271 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:59:59.127271 [info ] [Thread-1 (]: 13 of 46 START test not_null_stg_ecommerce_Purchase_Date ....................... [RUN]
[0m12:59:59.127271 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307)
[0m12:59:59.127271 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, idle-time=0.01562786102294922s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m12:59:59.127271 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:59:59.142907 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m12:59:59.142907 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:59:59.158523 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m12:59:59.158523 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m12:59:59.158523 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Purchase_Date
from `workspace`.`default`.`stg_ecommerce`
where Purchase_Date is null



  
  
      
    ) dbt_internal_test
[0m12:59:59.908522 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m12:59:59.908522 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-65f3-1030-a896-8904cbe4e99c) - Closing
[0m12:59:59.908522 [info ] [Thread-1 (]: 13 of 46 PASS not_null_stg_ecommerce_Purchase_Date ............................. [[32mPASS[0m in 0.78s]
[0m12:59:59.908522 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:59:59.924152 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:59:59.924152 [info ] [Thread-1 (]: 14 of 46 START test not_null_stg_ecommerce_User_ID ............................. [RUN]
[0m12:59:59.924152 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, now test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf)
[0m12:59:59.924152 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, idle-time=0.01563096046447754s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m12:59:59.924152 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:59:59.939770 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m12:59:59.939770 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m12:59:59.955397 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m12:59:59.955397 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m12:59:59.955397 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`stg_ecommerce`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m13:00:00.752267 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m13:00:00.752267 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-666d-16be-a011-8c6f76ac35d0) - Closing
[0m13:00:00.752267 [info ] [Thread-1 (]: 14 of 46 PASS not_null_stg_ecommerce_User_ID ................................... [[32mPASS[0m in 0.83s]
[0m13:00:00.752267 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m13:00:00.752267 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m13:00:00.767900 [info ] [Thread-1 (]: 15 of 46 START test unique_stg_ecommerce_Product_ID ............................ [RUN]
[0m13:00:00.767900 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, now test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1)
[0m13:00:00.767900 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1, idle-time=0.015633106231689453s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m13:00:00.767900 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m13:00:00.783525 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m13:00:00.799144 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m13:00:00.799144 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m13:00:00.799144 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m13:00:00.814772 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    Product_ID as unique_field,
    count(*) as n_records

from `workspace`.`default`.`stg_ecommerce`
where Product_ID is not null
group by Product_ID
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m13:00:01.609204 [debug] [Thread-1 (]: SQL status: OK in 0.790 seconds
[0m13:00:01.624781 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-66f0-1dce-8804-31fa344efe8c) - Closing
[0m13:00:01.624781 [info ] [Thread-1 (]: 15 of 46 PASS unique_stg_ecommerce_Product_ID .................................. [[32mPASS[0m in 0.86s]
[0m13:00:01.624781 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m13:00:01.624781 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_discount_by_category
[0m13:00:01.624781 [info ] [Thread-1 (]: 16 of 46 START sql view model default.avg_discount_by_category ................. [RUN]
[0m13:00:01.624781 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1, now model.dbt_databricks_cicd.avg_discount_by_category)
[0m13:00:01.640406 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=model.dbt_databricks_cicd.avg_discount_by_category, idle-time=0.015624523162841797s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m13:00:01.640406 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_discount_by_category
[0m13:00:01.640406 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m13:00:01.640406 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_discount_by_category
[0m13:00:01.656034 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m13:00:01.656034 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`avg_discount_by_category`
[0m13:00:01.656034 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m13:00:01.656034 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.avg_discount_by_category"
[0m13:00:01.656034 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_discount_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.avg_discount_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`avg_discount_by_category`
  
  as (
    SELECT
  Category,
  ROUND(AVG(CAST(`Discount` AS DOUBLE)), 2) AS avg_discount_percent
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY avg_discount_percent DESC
  )

[0m13:00:02.468525 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m13:00:02.484158 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-6771-12e5-8cdb-be1dc2f39ac4) - Closing
[0m13:00:02.484158 [debug] [Thread-1 (]: Applying tags to relation None
[0m13:00:02.484158 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57947df1-e203-4795-954a-ff7dc7f7f8c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DB156AF50>]}
[0m13:00:02.484158 [info ] [Thread-1 (]: 16 of 46 OK created sql view model default.avg_discount_by_category ............ [[32mOK[0m in 0.86s]
[0m13:00:02.484158 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_discount_by_category
[0m13:00:02.499789 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m13:00:02.499789 [info ] [Thread-1 (]: 17 of 46 START sql view model default.avg_ticket_by_category ................... [RUN]
[0m13:00:02.499789 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_discount_by_category, now model.dbt_databricks_cicd.avg_ticket_by_category)
[0m13:00:02.499789 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=model.dbt_databricks_cicd.avg_ticket_by_category, idle-time=0.01563119888305664s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.avg_discount_by_category
[0m13:00:02.499789 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_ticket_by_category
[0m13:00:02.515408 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m13:00:02.515408 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_ticket_by_category
[0m13:00:02.531032 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m13:00:02.546668 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`avg_ticket_by_category`
[0m13:00:02.546668 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m13:00:02.546668 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m13:00:02.546668 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_ticket_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.avg_ticket_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`avg_ticket_by_category`
  
  as (
    SELECT
  Category,
  ROUND(AVG(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS avg_ticket
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY avg_ticket DESC
  )

[0m13:00:03.343673 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m13:00:03.359158 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-67f9-15db-b7e4-464eb19c7661) - Closing
[0m13:00:03.359158 [debug] [Thread-1 (]: Applying tags to relation None
[0m13:00:03.359158 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57947df1-e203-4795-954a-ff7dc7f7f8c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DB156A750>]}
[0m13:00:03.359158 [info ] [Thread-1 (]: 17 of 46 OK created sql view model default.avg_ticket_by_category .............. [[32mOK[0m in 0.86s]
[0m13:00:03.359158 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m13:00:03.359158 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.monthly_revenue
[0m13:00:03.359158 [info ] [Thread-1 (]: 18 of 46 START sql view model default.monthly_revenue .......................... [RUN]
[0m13:00:03.359158 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_ticket_by_category, now model.dbt_databricks_cicd.monthly_revenue)
[0m13:00:03.359158 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=model.dbt_databricks_cicd.monthly_revenue, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.avg_ticket_by_category
[0m13:00:03.359158 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.monthly_revenue
[0m13:00:03.374780 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.monthly_revenue"
[0m13:00:03.374780 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.monthly_revenue
[0m13:00:03.374780 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m13:00:03.390448 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`monthly_revenue`
[0m13:00:03.390448 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.monthly_revenue"
[0m13:00:03.390448 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.monthly_revenue"
[0m13:00:03.390448 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.monthly_revenue: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.monthly_revenue"} */

  
  
  
  create or replace view `workspace`.`default`.`monthly_revenue`
  
  as (
    SELECT
  CAST(DATE_TRUNC('month', CAST(Purchase_Date AS DATE)) AS DATE) AS month,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS monthly_revenue
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY 1
ORDER BY 1
  )

[0m13:00:04.218672 [debug] [Thread-1 (]: SQL status: OK in 0.830 seconds
[0m13:00:04.218672 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-6879-1249-8678-821cb58c79c2) - Closing
[0m13:00:04.218672 [debug] [Thread-1 (]: Applying tags to relation None
[0m13:00:04.218672 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57947df1-e203-4795-954a-ff7dc7f7f8c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DBEAFE210>]}
[0m13:00:04.218672 [info ] [Thread-1 (]: 18 of 46 OK created sql view model default.monthly_revenue ..................... [[32mOK[0m in 0.86s]
[0m13:00:04.218672 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.monthly_revenue
[0m13:00:04.234156 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.payment_distribution
[0m13:00:04.234156 [info ] [Thread-1 (]: 19 of 46 START sql view model default.payment_distribution ..................... [RUN]
[0m13:00:04.234156 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.monthly_revenue, now model.dbt_databricks_cicd.payment_distribution)
[0m13:00:04.234156 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=model.dbt_databricks_cicd.payment_distribution, idle-time=0.015483856201171875s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.monthly_revenue
[0m13:00:04.234156 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.payment_distribution
[0m13:00:04.249776 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.payment_distribution"
[0m13:00:04.265403 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.payment_distribution
[0m13:00:04.265403 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m13:00:04.281030 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`payment_distribution`
[0m13:00:04.281030 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.payment_distribution"
[0m13:00:04.281030 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.payment_distribution"
[0m13:00:04.281030 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.payment_distribution: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.payment_distribution"} */

  
  
  
  create or replace view `workspace`.`default`.`payment_distribution`
  
  as (
    SELECT
  Payment_Method,
  COUNT(*) AS total_transactions,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_value
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Payment_Method
ORDER BY total_value DESC
  )

[0m13:00:05.015542 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m13:00:05.015542 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-6900-1ab2-97f8-61879b184d5b) - Closing
[0m13:00:05.015542 [debug] [Thread-1 (]: Applying tags to relation None
[0m13:00:05.015542 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57947df1-e203-4795-954a-ff7dc7f7f8c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DBEAFA010>]}
[0m13:00:05.015542 [info ] [Thread-1 (]: 19 of 46 OK created sql view model default.payment_distribution ................ [[32mOK[0m in 0.78s]
[0m13:00:05.015542 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.payment_distribution
[0m13:00:05.015542 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.sales_by_category
[0m13:00:05.031064 [info ] [Thread-1 (]: 20 of 46 START sql view model default.sales_by_category ........................ [RUN]
[0m13:00:05.031064 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.payment_distribution, now model.dbt_databricks_cicd.sales_by_category)
[0m13:00:05.031064 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=model.dbt_databricks_cicd.sales_by_category, idle-time=0.015522480010986328s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.payment_distribution
[0m13:00:05.031064 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.sales_by_category
[0m13:00:05.031064 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.sales_by_category"
[0m13:00:05.046657 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.sales_by_category
[0m13:00:05.046657 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m13:00:05.046657 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`sales_by_category`
[0m13:00:05.046657 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.sales_by_category"
[0m13:00:05.062281 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.sales_by_category"
[0m13:00:05.062281 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.sales_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.sales_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`sales_by_category`
  
  as (
    SELECT
  Category,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_revenue
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY total_revenue DESC
  )

[0m13:00:05.754911 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m13:00:05.754911 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-6976-1bf8-aa5f-e4d85c6e2160) - Closing
[0m13:00:05.770398 [debug] [Thread-1 (]: Applying tags to relation None
[0m13:00:05.770398 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57947df1-e203-4795-954a-ff7dc7f7f8c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DB159A210>]}
[0m13:00:05.770398 [info ] [Thread-1 (]: 20 of 46 OK created sql view model default.sales_by_category ................... [[32mOK[0m in 0.74s]
[0m13:00:05.770398 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.sales_by_category
[0m13:00:05.770398 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_5_products
[0m13:00:05.770398 [info ] [Thread-1 (]: 21 of 46 START sql view model default.top_5_products ........................... [RUN]
[0m13:00:05.770398 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.sales_by_category, now model.dbt_databricks_cicd.top_5_products)
[0m13:00:05.770398 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=model.dbt_databricks_cicd.top_5_products, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.sales_by_category
[0m13:00:05.786021 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_5_products
[0m13:00:05.786021 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_5_products"
[0m13:00:05.786021 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_5_products
[0m13:00:05.801649 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m13:00:05.801649 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`top_5_products`
[0m13:00:05.801649 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_5_products"
[0m13:00:05.801649 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.top_5_products"
[0m13:00:05.801649 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_5_products: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.top_5_products"} */

  
  
  
  create or replace view `workspace`.`default`.`top_5_products`
  
  as (
    WITH base AS (
    SELECT
        product_id,
        ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_sales
    FROM `workspace`.`default`.`stg_ecommerce`
    GROUP BY product_id
)

SELECT
    product_id,
    total_sales
FROM base
ORDER BY total_sales DESC
LIMIT 5
  )

[0m13:00:06.536165 [debug] [Thread-1 (]: SQL status: OK in 0.720 seconds
[0m13:00:06.536165 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-69e9-1adb-afa9-49303e402428) - Closing
[0m13:00:06.536165 [debug] [Thread-1 (]: Applying tags to relation None
[0m13:00:06.536165 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57947df1-e203-4795-954a-ff7dc7f7f8c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DBE421F50>]}
[0m13:00:06.536165 [info ] [Thread-1 (]: 21 of 46 OK created sql view model default.top_5_products ...................... [[32mOK[0m in 0.77s]
[0m13:00:06.551649 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_5_products
[0m13:00:06.551649 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_customers
[0m13:00:06.551649 [info ] [Thread-1 (]: 22 of 46 START sql view model default.top_customers ............................ [RUN]
[0m13:00:06.551649 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_5_products, now model.dbt_databricks_cicd.top_customers)
[0m13:00:06.551649 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=model.dbt_databricks_cicd.top_customers, idle-time=0.015483617782592773s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.top_5_products
[0m13:00:06.551649 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_customers
[0m13:00:06.567328 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_customers"
[0m13:00:06.567328 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_customers
[0m13:00:06.567328 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m13:00:06.567328 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`top_customers`
[0m13:00:06.567328 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_customers"
[0m13:00:06.582895 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.top_customers"
[0m13:00:06.582895 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_customers: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.top_customers"} */

  
  
  
  create or replace view `workspace`.`default`.`top_customers`
  
  as (
    SELECT
  User_ID,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_spent
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY User_ID
ORDER BY total_spent DESC
LIMIT 10
  )

[0m13:00:07.317413 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m13:00:07.317413 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-6a5f-1121-8b34-ec18570ebd7c) - Closing
[0m13:00:07.332897 [debug] [Thread-1 (]: Applying tags to relation None
[0m13:00:07.332897 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '57947df1-e203-4795-954a-ff7dc7f7f8c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DBE07CE90>]}
[0m13:00:07.332897 [info ] [Thread-1 (]: 22 of 46 OK created sql view model default.top_customers ....................... [[32mOK[0m in 0.78s]
[0m13:00:07.332897 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_customers
[0m13:00:07.332897 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m13:00:07.332897 [info ] [Thread-1 (]: 23 of 46 START test non_negative_avg_discount_by_category_avg_discount_percent . [RUN]
[0m13:00:07.332897 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_customers, now test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f)
[0m13:00:07.332897 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.top_customers
[0m13:00:07.348521 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m13:00:07.348521 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"
[0m13:00:07.348521 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m13:00:07.364150 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"
[0m13:00:07.364150 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"
[0m13:00:07.364150 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`avg_discount_by_category`
where TRY_CAST(REPLACE(avg_discount_percent, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m13:00:12.171447 [debug] [Thread-1 (]: SQL status: OK in 4.810 seconds
[0m13:00:12.171447 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-6ad7-1be8-8e0b-9426ae895c25) - Closing
[0m13:00:12.171447 [info ] [Thread-1 (]: 23 of 46 PASS non_negative_avg_discount_by_category_avg_discount_percent ....... [[32mPASS[0m in 4.84s]
[0m13:00:12.187074 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m13:00:12.187074 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m13:00:12.187074 [info ] [Thread-1 (]: 24 of 46 START test not_null_avg_discount_by_category_Category ................. [RUN]
[0m13:00:12.187074 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b)
[0m13:00:12.187074 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, idle-time=0.015627622604370117s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m13:00:12.202698 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m13:00:12.218340 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m13:00:12.218340 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m13:00:12.233951 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m13:00:12.249573 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m13:00:12.249573 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_discount_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m13:00:13.015197 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m13:00:13.030823 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-6dc1-17c7-8322-3f3009893f0a) - Closing
[0m13:00:13.030823 [info ] [Thread-1 (]: 24 of 46 PASS not_null_avg_discount_by_category_Category ....................... [[32mPASS[0m in 0.84s]
[0m13:00:13.030823 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m13:00:13.030823 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m13:00:13.030823 [info ] [Thread-1 (]: 25 of 46 START test not_null_avg_discount_by_category_avg_discount_percent ..... [RUN]
[0m13:00:13.046447 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101)
[0m13:00:13.046447 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, idle-time=0.015624284744262695s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m13:00:13.046447 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m13:00:13.062072 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m13:00:13.062072 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m13:00:13.077702 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m13:00:13.077702 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m13:00:13.077702 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_discount_percent
from `workspace`.`default`.`avg_discount_by_category`
where avg_discount_percent is null



  
  
      
    ) dbt_internal_test
[0m13:00:13.921586 [debug] [Thread-1 (]: SQL status: OK in 0.840 seconds
[0m13:00:13.921586 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-6e3f-1726-8f61-62e9e411b483) - Closing
[0m13:00:13.921586 [info ] [Thread-1 (]: 25 of 46 PASS not_null_avg_discount_by_category_avg_discount_percent ........... [[32mPASS[0m in 0.88s]
[0m13:00:13.937073 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m13:00:13.937073 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m13:00:13.937073 [info ] [Thread-1 (]: 26 of 46 START test non_negative_avg_ticket_by_category_avg_ticket ............. [RUN]
[0m13:00:13.937073 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, now test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095)
[0m13:00:13.937073 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095, idle-time=0.015486955642700195s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m13:00:13.937073 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m13:00:13.952702 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"
[0m13:00:13.952702 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m13:00:13.952702 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"
[0m13:00:13.968367 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"
[0m13:00:13.968367 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`avg_ticket_by_category`
where TRY_CAST(REPLACE(avg_ticket, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m13:00:15.062076 [debug] [Thread-1 (]: SQL status: OK in 1.090 seconds
[0m13:00:15.062076 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-6ec8-17b0-9e27-63c68a7b921a) - Closing
[0m13:00:15.062076 [info ] [Thread-1 (]: 26 of 46 PASS non_negative_avg_ticket_by_category_avg_ticket ................... [[32mPASS[0m in 1.13s]
[0m13:00:15.062076 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m13:00:15.062076 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m13:00:15.062076 [info ] [Thread-1 (]: 27 of 46 START test not_null_avg_ticket_by_category_Category ................... [RUN]
[0m13:00:15.077695 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f)
[0m13:00:15.077695 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, idle-time=0.015619516372680664s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m13:00:15.077695 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m13:00:15.077695 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m13:00:15.077695 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m13:00:15.093360 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m13:00:15.093360 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m13:00:15.093360 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_ticket_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m13:00:15.843324 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m13:00:15.843324 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-6f73-1604-b0db-09bf129d03d5) - Closing
[0m13:00:15.843324 [info ] [Thread-1 (]: 27 of 46 PASS not_null_avg_ticket_by_category_Category ......................... [[32mPASS[0m in 0.77s]
[0m13:00:15.843324 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m13:00:15.843324 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m13:00:15.843324 [info ] [Thread-1 (]: 28 of 46 START test not_null_avg_ticket_by_category_avg_ticket ................. [RUN]
[0m13:00:15.843324 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41)
[0m13:00:15.858951 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, idle-time=0.01562643051147461s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m13:00:15.858951 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m13:00:15.858951 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m13:00:15.874580 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m13:00:15.874580 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m13:00:15.874580 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m13:00:15.874580 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_ticket
from `workspace`.`default`.`avg_ticket_by_category`
where avg_ticket is null



  
  
      
    ) dbt_internal_test
[0m13:00:16.624714 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m13:00:16.624714 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-6fe9-1a5d-83e4-0186f0bf70cf) - Closing
[0m13:00:16.624714 [info ] [Thread-1 (]: 28 of 46 PASS not_null_avg_ticket_by_category_avg_ticket ....................... [[32mPASS[0m in 0.78s]
[0m13:00:16.640194 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m13:00:16.640194 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m13:00:16.640194 [info ] [Thread-1 (]: 29 of 46 START test non_negative_monthly_revenue_monthly_revenue ............... [RUN]
[0m13:00:16.640194 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, now test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294)
[0m13:00:16.640194 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294, idle-time=0.015479803085327148s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m13:00:16.640194 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m13:00:16.655835 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"
[0m13:00:16.655835 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m13:00:16.655835 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"
[0m13:00:16.655835 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"
[0m13:00:16.655835 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`monthly_revenue`
where TRY_CAST(REPLACE(monthly_revenue, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m13:00:17.905960 [debug] [Thread-1 (]: SQL status: OK in 1.230 seconds
[0m13:00:17.905960 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-7062-129d-98df-3e8d9fba2226) - Closing
[0m13:00:17.905960 [info ] [Thread-1 (]: 29 of 46 PASS non_negative_monthly_revenue_monthly_revenue ..................... [[32mPASS[0m in 1.27s]
[0m13:00:17.921448 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m13:00:17.921448 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m13:00:17.921448 [info ] [Thread-1 (]: 30 of 46 START test not_null_monthly_revenue_month ............................. [RUN]
[0m13:00:17.921448 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294, now test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b)
[0m13:00:17.921448 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, idle-time=0.0154876708984375s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m13:00:17.921448 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m13:00:17.937075 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m13:00:17.937075 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m13:00:17.937075 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m13:00:17.952737 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m13:00:17.952737 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select month
from `workspace`.`default`.`monthly_revenue`
where month is null



  
  
      
    ) dbt_internal_test
[0m13:00:18.655967 [debug] [Thread-1 (]: SQL status: OK in 0.700 seconds
[0m13:00:18.671456 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-7126-1eea-98c5-9646be1eed98) - Closing
[0m13:00:18.671456 [info ] [Thread-1 (]: 30 of 46 PASS not_null_monthly_revenue_month ................................... [[32mPASS[0m in 0.75s]
[0m13:00:18.671456 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m13:00:18.671456 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m13:00:18.671456 [info ] [Thread-1 (]: 31 of 46 START test not_null_monthly_revenue_monthly_revenue ................... [RUN]
[0m13:00:18.671456 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, now test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b)
[0m13:00:18.671456 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m13:00:18.671456 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m13:00:18.687074 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m13:00:18.687074 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m13:00:18.702697 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m13:00:18.702697 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m13:00:18.702697 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select monthly_revenue
from `workspace`.`default`.`monthly_revenue`
where monthly_revenue is null



  
  
      
    ) dbt_internal_test
[0m13:00:19.530835 [debug] [Thread-1 (]: SQL status: OK in 0.830 seconds
[0m13:00:19.530835 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-7199-162f-b26e-e8037f85936c) - Closing
[0m13:00:19.530835 [info ] [Thread-1 (]: 31 of 46 PASS not_null_monthly_revenue_monthly_revenue ......................... [[32mPASS[0m in 0.86s]
[0m13:00:19.530835 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m13:00:19.530835 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m13:00:19.546445 [info ] [Thread-1 (]: 32 of 46 START test non_negative_payment_distribution_total_value .............. [RUN]
[0m13:00:19.546445 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, now test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282)
[0m13:00:19.546445 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282, idle-time=0.015609979629516602s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m13:00:19.546445 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m13:00:19.546445 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"
[0m13:00:19.562078 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m13:00:19.562078 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"
[0m13:00:19.562078 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"
[0m13:00:19.562078 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`payment_distribution`
where TRY_CAST(REPLACE(total_value, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m13:00:20.593320 [debug] [Thread-1 (]: SQL status: OK in 1.030 seconds
[0m13:00:20.593320 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-721e-1894-a413-fefb15334847) - Closing
[0m13:00:20.593320 [info ] [Thread-1 (]: 32 of 46 PASS non_negative_payment_distribution_total_value .................... [[32mPASS[0m in 1.05s]
[0m13:00:20.593320 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m13:00:20.593320 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m13:00:20.593320 [info ] [Thread-1 (]: 33 of 46 START test not_null_payment_distribution_Payment_Method ............... [RUN]
[0m13:00:20.608947 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282, now test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae)
[0m13:00:20.608947 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, idle-time=0.015626907348632812s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m13:00:20.608947 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m13:00:20.608947 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m13:00:20.608947 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m13:00:20.624571 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m13:00:20.624571 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m13:00:20.624571 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`payment_distribution`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m13:00:21.327693 [debug] [Thread-1 (]: SQL status: OK in 0.700 seconds
[0m13:00:21.327693 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-72bf-1839-9ef5-b18eba5488c4) - Closing
[0m13:00:21.327693 [info ] [Thread-1 (]: 33 of 46 PASS not_null_payment_distribution_Payment_Method ..................... [[32mPASS[0m in 0.72s]
[0m13:00:21.327693 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m13:00:21.327693 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m13:00:21.327693 [info ] [Thread-1 (]: 34 of 46 START test not_null_payment_distribution_total_transactions ........... [RUN]
[0m13:00:21.343338 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, now test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8)
[0m13:00:21.343338 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, idle-time=0.015645980834960938s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m13:00:21.343338 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m13:00:21.343338 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m13:00:21.343338 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m13:00:21.358964 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m13:00:21.358964 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m13:00:21.358964 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_transactions
from `workspace`.`default`.`payment_distribution`
where total_transactions is null



  
  
      
    ) dbt_internal_test
[0m13:00:22.233952 [debug] [Thread-1 (]: SQL status: OK in 0.870 seconds
[0m13:00:22.233952 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-732e-14f5-9fcc-473d2dcdc56c) - Closing
[0m13:00:22.233952 [info ] [Thread-1 (]: 34 of 46 PASS not_null_payment_distribution_total_transactions ................. [[32mPASS[0m in 0.89s]
[0m13:00:22.249572 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m13:00:22.249572 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m13:00:22.249572 [info ] [Thread-1 (]: 35 of 46 START test not_null_payment_distribution_total_value .................. [RUN]
[0m13:00:22.249572 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, now test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03)
[0m13:00:22.249572 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, idle-time=0.015620231628417969s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m13:00:22.265197 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m13:00:22.280821 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m13:00:22.280821 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m13:00:22.296454 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m13:00:22.296454 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m13:00:22.296454 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_value
from `workspace`.`default`.`payment_distribution`
where total_value is null



  
  
      
    ) dbt_internal_test
[0m13:00:23.124678 [debug] [Thread-1 (]: SQL status: OK in 0.830 seconds
[0m13:00:23.140199 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-73bd-1751-87d0-bf1744e27eac) - Closing
[0m13:00:23.140199 [info ] [Thread-1 (]: 35 of 46 PASS not_null_payment_distribution_total_value ........................ [[32mPASS[0m in 0.89s]
[0m13:00:23.140199 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m13:00:23.140199 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m13:00:23.140199 [info ] [Thread-1 (]: 36 of 46 START test non_negative_sales_by_category_total_revenue ............... [RUN]
[0m13:00:23.140199 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, now test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41)
[0m13:00:23.140199 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m13:00:23.140199 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m13:00:23.155820 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"
[0m13:00:23.155820 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m13:00:23.171470 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"
[0m13:00:23.171470 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"
[0m13:00:23.171470 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`sales_by_category`
where TRY_CAST(REPLACE(total_revenue, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m13:00:24.234083 [debug] [Thread-1 (]: SQL status: OK in 1.060 seconds
[0m13:00:24.234083 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-7443-170f-89a6-2ffb8ed0b72e) - Closing
[0m13:00:24.249578 [info ] [Thread-1 (]: 36 of 46 PASS non_negative_sales_by_category_total_revenue ..................... [[32mPASS[0m in 1.11s]
[0m13:00:24.249578 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m13:00:24.249578 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m13:00:24.249578 [info ] [Thread-1 (]: 37 of 46 START test not_null_sales_by_category_Category ........................ [RUN]
[0m13:00:24.249578 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41, now test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507)
[0m13:00:24.265202 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, idle-time=0.015624284744262695s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m13:00:24.265202 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m13:00:24.280827 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m13:00:24.280827 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m13:00:24.280827 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m13:00:24.296447 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m13:00:24.296447 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`sales_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m13:00:24.983951 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m13:00:24.983951 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-74ee-1ae5-941f-906a64ed4ec7) - Closing
[0m13:00:24.983951 [info ] [Thread-1 (]: 37 of 46 PASS not_null_sales_by_category_Category .............................. [[32mPASS[0m in 0.73s]
[0m13:00:24.983951 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m13:00:24.983951 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m13:00:24.999581 [info ] [Thread-1 (]: 38 of 46 START test not_null_sales_by_category_total_orders .................... [RUN]
[0m13:00:24.999581 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, now test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e)
[0m13:00:24.999581 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, idle-time=0.01563096046447754s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m13:00:24.999581 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m13:00:24.999581 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m13:00:25.015212 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m13:00:25.015212 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m13:00:25.015212 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m13:00:25.015212 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`sales_by_category`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m13:00:25.807886 [debug] [Thread-1 (]: SQL status: OK in 0.790 seconds
[0m13:00:25.807886 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-755d-1788-8df0-c8ef97a49bac) - Closing
[0m13:00:25.807886 [info ] [Thread-1 (]: 38 of 46 PASS not_null_sales_by_category_total_orders .......................... [[32mPASS[0m in 0.81s]
[0m13:00:25.807886 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m13:00:25.823413 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m13:00:25.823413 [info ] [Thread-1 (]: 39 of 46 START test not_null_sales_by_category_total_revenue ................... [RUN]
[0m13:00:25.823413 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, now test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd)
[0m13:00:25.823413 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, idle-time=0.015526771545410156s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m13:00:25.823413 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m13:00:25.839018 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m13:00:25.839018 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m13:00:25.839018 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m13:00:25.839018 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m13:00:25.839018 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_revenue
from `workspace`.`default`.`sales_by_category`
where total_revenue is null



  
  
      
    ) dbt_internal_test
[0m13:00:26.587593 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m13:00:26.603221 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-75db-170a-b476-f4b581190719) - Closing
[0m13:00:26.603221 [info ] [Thread-1 (]: 39 of 46 PASS not_null_sales_by_category_total_revenue ......................... [[32mPASS[0m in 0.78s]
[0m13:00:26.603221 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m13:00:26.603221 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m13:00:26.603221 [info ] [Thread-1 (]: 40 of 46 START test non_negative_top_5_products_total_sales .................... [RUN]
[0m13:00:26.603221 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, now test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34)
[0m13:00:26.603221 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m13:00:26.603221 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m13:00:26.618811 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"
[0m13:00:26.618811 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m13:00:26.634501 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"
[0m13:00:26.634501 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"
[0m13:00:26.634501 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`top_5_products`
where TRY_CAST(REPLACE(total_sales, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m13:00:27.671905 [debug] [Thread-1 (]: SQL status: OK in 1.040 seconds
[0m13:00:27.671905 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-7653-19c4-92aa-4047854b6211) - Closing
[0m13:00:27.671905 [info ] [Thread-1 (]: 40 of 46 PASS non_negative_top_5_products_total_sales .......................... [[32mPASS[0m in 1.07s]
[0m13:00:27.687391 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m13:00:27.687391 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m13:00:27.687391 [info ] [Thread-1 (]: 41 of 46 START test not_null_top_5_products_product_id ......................... [RUN]
[0m13:00:27.687391 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34, now test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe)
[0m13:00:27.687391 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, idle-time=0.015485286712646484s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m13:00:27.687391 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m13:00:27.703061 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m13:00:27.703061 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m13:00:27.703061 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m13:00:27.703061 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m13:00:27.703061 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select product_id
from `workspace`.`default`.`top_5_products`
where product_id is null



  
  
      
    ) dbt_internal_test
[0m13:00:28.421806 [debug] [Thread-1 (]: SQL status: OK in 0.720 seconds
[0m13:00:28.421806 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-76f7-100f-8f31-abf8e4e2f7f3) - Closing
[0m13:00:28.421806 [info ] [Thread-1 (]: 41 of 46 PASS not_null_top_5_products_product_id ............................... [[32mPASS[0m in 0.73s]
[0m13:00:28.421806 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m13:00:28.421806 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m13:00:28.421806 [info ] [Thread-1 (]: 42 of 46 START test not_null_top_5_products_total_sales ........................ [RUN]
[0m13:00:28.437432 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, now test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818)
[0m13:00:28.437432 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, idle-time=0.015625476837158203s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m13:00:28.437432 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m13:00:28.437432 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m13:00:28.437432 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m13:00:28.453022 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m13:00:28.453022 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m13:00:28.453022 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_sales
from `workspace`.`default`.`top_5_products`
where total_sales is null



  
  
      
    ) dbt_internal_test
[0m13:00:29.203156 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m13:00:29.203156 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-7769-11c2-82f0-67aa4be81a28) - Closing
[0m13:00:29.203156 [info ] [Thread-1 (]: 42 of 46 PASS not_null_top_5_products_total_sales .............................. [[32mPASS[0m in 0.78s]
[0m13:00:29.218684 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m13:00:29.218684 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m13:00:29.218684 [info ] [Thread-1 (]: 43 of 46 START test non_negative_top_customers_total_spent ..................... [RUN]
[0m13:00:29.218684 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, now test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667)
[0m13:00:29.218684 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667, idle-time=0.015527725219726562s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m13:00:29.218684 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m13:00:29.234313 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"
[0m13:00:29.234313 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m13:00:29.249895 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"
[0m13:00:29.265516 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"
[0m13:00:29.265516 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`top_customers`
where TRY_CAST(REPLACE(total_spent, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m13:00:30.187509 [debug] [Thread-1 (]: SQL status: OK in 0.920 seconds
[0m13:00:30.203059 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-77e8-18eb-84a3-07d4452fb3fb) - Closing
[0m13:00:30.203059 [info ] [Thread-1 (]: 43 of 46 PASS non_negative_top_customers_total_spent ........................... [[32mPASS[0m in 0.98s]
[0m13:00:30.203059 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m13:00:30.203059 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m13:00:30.203059 [info ] [Thread-1 (]: 44 of 46 START test not_null_top_customers_User_ID ............................. [RUN]
[0m13:00:30.203059 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667, now test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0)
[0m13:00:30.203059 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m13:00:30.218641 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m13:00:30.218641 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m13:00:30.218641 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m13:00:30.234325 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m13:00:30.234325 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m13:00:30.234325 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`top_customers`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m13:00:30.937433 [debug] [Thread-1 (]: SQL status: OK in 0.670 seconds
[0m13:00:30.937433 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-787a-1569-bc48-c63a82490c5e) - Closing
[0m13:00:30.937433 [info ] [Thread-1 (]: 44 of 46 PASS not_null_top_customers_User_ID ................................... [[32mPASS[0m in 0.73s]
[0m13:00:30.937433 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m13:00:30.937433 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m13:00:30.937433 [info ] [Thread-1 (]: 45 of 46 START test not_null_top_customers_total_orders ........................ [RUN]
[0m13:00:30.937433 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, now test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746)
[0m13:00:30.937433 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m13:00:30.953055 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m13:00:30.953055 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m13:00:30.968649 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m13:00:30.968649 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m13:00:30.968649 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m13:00:30.968649 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`top_customers`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m13:00:31.800621 [debug] [Thread-1 (]: SQL status: OK in 0.820 seconds
[0m13:00:31.800621 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-78e9-1f47-9702-ebf689feeffb) - Closing
[0m13:00:31.800621 [info ] [Thread-1 (]: 45 of 46 PASS not_null_top_customers_total_orders .............................. [[32mPASS[0m in 0.86s]
[0m13:00:31.800621 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m13:00:31.800621 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m13:00:31.800621 [info ] [Thread-1 (]: 46 of 46 START test not_null_top_customers_total_spent ......................... [RUN]
[0m13:00:31.816249 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, now test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73)
[0m13:00:31.816249 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, name=test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73, idle-time=0.01562786102294922s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m13:00:31.816249 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m13:00:31.816249 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m13:00:31.816249 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m13:00:31.831875 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m13:00:31.831875 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m13:00:31.831875 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_spent
from `workspace`.`default`.`top_customers`
where total_spent is null



  
  
      
    ) dbt_internal_test
[0m13:00:32.550761 [debug] [Thread-1 (]: SQL status: OK in 0.720 seconds
[0m13:00:32.550761 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07795-5ded-1b25-9037-865bd2b363ca, command-id=01f07795-796c-1fa1-a708-6659867f5814) - Closing
[0m13:00:32.566250 [info ] [Thread-1 (]: 46 of 46 PASS not_null_top_customers_total_spent ............................... [[32mPASS[0m in 0.75s]
[0m13:00:32.566250 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m13:00:32.566250 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=190.90207314491272s, language=None, compute-name=) - Recreating due to idleness
[0m13:00:32.566250 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=0s, language=None, compute-name=) - Reset connection handle
[0m13:00:32.566250 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=0s, language=None, compute-name=) - Reusing connection previously named master
[0m13:00:32.566250 [debug] [MainThread]: Connection 'master' was properly closed.
[0m13:00:32.581871 [debug] [MainThread]: Connection 'list_workspace' was properly closed.
[0m13:00:32.581871 [debug] [MainThread]: On list_workspace: Close
[0m13:00:32.581871 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07794-df2a-1136-93ef-089a51f56a0b) - Closing
[0m13:00:33.285136 [debug] [MainThread]: Connection 'list_workspace_default' was properly closed.
[0m13:00:33.285136 [debug] [MainThread]: On list_workspace_default: Close
[0m13:00:33.285136 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07795-0539-18a4-99b0-712fc1717806) - Closing
[0m13:00:33.977454 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73' was properly closed.
[0m13:00:33.977454 [debug] [MainThread]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: Close
[0m13:00:33.977454 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07795-5ded-1b25-9037-865bd2b363ca) - Closing
[0m13:00:34.196330 [info ] [MainThread]: 
[0m13:00:34.196330 [info ] [MainThread]: Finished running 37 data tests, 9 view models in 0 hours 4 minutes and 22.15 seconds (262.15s).
[0m13:00:34.211818 [debug] [MainThread]: Command end result
[0m13:00:34.349524 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m13:00:34.354524 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m13:00:34.371345 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m13:00:34.373350 [info ] [MainThread]: 
[0m13:00:34.374356 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:00:34.377636 [info ] [MainThread]: 
[0m13:00:34.377636 [info ] [MainThread]: Done. PASS=46 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=46
[0m13:00:34.377636 [debug] [MainThread]: Command `dbt build` succeeded at 13:00:34.377636 after 269.17 seconds
[0m13:00:34.377636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DAAFF3DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DB18A4950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018DAB2510D0>]}
[0m13:00:34.377636 [debug] [MainThread]: Flushing usage events
[0m13:00:35.768300 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:10:11.162371 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107DCDE6110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107DCDE4A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107DCDE6B90>]}


============================== 10:10:11.162371 | 7d9c65a4-740a-46dc-9a10-20be8cdab995 ==============================
[0m10:10:11.162371 [info ] [MainThread]: Running with dbt=1.10.3
[0m10:10:11.177999 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt build --target databricks', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:10:17.894535 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m10:10:17.894535 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m10:10:17.894535 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m10:10:24.082034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7d9c65a4-740a-46dc-9a10-20be8cdab995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107E8086510>]}
[0m10:10:24.207043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7d9c65a4-740a-46dc-9a10-20be8cdab995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107DC559B10>]}
[0m10:10:24.207043 [info ] [MainThread]: Registered adapter: databricks=1.10.4
[0m10:10:25.519585 [debug] [MainThread]: checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, vars: {}, profile: , target: databricks, version: 1.10.3
[0m10:10:29.269537 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 1 files added, 2 files changed.
[0m10:10:29.269537 [debug] [MainThread]: Partial parsing: added file: dbt_databricks_cicd://macros\non_negative.sql
[0m10:10:29.285163 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://dbt_databricks_cicd/models\mart\databricks\schema.yml
[0m10:10:29.285163 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://dbt_databricks_cicd/models\raw\databricks\schema.yml
[0m10:10:29.285163 [debug] [MainThread]: Partial parsing: deleted file: dbt_databricks_cicd://macros\tests\non_negative.sql
[0m10:10:30.566423 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m10:10:30.582049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7d9c65a4-740a-46dc-9a10-20be8cdab995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107E97F7A50>]}
[0m10:10:30.769544 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m10:10:30.800788 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m10:10:31.003909 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7d9c65a4-740a-46dc-9a10-20be8cdab995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107DC8F1690>]}
[0m10:10:31.003909 [info ] [MainThread]: Found 9 models, 48 data tests, 1 source, 800 macros
[0m10:10:31.003909 [info ] [MainThread]: 
[0m10:10:31.003909 [info ] [MainThread]: Concurrency: 1 threads (target='databricks')
[0m10:10:31.019542 [info ] [MainThread]: 
[0m10:10:31.019542 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:10:31.019542 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:10:31.035158 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:10:31.035158 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace'
[0m10:10:31.035158 [debug] [ThreadPool]: Using databricks connection "list_workspace"
[0m10:10:31.035158 [debug] [ThreadPool]: On list_workspace: GetSchemas(database=workspace, schema=None)
[0m10:10:31.035158 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:10:32.425783 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f07c34-b857-1425-9fbf-2829f9d5217d) - Created
[0m10:11:35.346001 [debug] [ThreadPool]: SQL status: OK in 64.310 seconds
[0m10:11:35.349003 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f07c34-b857-1425-9fbf-2829f9d5217d, command-id=01f07c34-dc90-1fe4-8523-11a61ef20bda) - Closing
[0m10:11:35.354013 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace_default, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:11:35.355005 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace_default'
[0m10:11:35.377043 [debug] [ThreadPool]: Using databricks connection "list_workspace_default"
[0m10:11:35.378044 [debug] [ThreadPool]: On list_workspace_default: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "connection_name": "list_workspace_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'workspace' 
  AND table_schema = 'default'

  
[0m10:11:35.380008 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:11:36.167539 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f07c34-de71-110b-b136-e8cf7359cb0c) - Created
[0m10:11:41.532493 [debug] [ThreadPool]: SQL status: OK in 6.150 seconds
[0m10:11:41.579427 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f07c34-de71-110b-b136-e8cf7359cb0c, command-id=01f07c34-de93-1acf-8f09-753e048ec493) - Closing
[0m10:11:41.829506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7d9c65a4-740a-46dc-9a10-20be8cdab995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107E9745A50>]}
[0m10:11:41.845114 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m10:11:41.845114 [info ] [Thread-1 (]: 1 of 57 START sql view model default.src_ecommerce ............................. [RUN]
[0m10:11:41.860623 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_cicd.src_ecommerce, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:11:41.860623 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m10:11:41.860623 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m10:11:41.876248 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m10:11:41.876248 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m10:11:41.907491 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:11:41.907491 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m10:11:41.907491 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '7d9c65a4-740a-46dc-9a10-20be8cdab995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107DC938690>]}
[0m10:11:41.938742 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`src_ecommerce`
[0m10:11:41.954365 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m10:11:41.954365 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.src_ecommerce"
[0m10:11:41.954365 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`src_ecommerce`
  
  as (
    SELECT * FROM default.sales_ecommerce
  )

[0m10:11:41.954365 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:11:42.735737 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee) - Created
[0m10:11:47.391861 [debug] [Thread-1 (]: SQL status: OK in 5.440 seconds
[0m10:11:47.391861 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-e27f-1dd7-b5a1-0f39e6c7b5e3) - Closing
[0m10:11:47.407504 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:11:47.423237 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c65a4-740a-46dc-9a10-20be8cdab995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107E973BA10>]}
[0m10:11:47.423237 [info ] [Thread-1 (]: 1 of 57 OK created sql view model default.src_ecommerce ........................ [[32mOK[0m in 5.55s]
[0m10:11:47.423237 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m10:11:47.423237 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m10:11:47.423237 [info ] [Thread-1 (]: 2 of 57 START test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m10:11:47.423237 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931)
[0m10:11:47.423237 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931, idle-time=0.015733718872070312s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.src_ecommerce
[0m10:11:47.438749 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m10:11:47.438749 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"
[0m10:11:47.438749 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m10:11:47.485627 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"
[0m10:11:47.485627 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"
[0m10:11:47.485627 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from `my_db`.`dbo`.`ecommerce`
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    'Credit Card','Net Banking','UPI','Debit Card','Cash on Delivery'
)



  
  
      
    ) dbt_internal_test
[0m10:11:48.407493 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from `my_db`.`dbo`.`ecommerce`
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    'Credit Card','Net Banking','UPI','Debit Card','Cash on Delivery'
)



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:744)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f07c34-e555-1184-8add-47dd33edd390
[0m10:11:48.626277 [debug] [Thread-1 (]: Database Error in test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_accepted_values_sqlserv_de5401a33d073d59e860da01ddb6837b.sql
[0m10:11:48.626277 [error] [Thread-1 (]: 2 of 57 ERROR source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[31mERROR[0m in 1.20s]
[0m10:11:48.641874 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m10:11:48.641874 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m10:11:48.641874 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931' to be skipped because of status 'error'.  Reason: Database Error in test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_accepted_values_sqlserv_de5401a33d073d59e860da01ddb6837b.sql.
[0m10:11:48.641874 [info ] [Thread-1 (]: 3 of 57 START test source_not_null_sqlserver_data_ecommerce_Category ........... [RUN]
[0m10:11:48.641874 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023)
[0m10:11:48.641874 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023, idle-time=0.015597105026245117s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.380ed0b931
[0m10:11:48.641874 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m10:11:48.657503 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"
[0m10:11:48.657503 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m10:11:48.673128 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"
[0m10:11:48.673128 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"
[0m10:11:48.673128 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `my_db`.`dbo`.`ecommerce`
where Category is null



  
  
      
    ) dbt_internal_test
[0m10:11:49.267006 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `my_db`.`dbo`.`ecommerce`
where Category is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:744)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f07c34-e608-1a5a-9665-779ed8d3f35e
[0m10:11:49.267006 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Category (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Category.sql
[0m10:11:49.282505 [error] [Thread-1 (]: 3 of 57 ERROR source_not_null_sqlserver_data_ecommerce_Category ................ [[31mERROR[0m in 0.64s]
[0m10:11:49.282505 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m10:11:49.282505 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m10:11:49.282505 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Category (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Category.sql.
[0m10:11:49.282505 [info ] [Thread-1 (]: 4 of 57 START test source_not_null_sqlserver_data_ecommerce_Discount ........... [RUN]
[0m10:11:49.282505 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6)
[0m10:11:49.282505 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Category.9952791023
[0m10:11:49.282505 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m10:11:49.298118 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"
[0m10:11:49.298118 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m10:11:49.313780 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"
[0m10:11:49.313780 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"
[0m10:11:49.313780 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Discount
from `my_db`.`dbo`.`ecommerce`
where Discount is null



  
  
      
    ) dbt_internal_test
[0m10:11:49.860756 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Discount
from `my_db`.`dbo`.`ecommerce`
where Discount is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:744)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f07c34-e66b-107d-a17c-9b633863eb55
[0m10:11:49.860756 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Discount (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Discount.sql
[0m10:11:49.860756 [error] [Thread-1 (]: 4 of 57 ERROR source_not_null_sqlserver_data_ecommerce_Discount ................ [[31mERROR[0m in 0.58s]
[0m10:11:49.860756 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m10:11:49.876246 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Discount (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Discount.sql.
[0m10:11:49.860756 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m10:11:49.876246 [info ] [Thread-1 (]: 5 of 57 START test source_not_null_sqlserver_data_ecommerce_Final_Price ........ [RUN]
[0m10:11:49.876246 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823)
[0m10:11:49.876246 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823, idle-time=0.015490293502807617s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Discount.325e0946d6
[0m10:11:49.876246 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m10:11:49.876246 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"
[0m10:11:49.891921 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m10:11:49.891921 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"
[0m10:11:49.891921 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"
[0m10:11:49.907498 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Final_Price
from `my_db`.`dbo`.`ecommerce`
where Final_Price is null



  
  
      
    ) dbt_internal_test
[0m10:11:50.438880 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Final_Price
from `my_db`.`dbo`.`ecommerce`
where Final_Price is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:744)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f07c34-e6c4-1cd4-8ffd-f5d35cf8ba95
[0m10:11:50.438880 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Final_Price (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Final_Price.sql
[0m10:11:50.438880 [error] [Thread-1 (]: 5 of 57 ERROR source_not_null_sqlserver_data_ecommerce_Final_Price ............. [[31mERROR[0m in 0.56s]
[0m10:11:50.438880 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m10:11:50.438880 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m10:11:50.438880 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Final_Price (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Final_Price.sql.
[0m10:11:50.454371 [info ] [Thread-1 (]: 6 of 57 START test source_not_null_sqlserver_data_ecommerce_Payment_Method ..... [RUN]
[0m10:11:50.454371 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32)
[0m10:11:50.454371 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32, idle-time=0.015491008758544922s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Final_Price.02a9691823
[0m10:11:50.454371 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m10:11:50.454371 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"
[0m10:11:50.454371 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m10:11:50.469991 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"
[0m10:11:50.469991 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"
[0m10:11:50.469991 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `my_db`.`dbo`.`ecommerce`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m10:11:51.032632 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `my_db`.`dbo`.`ecommerce`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:744)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f07c34-e71b-1e1e-993c-f6122a494617
[0m10:11:51.048123 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Payment_Method (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Payment_Method.sql
[0m10:11:51.048123 [error] [Thread-1 (]: 6 of 57 ERROR source_not_null_sqlserver_data_ecommerce_Payment_Method .......... [[31mERROR[0m in 0.59s]
[0m10:11:51.048123 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m10:11:51.048123 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m10:11:51.048123 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Payment_Method (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Payment_Method.sql.
[0m10:11:51.048123 [info ] [Thread-1 (]: 7 of 57 START test source_not_null_sqlserver_data_ecommerce_Price .............. [RUN]
[0m10:11:51.048123 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a)
[0m10:11:51.048123 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Payment_Method.5fc9e11b32
[0m10:11:51.048123 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m10:11:51.063746 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"
[0m10:11:51.063746 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m10:11:51.079372 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"
[0m10:11:51.079372 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"
[0m10:11:51.079372 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Price
from `my_db`.`dbo`.`ecommerce`
where Price is null



  
  
      
    ) dbt_internal_test
[0m10:11:51.657493 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Price
from `my_db`.`dbo`.`ecommerce`
where Price is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:744)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f07c34-e778-1711-a693-f0f4c5deab25
[0m10:11:51.657493 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Price (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Price.sql
[0m10:11:51.657493 [error] [Thread-1 (]: 7 of 57 ERROR source_not_null_sqlserver_data_ecommerce_Price ................... [[31mERROR[0m in 0.61s]
[0m10:11:51.657493 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m10:11:51.657493 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m10:11:51.657493 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Price (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Price.sql.
[0m10:11:51.673118 [info ] [Thread-1 (]: 8 of 57 START test source_not_null_sqlserver_data_ecommerce_Product_ID ......... [RUN]
[0m10:11:51.673118 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd)
[0m10:11:51.673118 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd, idle-time=0.015624284744262695s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Price.ffd98ee55a
[0m10:11:51.673118 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m10:11:51.673118 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"
[0m10:11:51.673118 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m10:11:51.688741 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"
[0m10:11:51.688741 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"
[0m10:11:51.688741 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Product_ID
from `my_db`.`dbo`.`ecommerce`
where Product_ID is null



  
  
      
    ) dbt_internal_test
[0m10:11:52.204510 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Product_ID
from `my_db`.`dbo`.`ecommerce`
where Product_ID is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:744)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f07c34-e7d5-1ab2-8de4-d0d5c5c444fa
[0m10:11:52.219989 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Product_ID.sql
[0m10:11:52.219989 [error] [Thread-1 (]: 8 of 57 ERROR source_not_null_sqlserver_data_ecommerce_Product_ID .............. [[31mERROR[0m in 0.55s]
[0m10:11:52.219989 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m10:11:52.219989 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m10:11:52.219989 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Product_ID.sql.
[0m10:11:52.219989 [info ] [Thread-1 (]: 9 of 57 START test source_not_null_sqlserver_data_ecommerce_Purchase_Date ...... [RUN]
[0m10:11:52.219989 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23)
[0m10:11:52.235623 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23, idle-time=0.015633821487426758s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Product_ID.1a04fc4acd
[0m10:11:52.235623 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m10:11:52.235623 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"
[0m10:11:52.251365 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m10:11:52.251365 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"
[0m10:11:52.251365 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"
[0m10:11:52.266872 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Purchase_Date
from `my_db`.`dbo`.`ecommerce`
where Purchase_Date is null



  
  
      
    ) dbt_internal_test
[0m10:11:52.766872 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Purchase_Date
from `my_db`.`dbo`.`ecommerce`
where Purchase_Date is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:744)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f07c34-e82c-16ee-b565-74ffc9c84209
[0m10:11:52.766872 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_Purchase_Date (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Purchase_Date.sql
[0m10:11:52.766872 [error] [Thread-1 (]: 9 of 57 ERROR source_not_null_sqlserver_data_ecommerce_Purchase_Date ........... [[31mERROR[0m in 0.55s]
[0m10:11:52.766872 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m10:11:52.766872 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m10:11:52.766872 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_Purchase_Date (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Purchase_Date.sql.
[0m10:11:52.766872 [info ] [Thread-1 (]: 10 of 57 START test source_not_null_sqlserver_data_ecommerce_User_ID ........... [RUN]
[0m10:11:52.782493 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23, now test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325)
[0m10:11:52.782493 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325, idle-time=0.015620946884155273s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_Purchase_Date.ff0ecd3a23
[0m10:11:52.782493 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m10:11:52.782493 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"
[0m10:11:52.782493 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m10:11:52.798114 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"
[0m10:11:52.798114 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"
[0m10:11:52.798114 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `my_db`.`dbo`.`ecommerce`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m10:11:53.298113 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `my_db`.`dbo`.`ecommerce`
where User_ID is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:744)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f07c34-e87f-1f64-991b-be1407574a83
[0m10:11:53.313745 [debug] [Thread-1 (]: Database Error in test source_not_null_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_User_ID.sql
[0m10:11:53.313745 [error] [Thread-1 (]: 10 of 57 ERROR source_not_null_sqlserver_data_ecommerce_User_ID ................ [[31mERROR[0m in 0.53s]
[0m10:11:53.313745 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m10:11:53.313745 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_Product_ID.8085cf0ae3
[0m10:11:53.313745 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325' to be skipped because of status 'error'.  Reason: Database Error in test source_not_null_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_User_ID.sql.
[0m10:11:53.313745 [info ] [Thread-1 (]: 11 of 57 START test source_unique_sqlserver_data_ecommerce_Product_ID .......... [RUN]
[0m10:11:53.313745 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325, now test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_Product_ID.8085cf0ae3)
[0m10:11:53.313745 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_Product_ID.8085cf0ae3, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_not_null_sqlserver_data_ecommerce_User_ID.6485382325
[0m10:11:53.313745 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_Product_ID.8085cf0ae3
[0m10:11:53.329402 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_Product_ID.8085cf0ae3"
[0m10:11:53.438863 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_Product_ID.8085cf0ae3
[0m10:11:53.454369 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_Product_ID.8085cf0ae3"
[0m10:11:53.454369 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_Product_ID.8085cf0ae3"
[0m10:11:53.454369 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_Product_ID.8085cf0ae3: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_Product_ID.8085cf0ae3"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    Product_ID as unique_field,
    count(*) as n_records

from `my_db`.`dbo`.`ecommerce`
where Product_ID is not null
group by Product_ID
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m10:11:53.970134 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_Product_ID.8085cf0ae3"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    Product_ID as unique_field,
    count(*) as n_records

from `my_db`.`dbo`.`ecommerce`
where Product_ID is not null
group by Product_ID
having count(*) > 1



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 18 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 18 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:744)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 18 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f07c34-e8e3-1b63-9d60-4432ef0816fc
[0m10:11:53.985625 [debug] [Thread-1 (]: Database Error in test source_unique_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 18 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_unique_sqlserver_data_ecommerce_Product_ID.sql
[0m10:11:53.985625 [error] [Thread-1 (]: 11 of 57 ERROR source_unique_sqlserver_data_ecommerce_Product_ID ............... [[31mERROR[0m in 0.67s]
[0m10:11:53.985625 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_Product_ID.8085cf0ae3
[0m10:11:53.985625 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_User_ID.1062772225
[0m10:11:53.985625 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_Product_ID.8085cf0ae3' to be skipped because of status 'error'.  Reason: Database Error in test source_unique_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 18 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_unique_sqlserver_data_ecommerce_Product_ID.sql.
[0m10:11:53.985625 [info ] [Thread-1 (]: 12 of 57 START test source_unique_sqlserver_data_ecommerce_User_ID ............. [RUN]
[0m10:11:53.985625 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_Product_ID.8085cf0ae3, now test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_User_ID.1062772225)
[0m10:11:53.985625 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_User_ID.1062772225, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_Product_ID.8085cf0ae3
[0m10:11:53.985625 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_User_ID.1062772225
[0m10:11:54.001247 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_User_ID.1062772225"
[0m10:11:54.016871 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_User_ID.1062772225
[0m10:11:54.016871 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_User_ID.1062772225"
[0m10:11:54.016871 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_User_ID.1062772225"
[0m10:11:54.016871 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_User_ID.1062772225: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_User_ID.1062772225"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    User_ID as unique_field,
    count(*) as n_records

from `my_db`.`dbo`.`ecommerce`
where User_ID is not null
group by User_ID
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m10:11:54.548231 [debug] [Thread-1 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_User_ID.1062772225"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    User_ID as unique_field,
    count(*) as n_records

from `my_db`.`dbo`.`ecommerce`
where User_ID is not null
group by User_ID
having count(*) > 1



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 18 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 18 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:744)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 18 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f07c34-e939-1f15-be62-e9b550a48e7b
[0m10:11:54.548231 [debug] [Thread-1 (]: Database Error in test source_unique_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 18 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_unique_sqlserver_data_ecommerce_User_ID.sql
[0m10:11:54.563744 [error] [Thread-1 (]: 12 of 57 ERROR source_unique_sqlserver_data_ecommerce_User_ID .................. [[31mERROR[0m in 0.58s]
[0m10:11:54.563744 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_User_ID.1062772225
[0m10:11:54.563744 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m10:11:54.563744 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_User_ID.1062772225' to be skipped because of status 'error'.  Reason: Database Error in test source_unique_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 18 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_unique_sqlserver_data_ecommerce_User_ID.sql.
[0m10:11:54.563744 [info ] [Thread-1 (]: 13 of 57 START sql view model default.stg_ecommerce ............................ [RUN]
[0m10:11:54.563744 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_User_ID.1062772225, now model.dbt_databricks_cicd.stg_ecommerce)
[0m10:11:54.563744 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=model.dbt_databricks_cicd.stg_ecommerce, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.source_unique_sqlserver_data_ecommerce_User_ID.1062772225
[0m10:11:54.563744 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m10:11:54.579407 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:11:54.579407 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m10:11:54.595031 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:11:54.595031 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`stg_ecommerce`
[0m10:11:54.595031 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:11:54.595031 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:11:54.595031 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`stg_ecommerce`
  
  as (
    SELECT
  User_ID,
  Product_ID,
  Category,
  Price,
  Discount,
  Final_Price,
  Payment_Method,
  Purchase_Date
FROM `workspace`.`default`.`src_ecommerce`
  )

[0m10:11:55.548246 [debug] [Thread-1 (]: SQL status: OK in 0.950 seconds
[0m10:11:55.548246 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-e991-1da9-9ecf-0cbcca7a15b4) - Closing
[0m10:11:55.548246 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:11:55.548246 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c65a4-740a-46dc-9a10-20be8cdab995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107EA1F3890>]}
[0m10:11:55.548246 [info ] [Thread-1 (]: 13 of 57 OK created sql view model default.stg_ecommerce ....................... [[32mOK[0m in 0.98s]
[0m10:11:55.563738 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m10:11:55.563738 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m10:11:55.563738 [info ] [Thread-1 (]: 14 of 57 START test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m10:11:55.563738 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6)
[0m10:11:55.563738 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, idle-time=0.015492439270019531s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.stg_ecommerce
[0m10:11:55.563738 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m10:11:55.579375 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m10:11:55.579375 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m10:11:55.594998 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m10:11:55.594998 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m10:11:55.594998 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from `workspace`.`default`.`stg_ecommerce`
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    'Credit Card','Net Banking','UPI','Debit Card','Cash on Delivery'
)



  
  
      
    ) dbt_internal_test
[0m10:11:59.844990 [debug] [Thread-1 (]: SQL status: OK in 4.250 seconds
[0m10:11:59.844990 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-ea28-1de0-8c73-fba05f0059c7) - Closing
[0m10:11:59.860629 [info ] [Thread-1 (]: 14 of 57 PASS accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[32mPASS[0m in 4.30s]
[0m10:11:59.860629 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m10:11:59.860629 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m10:11:59.860629 [info ] [Thread-1 (]: 15 of 57 START test non_negative_stg_ecommerce_Discount ........................ [RUN]
[0m10:11:59.860629 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb)
[0m10:11:59.860629 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m10:11:59.860629 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m10:11:59.876247 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m10:11:59.876247 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m10:11:59.891875 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m10:11:59.891875 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m10:11:59.891875 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`stg_ecommerce`
where TRY_CAST(REPLACE(Discount, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:12:01.313790 [debug] [Thread-1 (]: SQL status: OK in 1.420 seconds
[0m10:12:01.313790 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-ecb9-1937-becc-90d1dad94211) - Closing
[0m10:12:01.329373 [info ] [Thread-1 (]: 15 of 57 PASS non_negative_stg_ecommerce_Discount .............................. [[32mPASS[0m in 1.45s]
[0m10:12:01.329373 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m10:12:01.329373 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m10:12:01.329373 [info ] [Thread-1 (]: 16 of 57 START test non_negative_stg_ecommerce_Final_Price ..................... [RUN]
[0m10:12:01.329373 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7)
[0m10:12:01.329373 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7, idle-time=0.015582084655761719s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m10:12:01.329373 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m10:12:01.345002 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m10:12:01.345002 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m10:12:01.360623 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m10:12:01.360623 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m10:12:01.360623 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`stg_ecommerce`
where TRY_CAST(REPLACE(Final_Price, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:12:02.345132 [debug] [Thread-1 (]: SQL status: OK in 0.980 seconds
[0m10:12:02.345132 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-ed99-1023-8d12-f2960d602d18) - Closing
[0m10:12:02.360626 [info ] [Thread-1 (]: 16 of 57 PASS non_negative_stg_ecommerce_Final_Price ........................... [[32mPASS[0m in 1.02s]
[0m10:12:02.360626 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m10:12:02.360626 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m10:12:02.360626 [info ] [Thread-1 (]: 17 of 57 START test non_negative_stg_ecommerce_Price ........................... [RUN]
[0m10:12:02.360626 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d)
[0m10:12:02.360626 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d, idle-time=0.01549386978149414s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m10:12:02.360626 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m10:12:02.376277 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m10:12:02.376277 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m10:12:02.376277 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m10:12:02.376277 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m10:12:02.376277 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`stg_ecommerce`
where TRY_CAST(REPLACE(Price, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:12:03.595133 [debug] [Thread-1 (]: SQL status: OK in 1.200 seconds
[0m10:12:03.595133 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-ee35-1f9d-8a6c-5870f07ff2a4) - Closing
[0m10:12:03.595133 [info ] [Thread-1 (]: 17 of 57 PASS non_negative_stg_ecommerce_Price ................................. [[32mPASS[0m in 1.23s]
[0m10:12:03.610619 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m10:12:03.610619 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m10:12:03.610619 [info ] [Thread-1 (]: 18 of 57 START test not_null_stg_ecommerce_Category ............................ [RUN]
[0m10:12:03.610619 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14)
[0m10:12:03.610619 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, idle-time=0.01548624038696289s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m10:12:03.610619 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m10:12:03.626255 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m10:12:03.626255 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m10:12:03.626255 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m10:12:03.626255 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m10:12:03.626255 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`stg_ecommerce`
where Category is null



  
  
      
    ) dbt_internal_test
[0m10:12:04.407634 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m10:12:04.423122 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-eef3-1e34-b2ca-da5af396b71a) - Closing
[0m10:12:04.423122 [info ] [Thread-1 (]: 18 of 57 PASS not_null_stg_ecommerce_Category .................................. [[32mPASS[0m in 0.81s]
[0m10:12:04.423122 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m10:12:04.423122 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m10:12:04.423122 [info ] [Thread-1 (]: 19 of 57 START test not_null_stg_ecommerce_Discount ............................ [RUN]
[0m10:12:04.423122 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836)
[0m10:12:04.423122 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m10:12:04.423122 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m10:12:04.438748 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m10:12:04.438748 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m10:12:04.454368 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m10:12:04.454368 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m10:12:04.454368 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Discount
from `workspace`.`default`.`stg_ecommerce`
where Discount is null



  
  
      
    ) dbt_internal_test
[0m10:12:05.438883 [debug] [Thread-1 (]: SQL status: OK in 0.980 seconds
[0m10:12:05.438883 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-ef71-1fab-8774-d2b35bfc628f) - Closing
[0m10:12:05.438883 [info ] [Thread-1 (]: 19 of 57 PASS not_null_stg_ecommerce_Discount .................................. [[32mPASS[0m in 1.02s]
[0m10:12:05.454370 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m10:12:05.454370 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m10:12:05.454370 [info ] [Thread-1 (]: 20 of 57 START test not_null_stg_ecommerce_Final_Price ......................... [RUN]
[0m10:12:05.454370 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc)
[0m10:12:05.454370 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, idle-time=0.015486478805541992s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m10:12:05.454370 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m10:12:05.469996 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m10:12:05.469996 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m10:12:05.469996 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m10:12:05.485621 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m10:12:05.485621 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Final_Price
from `workspace`.`default`.`stg_ecommerce`
where Final_Price is null



  
  
      
    ) dbt_internal_test
[0m10:12:06.251281 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m10:12:06.251281 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f00d-1e50-8b97-f9d4b1bd4386) - Closing
[0m10:12:06.266868 [info ] [Thread-1 (]: 20 of 57 PASS not_null_stg_ecommerce_Final_Price ............................... [[32mPASS[0m in 0.81s]
[0m10:12:06.266868 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m10:12:06.266868 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m10:12:06.266868 [info ] [Thread-1 (]: 21 of 57 START test not_null_stg_ecommerce_Payment_Method ...................... [RUN]
[0m10:12:06.266868 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d)
[0m10:12:06.266868 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m10:12:06.266868 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m10:12:06.282489 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m10:12:06.282489 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m10:12:06.282489 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m10:12:06.282489 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m10:12:06.298161 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`stg_ecommerce`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m10:12:07.094992 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m10:12:07.094992 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f088-1fa2-878f-b57d5c4d2020) - Closing
[0m10:12:07.094992 [info ] [Thread-1 (]: 21 of 57 PASS not_null_stg_ecommerce_Payment_Method ............................ [[32mPASS[0m in 0.83s]
[0m10:12:07.094992 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m10:12:07.094992 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m10:12:07.094992 [info ] [Thread-1 (]: 22 of 57 START test not_null_stg_ecommerce_Price ............................... [RUN]
[0m10:12:07.094992 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a)
[0m10:12:07.094992 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m10:12:07.110615 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m10:12:07.110615 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m10:12:07.110615 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m10:12:07.126239 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m10:12:07.126239 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m10:12:07.126239 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Price
from `workspace`.`default`.`stg_ecommerce`
where Price is null



  
  
      
    ) dbt_internal_test
[0m10:12:08.001282 [debug] [Thread-1 (]: SQL status: OK in 0.880 seconds
[0m10:12:08.001282 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f108-1bdc-b457-493d9da31580) - Closing
[0m10:12:08.001282 [info ] [Thread-1 (]: 22 of 57 PASS not_null_stg_ecommerce_Price ..................................... [[32mPASS[0m in 0.91s]
[0m10:12:08.001282 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m10:12:08.001282 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m10:12:08.016867 [info ] [Thread-1 (]: 23 of 57 START test not_null_stg_ecommerce_Product_ID .......................... [RUN]
[0m10:12:08.016867 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c)
[0m10:12:08.016867 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, idle-time=0.015584468841552734s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m10:12:08.016867 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m10:12:08.032507 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m10:12:08.032507 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m10:12:08.032507 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m10:12:08.032507 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m10:12:08.048119 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Product_ID
from `workspace`.`default`.`stg_ecommerce`
where Product_ID is null



  
  
      
    ) dbt_internal_test
[0m10:12:08.923114 [debug] [Thread-1 (]: SQL status: OK in 0.870 seconds
[0m10:12:08.938748 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f194-1d8c-8206-6d2a7d04e55c) - Closing
[0m10:12:08.938748 [info ] [Thread-1 (]: 23 of 57 PASS not_null_stg_ecommerce_Product_ID ................................ [[32mPASS[0m in 0.92s]
[0m10:12:08.938748 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m10:12:08.938748 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m10:12:08.938748 [info ] [Thread-1 (]: 24 of 57 START test not_null_stg_ecommerce_Purchase_Date ....................... [RUN]
[0m10:12:08.938748 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307)
[0m10:12:08.938748 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m10:12:08.938748 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m10:12:08.954378 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m10:12:08.954378 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m10:12:08.970032 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m10:12:08.970032 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m10:12:08.970032 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Purchase_Date
from `workspace`.`default`.`stg_ecommerce`
where Purchase_Date is null



  
  
      
    ) dbt_internal_test
[0m10:12:10.016861 [debug] [Thread-1 (]: SQL status: OK in 1.050 seconds
[0m10:12:10.016861 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f221-1a05-a915-c0834b044703) - Closing
[0m10:12:10.016861 [info ] [Thread-1 (]: 24 of 57 PASS not_null_stg_ecommerce_Purchase_Date ............................. [[32mPASS[0m in 1.08s]
[0m10:12:10.016861 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m10:12:10.016861 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m10:12:10.016861 [info ] [Thread-1 (]: 25 of 57 START test not_null_stg_ecommerce_User_ID ............................. [RUN]
[0m10:12:10.032496 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, now test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf)
[0m10:12:10.032496 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, idle-time=0.015634775161743164s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m10:12:10.032496 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m10:12:10.032496 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m10:12:10.048117 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m10:12:10.048117 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m10:12:10.048117 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m10:12:10.048117 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`stg_ecommerce`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m10:12:11.173121 [debug] [Thread-1 (]: SQL status: OK in 1.130 seconds
[0m10:12:11.173121 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f2c7-1966-8fb2-1337f095e418) - Closing
[0m10:12:11.173121 [info ] [Thread-1 (]: 25 of 57 PASS not_null_stg_ecommerce_User_ID ................................... [[32mPASS[0m in 1.14s]
[0m10:12:11.173121 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m10:12:11.173121 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m10:12:11.173121 [info ] [Thread-1 (]: 26 of 57 START test unique_stg_ecommerce_Product_ID ............................ [RUN]
[0m10:12:11.173121 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, now test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1)
[0m10:12:11.188747 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1, idle-time=0.015626907348632812s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m10:12:11.188747 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m10:12:11.188747 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m10:12:11.188747 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m10:12:11.204371 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m10:12:11.204371 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m10:12:11.204371 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    Product_ID as unique_field,
    count(*) as n_records

from `workspace`.`default`.`stg_ecommerce`
where Product_ID is not null
group by Product_ID
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m10:12:12.141996 [debug] [Thread-1 (]: SQL status: OK in 0.940 seconds
[0m10:12:12.157499 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f377-1b01-98bb-1bd91b33c020) - Closing
[0m10:12:12.157499 [info ] [Thread-1 (]: 26 of 57 PASS unique_stg_ecommerce_Product_ID .................................. [[32mPASS[0m in 0.98s]
[0m10:12:12.157499 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m10:12:12.157499 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_discount_by_category
[0m10:12:12.157499 [info ] [Thread-1 (]: 27 of 57 START sql view model default.avg_discount_by_category ................. [RUN]
[0m10:12:12.157499 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1, now model.dbt_databricks_cicd.avg_discount_by_category)
[0m10:12:12.157499 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=model.dbt_databricks_cicd.avg_discount_by_category, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m10:12:12.157499 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_discount_by_category
[0m10:12:12.173124 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m10:12:12.173124 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_discount_by_category
[0m10:12:12.173124 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:12:12.188745 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`avg_discount_by_category`
[0m10:12:12.188745 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m10:12:12.188745 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.avg_discount_by_category"
[0m10:12:12.188745 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_discount_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.avg_discount_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`avg_discount_by_category`
  
  as (
    SELECT
  Category,
  ROUND(AVG(CAST(`Discount` AS DOUBLE)), 2) AS avg_discount_percent
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY avg_discount_percent DESC
  )

[0m10:12:12.923157 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m10:12:12.923157 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f40d-1418-aeb3-ea83faf38e59) - Closing
[0m10:12:12.923157 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:12:12.923157 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c65a4-740a-46dc-9a10-20be8cdab995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107DC923490>]}
[0m10:12:12.923157 [info ] [Thread-1 (]: 27 of 57 OK created sql view model default.avg_discount_by_category ............ [[32mOK[0m in 0.77s]
[0m10:12:12.923157 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_discount_by_category
[0m10:12:12.938749 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:12:12.938749 [info ] [Thread-1 (]: 28 of 57 START sql view model default.avg_ticket_by_category ................... [RUN]
[0m10:12:12.938749 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_discount_by_category, now model.dbt_databricks_cicd.avg_ticket_by_category)
[0m10:12:12.938749 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=model.dbt_databricks_cicd.avg_ticket_by_category, idle-time=0.015592575073242188s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.avg_discount_by_category
[0m10:12:12.938749 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:12:12.954372 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m10:12:12.954372 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:12:12.954372 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:12:12.954372 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`avg_ticket_by_category`
[0m10:12:12.954372 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m10:12:12.969992 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m10:12:12.969992 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_ticket_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.avg_ticket_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`avg_ticket_by_category`
  
  as (
    SELECT
  Category,
  ROUND(AVG(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS avg_ticket
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY avg_ticket DESC
  )

[0m10:12:13.610756 [debug] [Thread-1 (]: SQL status: OK in 0.640 seconds
[0m10:12:13.610756 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f484-14d6-b783-70b0e429b08c) - Closing
[0m10:12:13.610756 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:12:13.610756 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c65a4-740a-46dc-9a10-20be8cdab995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107EA336550>]}
[0m10:12:13.610756 [info ] [Thread-1 (]: 28 of 57 OK created sql view model default.avg_ticket_by_category .............. [[32mOK[0m in 0.67s]
[0m10:12:13.626240 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:12:13.626240 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.monthly_revenue
[0m10:12:13.626240 [info ] [Thread-1 (]: 29 of 57 START sql view model default.monthly_revenue .......................... [RUN]
[0m10:12:13.626240 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_ticket_by_category, now model.dbt_databricks_cicd.monthly_revenue)
[0m10:12:13.626240 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=model.dbt_databricks_cicd.monthly_revenue, idle-time=0.01548314094543457s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:12:13.626240 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.monthly_revenue
[0m10:12:13.641879 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.monthly_revenue"
[0m10:12:13.641879 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.monthly_revenue
[0m10:12:13.641879 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:12:13.641879 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`monthly_revenue`
[0m10:12:13.641879 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.monthly_revenue"
[0m10:12:13.641879 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.monthly_revenue"
[0m10:12:13.657491 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.monthly_revenue: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.monthly_revenue"} */

  
  
  
  create or replace view `workspace`.`default`.`monthly_revenue`
  
  as (
    SELECT
  CAST(DATE_TRUNC('month', CAST(Purchase_Date AS DATE)) AS DATE) AS month,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS monthly_revenue
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY 1
ORDER BY 1
  )

[0m10:12:14.345076 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m10:12:14.345076 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f4ec-1380-8f4b-09d25a4224ab) - Closing
[0m10:12:14.345076 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:12:14.345076 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c65a4-740a-46dc-9a10-20be8cdab995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107DC8EA990>]}
[0m10:12:14.345076 [info ] [Thread-1 (]: 29 of 57 OK created sql view model default.monthly_revenue ..................... [[32mOK[0m in 0.72s]
[0m10:12:14.345076 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.monthly_revenue
[0m10:12:14.345076 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.payment_distribution
[0m10:12:14.345076 [info ] [Thread-1 (]: 30 of 57 START sql view model default.payment_distribution ..................... [RUN]
[0m10:12:14.360619 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.monthly_revenue, now model.dbt_databricks_cicd.payment_distribution)
[0m10:12:14.360619 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=model.dbt_databricks_cicd.payment_distribution, idle-time=0.015542745590209961s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.monthly_revenue
[0m10:12:14.360619 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.payment_distribution
[0m10:12:14.360619 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.payment_distribution"
[0m10:12:14.360619 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.payment_distribution
[0m10:12:14.376251 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:12:14.376251 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`payment_distribution`
[0m10:12:14.376251 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.payment_distribution"
[0m10:12:14.376251 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.payment_distribution"
[0m10:12:14.376251 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.payment_distribution: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.payment_distribution"} */

  
  
  
  create or replace view `workspace`.`default`.`payment_distribution`
  
  as (
    SELECT
  Payment_Method,
  COUNT(*) AS total_transactions,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_value
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Payment_Method
ORDER BY total_value DESC
  )

[0m10:12:15.095133 [debug] [Thread-1 (]: SQL status: OK in 0.720 seconds
[0m10:12:15.095133 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f55b-1c67-957d-4cd9d252b0ed) - Closing
[0m10:12:15.095133 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:12:15.095133 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c65a4-740a-46dc-9a10-20be8cdab995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107EA1F2BD0>]}
[0m10:12:15.095133 [info ] [Thread-1 (]: 30 of 57 OK created sql view model default.payment_distribution ................ [[32mOK[0m in 0.73s]
[0m10:12:15.095133 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.payment_distribution
[0m10:12:15.095133 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.sales_by_category
[0m10:12:15.110623 [info ] [Thread-1 (]: 31 of 57 START sql view model default.sales_by_category ........................ [RUN]
[0m10:12:15.110623 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.payment_distribution, now model.dbt_databricks_cicd.sales_by_category)
[0m10:12:15.110623 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=model.dbt_databricks_cicd.sales_by_category, idle-time=0.015489578247070312s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.payment_distribution
[0m10:12:15.110623 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.sales_by_category
[0m10:12:15.110623 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.sales_by_category"
[0m10:12:15.110623 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.sales_by_category
[0m10:12:15.126249 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:12:15.126249 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`sales_by_category`
[0m10:12:15.126249 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.sales_by_category"
[0m10:12:15.126249 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.sales_by_category"
[0m10:12:15.126249 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.sales_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.sales_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`sales_by_category`
  
  as (
    SELECT
  Category,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_revenue
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY total_revenue DESC
  )

[0m10:12:15.891870 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m10:12:15.891870 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f5ce-1348-8222-8c6076553637) - Closing
[0m10:12:15.891870 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:12:15.891870 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c65a4-740a-46dc-9a10-20be8cdab995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107EA3DB690>]}
[0m10:12:15.891870 [info ] [Thread-1 (]: 31 of 57 OK created sql view model default.sales_by_category ................... [[32mOK[0m in 0.78s]
[0m10:12:15.891870 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.sales_by_category
[0m10:12:15.891870 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_5_products
[0m10:12:15.891870 [info ] [Thread-1 (]: 32 of 57 START sql view model default.top_5_products ........................... [RUN]
[0m10:12:15.891870 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.sales_by_category, now model.dbt_databricks_cicd.top_5_products)
[0m10:12:15.891870 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=model.dbt_databricks_cicd.top_5_products, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.sales_by_category
[0m10:12:15.907498 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_5_products
[0m10:12:15.907498 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_5_products"
[0m10:12:15.907498 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_5_products
[0m10:12:15.907498 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:12:15.923122 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`top_5_products`
[0m10:12:15.923122 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_5_products"
[0m10:12:15.923122 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.top_5_products"
[0m10:12:15.923122 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_5_products: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.top_5_products"} */

  
  
  
  create or replace view `workspace`.`default`.`top_5_products`
  
  as (
    WITH base AS (
    SELECT
        product_id,
        ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_sales
    FROM `workspace`.`default`.`stg_ecommerce`
    GROUP BY product_id
)

SELECT
    product_id,
    total_sales
FROM base
ORDER BY total_sales DESC
LIMIT 5
  )

[0m10:12:16.626238 [debug] [Thread-1 (]: SQL status: OK in 0.700 seconds
[0m10:12:16.626238 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f647-142a-8a37-0a31df053d62) - Closing
[0m10:12:16.626238 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:12:16.626238 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c65a4-740a-46dc-9a10-20be8cdab995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107EA3DAD10>]}
[0m10:12:16.626238 [info ] [Thread-1 (]: 32 of 57 OK created sql view model default.top_5_products ...................... [[32mOK[0m in 0.73s]
[0m10:12:16.641866 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_5_products
[0m10:12:16.641866 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_customers
[0m10:12:16.641866 [info ] [Thread-1 (]: 33 of 57 START sql view model default.top_customers ............................ [RUN]
[0m10:12:16.641866 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_5_products, now model.dbt_databricks_cicd.top_customers)
[0m10:12:16.641866 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=model.dbt_databricks_cicd.top_customers, idle-time=0.01562786102294922s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.top_5_products
[0m10:12:16.641866 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_customers
[0m10:12:16.641866 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_customers"
[0m10:12:16.657500 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_customers
[0m10:12:16.657500 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:12:16.657500 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`top_customers`
[0m10:12:16.657500 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_customers"
[0m10:12:16.673117 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.top_customers"
[0m10:12:16.673117 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_customers: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.top_customers"} */

  
  
  
  create or replace view `workspace`.`default`.`top_customers`
  
  as (
    SELECT
  User_ID,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_spent
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY User_ID
ORDER BY total_spent DESC
LIMIT 10
  )

[0m10:12:17.345129 [debug] [Thread-1 (]: SQL status: OK in 0.670 seconds
[0m10:12:17.360623 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f6b8-192e-8561-c837979060f4) - Closing
[0m10:12:17.360623 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:12:17.360623 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7d9c65a4-740a-46dc-9a10-20be8cdab995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107EA3DB050>]}
[0m10:12:17.360623 [info ] [Thread-1 (]: 33 of 57 OK created sql view model default.top_customers ....................... [[32mOK[0m in 0.72s]
[0m10:12:17.360623 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_customers
[0m10:12:17.360623 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:12:17.360623 [info ] [Thread-1 (]: 34 of 57 START test non_negative_avg_discount_by_category_avg_discount_percent . [RUN]
[0m10:12:17.360623 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_customers, now test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f)
[0m10:12:17.376244 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f, idle-time=0.01562047004699707s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.top_customers
[0m10:12:17.376244 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:12:17.376244 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"
[0m10:12:17.376244 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:12:17.391872 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"
[0m10:12:17.391872 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"
[0m10:12:17.391872 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`avg_discount_by_category`
where TRY_CAST(REPLACE(avg_discount_percent, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:12:18.579508 [debug] [Thread-1 (]: SQL status: OK in 1.190 seconds
[0m10:12:18.579508 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f727-1282-a50c-2889e7168058) - Closing
[0m10:12:18.595002 [info ] [Thread-1 (]: 34 of 57 PASS non_negative_avg_discount_by_category_avg_discount_percent ....... [[32mPASS[0m in 1.23s]
[0m10:12:18.595002 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:12:18.595002 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:12:18.595002 [info ] [Thread-1 (]: 35 of 57 START test not_null_avg_discount_by_category_Category ................. [RUN]
[0m10:12:18.595002 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b)
[0m10:12:18.595002 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:12:18.595002 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:12:18.610630 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m10:12:18.610630 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:12:18.610630 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m10:12:18.626266 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m10:12:18.626266 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_discount_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m10:12:19.334756 [debug] [Thread-1 (]: SQL status: OK in 0.710 seconds
[0m10:12:19.350274 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f7e4-12bc-b3f4-d232b1c22656) - Closing
[0m10:12:19.350274 [info ] [Thread-1 (]: 35 of 57 PASS not_null_avg_discount_by_category_Category ....................... [[32mPASS[0m in 0.76s]
[0m10:12:19.350274 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:12:19.350274 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:12:19.350274 [info ] [Thread-1 (]: 36 of 57 START test not_null_avg_discount_by_category_avg_discount_percent ..... [RUN]
[0m10:12:19.350274 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101)
[0m10:12:19.350274 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:12:19.350274 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:12:19.365896 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m10:12:19.365896 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:12:19.381554 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m10:12:19.381554 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m10:12:19.381554 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_discount_percent
from `workspace`.`default`.`avg_discount_by_category`
where avg_discount_percent is null



  
  
      
    ) dbt_internal_test
[0m10:12:20.256520 [debug] [Thread-1 (]: SQL status: OK in 0.870 seconds
[0m10:12:20.256520 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f856-13b7-a904-6a9e04bb5637) - Closing
[0m10:12:20.256520 [info ] [Thread-1 (]: 36 of 57 PASS not_null_avg_discount_by_category_avg_discount_percent ........... [[32mPASS[0m in 0.91s]
[0m10:12:20.256520 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:12:20.256520 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:12:20.256520 [info ] [Thread-1 (]: 37 of 57 START test non_negative_avg_ticket_by_category_avg_ticket ............. [RUN]
[0m10:12:20.256520 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, now test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095)
[0m10:12:20.256520 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:12:20.272146 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:12:20.272146 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"
[0m10:12:20.272146 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:12:20.287777 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"
[0m10:12:20.287777 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"
[0m10:12:20.287777 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`avg_ticket_by_category`
where TRY_CAST(REPLACE(avg_ticket, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:12:21.350401 [debug] [Thread-1 (]: SQL status: OK in 1.060 seconds
[0m10:12:21.350401 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f8e1-1c36-b72e-8f2295b93046) - Closing
[0m10:12:21.350401 [info ] [Thread-1 (]: 37 of 57 PASS non_negative_avg_ticket_by_category_avg_ticket ................... [[32mPASS[0m in 1.09s]
[0m10:12:21.350401 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:12:21.365898 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:12:21.365898 [info ] [Thread-1 (]: 38 of 57 START test not_null_avg_ticket_by_category_Category ................... [RUN]
[0m10:12:21.365898 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f)
[0m10:12:21.365898 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, idle-time=0.015496253967285156s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:12:21.365898 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:12:21.365898 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m10:12:21.381522 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:12:21.381522 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m10:12:21.381522 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m10:12:21.381522 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_ticket_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m10:12:22.053536 [debug] [Thread-1 (]: SQL status: OK in 0.670 seconds
[0m10:12:22.053536 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f988-1e7c-a1fa-536ec9beb2a0) - Closing
[0m10:12:22.053536 [info ] [Thread-1 (]: 38 of 57 PASS not_null_avg_ticket_by_category_Category ......................... [[32mPASS[0m in 0.69s]
[0m10:12:22.069019 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:12:22.069019 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:12:22.069019 [info ] [Thread-1 (]: 39 of 57 START test not_null_avg_ticket_by_category_avg_ticket ................. [RUN]
[0m10:12:22.069019 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41)
[0m10:12:22.069019 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, idle-time=0.015481948852539062s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:12:22.069019 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:12:22.084649 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m10:12:22.084649 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:12:22.084649 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m10:12:22.084649 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m10:12:22.084649 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_ticket
from `workspace`.`default`.`avg_ticket_by_category`
where avg_ticket is null



  
  
      
    ) dbt_internal_test
[0m10:12:23.006657 [debug] [Thread-1 (]: SQL status: OK in 0.910 seconds
[0m10:12:23.006657 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-f9f4-1124-81e1-148234d1a463) - Closing
[0m10:12:23.022146 [info ] [Thread-1 (]: 39 of 57 PASS not_null_avg_ticket_by_category_avg_ticket ....................... [[32mPASS[0m in 0.95s]
[0m10:12:23.022146 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:12:23.022146 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:12:23.022146 [info ] [Thread-1 (]: 40 of 57 START test non_negative_monthly_revenue_monthly_revenue ............... [RUN]
[0m10:12:23.022146 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, now test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294)
[0m10:12:23.022146 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:12:23.022146 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:12:23.037780 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"
[0m10:12:23.037780 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:12:23.037780 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"
[0m10:12:23.037780 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"
[0m10:12:23.037780 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`monthly_revenue`
where TRY_CAST(REPLACE(monthly_revenue, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:12:23.928394 [debug] [Thread-1 (]: SQL status: OK in 0.890 seconds
[0m10:12:23.928394 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-fa86-12e1-b589-89f2c2c9a013) - Closing
[0m10:12:23.928394 [info ] [Thread-1 (]: 40 of 57 PASS non_negative_monthly_revenue_monthly_revenue ..................... [[32mPASS[0m in 0.91s]
[0m10:12:23.928394 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:12:23.928394 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:12:23.928394 [info ] [Thread-1 (]: 41 of 57 START test not_null_monthly_revenue_month ............................. [RUN]
[0m10:12:23.928394 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294, now test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b)
[0m10:12:23.944024 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:12:23.944024 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:12:23.944024 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m10:12:23.944024 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:12:23.959641 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m10:12:23.959641 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m10:12:23.959641 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select month
from `workspace`.`default`.`monthly_revenue`
where month is null



  
  
      
    ) dbt_internal_test
[0m10:12:24.803395 [debug] [Thread-1 (]: SQL status: OK in 0.840 seconds
[0m10:12:24.803395 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-fb11-1052-a06b-4e20ab80f163) - Closing
[0m10:12:24.803395 [info ] [Thread-1 (]: 41 of 57 PASS not_null_monthly_revenue_month ................................... [[32mPASS[0m in 0.88s]
[0m10:12:24.803395 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:12:24.803395 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:12:24.803395 [info ] [Thread-1 (]: 42 of 57 START test not_null_monthly_revenue_monthly_revenue ................... [RUN]
[0m10:12:24.803395 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, now test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b)
[0m10:12:24.819018 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, idle-time=0.015623331069946289s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:12:24.819018 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:12:24.819018 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m10:12:24.819018 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:12:24.834648 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m10:12:24.834648 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m10:12:24.834648 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select monthly_revenue
from `workspace`.`default`.`monthly_revenue`
where monthly_revenue is null



  
  
      
    ) dbt_internal_test
[0m10:12:25.772268 [debug] [Thread-1 (]: SQL status: OK in 0.940 seconds
[0m10:12:25.772268 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-fb97-1231-a19e-fc2fb49aa7ee) - Closing
[0m10:12:25.772268 [info ] [Thread-1 (]: 42 of 57 PASS not_null_monthly_revenue_monthly_revenue ......................... [[32mPASS[0m in 0.97s]
[0m10:12:25.787775 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:12:25.787775 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:12:25.787775 [info ] [Thread-1 (]: 43 of 57 START test non_negative_payment_distribution_total_value .............. [RUN]
[0m10:12:25.787775 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, now test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282)
[0m10:12:25.787775 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282, idle-time=0.015506744384765625s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:12:25.787775 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:12:25.803436 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"
[0m10:12:25.803436 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:12:25.803436 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"
[0m10:12:25.803436 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"
[0m10:12:25.819018 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`payment_distribution`
where TRY_CAST(REPLACE(total_value, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:12:26.850308 [debug] [Thread-1 (]: SQL status: OK in 1.030 seconds
[0m10:12:26.865893 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-fc2c-16fa-aa13-2faca839ed58) - Closing
[0m10:12:26.865893 [info ] [Thread-1 (]: 43 of 57 PASS non_negative_payment_distribution_total_value .................... [[32mPASS[0m in 1.08s]
[0m10:12:26.865893 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:12:26.865893 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:12:26.865893 [info ] [Thread-1 (]: 44 of 57 START test not_null_payment_distribution_Payment_Method ............... [RUN]
[0m10:12:26.881522 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282, now test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae)
[0m10:12:26.881522 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, idle-time=0.01562976837158203s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:12:26.881522 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:12:26.881522 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m10:12:26.897145 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:12:26.897145 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m10:12:26.897145 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m10:12:26.897145 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`payment_distribution`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m10:12:27.647156 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m10:12:27.647156 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-fcd4-1037-a9d7-990770be8687) - Closing
[0m10:12:27.647156 [info ] [Thread-1 (]: 44 of 57 PASS not_null_payment_distribution_Payment_Method ..................... [[32mPASS[0m in 0.77s]
[0m10:12:27.647156 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:12:27.647156 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:12:27.647156 [info ] [Thread-1 (]: 45 of 57 START test not_null_payment_distribution_total_transactions ........... [RUN]
[0m10:12:27.647156 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, now test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8)
[0m10:12:27.647156 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:12:27.662772 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:12:27.662772 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m10:12:27.662772 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:12:27.678401 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m10:12:27.678401 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m10:12:27.678401 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_transactions
from `workspace`.`default`.`payment_distribution`
where total_transactions is null



  
  
      
    ) dbt_internal_test
[0m10:12:28.334783 [debug] [Thread-1 (]: SQL status: OK in 0.660 seconds
[0m10:12:28.334783 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-fd48-1a9a-8d91-a26f3b04944d) - Closing
[0m10:12:28.334783 [info ] [Thread-1 (]: 45 of 57 PASS not_null_payment_distribution_total_transactions ................. [[32mPASS[0m in 0.69s]
[0m10:12:28.350272 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:12:28.350272 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:12:28.350272 [info ] [Thread-1 (]: 46 of 57 START test not_null_payment_distribution_total_value .................. [RUN]
[0m10:12:28.350272 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, now test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03)
[0m10:12:28.350272 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, idle-time=0.01548910140991211s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:12:28.350272 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:12:28.350272 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m10:12:28.365906 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:12:28.365906 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m10:12:28.365906 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m10:12:28.365906 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_value
from `workspace`.`default`.`payment_distribution`
where total_value is null



  
  
      
    ) dbt_internal_test
[0m10:12:29.194155 [debug] [Thread-1 (]: SQL status: OK in 0.830 seconds
[0m10:12:29.194155 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-fdb3-13fd-93a3-7d0977b7da84) - Closing
[0m10:12:29.194155 [info ] [Thread-1 (]: 46 of 57 PASS not_null_payment_distribution_total_value ........................ [[32mPASS[0m in 0.84s]
[0m10:12:29.209662 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:12:29.209662 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:12:29.209662 [info ] [Thread-1 (]: 47 of 57 START test non_negative_sales_by_category_total_revenue ............... [RUN]
[0m10:12:29.209662 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, now test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41)
[0m10:12:29.209662 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41, idle-time=0.015507698059082031s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:12:29.209662 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:12:29.225275 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"
[0m10:12:29.225275 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:12:29.225275 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"
[0m10:12:29.225275 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"
[0m10:12:29.240891 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`sales_by_category`
where TRY_CAST(REPLACE(total_revenue, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:12:30.069155 [debug] [Thread-1 (]: SQL status: OK in 0.830 seconds
[0m10:12:30.069155 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-fe36-117b-959f-7fb322d0edf4) - Closing
[0m10:12:30.084652 [info ] [Thread-1 (]: 47 of 57 PASS non_negative_sales_by_category_total_revenue ..................... [[32mPASS[0m in 0.87s]
[0m10:12:30.084652 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:12:30.084652 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:12:30.084652 [info ] [Thread-1 (]: 48 of 57 START test not_null_sales_by_category_Category ........................ [RUN]
[0m10:12:30.084652 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41, now test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507)
[0m10:12:30.084652 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:12:30.084652 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:12:30.100279 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m10:12:30.100279 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:12:30.100279 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m10:12:30.100279 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m10:12:30.100279 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`sales_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m10:12:30.803513 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m10:12:30.803513 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-febb-17db-bf64-8753c12a3530) - Closing
[0m10:12:30.819024 [info ] [Thread-1 (]: 48 of 57 PASS not_null_sales_by_category_Category .............................. [[32mPASS[0m in 0.73s]
[0m10:12:30.819024 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:12:30.819024 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:12:30.819024 [info ] [Thread-1 (]: 49 of 57 START test not_null_sales_by_category_total_orders .................... [RUN]
[0m10:12:30.819024 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, now test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e)
[0m10:12:30.819024 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:12:30.819024 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:12:30.834645 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m10:12:30.834645 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:12:30.834645 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m10:12:30.834645 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m10:12:30.834645 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`sales_by_category`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m10:12:31.506658 [debug] [Thread-1 (]: SQL status: OK in 0.670 seconds
[0m10:12:31.506658 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-ff2b-1687-85c8-dd04e0bbccda) - Closing
[0m10:12:31.522151 [info ] [Thread-1 (]: 49 of 57 PASS not_null_sales_by_category_total_orders .......................... [[32mPASS[0m in 0.70s]
[0m10:12:31.522151 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:12:31.522151 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:12:31.522151 [info ] [Thread-1 (]: 50 of 57 START test not_null_sales_by_category_total_revenue ................... [RUN]
[0m10:12:31.522151 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, now test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd)
[0m10:12:31.522151 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:12:31.522151 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:12:31.537770 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m10:12:31.537770 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:12:31.537770 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m10:12:31.537770 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m10:12:31.553392 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_revenue
from `workspace`.`default`.`sales_by_category`
where total_revenue is null



  
  
      
    ) dbt_internal_test
[0m10:12:32.240897 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m10:12:32.240897 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c34-ff97-1931-be13-094ddf70f92c) - Closing
[0m10:12:32.240897 [info ] [Thread-1 (]: 50 of 57 PASS not_null_sales_by_category_total_revenue ......................... [[32mPASS[0m in 0.72s]
[0m10:12:32.240897 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:12:32.240897 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:12:32.240897 [info ] [Thread-1 (]: 51 of 57 START test non_negative_top_5_products_total_sales .................... [RUN]
[0m10:12:32.240897 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, now test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34)
[0m10:12:32.240897 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:12:32.256524 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:12:32.256524 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"
[0m10:12:32.256524 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:12:32.272165 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"
[0m10:12:32.272165 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"
[0m10:12:32.272165 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`top_5_products`
where TRY_CAST(REPLACE(total_sales, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:12:33.225369 [debug] [Thread-1 (]: SQL status: OK in 0.950 seconds
[0m10:12:33.240931 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c35-0005-1f65-bc3c-2d05f9c7bd77) - Closing
[0m10:12:33.240931 [info ] [Thread-1 (]: 51 of 57 PASS non_negative_top_5_products_total_sales .......................... [[32mPASS[0m in 1.00s]
[0m10:12:33.240931 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:12:33.240931 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:12:33.240931 [info ] [Thread-1 (]: 52 of 57 START test not_null_top_5_products_product_id ......................... [RUN]
[0m10:12:33.240931 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34, now test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe)
[0m10:12:33.240931 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:12:33.240931 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:12:33.256528 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m10:12:33.256528 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:12:33.272187 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m10:12:33.272187 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m10:12:33.272187 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select product_id
from `workspace`.`default`.`top_5_products`
where product_id is null



  
  
      
    ) dbt_internal_test
[0m10:12:34.069156 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m10:12:34.084646 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c35-009e-18ea-8dca-2c1f5caf78b6) - Closing
[0m10:12:34.084646 [info ] [Thread-1 (]: 52 of 57 PASS not_null_top_5_products_product_id ............................... [[32mPASS[0m in 0.84s]
[0m10:12:34.084646 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:12:34.084646 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:12:34.084646 [info ] [Thread-1 (]: 53 of 57 START test not_null_top_5_products_total_sales ........................ [RUN]
[0m10:12:34.084646 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, now test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818)
[0m10:12:34.084646 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:12:34.084646 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:12:34.100275 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m10:12:34.100275 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:12:34.100275 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m10:12:34.115895 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m10:12:34.115895 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_sales
from `workspace`.`default`.`top_5_products`
where total_sales is null



  
  
      
    ) dbt_internal_test
[0m10:12:34.881627 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m10:12:34.881627 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c35-011f-13b1-b54c-3a8be01ade22) - Closing
[0m10:12:34.881627 [info ] [Thread-1 (]: 53 of 57 PASS not_null_top_5_products_total_sales .............................. [[32mPASS[0m in 0.80s]
[0m10:12:34.881627 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:12:34.897146 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:12:34.897146 [info ] [Thread-1 (]: 54 of 57 START test non_negative_top_customers_total_spent ..................... [RUN]
[0m10:12:34.897146 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, now test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667)
[0m10:12:34.897146 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667, idle-time=0.015519142150878906s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:12:34.897146 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:12:34.897146 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"
[0m10:12:34.912775 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:12:34.912775 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"
[0m10:12:34.912775 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"
[0m10:12:34.912775 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`top_customers`
where TRY_CAST(REPLACE(total_spent, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:12:35.803537 [debug] [Thread-1 (]: SQL status: OK in 0.890 seconds
[0m10:12:35.803537 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c35-019a-142f-8f7f-f97c1bc25c7c) - Closing
[0m10:12:35.819023 [info ] [Thread-1 (]: 54 of 57 PASS non_negative_top_customers_total_spent ........................... [[32mPASS[0m in 0.91s]
[0m10:12:35.819023 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:12:35.819023 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:12:35.819023 [info ] [Thread-1 (]: 55 of 57 START test not_null_top_customers_User_ID ............................. [RUN]
[0m10:12:35.819023 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667, now test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0)
[0m10:12:35.819023 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, idle-time=0.015485525131225586s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:12:35.819023 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:12:35.944081 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m10:12:35.959654 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:12:35.959654 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m10:12:35.959654 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m10:12:35.959654 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`top_customers`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m10:12:36.787904 [debug] [Thread-1 (]: SQL status: OK in 0.830 seconds
[0m10:12:36.787904 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c35-0239-17ea-ae98-edf3ed894244) - Closing
[0m10:12:36.803400 [info ] [Thread-1 (]: 55 of 57 PASS not_null_top_customers_User_ID ................................... [[32mPASS[0m in 0.98s]
[0m10:12:36.803400 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:12:36.803400 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:12:36.803400 [info ] [Thread-1 (]: 56 of 57 START test not_null_top_customers_total_orders ........................ [RUN]
[0m10:12:36.803400 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, now test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746)
[0m10:12:36.803400 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:12:36.803400 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:12:36.819030 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m10:12:36.819030 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:12:36.819030 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m10:12:36.819030 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m10:12:36.819030 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`top_customers`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m10:12:37.444020 [debug] [Thread-1 (]: SQL status: OK in 0.610 seconds
[0m10:12:37.444020 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c35-02be-15fe-8369-72656132d024) - Closing
[0m10:12:37.444020 [info ] [Thread-1 (]: 56 of 57 PASS not_null_top_customers_total_orders .............................. [[32mPASS[0m in 0.64s]
[0m10:12:37.444020 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:12:37.444020 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m10:12:37.444020 [info ] [Thread-1 (]: 57 of 57 START test not_null_top_customers_total_spent ......................... [RUN]
[0m10:12:37.444020 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, now test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73)
[0m10:12:37.459649 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, name=test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73, idle-time=0.015629053115844727s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:12:37.459649 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m10:12:37.459649 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m10:12:37.459649 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m10:12:37.475272 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m10:12:37.475272 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m10:12:37.475272 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_spent
from `workspace`.`default`.`top_customers`
where total_spent is null



  
  
      
    ) dbt_internal_test
[0m10:12:38.205446 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m10:12:38.205446 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee, command-id=01f07c35-0320-13b2-ba86-4f3556803c92) - Closing
[0m10:12:38.205446 [info ] [Thread-1 (]: 57 of 57 PASS not_null_top_customers_total_spent ............................... [[32mPASS[0m in 0.76s]
[0m10:12:38.205446 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m10:12:38.220957 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=56.391451597213745s, language=None, compute-name=) - Reusing connection previously named master
[0m10:12:38.220957 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:12:38.220957 [debug] [MainThread]: Connection 'list_workspace' was properly closed.
[0m10:12:38.220957 [debug] [MainThread]: On list_workspace: Close
[0m10:12:38.220957 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07c34-b857-1425-9fbf-2829f9d5217d) - Closing
[0m10:12:38.439842 [debug] [MainThread]: Connection 'list_workspace_default' was properly closed.
[0m10:12:38.439842 [debug] [MainThread]: On list_workspace_default: Close
[0m10:12:38.439842 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07c34-de71-110b-b136-e8cf7359cb0c) - Closing
[0m10:12:38.642972 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73' was properly closed.
[0m10:12:38.642972 [debug] [MainThread]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: Close
[0m10:12:38.642972 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07c34-e25d-1fc8-a21f-50520712b7ee) - Closing
[0m10:12:38.861723 [info ] [MainThread]: 
[0m10:12:38.861723 [info ] [MainThread]: Finished running 48 data tests, 9 view models in 0 hours 2 minutes and 7.84 seconds (127.84s).
[0m10:12:38.892844 [debug] [MainThread]: Command end result
[0m10:12:38.970986 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m10:12:38.986619 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m10:12:39.002248 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m10:12:39.002248 [info ] [MainThread]: 
[0m10:12:39.002248 [info ] [MainThread]: [31mCompleted with 11 errors, 0 partial successes, and 0 warnings:[0m
[0m10:12:39.002248 [info ] [MainThread]: 
[0m10:12:39.002248 [error] [MainThread]: [31mFailure in test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery (dbt_databricks_cicd/models\raw\databricks\schema.yml)[0m
[0m10:12:39.002248 [error] [MainThread]:   Database Error in test source_accepted_values_sqlserver_data_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 20 pos 9
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_accepted_values_sqlserv_de5401a33d073d59e860da01ddb6837b.sql
[0m10:12:39.002248 [info ] [MainThread]: 
[0m10:12:39.002248 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_accepted_values_sqlserv_de5401a33d073d59e860da01ddb6837b.sql
[0m10:12:39.002248 [info ] [MainThread]: 
[0m10:12:39.017865 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Category (dbt_databricks_cicd/models\raw\databricks\schema.yml)[0m
[0m10:12:39.017865 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Category (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Category.sql
[0m10:12:39.017865 [info ] [MainThread]: 
[0m10:12:39.017865 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Category.sql
[0m10:12:39.017865 [info ] [MainThread]: 
[0m10:12:39.017865 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Discount (dbt_databricks_cicd/models\raw\databricks\schema.yml)[0m
[0m10:12:39.033449 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Discount (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Discount.sql
[0m10:12:39.033449 [info ] [MainThread]: 
[0m10:12:39.033449 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Discount.sql
[0m10:12:39.033449 [info ] [MainThread]: 
[0m10:12:39.033449 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Final_Price (dbt_databricks_cicd/models\raw\databricks\schema.yml)[0m
[0m10:12:39.033449 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Final_Price (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Final_Price.sql
[0m10:12:39.049083 [info ] [MainThread]: 
[0m10:12:39.049083 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Final_Price.sql
[0m10:12:39.049083 [info ] [MainThread]: 
[0m10:12:39.049083 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Payment_Method (dbt_databricks_cicd/models\raw\databricks\schema.yml)[0m
[0m10:12:39.049083 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Payment_Method (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Payment_Method.sql
[0m10:12:39.049083 [info ] [MainThread]: 
[0m10:12:39.064702 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Payment_Method.sql
[0m10:12:39.064702 [info ] [MainThread]: 
[0m10:12:39.064702 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Price (dbt_databricks_cicd/models\raw\databricks\schema.yml)[0m
[0m10:12:39.064702 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Price (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Price.sql
[0m10:12:39.064702 [info ] [MainThread]: 
[0m10:12:39.064702 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Price.sql
[0m10:12:39.064702 [info ] [MainThread]: 
[0m10:12:39.080324 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\databricks\schema.yml)[0m
[0m10:12:39.080324 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Product_ID.sql
[0m10:12:39.080324 [info ] [MainThread]: 
[0m10:12:39.080324 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Product_ID.sql
[0m10:12:39.080324 [info ] [MainThread]: 
[0m10:12:39.080324 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_Purchase_Date (dbt_databricks_cicd/models\raw\databricks\schema.yml)[0m
[0m10:12:39.095986 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_Purchase_Date (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Purchase_Date.sql
[0m10:12:39.095986 [info ] [MainThread]: 
[0m10:12:39.095986 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_Purchase_Date.sql
[0m10:12:39.095986 [info ] [MainThread]: 
[0m10:12:39.095986 [error] [MainThread]: [31mFailure in test source_not_null_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\databricks\schema.yml)[0m
[0m10:12:39.095986 [error] [MainThread]:   Database Error in test source_not_null_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_User_ID.sql
[0m10:12:39.111578 [info ] [MainThread]: 
[0m10:12:39.111578 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_not_null_sqlserver_data_ecommerce_User_ID.sql
[0m10:12:39.111578 [info ] [MainThread]: 
[0m10:12:39.111578 [error] [MainThread]: [31mFailure in test source_unique_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\databricks\schema.yml)[0m
[0m10:12:39.111578 [error] [MainThread]:   Database Error in test source_unique_sqlserver_data_ecommerce_Product_ID (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 18 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_unique_sqlserver_data_ecommerce_Product_ID.sql
[0m10:12:39.111578 [info ] [MainThread]: 
[0m10:12:39.127205 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_unique_sqlserver_data_ecommerce_Product_ID.sql
[0m10:12:39.127205 [info ] [MainThread]: 
[0m10:12:39.127205 [error] [MainThread]: [31mFailure in test source_unique_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\databricks\schema.yml)[0m
[0m10:12:39.127205 [error] [MainThread]:   Database Error in test source_unique_sqlserver_data_ecommerce_User_ID (dbt_databricks_cicd/models\raw\databricks\schema.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `my_db`.`dbo`.`ecommerce` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 18 pos 5
  compiled code at target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_unique_sqlserver_data_ecommerce_User_ID.sql
[0m10:12:39.127205 [info ] [MainThread]: 
[0m10:12:39.127205 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\raw\databricks\schema.yml\source_unique_sqlserver_data_ecommerce_User_ID.sql
[0m10:12:39.142827 [info ] [MainThread]: 
[0m10:12:39.142827 [info ] [MainThread]: Done. PASS=46 WARN=0 ERROR=11 SKIP=0 NO-OP=0 TOTAL=57
[0m10:12:39.142827 [debug] [MainThread]: Command `dbt build` failed at 10:12:39.142827 after 148.17 seconds
[0m10:12:39.142827 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107D6383DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107D65E11D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000107D65E10D0>]}
[0m10:12:39.142827 [debug] [MainThread]: Flushing usage events
[0m10:12:40.096095 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:13:53.675924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000188511A5A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000188511A4A90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000188511A4310>]}


============================== 10:13:53.675924 | d78e1e36-e22d-4afe-aead-850509ccfc49 ==============================
[0m10:13:53.675924 [info ] [MainThread]: Running with dbt=1.10.3
[0m10:13:53.675924 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'version_check': 'True', 'debug': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt build --target databricks', 'send_anonymous_usage_stats': 'True'}
[0m10:13:55.472809 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m10:13:55.472809 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m10:13:55.472809 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m10:13:57.269678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd78e1e36-e22d-4afe-aead-850509ccfc49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001885A25F9D0>]}
[0m10:13:57.394722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd78e1e36-e22d-4afe-aead-850509ccfc49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018850919C10>]}
[0m10:13:57.394722 [info ] [MainThread]: Registered adapter: databricks=1.10.4
[0m10:13:58.457182 [debug] [MainThread]: checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, vars: {}, profile: , target: databricks, version: 1.10.3
[0m10:13:59.004059 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m10:13:59.004059 [debug] [MainThread]: Partial parsing: updated file: dbt_databricks_cicd://dbt_databricks_cicd/models\raw\databricks\schema.yml
[0m10:13:59.441565 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m10:13:59.472807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd78e1e36-e22d-4afe-aead-850509ccfc49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001885D550990>]}
[0m10:13:59.644683 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m10:13:59.644683 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m10:13:59.738465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd78e1e36-e22d-4afe-aead-850509ccfc49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001885DC1CA90>]}
[0m10:13:59.754097 [info ] [MainThread]: Found 9 models, 37 data tests, 1 source, 800 macros
[0m10:13:59.754097 [info ] [MainThread]: 
[0m10:13:59.769675 [info ] [MainThread]: Concurrency: 1 threads (target='databricks')
[0m10:13:59.769675 [info ] [MainThread]: 
[0m10:13:59.769675 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:13:59.769675 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:13:59.800930 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:13:59.800930 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace'
[0m10:13:59.800930 [debug] [ThreadPool]: Using databricks connection "list_workspace"
[0m10:13:59.800930 [debug] [ThreadPool]: On list_workspace: GetSchemas(database=workspace, schema=None)
[0m10:13:59.800930 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:14:00.613424 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f07c35-348d-1224-8599-e426608bc666) - Created
[0m10:14:00.972809 [debug] [ThreadPool]: SQL status: OK in 1.170 seconds
[0m10:14:00.972809 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f07c35-348d-1224-8599-e426608bc666, command-id=01f07c35-34b4-1844-ba31-442ada44368c) - Closing
[0m10:14:00.988428 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace_default, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:14:00.988428 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace_default'
[0m10:14:01.019682 [debug] [ThreadPool]: Using databricks connection "list_workspace_default"
[0m10:14:01.019682 [debug] [ThreadPool]: On list_workspace_default: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "connection_name": "list_workspace_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'workspace' 
  AND table_schema = 'default'

  
[0m10:14:01.019682 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:14:01.785300 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f07c35-3541-104e-9a50-96c9c943e0da) - Created
[0m10:14:02.332296 [debug] [ThreadPool]: SQL status: OK in 1.310 seconds
[0m10:14:02.347807 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f07c35-3541-104e-9a50-96c9c943e0da, command-id=01f07c35-355f-172b-98a9-e75857b2ea56) - Closing
[0m10:14:02.347807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd78e1e36-e22d-4afe-aead-850509ccfc49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001885DA3A910>]}
[0m10:14:02.363422 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m10:14:02.363422 [info ] [Thread-1 (]: 1 of 46 START sql view model default.src_ecommerce ............................. [RUN]
[0m10:14:02.363422 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_cicd.src_ecommerce, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:14:02.363422 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m10:14:02.363422 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m10:14:02.379086 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m10:14:02.379086 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m10:14:02.394675 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:14:02.410350 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m10:14:02.410350 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'd78e1e36-e22d-4afe-aead-850509ccfc49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001885DC8C950>]}
[0m10:14:02.441554 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`src_ecommerce`
[0m10:14:02.457181 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m10:14:02.457181 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.src_ecommerce"
[0m10:14:02.457181 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`src_ecommerce`
  
  as (
    SELECT * FROM default.sales_ecommerce
  )

[0m10:14:02.457181 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:14:03.176069 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a) - Created
[0m10:14:03.847839 [debug] [Thread-1 (]: SQL status: OK in 1.390 seconds
[0m10:14:03.847839 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3635-1f35-afc6-58a161c803a7) - Closing
[0m10:14:03.863474 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:14:03.879093 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd78e1e36-e22d-4afe-aead-850509ccfc49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001885DA115D0>]}
[0m10:14:03.879093 [info ] [Thread-1 (]: 1 of 46 OK created sql view model default.src_ecommerce ........................ [[32mOK[0m in 1.52s]
[0m10:14:03.879093 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m10:14:03.879093 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m10:14:03.879093 [info ] [Thread-1 (]: 2 of 46 START sql view model default.stg_ecommerce ............................. [RUN]
[0m10:14:03.879093 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m10:14:03.894676 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=model.dbt_databricks_cicd.stg_ecommerce, idle-time=0.015582799911499023s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.src_ecommerce
[0m10:14:03.894676 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m10:14:03.894676 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:14:03.894676 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m10:14:03.910301 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:14:03.910301 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`stg_ecommerce`
[0m10:14:03.910301 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:14:03.910301 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:14:03.910301 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`stg_ecommerce`
  
  as (
    SELECT
  User_ID,
  Product_ID,
  Category,
  Price,
  Discount,
  Final_Price,
  Payment_Method,
  Purchase_Date
FROM `workspace`.`default`.`src_ecommerce`
  )

[0m10:14:04.519714 [debug] [Thread-1 (]: SQL status: OK in 0.610 seconds
[0m10:14:04.519714 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-36a5-1234-ad8e-7171a255f444) - Closing
[0m10:14:04.519714 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:14:04.519714 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd78e1e36-e22d-4afe-aead-850509ccfc49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001885DD25E10>]}
[0m10:14:04.519714 [info ] [Thread-1 (]: 2 of 46 OK created sql view model default.stg_ecommerce ........................ [[32mOK[0m in 0.64s]
[0m10:14:04.519714 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m10:14:04.519714 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m10:14:04.519714 [info ] [Thread-1 (]: 3 of 46 START test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m10:14:04.535339 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6)
[0m10:14:04.535339 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, idle-time=0.015624761581420898s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.stg_ecommerce
[0m10:14:04.535339 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m10:14:04.550970 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m10:14:04.566547 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m10:14:04.597804 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m10:14:04.597804 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m10:14:04.597804 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from `workspace`.`default`.`stg_ecommerce`
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    'Credit Card','Net Banking','UPI','Debit Card','Cash on Delivery'
)



  
  
      
    ) dbt_internal_test
[0m10:14:04.957298 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m10:14:04.957298 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-370e-114d-9db3-be316de72931) - Closing
[0m10:14:04.972843 [info ] [Thread-1 (]: 3 of 46 PASS accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[32mPASS[0m in 0.45s]
[0m10:14:04.972843 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m10:14:04.972843 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m10:14:04.972843 [info ] [Thread-1 (]: 4 of 46 START test non_negative_stg_ecommerce_Discount ......................... [RUN]
[0m10:14:04.972843 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb)
[0m10:14:04.972843 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m10:14:04.972843 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m10:14:04.988471 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m10:14:04.988471 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m10:14:04.988471 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m10:14:05.004095 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m10:14:05.004095 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`stg_ecommerce`
where TRY_CAST(REPLACE(Discount, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:14:05.457297 [debug] [Thread-1 (]: SQL status: OK in 0.450 seconds
[0m10:14:05.457297 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-374c-1493-ac2c-7bba93a5a742) - Closing
[0m10:14:05.457297 [info ] [Thread-1 (]: 4 of 46 PASS non_negative_stg_ecommerce_Discount ............................... [[32mPASS[0m in 0.48s]
[0m10:14:05.457297 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m10:14:05.457297 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m10:14:05.457297 [info ] [Thread-1 (]: 5 of 46 START test non_negative_stg_ecommerce_Final_Price ...................... [RUN]
[0m10:14:05.472838 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7)
[0m10:14:05.472838 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7, idle-time=0.015541315078735352s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m10:14:05.472838 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m10:14:05.472838 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m10:14:05.472838 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m10:14:05.488466 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m10:14:05.488466 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m10:14:05.488466 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`stg_ecommerce`
where TRY_CAST(REPLACE(Final_Price, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:14:05.832215 [debug] [Thread-1 (]: SQL status: OK in 0.340 seconds
[0m10:14:05.832215 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3795-1104-9b69-57d7489d7fc2) - Closing
[0m10:14:05.832215 [info ] [Thread-1 (]: 5 of 46 PASS non_negative_stg_ecommerce_Final_Price ............................ [[32mPASS[0m in 0.36s]
[0m10:14:05.832215 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m10:14:05.832215 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m10:14:05.832215 [info ] [Thread-1 (]: 6 of 46 START test non_negative_stg_ecommerce_Price ............................ [RUN]
[0m10:14:05.847799 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d)
[0m10:14:05.847799 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d, idle-time=0.015584230422973633s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m10:14:05.847799 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m10:14:05.863430 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m10:14:05.863430 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m10:14:05.863430 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m10:14:05.863430 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m10:14:05.863430 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`stg_ecommerce`
where TRY_CAST(REPLACE(Price, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:14:06.207295 [debug] [Thread-1 (]: SQL status: OK in 0.330 seconds
[0m10:14:06.222843 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-37d0-188a-898f-3c2afc79e98e) - Closing
[0m10:14:06.222843 [info ] [Thread-1 (]: 6 of 46 PASS non_negative_stg_ecommerce_Price .................................. [[32mPASS[0m in 0.38s]
[0m10:14:06.222843 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m10:14:06.222843 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m10:14:06.222843 [info ] [Thread-1 (]: 7 of 46 START test not_null_stg_ecommerce_Category ............................. [RUN]
[0m10:14:06.222843 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14)
[0m10:14:06.222843 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m10:14:06.222843 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m10:14:06.238471 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m10:14:06.238471 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m10:14:06.254087 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m10:14:06.254087 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m10:14:06.254087 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`stg_ecommerce`
where Category is null



  
  
      
    ) dbt_internal_test
[0m10:14:06.629087 [debug] [Thread-1 (]: SQL status: OK in 0.370 seconds
[0m10:14:06.629087 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-380b-10b0-8ae7-566c8375806e) - Closing
[0m10:14:06.629087 [info ] [Thread-1 (]: 7 of 46 PASS not_null_stg_ecommerce_Category ................................... [[32mPASS[0m in 0.41s]
[0m10:14:06.629087 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m10:14:06.629087 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m10:14:06.629087 [info ] [Thread-1 (]: 8 of 46 START test not_null_stg_ecommerce_Discount ............................. [RUN]
[0m10:14:06.629087 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836)
[0m10:14:06.644716 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, idle-time=0.01562976837158203s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m10:14:06.644716 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m10:14:06.644716 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m10:14:06.644716 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m10:14:06.660343 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m10:14:06.660343 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m10:14:06.660343 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Discount
from `workspace`.`default`.`stg_ecommerce`
where Discount is null



  
  
      
    ) dbt_internal_test
[0m10:14:07.004194 [debug] [Thread-1 (]: SQL status: OK in 0.340 seconds
[0m10:14:07.019674 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3848-166c-85f4-d1e8d100e743) - Closing
[0m10:14:07.019674 [info ] [Thread-1 (]: 8 of 46 PASS not_null_stg_ecommerce_Discount ................................... [[32mPASS[0m in 0.39s]
[0m10:14:07.019674 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m10:14:07.019674 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m10:14:07.019674 [info ] [Thread-1 (]: 9 of 46 START test not_null_stg_ecommerce_Final_Price .......................... [RUN]
[0m10:14:07.019674 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc)
[0m10:14:07.019674 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m10:14:07.019674 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m10:14:07.035339 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m10:14:07.035339 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m10:14:07.035339 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m10:14:07.050970 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m10:14:07.050970 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Final_Price
from `workspace`.`default`.`stg_ecommerce`
where Final_Price is null



  
  
      
    ) dbt_internal_test
[0m10:14:07.410412 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m10:14:07.425927 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3883-1d5a-ae3c-5d472a5d7061) - Closing
[0m10:14:07.425927 [info ] [Thread-1 (]: 9 of 46 PASS not_null_stg_ecommerce_Final_Price ................................ [[32mPASS[0m in 0.41s]
[0m10:14:07.425927 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m10:14:07.425927 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m10:14:07.425927 [info ] [Thread-1 (]: 10 of 46 START test not_null_stg_ecommerce_Payment_Method ...................... [RUN]
[0m10:14:07.425927 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d)
[0m10:14:07.425927 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m10:14:07.425927 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m10:14:07.441586 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m10:14:07.441586 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m10:14:07.457177 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m10:14:07.457177 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m10:14:07.457177 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`stg_ecommerce`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m10:14:07.816690 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m10:14:07.816690 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-38c1-15ea-a3c8-93776cf4dcf6) - Closing
[0m10:14:07.832220 [info ] [Thread-1 (]: 10 of 46 PASS not_null_stg_ecommerce_Payment_Method ............................ [[32mPASS[0m in 0.41s]
[0m10:14:07.832220 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m10:14:07.832220 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m10:14:07.832220 [info ] [Thread-1 (]: 11 of 46 START test not_null_stg_ecommerce_Price ............................... [RUN]
[0m10:14:07.832220 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a)
[0m10:14:07.832220 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m10:14:07.832220 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m10:14:07.847849 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m10:14:07.847849 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m10:14:07.863429 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m10:14:07.863429 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m10:14:07.863429 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Price
from `workspace`.`default`.`stg_ecommerce`
where Price is null



  
  
      
    ) dbt_internal_test
[0m10:14:08.238460 [debug] [Thread-1 (]: SQL status: OK in 0.380 seconds
[0m10:14:08.238460 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-38ff-19ad-860d-81d9b83794bb) - Closing
[0m10:14:08.238460 [info ] [Thread-1 (]: 11 of 46 PASS not_null_stg_ecommerce_Price ..................................... [[32mPASS[0m in 0.41s]
[0m10:14:08.238460 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m10:14:08.238460 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m10:14:08.238460 [info ] [Thread-1 (]: 12 of 46 START test not_null_stg_ecommerce_Product_ID .......................... [RUN]
[0m10:14:08.238460 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c)
[0m10:14:08.238460 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m10:14:08.254089 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m10:14:08.254089 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m10:14:08.254089 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m10:14:08.269686 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m10:14:08.269686 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m10:14:08.269686 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Product_ID
from `workspace`.`default`.`stg_ecommerce`
where Product_ID is null



  
  
      
    ) dbt_internal_test
[0m10:14:08.660338 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m10:14:08.660338 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-393d-1acc-9f98-92bfa4c50564) - Closing
[0m10:14:08.660338 [info ] [Thread-1 (]: 12 of 46 PASS not_null_stg_ecommerce_Product_ID ................................ [[32mPASS[0m in 0.42s]
[0m10:14:08.660338 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m10:14:08.660338 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m10:14:08.660338 [info ] [Thread-1 (]: 13 of 46 START test not_null_stg_ecommerce_Purchase_Date ....................... [RUN]
[0m10:14:08.675925 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307)
[0m10:14:08.675925 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, idle-time=0.015586614608764648s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m10:14:08.675925 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m10:14:08.675925 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m10:14:08.675925 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m10:14:08.691592 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m10:14:08.691592 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m10:14:08.691592 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Purchase_Date
from `workspace`.`default`.`stg_ecommerce`
where Purchase_Date is null



  
  
      
    ) dbt_internal_test
[0m10:14:09.019716 [debug] [Thread-1 (]: SQL status: OK in 0.330 seconds
[0m10:14:09.019716 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-397d-1e51-a328-d6be05f76da4) - Closing
[0m10:14:09.019716 [info ] [Thread-1 (]: 13 of 46 PASS not_null_stg_ecommerce_Purchase_Date ............................. [[32mPASS[0m in 0.34s]
[0m10:14:09.019716 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m10:14:09.019716 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m10:14:09.019716 [info ] [Thread-1 (]: 14 of 46 START test not_null_stg_ecommerce_User_ID ............................. [RUN]
[0m10:14:09.019716 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, now test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf)
[0m10:14:09.035300 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, idle-time=0.015584468841552734s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m10:14:09.035300 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m10:14:09.035300 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m10:14:09.035300 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m10:14:09.050966 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m10:14:09.050966 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m10:14:09.050966 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`stg_ecommerce`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m10:14:09.394816 [debug] [Thread-1 (]: SQL status: OK in 0.340 seconds
[0m10:14:09.394816 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-39b5-1329-83dc-0d70fd2e182e) - Closing
[0m10:14:09.394816 [info ] [Thread-1 (]: 14 of 46 PASS not_null_stg_ecommerce_User_ID ................................... [[32mPASS[0m in 0.38s]
[0m10:14:09.394816 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m10:14:09.394816 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m10:14:09.410305 [info ] [Thread-1 (]: 15 of 46 START test unique_stg_ecommerce_Product_ID ............................ [RUN]
[0m10:14:09.410305 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, now test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1)
[0m10:14:09.410305 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1, idle-time=0.015489816665649414s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m10:14:09.410305 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m10:14:09.425938 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m10:14:09.425938 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m10:14:09.425938 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m10:14:09.441641 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m10:14:09.441641 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    Product_ID as unique_field,
    count(*) as n_records

from `workspace`.`default`.`stg_ecommerce`
where Product_ID is not null
group by Product_ID
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m10:14:09.800964 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m10:14:09.800964 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-39f1-1711-a441-b84f1d8618f9) - Closing
[0m10:14:09.800964 [info ] [Thread-1 (]: 15 of 46 PASS unique_stg_ecommerce_Product_ID .................................. [[32mPASS[0m in 0.39s]
[0m10:14:09.800964 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m10:14:09.800964 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_discount_by_category
[0m10:14:09.816550 [info ] [Thread-1 (]: 16 of 46 START sql view model default.avg_discount_by_category ................. [RUN]
[0m10:14:09.816550 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1, now model.dbt_databricks_cicd.avg_discount_by_category)
[0m10:14:09.816550 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=model.dbt_databricks_cicd.avg_discount_by_category, idle-time=0.015586614608764648s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m10:14:09.816550 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_discount_by_category
[0m10:14:09.816550 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m10:14:09.816550 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_discount_by_category
[0m10:14:09.832226 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:14:09.847843 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`avg_discount_by_category`
[0m10:14:09.847843 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m10:14:09.847843 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.avg_discount_by_category"
[0m10:14:09.847843 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_discount_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.avg_discount_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`avg_discount_by_category`
  
  as (
    SELECT
  Category,
  ROUND(AVG(CAST(`Discount` AS DOUBLE)), 2) AS avg_discount_percent
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY avg_discount_percent DESC
  )

[0m10:14:10.535343 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m10:14:10.535343 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3a2f-1d7b-b326-a6af2161d2ca) - Closing
[0m10:14:10.535343 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:14:10.550938 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd78e1e36-e22d-4afe-aead-850509ccfc49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001885E0AC150>]}
[0m10:14:10.550938 [info ] [Thread-1 (]: 16 of 46 OK created sql view model default.avg_discount_by_category ............ [[32mOK[0m in 0.73s]
[0m10:14:10.550938 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_discount_by_category
[0m10:14:10.550938 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:14:10.550938 [info ] [Thread-1 (]: 17 of 46 START sql view model default.avg_ticket_by_category ................... [RUN]
[0m10:14:10.550938 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_discount_by_category, now model.dbt_databricks_cicd.avg_ticket_by_category)
[0m10:14:10.566554 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=model.dbt_databricks_cicd.avg_ticket_by_category, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.avg_discount_by_category
[0m10:14:10.566554 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:14:10.582177 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m10:14:10.582177 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:14:10.582177 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:14:10.582177 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`avg_ticket_by_category`
[0m10:14:10.597804 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m10:14:10.597804 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m10:14:10.597804 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_ticket_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.avg_ticket_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`avg_ticket_by_category`
  
  as (
    SELECT
  Category,
  ROUND(AVG(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS avg_ticket
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY avg_ticket DESC
  )

[0m10:14:11.222837 [debug] [Thread-1 (]: SQL status: OK in 0.630 seconds
[0m10:14:11.222837 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3aa0-1d85-815c-5273047f2410) - Closing
[0m10:14:11.222837 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:14:11.222837 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd78e1e36-e22d-4afe-aead-850509ccfc49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001885DC99990>]}
[0m10:14:11.222837 [info ] [Thread-1 (]: 17 of 46 OK created sql view model default.avg_ticket_by_category .............. [[32mOK[0m in 0.67s]
[0m10:14:11.222837 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:14:11.222837 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.monthly_revenue
[0m10:14:11.238428 [info ] [Thread-1 (]: 18 of 46 START sql view model default.monthly_revenue .......................... [RUN]
[0m10:14:11.238428 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_ticket_by_category, now model.dbt_databricks_cicd.monthly_revenue)
[0m10:14:11.238428 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=model.dbt_databricks_cicd.monthly_revenue, idle-time=0.015590667724609375s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:14:11.238428 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.monthly_revenue
[0m10:14:11.238428 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.monthly_revenue"
[0m10:14:11.238428 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.monthly_revenue
[0m10:14:11.254095 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:14:11.254095 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`monthly_revenue`
[0m10:14:11.254095 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.monthly_revenue"
[0m10:14:11.254095 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.monthly_revenue"
[0m10:14:11.269679 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.monthly_revenue: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.monthly_revenue"} */

  
  
  
  create or replace view `workspace`.`default`.`monthly_revenue`
  
  as (
    SELECT
  CAST(DATE_TRUNC('month', CAST(Purchase_Date AS DATE)) AS DATE) AS month,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS monthly_revenue
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY 1
ORDER BY 1
  )

[0m10:14:11.894711 [debug] [Thread-1 (]: SQL status: OK in 0.630 seconds
[0m10:14:11.894711 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3b06-1940-9b60-f457a94e6b84) - Closing
[0m10:14:11.894711 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:14:11.894711 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd78e1e36-e22d-4afe-aead-850509ccfc49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001885E159F50>]}
[0m10:14:11.894711 [info ] [Thread-1 (]: 18 of 46 OK created sql view model default.monthly_revenue ..................... [[32mOK[0m in 0.66s]
[0m10:14:11.894711 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.monthly_revenue
[0m10:14:11.894711 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.payment_distribution
[0m10:14:11.910305 [info ] [Thread-1 (]: 19 of 46 START sql view model default.payment_distribution ..................... [RUN]
[0m10:14:11.910305 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.monthly_revenue, now model.dbt_databricks_cicd.payment_distribution)
[0m10:14:11.910305 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=model.dbt_databricks_cicd.payment_distribution, idle-time=0.015593767166137695s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.monthly_revenue
[0m10:14:11.910305 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.payment_distribution
[0m10:14:11.910305 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.payment_distribution"
[0m10:14:11.925965 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.payment_distribution
[0m10:14:11.925965 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:14:11.925965 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`payment_distribution`
[0m10:14:11.925965 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.payment_distribution"
[0m10:14:11.925965 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.payment_distribution"
[0m10:14:11.941550 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.payment_distribution: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.payment_distribution"} */

  
  
  
  create or replace view `workspace`.`default`.`payment_distribution`
  
  as (
    SELECT
  Payment_Method,
  COUNT(*) AS total_transactions,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_value
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Payment_Method
ORDER BY total_value DESC
  )

[0m10:14:12.535432 [debug] [Thread-1 (]: SQL status: OK in 0.590 seconds
[0m10:14:12.535432 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3b6d-1493-a107-e9f80e0d9e56) - Closing
[0m10:14:12.535432 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:14:12.535432 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd78e1e36-e22d-4afe-aead-850509ccfc49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001885DC67C10>]}
[0m10:14:12.535432 [info ] [Thread-1 (]: 19 of 46 OK created sql view model default.payment_distribution ................ [[32mOK[0m in 0.63s]
[0m10:14:12.535432 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.payment_distribution
[0m10:14:12.550926 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.sales_by_category
[0m10:14:12.550926 [info ] [Thread-1 (]: 20 of 46 START sql view model default.sales_by_category ........................ [RUN]
[0m10:14:12.550926 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.payment_distribution, now model.dbt_databricks_cicd.sales_by_category)
[0m10:14:12.550926 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=model.dbt_databricks_cicd.sales_by_category, idle-time=0.01549386978149414s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.payment_distribution
[0m10:14:12.550926 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.sales_by_category
[0m10:14:12.550926 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.sales_by_category"
[0m10:14:12.566551 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.sales_by_category
[0m10:14:12.566551 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:14:12.566551 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`sales_by_category`
[0m10:14:12.566551 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.sales_by_category"
[0m10:14:12.566551 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.sales_by_category"
[0m10:14:12.582218 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.sales_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.sales_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`sales_by_category`
  
  as (
    SELECT
  Category,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_revenue
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY total_revenue DESC
  )

[0m10:14:13.129058 [debug] [Thread-1 (]: SQL status: OK in 0.550 seconds
[0m10:14:13.144679 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3bcf-1b62-8d83-aff73cca2377) - Closing
[0m10:14:13.144679 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:14:13.144679 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd78e1e36-e22d-4afe-aead-850509ccfc49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001885DC1D550>]}
[0m10:14:13.144679 [info ] [Thread-1 (]: 20 of 46 OK created sql view model default.sales_by_category ................... [[32mOK[0m in 0.59s]
[0m10:14:13.144679 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.sales_by_category
[0m10:14:13.160309 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_5_products
[0m10:14:13.160309 [info ] [Thread-1 (]: 21 of 46 START sql view model default.top_5_products ........................... [RUN]
[0m10:14:13.160309 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.sales_by_category, now model.dbt_databricks_cicd.top_5_products)
[0m10:14:13.160309 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=model.dbt_databricks_cicd.top_5_products, idle-time=0.015630245208740234s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.sales_by_category
[0m10:14:13.160309 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_5_products
[0m10:14:13.175933 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_5_products"
[0m10:14:13.175933 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_5_products
[0m10:14:13.191550 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:14:13.191550 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`top_5_products`
[0m10:14:13.191550 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_5_products"
[0m10:14:13.191550 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.top_5_products"
[0m10:14:13.191550 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_5_products: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.top_5_products"} */

  
  
  
  create or replace view `workspace`.`default`.`top_5_products`
  
  as (
    WITH base AS (
    SELECT
        product_id,
        ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_sales
    FROM `workspace`.`default`.`stg_ecommerce`
    GROUP BY product_id
)

SELECT
    product_id,
    total_sales
FROM base
ORDER BY total_sales DESC
LIMIT 5
  )

[0m10:14:13.769819 [debug] [Thread-1 (]: SQL status: OK in 0.580 seconds
[0m10:14:13.785337 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3c2d-1dc5-a740-6587faa9b555) - Closing
[0m10:14:13.785337 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:14:13.785337 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd78e1e36-e22d-4afe-aead-850509ccfc49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001885E0AE150>]}
[0m10:14:13.785337 [info ] [Thread-1 (]: 21 of 46 OK created sql view model default.top_5_products ...................... [[32mOK[0m in 0.63s]
[0m10:14:13.785337 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_5_products
[0m10:14:13.785337 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_customers
[0m10:14:13.785337 [info ] [Thread-1 (]: 22 of 46 START sql view model default.top_customers ............................ [RUN]
[0m10:14:13.785337 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_5_products, now model.dbt_databricks_cicd.top_customers)
[0m10:14:13.800967 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=model.dbt_databricks_cicd.top_customers, idle-time=0.015629291534423828s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.top_5_products
[0m10:14:13.800967 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_customers
[0m10:14:13.800967 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_customers"
[0m10:14:13.800967 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_customers
[0m10:14:13.816556 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:14:13.816556 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`top_customers`
[0m10:14:13.816556 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_customers"
[0m10:14:13.816556 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.top_customers"
[0m10:14:13.816556 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_customers: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.top_customers"} */

  
  
  
  create or replace view `workspace`.`default`.`top_customers`
  
  as (
    SELECT
  User_ID,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_spent
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY User_ID
ORDER BY total_spent DESC
LIMIT 10
  )

[0m10:14:14.441588 [debug] [Thread-1 (]: SQL status: OK in 0.630 seconds
[0m10:14:14.441588 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3c8d-114b-be0c-23f022658c93) - Closing
[0m10:14:14.441588 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:14:14.441588 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd78e1e36-e22d-4afe-aead-850509ccfc49', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001885E107650>]}
[0m10:14:14.441588 [info ] [Thread-1 (]: 22 of 46 OK created sql view model default.top_customers ....................... [[32mOK[0m in 0.66s]
[0m10:14:14.441588 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_customers
[0m10:14:14.441588 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:14:14.441588 [info ] [Thread-1 (]: 23 of 46 START test non_negative_avg_discount_by_category_avg_discount_percent . [RUN]
[0m10:14:14.457173 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_customers, now test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f)
[0m10:14:14.457173 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f, idle-time=0.015585184097290039s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.top_customers
[0m10:14:14.457173 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:14:14.457173 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"
[0m10:14:14.457173 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:14:14.472800 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"
[0m10:14:14.472800 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"
[0m10:14:14.472800 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`avg_discount_by_category`
where TRY_CAST(REPLACE(avg_discount_percent, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:14:14.832214 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m10:14:14.832214 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3cf0-1d6e-ab45-11455084a6b0) - Closing
[0m10:14:14.832214 [info ] [Thread-1 (]: 23 of 46 PASS non_negative_avg_discount_by_category_avg_discount_percent ....... [[32mPASS[0m in 0.38s]
[0m10:14:14.832214 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:14:14.832214 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:14:14.832214 [info ] [Thread-1 (]: 24 of 46 START test not_null_avg_discount_by_category_Category ................. [RUN]
[0m10:14:14.847801 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b)
[0m10:14:14.847801 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, idle-time=0.015587329864501953s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:14:14.847801 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:14:14.863424 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m10:14:14.863424 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:14:14.863424 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m10:14:14.879097 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m10:14:14.879097 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_discount_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m10:14:15.269817 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m10:14:15.269817 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3d2d-1b91-b5dd-f4ff0d372899) - Closing
[0m10:14:15.269817 [info ] [Thread-1 (]: 24 of 46 PASS not_null_avg_discount_by_category_Category ....................... [[32mPASS[0m in 0.42s]
[0m10:14:15.269817 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:14:15.269817 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:14:15.285306 [info ] [Thread-1 (]: 25 of 46 START test not_null_avg_discount_by_category_avg_discount_percent ..... [RUN]
[0m10:14:15.285306 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101)
[0m10:14:15.285306 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, idle-time=0.015488862991333008s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:14:15.285306 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:14:15.285306 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m10:14:15.300936 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:14:15.300936 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m10:14:15.300936 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m10:14:15.300936 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_discount_percent
from `workspace`.`default`.`avg_discount_by_category`
where avg_discount_percent is null



  
  
      
    ) dbt_internal_test
[0m10:14:15.676068 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m10:14:15.676068 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3d70-142b-a07f-74b083f7c30d) - Closing
[0m10:14:15.691597 [info ] [Thread-1 (]: 25 of 46 PASS not_null_avg_discount_by_category_avg_discount_percent ........... [[32mPASS[0m in 0.41s]
[0m10:14:15.691597 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:14:15.691597 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:14:15.691597 [info ] [Thread-1 (]: 26 of 46 START test non_negative_avg_ticket_by_category_avg_ticket ............. [RUN]
[0m10:14:15.691597 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, now test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095)
[0m10:14:15.691597 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:14:15.691597 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:14:15.707218 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"
[0m10:14:15.707218 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:14:15.722849 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"
[0m10:14:15.722849 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"
[0m10:14:15.722849 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`avg_ticket_by_category`
where TRY_CAST(REPLACE(avg_ticket, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:14:16.082187 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m10:14:16.082187 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3dad-1ea5-aac3-1dab38fa0d87) - Closing
[0m10:14:16.082187 [info ] [Thread-1 (]: 26 of 46 PASS non_negative_avg_ticket_by_category_avg_ticket ................... [[32mPASS[0m in 0.39s]
[0m10:14:16.082187 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:14:16.097809 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:14:16.097809 [info ] [Thread-1 (]: 27 of 46 START test not_null_avg_ticket_by_category_Category ................... [RUN]
[0m10:14:16.097809 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f)
[0m10:14:16.097809 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, idle-time=0.01562190055847168s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:14:16.097809 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:14:16.113433 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m10:14:16.113433 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:14:16.113433 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m10:14:16.113433 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m10:14:16.113433 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_ticket_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m10:14:16.472836 [debug] [Thread-1 (]: SQL status: OK in 0.340 seconds
[0m10:14:16.472836 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3deb-1f92-936b-756ae5f6c2c2) - Closing
[0m10:14:16.472836 [info ] [Thread-1 (]: 27 of 46 PASS not_null_avg_ticket_by_category_Category ......................... [[32mPASS[0m in 0.38s]
[0m10:14:16.472836 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:14:16.472836 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:14:16.472836 [info ] [Thread-1 (]: 28 of 46 START test not_null_avg_ticket_by_category_avg_ticket ................. [RUN]
[0m10:14:16.472836 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41)
[0m10:14:16.488437 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, idle-time=0.015601634979248047s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:14:16.488437 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:14:16.488437 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m10:14:16.488437 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:14:16.504059 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m10:14:16.504059 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m10:14:16.504059 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_ticket
from `workspace`.`default`.`avg_ticket_by_category`
where avg_ticket is null



  
  
      
    ) dbt_internal_test
[0m10:14:16.863463 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m10:14:16.863463 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3e27-108f-9236-e25ce46a6db3) - Closing
[0m10:14:16.863463 [info ] [Thread-1 (]: 28 of 46 PASS not_null_avg_ticket_by_category_avg_ticket ....................... [[32mPASS[0m in 0.39s]
[0m10:14:16.863463 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:14:16.863463 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:14:16.863463 [info ] [Thread-1 (]: 29 of 46 START test non_negative_monthly_revenue_monthly_revenue ............... [RUN]
[0m10:14:16.863463 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, now test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294)
[0m10:14:16.879092 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294, idle-time=0.015628576278686523s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:14:16.879092 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:14:16.879092 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"
[0m10:14:16.879092 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:14:16.894717 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"
[0m10:14:16.894717 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"
[0m10:14:16.894717 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`monthly_revenue`
where TRY_CAST(REPLACE(monthly_revenue, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:14:17.254202 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m10:14:17.254202 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3e62-1802-89ad-b4b65b072e28) - Closing
[0m10:14:17.269675 [info ] [Thread-1 (]: 29 of 46 PASS non_negative_monthly_revenue_monthly_revenue ..................... [[32mPASS[0m in 0.41s]
[0m10:14:17.269675 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:14:17.269675 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:14:17.269675 [info ] [Thread-1 (]: 30 of 46 START test not_null_monthly_revenue_month ............................. [RUN]
[0m10:14:17.269675 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294, now test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b)
[0m10:14:17.269675 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:14:17.269675 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:14:17.285342 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m10:14:17.285342 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:14:17.300928 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m10:14:17.300928 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m10:14:17.300928 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select month
from `workspace`.`default`.`monthly_revenue`
where month is null



  
  
      
    ) dbt_internal_test
[0m10:14:17.738563 [debug] [Thread-1 (]: SQL status: OK in 0.440 seconds
[0m10:14:17.738563 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3e9f-1ba5-b972-61d377e95240) - Closing
[0m10:14:17.738563 [info ] [Thread-1 (]: 30 of 46 PASS not_null_monthly_revenue_month ................................... [[32mPASS[0m in 0.47s]
[0m10:14:17.738563 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:14:17.738563 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:14:17.754062 [info ] [Thread-1 (]: 31 of 46 START test not_null_monthly_revenue_monthly_revenue ................... [RUN]
[0m10:14:17.754062 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, now test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b)
[0m10:14:17.754062 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, idle-time=0.015499114990234375s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:14:17.754062 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:14:17.754062 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m10:14:17.769676 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:14:17.769676 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m10:14:17.769676 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m10:14:17.769676 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select monthly_revenue
from `workspace`.`default`.`monthly_revenue`
where monthly_revenue is null



  
  
      
    ) dbt_internal_test
[0m10:14:18.113560 [debug] [Thread-1 (]: SQL status: OK in 0.340 seconds
[0m10:14:18.129095 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3ee8-133d-a643-041a9672d9e6) - Closing
[0m10:14:18.129095 [info ] [Thread-1 (]: 31 of 46 PASS not_null_monthly_revenue_monthly_revenue ......................... [[32mPASS[0m in 0.38s]
[0m10:14:18.129095 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:14:18.129095 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:14:18.129095 [info ] [Thread-1 (]: 32 of 46 START test non_negative_payment_distribution_total_value .............. [RUN]
[0m10:14:18.129095 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, now test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282)
[0m10:14:18.129095 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:14:18.144676 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:14:18.144676 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"
[0m10:14:18.144676 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:14:18.160303 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"
[0m10:14:18.160303 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"
[0m10:14:18.160303 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`payment_distribution`
where TRY_CAST(REPLACE(total_value, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:14:18.550961 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m10:14:18.550961 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3f22-1b75-9e83-4520ec314f9b) - Closing
[0m10:14:18.550961 [info ] [Thread-1 (]: 32 of 46 PASS non_negative_payment_distribution_total_value .................... [[32mPASS[0m in 0.42s]
[0m10:14:18.550961 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:14:18.550961 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:14:18.550961 [info ] [Thread-1 (]: 33 of 46 START test not_null_payment_distribution_Payment_Method ............... [RUN]
[0m10:14:18.566588 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282, now test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae)
[0m10:14:18.566588 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, idle-time=0.01562643051147461s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:14:18.566588 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:14:18.566588 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m10:14:18.582179 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:14:18.582179 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m10:14:18.582179 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m10:14:18.597808 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`payment_distribution`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m10:14:18.957213 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m10:14:18.957213 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3f65-1081-b109-ed6148856fd1) - Closing
[0m10:14:18.957213 [info ] [Thread-1 (]: 33 of 46 PASS not_null_payment_distribution_Payment_Method ..................... [[32mPASS[0m in 0.41s]
[0m10:14:18.957213 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:14:18.957213 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:14:18.957213 [info ] [Thread-1 (]: 34 of 46 START test not_null_payment_distribution_total_transactions ........... [RUN]
[0m10:14:18.972804 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, now test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8)
[0m10:14:18.972804 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, idle-time=0.015590906143188477s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:14:18.972804 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:14:18.972804 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m10:14:18.972804 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:14:18.988431 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m10:14:18.988431 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m10:14:18.988431 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_transactions
from `workspace`.`default`.`payment_distribution`
where total_transactions is null



  
  
      
    ) dbt_internal_test
[0m10:14:19.347856 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m10:14:19.363426 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3fa2-1d49-b236-358e5efce95a) - Closing
[0m10:14:19.363426 [info ] [Thread-1 (]: 34 of 46 PASS not_null_payment_distribution_total_transactions ................. [[32mPASS[0m in 0.41s]
[0m10:14:19.363426 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:14:19.363426 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:14:19.363426 [info ] [Thread-1 (]: 35 of 46 START test not_null_payment_distribution_total_value .................. [RUN]
[0m10:14:19.363426 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, now test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03)
[0m10:14:19.363426 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:14:19.363426 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:14:19.379061 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m10:14:19.379061 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:14:19.394678 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m10:14:19.394678 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m10:14:19.394678 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_value
from `workspace`.`default`.`payment_distribution`
where total_value is null



  
  
      
    ) dbt_internal_test
[0m10:14:19.769674 [debug] [Thread-1 (]: SQL status: OK in 0.370 seconds
[0m10:14:19.769674 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-3fdf-131d-bd08-42ea72219324) - Closing
[0m10:14:19.769674 [info ] [Thread-1 (]: 35 of 46 PASS not_null_payment_distribution_total_value ........................ [[32mPASS[0m in 0.41s]
[0m10:14:19.769674 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:14:19.769674 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:14:19.769674 [info ] [Thread-1 (]: 36 of 46 START test non_negative_sales_by_category_total_revenue ............... [RUN]
[0m10:14:19.785301 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, now test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41)
[0m10:14:19.785301 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41, idle-time=0.01562666893005371s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:14:19.785301 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:14:19.800932 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"
[0m10:14:19.800932 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:14:19.816554 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"
[0m10:14:19.816554 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"
[0m10:14:19.816554 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`sales_by_category`
where TRY_CAST(REPLACE(total_revenue, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:14:20.191554 [debug] [Thread-1 (]: SQL status: OK in 0.380 seconds
[0m10:14:20.207179 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-4020-1dbd-8f94-1530ae878866) - Closing
[0m10:14:20.207179 [info ] [Thread-1 (]: 36 of 46 PASS non_negative_sales_by_category_total_revenue ..................... [[32mPASS[0m in 0.42s]
[0m10:14:20.207179 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:14:20.207179 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:14:20.207179 [info ] [Thread-1 (]: 37 of 46 START test not_null_sales_by_category_Category ........................ [RUN]
[0m10:14:20.207179 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41, now test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507)
[0m10:14:20.207179 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:14:20.222801 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:14:20.238434 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m10:14:20.238434 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:14:20.238434 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m10:14:20.254057 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m10:14:20.254057 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`sales_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m10:14:20.613428 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m10:14:20.613428 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-4061-1d1c-bbd1-0f0ad1c834bc) - Closing
[0m10:14:20.613428 [info ] [Thread-1 (]: 37 of 46 PASS not_null_sales_by_category_Category .............................. [[32mPASS[0m in 0.41s]
[0m10:14:20.613428 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:14:20.629050 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:14:20.629050 [info ] [Thread-1 (]: 38 of 46 START test not_null_sales_by_category_total_orders .................... [RUN]
[0m10:14:20.629050 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, now test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e)
[0m10:14:20.629050 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, idle-time=0.01562190055847168s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:14:20.629050 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:14:20.644724 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m10:14:20.644724 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:14:20.660303 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m10:14:20.660303 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m10:14:20.660303 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`sales_by_category`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m10:14:21.019814 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m10:14:21.019814 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-40a0-1a49-89c8-e330ecad461f) - Closing
[0m10:14:21.035347 [info ] [Thread-1 (]: 38 of 46 PASS not_null_sales_by_category_total_orders .......................... [[32mPASS[0m in 0.41s]
[0m10:14:21.035347 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:14:21.035347 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:14:21.035347 [info ] [Thread-1 (]: 39 of 46 START test not_null_sales_by_category_total_revenue ................... [RUN]
[0m10:14:21.035347 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, now test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd)
[0m10:14:21.035347 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:14:21.035347 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:14:21.050968 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m10:14:21.050968 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:14:21.050968 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m10:14:21.066594 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m10:14:21.066594 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_revenue
from `workspace`.`default`.`sales_by_category`
where total_revenue is null



  
  
      
    ) dbt_internal_test
[0m10:14:21.457299 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m10:14:21.457299 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-40de-10c2-b02d-da90e0721cc0) - Closing
[0m10:14:21.457299 [info ] [Thread-1 (]: 39 of 46 PASS not_null_sales_by_category_total_revenue ......................... [[32mPASS[0m in 0.42s]
[0m10:14:21.457299 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:14:21.472804 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:14:21.472804 [info ] [Thread-1 (]: 40 of 46 START test non_negative_top_5_products_total_sales .................... [RUN]
[0m10:14:21.472804 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, now test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34)
[0m10:14:21.472804 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34, idle-time=0.015505313873291016s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:14:21.472804 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:14:21.472804 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"
[0m10:14:21.488440 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:14:21.488440 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"
[0m10:14:21.488440 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"
[0m10:14:21.488440 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`top_5_products`
where TRY_CAST(REPLACE(total_sales, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:14:21.879193 [debug] [Thread-1 (]: SQL status: OK in 0.390 seconds
[0m10:14:21.879193 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-4120-163b-a080-00bf7fae80c8) - Closing
[0m10:14:21.879193 [info ] [Thread-1 (]: 40 of 46 PASS non_negative_top_5_products_total_sales .......................... [[32mPASS[0m in 0.41s]
[0m10:14:21.879193 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:14:21.894675 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:14:21.894675 [info ] [Thread-1 (]: 41 of 46 START test not_null_top_5_products_product_id ......................... [RUN]
[0m10:14:21.894675 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34, now test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe)
[0m10:14:21.894675 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, idle-time=0.01548147201538086s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:14:21.894675 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:14:21.894675 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m10:14:21.910344 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:14:21.910344 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m10:14:21.910344 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m10:14:21.910344 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select product_id
from `workspace`.`default`.`top_5_products`
where product_id is null



  
  
      
    ) dbt_internal_test
[0m10:14:22.254188 [debug] [Thread-1 (]: SQL status: OK in 0.330 seconds
[0m10:14:22.269713 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-4160-19be-b78d-d6d905d75e36) - Closing
[0m10:14:22.269713 [info ] [Thread-1 (]: 41 of 46 PASS not_null_top_5_products_product_id ............................... [[32mPASS[0m in 0.38s]
[0m10:14:22.269713 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:14:22.269713 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:14:22.269713 [info ] [Thread-1 (]: 42 of 46 START test not_null_top_5_products_total_sales ........................ [RUN]
[0m10:14:22.269713 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, now test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818)
[0m10:14:22.269713 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:14:22.269713 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:14:22.285301 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m10:14:22.285301 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:14:22.300964 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m10:14:22.300964 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m10:14:22.300964 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_sales
from `workspace`.`default`.`top_5_products`
where total_sales is null



  
  
      
    ) dbt_internal_test
[0m10:14:22.676065 [debug] [Thread-1 (]: SQL status: OK in 0.380 seconds
[0m10:14:22.676065 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-419b-1ba2-bc20-0d99ea82f39b) - Closing
[0m10:14:22.676065 [info ] [Thread-1 (]: 42 of 46 PASS not_null_top_5_products_total_sales .............................. [[32mPASS[0m in 0.41s]
[0m10:14:22.691550 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:14:22.691550 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:14:22.691550 [info ] [Thread-1 (]: 43 of 46 START test non_negative_top_customers_total_spent ..................... [RUN]
[0m10:14:22.691550 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, now test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667)
[0m10:14:22.691550 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667, idle-time=0.015484809875488281s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:14:22.691550 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:14:22.707185 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"
[0m10:14:22.707185 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:14:22.707185 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"
[0m10:14:22.707185 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"
[0m10:14:22.707185 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`top_customers`
where TRY_CAST(REPLACE(total_spent, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:14:23.082214 [debug] [Thread-1 (]: SQL status: OK in 0.380 seconds
[0m10:14:23.082214 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-41d9-18d4-83a5-9e0fd7780874) - Closing
[0m10:14:23.082214 [info ] [Thread-1 (]: 43 of 46 PASS non_negative_top_customers_total_spent ........................... [[32mPASS[0m in 0.39s]
[0m10:14:23.082214 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:14:23.082214 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:14:23.082214 [info ] [Thread-1 (]: 44 of 46 START test not_null_top_customers_User_ID ............................. [RUN]
[0m10:14:23.082214 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667, now test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0)
[0m10:14:23.097841 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, idle-time=0.015627145767211914s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:14:23.097841 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:14:23.097841 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m10:14:23.097841 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:14:23.113466 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m10:14:23.113466 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m10:14:23.113466 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`top_customers`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m10:14:23.535344 [debug] [Thread-1 (]: SQL status: OK in 0.420 seconds
[0m10:14:23.535344 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-4218-12a0-9431-138e978a381f) - Closing
[0m10:14:23.535344 [info ] [Thread-1 (]: 44 of 46 PASS not_null_top_customers_User_ID ................................... [[32mPASS[0m in 0.45s]
[0m10:14:23.535344 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:14:23.535344 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:14:23.535344 [info ] [Thread-1 (]: 45 of 46 START test not_null_top_customers_total_orders ........................ [RUN]
[0m10:14:23.535344 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, now test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746)
[0m10:14:23.535344 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:14:23.550964 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:14:23.550964 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m10:14:23.550964 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:14:23.566589 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m10:14:23.566589 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m10:14:23.566589 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`top_customers`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m10:14:23.941691 [debug] [Thread-1 (]: SQL status: OK in 0.380 seconds
[0m10:14:23.941691 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-425c-1fab-a13d-d4688f8b802c) - Closing
[0m10:14:23.941691 [info ] [Thread-1 (]: 45 of 46 PASS not_null_top_customers_total_orders .............................. [[32mPASS[0m in 0.41s]
[0m10:14:23.941691 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:14:23.957184 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m10:14:23.957184 [info ] [Thread-1 (]: 46 of 46 START test not_null_top_customers_total_spent ......................... [RUN]
[0m10:14:23.957184 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, now test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73)
[0m10:14:23.957184 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, name=test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73, idle-time=0.015492916107177734s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:14:23.957184 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m10:14:23.957184 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m10:14:23.972804 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m10:14:23.972804 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m10:14:23.972804 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m10:14:23.972804 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_spent
from `workspace`.`default`.`top_customers`
where total_spent is null



  
  
      
    ) dbt_internal_test
[0m10:14:24.332298 [debug] [Thread-1 (]: SQL status: OK in 0.360 seconds
[0m10:14:24.332298 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a, command-id=01f07c35-429a-1949-9d65-0b52d5511277) - Closing
[0m10:14:24.332298 [info ] [Thread-1 (]: 46 of 46 PASS not_null_top_customers_total_spent ............................... [[32mPASS[0m in 0.38s]
[0m10:14:24.347803 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m10:14:24.347803 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=21.999996423721313s, language=None, compute-name=) - Reusing connection previously named master
[0m10:14:24.347803 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:14:24.347803 [debug] [MainThread]: Connection 'list_workspace' was properly closed.
[0m10:14:24.347803 [debug] [MainThread]: On list_workspace: Close
[0m10:14:24.347803 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07c35-348d-1224-8599-e426608bc666) - Closing
[0m10:14:24.582297 [debug] [MainThread]: Connection 'list_workspace_default' was properly closed.
[0m10:14:24.582297 [debug] [MainThread]: On list_workspace_default: Close
[0m10:14:24.582297 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07c35-3541-104e-9a50-96c9c943e0da) - Closing
[0m10:14:24.801071 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73' was properly closed.
[0m10:14:24.801071 [debug] [MainThread]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: Close
[0m10:14:24.801071 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07c35-3616-1a26-bb53-c9b8e206da0a) - Closing
[0m10:14:25.019795 [info ] [MainThread]: 
[0m10:14:25.019795 [info ] [MainThread]: Finished running 37 data tests, 9 view models in 0 hours 0 minutes and 25.25 seconds (25.25s).
[0m10:14:25.050963 [debug] [MainThread]: Command end result
[0m10:14:25.129051 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m10:14:25.129051 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m10:14:25.144716 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m10:14:25.144716 [info ] [MainThread]: 
[0m10:14:25.144716 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:14:25.160305 [info ] [MainThread]: 
[0m10:14:25.160305 [info ] [MainThread]: Done. PASS=46 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=46
[0m10:14:25.160305 [debug] [MainThread]: Command `dbt build` succeeded at 10:14:25.160305 after 31.62 seconds
[0m10:14:25.160305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000018850F94B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001884A6F3DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001884A9510D0>]}
[0m10:14:25.160305 [debug] [MainThread]: Flushing usage events
[0m10:14:25.925933 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:11:17.821811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C50DAA3050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C50DAA3950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C50DAA1310>]}


============================== 15:11:17.839499 | 1d523f6f-de48-4862-b991-5c160063ba73 ==============================
[0m15:11:17.839499 [info ] [MainThread]: Running with dbt=1.10.3
[0m15:11:17.839499 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt build --target sqlserver', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:11:21.772771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1d523f6f-de48-4862-b991-5c160063ba73', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C50F37F510>]}
[0m15:11:21.882371 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1d523f6f-de48-4862-b991-5c160063ba73', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C50CA01ED0>]}
[0m15:11:21.882371 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m15:11:22.882113 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m15:11:23.096165 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m15:11:23.096165 [debug] [MainThread]: previous checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, current checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9
[0m15:11:23.096165 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m15:11:23.101122 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m15:11:23.101122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '1d523f6f-de48-4862-b991-5c160063ba73', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C50D1A41D0>]}
[0m15:11:29.573621 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m15:11:29.574622 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m15:11:29.575622 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m15:11:29.577624 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m15:11:29.579648 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m15:11:29.581621 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m15:11:29.582621 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m15:11:29.584621 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m15:11:29.585744 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m15:11:29.586749 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m15:11:29.587748 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m15:11:29.588747 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m15:11:29.590746 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m15:11:29.591749 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m15:11:29.592753 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m15:11:29.594749 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m15:11:29.595748 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m15:11:29.596747 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m15:11:29.598746 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m15:11:29.599745 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m15:11:29.600802 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m15:11:29.600802 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m15:11:29.600802 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m15:11:29.600802 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m15:11:29.758135 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m15:11:29.773762 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1d523f6f-de48-4862-b991-5c160063ba73', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C50FA44510>]}
[0m15:11:30.052275 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m15:11:30.060967 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m15:11:30.210611 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1d523f6f-de48-4862-b991-5c160063ba73', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C50FA61C10>]}
[0m15:11:30.210611 [info ] [MainThread]: Found 2 models, 13 data tests, 1 source, 628 macros
[0m15:11:30.226251 [info ] [MainThread]: 
[0m15:11:30.226251 [info ] [MainThread]: Concurrency: 1 threads (target='sqlserver')
[0m15:11:30.226251 [info ] [MainThread]: 
[0m15:11:30.226251 [debug] [MainThread]: Acquiring new sqlserver connection 'master'
[0m15:11:30.226251 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db'
[0m15:11:30.290011 [debug] [ThreadPool]: dbt-sqlserver
[0m15:11:30.294171 [debug] [ThreadPool]: Using sqlserver connection "list_my_db"
[0m15:11:30.294171 [debug] [ThreadPool]: On list_my_db: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db"} */
USE [my_db];
    select  name as [schema]
    from sys.schemas with (nolock) 
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m15:11:30.294171 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:11:30.294171 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:11:30.542929 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m15:11:30.553571 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:11:30.557693 [debug] [ThreadPool]: On list_my_db: Close
[0m15:11:30.561698 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db_dbo'
[0m15:11:30.572809 [debug] [ThreadPool]: dbt-sqlserver
[0m15:11:30.573770 [debug] [ThreadPool]: Using sqlserver connection "list_my_db_dbo"
[0m15:11:30.574813 [debug] [ThreadPool]: On list_my_db_dbo: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db_dbo"} */
USE [my_db];
    with base as (
      select
        DB_NAME() as [database],
        t.name as [name],
        SCHEMA_NAME(t.schema_id) as [schema],
        'table' as table_type
      from sys.tables as t with (nolock)
      union all
      select
        DB_NAME() as [database],
        v.name as [name],
        SCHEMA_NAME(v.schema_id) as [schema],
        'view' as table_type
      from sys.views as v with (nolock)
    )
    select * from base
    where [schema] like 'dbo'
    
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m15:11:30.575778 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:11:30.577772 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:11:30.579770 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m15:11:30.659614 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:11:30.675239 [debug] [ThreadPool]: On list_my_db_dbo: ROLLBACK
[0m15:11:30.675239 [debug] [ThreadPool]: On list_my_db_dbo: Close
[0m15:11:30.675239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1d523f6f-de48-4862-b991-5c160063ba73', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C50F8D2C50>]}
[0m15:11:30.675239 [debug] [MainThread]: On master: COMMIT
[0m15:11:30.690863 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m15:11:30.690863 [info ] [Thread-1 (]: 1 of 15 START sql view model dbo.src_ecommerce ................................. [RUN]
[0m15:11:30.690863 [debug] [Thread-1 (]: Acquiring new sqlserver connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m15:11:30.690863 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m15:11:30.710262 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m15:11:30.710262 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m15:11:30.804446 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m15:11:30.804446 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:11:30.810359 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."src_ecommerce__dbt_tmp" as 

select * from "my_db"."dbo"."ecommerce";
    ')


[0m15:11:30.810359 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m15:11:30.810359 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:11:30.810359 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:11:30.826006 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:30.841615 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:11:30.841615 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce', 'src_ecommerce__dbt_backup'
[0m15:11:31.126672 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:31.126672 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:11:31.126672 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce__dbt_tmp', 'src_ecommerce'
[0m15:11:31.126672 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:31.157922 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: COMMIT
[0m15:11:31.173587 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."src_ecommerce__dbt_backup"
[0m15:11:31.193194 [debug] [Thread-1 (]: dbt-sqlserver
[0m15:11:31.193194 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:11:31.193194 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'src_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m15:11:31.243049 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:31.243049 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m15:11:31.243049 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."src_ecommerce__dbt_backup";');

[0m15:11:31.243049 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:31.243049 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: ROLLBACK
[0m15:11:31.258678 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: Close
[0m15:11:31.258678 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1d523f6f-de48-4862-b991-5c160063ba73', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C50D1F6090>]}
[0m15:11:31.258678 [info ] [Thread-1 (]: 1 of 15 OK created sql view model dbo.src_ecommerce ............................ [[32mOK[0m in 0.57s]
[0m15:11:31.258678 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m15:11:31.274303 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m15:11:31.274303 [info ] [Thread-1 (]: 2 of 15 START sql view model dbo.stg_ecommerce ................................. [RUN]
[0m15:11:31.274303 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m15:11:31.274303 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m15:11:31.294540 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:11:31.294540 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m15:11:31.310166 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:11:31.310166 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:11:31.310166 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."stg_ecommerce__dbt_tmp" as 

SELECT
    
        CAST(User_ID AS VARCHAR) AS User_ID,
        CAST(Product_ID AS VARCHAR) AS Product_ID,
        CAST(Category AS VARCHAR) AS Category,
        CAST(Price AS FLOAT) AS Price,
        CAST(Discount AS INT) AS Discount,
        CAST(Final_Price AS FLOAT) AS Final_Price,
        CAST(Payment_Method AS VARCHAR) AS Payment_Method,
        CAST(Purchase_Date AS DATE) AS Purchase_Date
    
FROM "my_db"."dbo"."ecommerce";
    ')


[0m15:11:31.310166 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:11:31.310166 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:11:31.310166 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:11:31.329908 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:31.337017 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:11:31.339018 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce', 'stg_ecommerce__dbt_backup'
[0m15:11:31.344016 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:31.350014 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:11:31.351016 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce__dbt_tmp', 'stg_ecommerce'
[0m15:11:31.352070 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:31.352070 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: COMMIT
[0m15:11:31.359767 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."stg_ecommerce__dbt_backup"
[0m15:11:31.359767 [debug] [Thread-1 (]: dbt-sqlserver
[0m15:11:31.359767 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:11:31.359767 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'stg_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m15:11:31.375392 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:31.375392 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m15:11:31.391021 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."stg_ecommerce__dbt_backup";');

[0m15:11:31.391021 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:31.391021 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: ROLLBACK
[0m15:11:31.391021 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: Close
[0m15:11:31.391021 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1d523f6f-de48-4862-b991-5c160063ba73', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C50F8A7910>]}
[0m15:11:31.391021 [info ] [Thread-1 (]: 2 of 15 OK created sql view model dbo.stg_ecommerce ............................ [[32mOK[0m in 0.12s]
[0m15:11:31.391021 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m15:11:31.410580 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m15:11:31.410580 [info ] [Thread-1 (]: 3 of 15 START test accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [RUN]
[0m15:11:31.410580 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6)
[0m15:11:31.410580 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m15:11:31.410580 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m15:11:31.426231 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m15:11:31.473092 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m15:11:31.477201 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"
[0m15:11:31.477201 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_8538]
   as 
    
    
    

with all_values as (

    select
        Payment_Method as value_field,
        count(*) as n_records

    from "my_db"."dbo"."stg_ecommerce"
    group by Payment_Method

)

select *
from all_values
where value_field not in (
    ''Credit Card'',''Net Banking'',''UPI'',''Debit Card'',''Cash on Delivery''
)



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_8538]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_15dca9aaec8ef778fa7d6dae5ed47216_8538]
  ;')
[0m15:11:31.477201 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:11:31.477201 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:11:31.477201 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:11:31.492831 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:31.509721 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: ROLLBACK
[0m15:11:31.509721 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6: Close
[0m15:11:31.509721 [info ] [Thread-1 (]: 3 of 15 PASS accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery  [[32mPASS[0m in 0.10s]
[0m15:11:31.509721 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6
[0m15:11:31.509721 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m15:11:31.509721 [info ] [Thread-1 (]: 4 of 15 START test non_negative_stg_ecommerce_Discount ......................... [RUN]
[0m15:11:31.509721 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.accepted_values_stg_ecommerce_Payment_Method__Credit_Card__Net_Banking__UPI__Debit_Card__Cash_on_Delivery.bea16a73a6, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb)
[0m15:11:31.509721 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m15:11:31.525345 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m15:11:31.525345 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m15:11:31.543279 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m15:11:31.545201 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"
[0m15:11:31.546199 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_51dbea34b4242ad29f4241884f1076fc_18168]
   as 
    
select *
from "my_db"."dbo"."stg_ecommerce"
where TRY_CAST(REPLACE(Discount, '','', ''.'') AS DOUBLE) < 0

  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_51dbea34b4242ad29f4241884f1076fc_18168]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_51dbea34b4242ad29f4241884f1076fc_18168]
  ;')
[0m15:11:31.548199 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:11:31.549198 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:11:31.550201 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:11:31.555343 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:31.558347 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb: ROLLBACK
[0m15:11:31.561384 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb: Close
[0m15:11:31.562346 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\non_negative_stg_ecommerce_Discount.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)")
[0m15:11:31.694587 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)")

[0m15:11:31.694587 [error] [Thread-1 (]: 4 of 15 ERROR non_negative_stg_ecommerce_Discount .............................. [[31mERROR[0m in 0.18s]
[0m15:11:31.694587 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb
[0m15:11:31.694587 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m15:11:31.694587 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)").
[0m15:11:31.694587 [info ] [Thread-1 (]: 5 of 15 START test non_negative_stg_ecommerce_Final_Price ...................... [RUN]
[0m15:11:31.709217 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Discount.3a086c10fb, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7)
[0m15:11:31.709217 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m15:11:31.709217 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m15:11:31.709217 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m15:11:31.724837 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m15:11:31.724837 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"
[0m15:11:31.724837 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_c3a17526af5b949091c30d7cd3216d68_7292]
   as 
    
select *
from "my_db"."dbo"."stg_ecommerce"
where TRY_CAST(REPLACE(Final_Price, '','', ''.'') AS DOUBLE) < 0

  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_c3a17526af5b949091c30d7cd3216d68_7292]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_c3a17526af5b949091c30d7cd3216d68_7292]
  ;')
[0m15:11:31.724837 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:11:31.724837 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:11:31.724837 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:11:31.740472 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:31.740472 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7: ROLLBACK
[0m15:11:31.740472 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7: Close
[0m15:11:31.740472 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\non_negative_stg_ecommerce_Final_Price.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)")
[0m15:11:31.740472 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)")

[0m15:11:31.756131 [error] [Thread-1 (]: 5 of 15 ERROR non_negative_stg_ecommerce_Final_Price ........................... [[31mERROR[0m in 0.05s]
[0m15:11:31.756131 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7
[0m15:11:31.756131 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m15:11:31.756131 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)").
[0m15:11:31.756131 [info ] [Thread-1 (]: 6 of 15 START test non_negative_stg_ecommerce_Price ............................ [RUN]
[0m15:11:31.756131 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Final_Price.a03e1bb6f7, now test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d)
[0m15:11:31.756131 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m15:11:31.771750 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m15:11:31.771750 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m15:11:31.787381 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m15:11:31.791757 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"
[0m15:11:31.792850 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_0e0f52892ab87f822c7c27c4f6fac738_16075]
   as 
    
select *
from "my_db"."dbo"."stg_ecommerce"
where TRY_CAST(REPLACE(Price, '','', ''.'') AS DOUBLE) < 0

  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_0e0f52892ab87f822c7c27c4f6fac738_16075]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_0e0f52892ab87f822c7c27c4f6fac738_16075]
  ;')
[0m15:11:31.792850 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:11:31.792850 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:11:31.792850 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:11:31.792850 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:31.792850 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d: ROLLBACK
[0m15:11:31.792850 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d: Close
[0m15:11:31.792850 [error] [Thread-1 (]: [31mUnhandled error while executing target\run\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\non_negative_stg_ecommerce_Price.sql[0m
('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)")
[0m15:11:31.808478 [debug] [Thread-1 (]: Traceback (most recent call last):
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 363, in safe_run
    result = self.compile_and_execute(manifest, ctx)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 310, in compile_and_execute
    result = self.run(ctx.node, manifest)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\base.py", line 410, in run
    return self.execute(compiled_node, manifest)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 290, in execute
    test_result = self.execute_data_test(test, manifest)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\task\test.py", line 165, in execute_data_test
    macro_func()
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 170, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\clients\jinja.py", line 82, in __call__
    return self.call_macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\clients\jinja.py", line 395, in call_macro
    return macro(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 770, in __call__
    return self._invoke(arguments, autoescape)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 784, in _invoke
    rv = self._func(*arguments)
         ^^^^^^^^^^^^^^^^^^^^^^
  File "<template>", line 52, in macro
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\sandbox.py", line 401, in call
    return __context.call(__obj, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\jinja2\runtime.py", line 303, in call
    return __obj(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt_common\record.py", line 507, in record_replay_wrapper
    return func_to_record(*call_args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\base\impl.py", line 437, in execute
    return self.connections.execute(sql=sql, auto_begin=auto_begin, fetch=fetch, limit=limit)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\diniz\Python\Lib\site-packages\dbt\adapters\fabric\fabric_connection_manager.py", line 562, in execute
    if not cursor.nextset():
           ^^^^^^^^^^^^^^^^
pyodbc.ProgrammingError: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)")

[0m15:11:31.808478 [error] [Thread-1 (]: 6 of 15 ERROR non_negative_stg_ecommerce_Price ................................. [[31mERROR[0m in 0.05s]
[0m15:11:31.808478 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d
[0m15:11:31.808478 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m15:11:31.808478 [debug] [Thread-4 (]: Marking all children of 'test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d' to be skipped because of status 'error'.  Reason: ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)").
[0m15:11:31.808478 [info ] [Thread-1 (]: 7 of 15 START test not_null_stg_ecommerce_Category ............................. [RUN]
[0m15:11:31.825350 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_stg_ecommerce_Price.be317a5f5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14)
[0m15:11:31.828539 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m15:11:31.828539 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m15:11:31.844177 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m15:11:31.844177 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m15:11:31.844177 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"
[0m15:11:31.844177 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_10948]
   as 
    
    
    



select Category
from "my_db"."dbo"."stg_ecommerce"
where Category is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_10948]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_f2efa54166599ee6729840ee1e8dd7cc_10948]
  ;')
[0m15:11:31.844177 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:11:31.844177 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:11:31.844177 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:11:31.859803 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:31.859803 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: ROLLBACK
[0m15:11:31.876707 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14: Close
[0m15:11:31.877676 [info ] [Thread-1 (]: 7 of 15 PASS not_null_stg_ecommerce_Category ................................... [[32mPASS[0m in 0.05s]
[0m15:11:31.880657 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14
[0m15:11:31.882980 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m15:11:31.884975 [info ] [Thread-1 (]: 8 of 15 START test not_null_stg_ecommerce_Discount ............................. [RUN]
[0m15:11:31.887005 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Category.24412d1c14, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836)
[0m15:11:31.887976 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m15:11:31.899072 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m15:11:31.899072 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m15:11:31.914699 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m15:11:31.914699 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"
[0m15:11:31.914699 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_1385]
   as 
    
    
    



select Discount
from "my_db"."dbo"."stg_ecommerce"
where Discount is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_1385]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_cc47a10de63f9bb6cd878dca5424cab2_1385]
  ;')
[0m15:11:31.914699 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:11:31.914699 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:11:31.914699 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:11:31.930428 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:31.930428 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: ROLLBACK
[0m15:11:31.941616 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836: Close
[0m15:11:31.942502 [info ] [Thread-1 (]: 8 of 15 PASS not_null_stg_ecommerce_Discount ................................... [[32mPASS[0m in 0.06s]
[0m15:11:31.942502 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836
[0m15:11:31.942502 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m15:11:31.942502 [info ] [Thread-1 (]: 9 of 15 START test not_null_stg_ecommerce_Final_Price .......................... [RUN]
[0m15:11:31.942502 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Discount.75a7cab836, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc)
[0m15:11:31.942502 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m15:11:31.958128 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m15:11:31.958128 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m15:11:31.958128 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m15:11:31.958128 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"
[0m15:11:31.973760 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_18687]
   as 
    
    
    



select Final_Price
from "my_db"."dbo"."stg_ecommerce"
where Final_Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_18687]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_6d794e88c380010a357479d365d48dbd_18687]
  ;')
[0m15:11:31.973760 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:11:31.973760 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:11:31.973760 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:11:31.989416 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:31.994640 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: ROLLBACK
[0m15:11:31.995649 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc: Close
[0m15:11:31.997641 [info ] [Thread-1 (]: 9 of 15 PASS not_null_stg_ecommerce_Final_Price ................................ [[32mPASS[0m in 0.05s]
[0m15:11:32.000373 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc
[0m15:11:32.002362 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m15:11:32.003353 [info ] [Thread-1 (]: 10 of 15 START test not_null_stg_ecommerce_Payment_Method ...................... [RUN]
[0m15:11:32.005822 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Final_Price.8088a297fc, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d)
[0m15:11:32.006823 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m15:11:32.020907 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m15:11:32.023945 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m15:11:32.032901 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m15:11:32.034904 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"
[0m15:11:32.036904 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_12804]
   as 
    
    
    



select Payment_Method
from "my_db"."dbo"."stg_ecommerce"
where Payment_Method is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_12804]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_8b633e73afc3cff5f8746eb4346a739f_12804]
  ;')
[0m15:11:32.037902 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:11:32.040091 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:11:32.042093 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:11:32.059312 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:32.063316 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: ROLLBACK
[0m15:11:32.064314 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d: Close
[0m15:11:32.066313 [info ] [Thread-1 (]: 10 of 15 PASS not_null_stg_ecommerce_Payment_Method ............................ [[32mPASS[0m in 0.06s]
[0m15:11:32.069955 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d
[0m15:11:32.072986 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m15:11:32.076011 [info ] [Thread-1 (]: 11 of 15 START test not_null_stg_ecommerce_Price ............................... [RUN]
[0m15:11:32.078959 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Payment_Method.cc40c1cb5d, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a)
[0m15:11:32.080956 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m15:11:32.095958 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m15:11:32.097984 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m15:11:32.108112 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m15:11:32.112108 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"
[0m15:11:32.114115 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_13775]
   as 
    
    
    



select Price
from "my_db"."dbo"."stg_ecommerce"
where Price is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_13775]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_5340f7522393cd1159d3a7537ca9875c_13775]
  ;')
[0m15:11:32.116164 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:11:32.116164 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:11:32.116164 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:11:32.131791 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:32.131791 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: ROLLBACK
[0m15:11:32.131791 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a: Close
[0m15:11:32.131791 [info ] [Thread-1 (]: 11 of 15 PASS not_null_stg_ecommerce_Price ..................................... [[32mPASS[0m in 0.05s]
[0m15:11:32.131791 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a
[0m15:11:32.131791 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m15:11:32.131791 [info ] [Thread-1 (]: 12 of 15 START test not_null_stg_ecommerce_Product_ID .......................... [RUN]
[0m15:11:32.147414 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Price.5d9418fe6a, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c)
[0m15:11:32.147414 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m15:11:32.147414 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m15:11:32.147414 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m15:11:32.163041 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m15:11:32.163041 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"
[0m15:11:32.163041 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_11023]
   as 
    
    
    



select Product_ID
from "my_db"."dbo"."stg_ecommerce"
where Product_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_11023]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_8d41d628abbf902566fa856eff130be0_11023]
  ;')
[0m15:11:32.163041 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:11:32.163041 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:11:32.163041 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:11:32.176350 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:32.176350 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: ROLLBACK
[0m15:11:32.176350 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c: Close
[0m15:11:32.191966 [info ] [Thread-1 (]: 12 of 15 PASS not_null_stg_ecommerce_Product_ID ................................ [[32mPASS[0m in 0.04s]
[0m15:11:32.191966 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c
[0m15:11:32.191966 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m15:11:32.191966 [info ] [Thread-1 (]: 13 of 15 START test not_null_stg_ecommerce_Purchase_Date ....................... [RUN]
[0m15:11:32.191966 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Product_ID.e217887b0c, now test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307)
[0m15:11:32.191966 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m15:11:32.216743 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m15:11:32.218744 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m15:11:32.223744 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m15:11:32.225893 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"
[0m15:11:32.225893 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_11440]
   as 
    
    
    



select Purchase_Date
from "my_db"."dbo"."stg_ecommerce"
where Purchase_Date is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_11440]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_23cf1ea01d8d4ab9428eb660245ba129_11440]
  ;')
[0m15:11:32.225893 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:11:32.225893 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:11:32.225893 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:11:32.241510 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:32.241510 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: ROLLBACK
[0m15:11:32.241510 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307: Close
[0m15:11:32.241510 [info ] [Thread-1 (]: 13 of 15 PASS not_null_stg_ecommerce_Purchase_Date ............................. [[32mPASS[0m in 0.05s]
[0m15:11:32.257175 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307
[0m15:11:32.257175 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m15:11:32.257175 [info ] [Thread-1 (]: 14 of 15 START test not_null_stg_ecommerce_User_ID ............................. [RUN]
[0m15:11:32.257175 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_Purchase_Date.325f903307, now test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf)
[0m15:11:32.257175 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m15:11:32.293244 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m15:11:32.293244 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m15:11:32.308868 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m15:11:32.308868 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"
[0m15:11:32.308868 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_2912]
   as 
    
    
    



select User_ID
from "my_db"."dbo"."stg_ecommerce"
where User_ID is null



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_2912]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_c9caac9cada003d07021ea5868901956_2912]
  ;')
[0m15:11:32.308868 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:11:32.308868 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:11:32.308868 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:11:32.334612 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:32.335676 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: ROLLBACK
[0m15:11:32.335676 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf: Close
[0m15:11:32.335676 [info ] [Thread-1 (]: 14 of 15 PASS not_null_stg_ecommerce_User_ID ................................... [[32mPASS[0m in 0.08s]
[0m15:11:32.335676 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf
[0m15:11:32.335676 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m15:11:32.335676 [info ] [Thread-1 (]: 15 of 15 START test unique_stg_ecommerce_Product_ID ............................ [RUN]
[0m15:11:32.335676 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_stg_ecommerce_User_ID.b27c1a90bf, now test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1)
[0m15:11:32.335676 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m15:11:32.351305 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m15:11:32.366934 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m15:11:32.366934 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m15:11:32.366934 [debug] [Thread-1 (]: Using sqlserver connection "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"
[0m15:11:32.366934 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1"} */

    -- Create target schema if it does not
  USE [my_db];
  IF NOT EXISTS (SELECT * FROM sys.schemas WHERE name = 'dbo')
  BEGIN
    EXEC('CREATE SCHEMA [dbo]')
  END

  

  
  EXEC('create view 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_14049]
   as 
    
    
    

select
    Product_ID as unique_field,
    count(*) as n_records

from "my_db"."dbo"."stg_ecommerce"
where Product_ID is not null
group by Product_ID
having count(*) > 1



  ;')
  select
    
    count(*) as failures,
    case when count(*) != 0
      then 'true' else 'false' end as should_warn,
    case when count(*) != 0
      then 'true' else 'false' end as should_error
  from (
    select * from 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_14049]
  
  ) dbt_internal_test;

  EXEC('drop view 
    [dbo].[testview_360caf1b40abaee6c8c10c79f2c8bdc8_14049]
  ;')
[0m15:11:32.366934 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:11:32.366934 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m15:11:32.382559 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m15:11:32.398183 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:11:32.398183 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: ROLLBACK
[0m15:11:32.408621 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1: Close
[0m15:11:32.408621 [info ] [Thread-1 (]: 15 of 15 PASS unique_stg_ecommerce_Product_ID .................................. [[32mPASS[0m in 0.07s]
[0m15:11:32.408621 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1
[0m15:11:32.408621 [debug] [MainThread]: On master: COMMIT
[0m15:11:32.408621 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:11:32.408621 [debug] [MainThread]: Connection 'list_my_db' was properly closed.
[0m15:11:32.408621 [debug] [MainThread]: Connection 'list_my_db_dbo' was properly closed.
[0m15:11:32.408621 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.unique_stg_ecommerce_Product_ID.81501e6af1' was properly closed.
[0m15:11:32.408621 [info ] [MainThread]: 
[0m15:11:32.408621 [info ] [MainThread]: Finished running 13 data tests, 2 view models in 0 hours 0 minutes and 2.18 seconds (2.18s).
[0m15:11:32.431186 [debug] [MainThread]: Command end result
[0m15:11:32.491477 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m15:11:32.508510 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m15:11:32.508510 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m15:11:32.508510 [info ] [MainThread]: 
[0m15:11:32.526313 [info ] [MainThread]: [31mCompleted with 3 errors, 0 partial successes, and 0 warnings:[0m
[0m15:11:32.528340 [info ] [MainThread]: 
[0m15:11:32.531303 [error] [MainThread]: [31mFailure in test non_negative_stg_ecommerce_Discount (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m15:11:32.533302 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)")
[0m15:11:32.534304 [info ] [MainThread]: 
[0m15:11:32.536297 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\non_negative_stg_ecommerce_Discount.sql
[0m15:11:32.538306 [info ] [MainThread]: 
[0m15:11:32.542347 [error] [MainThread]: [31mFailure in test non_negative_stg_ecommerce_Final_Price (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m15:11:32.545308 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)")
[0m15:11:32.547298 [info ] [MainThread]: 
[0m15:11:32.549301 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\non_negative_stg_ecommerce_Final_Price.sql
[0m15:11:32.551323 [info ] [MainThread]: 
[0m15:11:32.553303 [error] [MainThread]: [31mFailure in test non_negative_stg_ecommerce_Price (dbt_databricks_cicd/models\staging\databricks\schema.yml)[0m
[0m15:11:32.555436 [error] [MainThread]:   ('42000', "[42000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Sintaxe incorreta próxima a ')'. (102) (SQLMoreResults)")
[0m15:11:32.560464 [info ] [MainThread]: 
[0m15:11:32.562428 [info ] [MainThread]:   compiled code at target\compiled\dbt_databricks_cicd\dbt_databricks_cicd/models\staging\databricks\schema.yml\non_negative_stg_ecommerce_Price.sql
[0m15:11:32.565420 [info ] [MainThread]: 
[0m15:11:32.567440 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=3 SKIP=0 NO-OP=0 TOTAL=15
[0m15:11:32.569532 [debug] [MainThread]: Command `dbt build` failed at 15:11:32.569532 after 14.89 seconds
[0m15:11:32.569532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C506FC3DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C50DAFAE10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C50B254650>]}
[0m15:11:32.569532 [debug] [MainThread]: Flushing usage events
[0m15:11:33.455613 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:58:41.281501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299AF903E50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299AF78F250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299AF96ACD0>]}


============================== 09:58:41.297126 | 3573349f-dc3d-45ec-99cd-9b3fb31cb6f1 ==============================
[0m09:58:41.297126 [info ] [MainThread]: Running with dbt=1.10.3
[0m09:58:41.297126 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt build --target sqlserver', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m09:58:46.562759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3573349f-dc3d-45ec-99cd-9b3fb31cb6f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299B11F01D0>]}
[0m09:58:46.672170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3573349f-dc3d-45ec-99cd-9b3fb31cb6f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299AE881FD0>]}
[0m09:58:46.672170 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m09:58:47.734625 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m09:58:48.109670 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading dbt_databricks_cicd: staging\databricks\schema.yml - Runtime Error
    Syntax error near line 1
    ------------------------------
    1  | {% if target.name == 'databricks' %}
    2  | version: 2
    3  | 
    4  | models:
    
    Raw Error:
    ------------------------------
    while scanning for the next token
    found character that cannot start any token
      in "<unicode string>", line 1, column 2
[0m09:58:48.125249 [debug] [MainThread]: Command `dbt build` failed at 09:58:48.125249 after 7.01 seconds
[0m09:58:48.125249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299AF912610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299A8F03DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000299A9160550>]}
[0m09:58:48.125249 [debug] [MainThread]: Flushing usage events
[0m09:58:49.531664 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:05:08.277959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225AD7EB110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225AD7C8390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225AD7C8BD0>]}


============================== 10:05:08.277959 | 6ca94a76-e51e-438f-947d-beb61898c2f3 ==============================
[0m10:05:08.277959 [info ] [MainThread]: Running with dbt=1.10.3
[0m10:05:08.293580 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --target sqlserver', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:05:09.215461 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6ca94a76-e51e-438f-947d-beb61898c2f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225AF072BD0>]}
[0m10:05:09.324867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6ca94a76-e51e-438f-947d-beb61898c2f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225AC701F50>]}
[0m10:05:09.324867 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m10:05:10.121743 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m10:05:10.356093 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading dbt_databricks_cicd: staging\databricks\schema.yml - Runtime Error
    Syntax error near line 1
    ------------------------------
    1  | {% if target.name == 'databricks' %}
    2  | version: 2
    3  | 
    4  | models:
    
    Raw Error:
    ------------------------------
    while scanning for the next token
    found character that cannot start any token
      in "<unicode string>", line 1, column 2
[0m10:05:10.356093 [debug] [MainThread]: Command `dbt build` failed at 10:05:10.356093 after 2.21 seconds
[0m10:05:10.356093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225A6CF3DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225AD793710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225AD7938D0>]}
[0m10:05:10.356093 [debug] [MainThread]: Flushing usage events
[0m10:05:10.965681 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:07:55.672821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002402D764590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002402D99FD10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002402D99FCD0>]}


============================== 10:07:55.688408 | 62ec4dd5-cab9-4fdf-a15a-d1287ced6b80 ==============================
[0m10:07:55.688408 [info ] [MainThread]: Running with dbt=1.10.3
[0m10:07:55.688408 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt build --target sqlserver', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True'}
[0m10:07:56.625948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '62ec4dd5-cab9-4fdf-a15a-d1287ced6b80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002402A714510>]}
[0m10:07:56.750922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '62ec4dd5-cab9-4fdf-a15a-d1287ced6b80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002402C8E1F90>]}
[0m10:07:56.750922 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m10:07:57.532157 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m10:08:00.641576 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 0 files changed.
[0m10:08:01.157202 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m10:08:01.188450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '62ec4dd5-cab9-4fdf-a15a-d1287ced6b80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002402F7EFE90>]}
[0m10:08:01.360291 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m10:08:01.391538 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m10:08:01.547789 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '62ec4dd5-cab9-4fdf-a15a-d1287ced6b80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002402F8CB950>]}
[0m10:08:01.547789 [info ] [MainThread]: Found 2 models, 1 source, 628 macros
[0m10:08:01.547789 [info ] [MainThread]: 
[0m10:08:01.547789 [info ] [MainThread]: Concurrency: 1 threads (target='sqlserver')
[0m10:08:01.547789 [info ] [MainThread]: 
[0m10:08:01.563408 [debug] [MainThread]: Acquiring new sqlserver connection 'master'
[0m10:08:01.563408 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db'
[0m10:08:01.594662 [debug] [ThreadPool]: dbt-sqlserver
[0m10:08:01.594662 [debug] [ThreadPool]: Using sqlserver connection "list_my_db"
[0m10:08:01.594662 [debug] [ThreadPool]: On list_my_db: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db"} */
USE [my_db];
    select  name as [schema]
    from sys.schemas with (nolock) 
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m10:08:01.594662 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:08:01.594662 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m10:08:01.750913 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m10:08:01.766537 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m10:08:01.766537 [debug] [ThreadPool]: On list_my_db: Close
[0m10:08:01.782160 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db_dbo'
[0m10:08:01.797788 [debug] [ThreadPool]: dbt-sqlserver
[0m10:08:01.797788 [debug] [ThreadPool]: Using sqlserver connection "list_my_db_dbo"
[0m10:08:01.797788 [debug] [ThreadPool]: On list_my_db_dbo: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db_dbo"} */
USE [my_db];
    with base as (
      select
        DB_NAME() as [database],
        t.name as [name],
        SCHEMA_NAME(t.schema_id) as [schema],
        'table' as table_type
      from sys.tables as t with (nolock)
      union all
      select
        DB_NAME() as [database],
        v.name as [name],
        SCHEMA_NAME(v.schema_id) as [schema],
        'view' as table_type
      from sys.views as v with (nolock)
    )
    select * from base
    where [schema] like 'dbo'
    
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m10:08:01.797788 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:08:01.797788 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m10:08:01.797788 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m10:08:01.891537 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m10:08:01.891537 [debug] [ThreadPool]: On list_my_db_dbo: ROLLBACK
[0m10:08:01.891537 [debug] [ThreadPool]: On list_my_db_dbo: Close
[0m10:08:01.907160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '62ec4dd5-cab9-4fdf-a15a-d1287ced6b80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002402F250390>]}
[0m10:08:01.907160 [debug] [MainThread]: On master: COMMIT
[0m10:08:01.907160 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m10:08:01.907160 [info ] [Thread-1 (]: 1 of 2 START sql view model dbo.src_ecommerce .................................. [RUN]
[0m10:08:01.907160 [debug] [Thread-1 (]: Acquiring new sqlserver connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m10:08:01.922819 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m10:08:01.938430 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m10:08:01.938430 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m10:08:02.016537 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m10:08:02.016537 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m10:08:02.016537 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."src_ecommerce__dbt_tmp" as 

select * from "my_db"."dbo"."ecommerce";
    ')


[0m10:08:02.016537 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:08:02.016537 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m10:08:02.032158 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m10:08:02.125908 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:08:02.141537 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m10:08:02.141537 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce', 'src_ecommerce__dbt_backup'
[0m10:08:03.282263 [debug] [Thread-1 (]: SQL status: OK in 1.000 seconds
[0m10:08:03.313420 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m10:08:03.313420 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce__dbt_tmp', 'src_ecommerce'
[0m10:08:03.329038 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:08:03.375916 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: COMMIT
[0m10:08:03.391534 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."src_ecommerce__dbt_backup"
[0m10:08:03.422784 [debug] [Thread-1 (]: dbt-sqlserver
[0m10:08:03.422784 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m10:08:03.422784 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'src_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m10:08:03.782157 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:08:03.797786 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m10:08:03.797786 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."src_ecommerce__dbt_backup";');

[0m10:08:03.797786 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:08:03.797786 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: ROLLBACK
[0m10:08:03.797786 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: Close
[0m10:08:03.813412 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '62ec4dd5-cab9-4fdf-a15a-d1287ced6b80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002402F210350>]}
[0m10:08:03.813412 [info ] [Thread-1 (]: 1 of 2 OK created sql view model dbo.src_ecommerce ............................. [[32mOK[0m in 1.91s]
[0m10:08:03.813412 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m10:08:03.813412 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m10:08:03.813412 [info ] [Thread-1 (]: 2 of 2 START sql view model dbo.stg_ecommerce .................................. [RUN]
[0m10:08:03.829036 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m10:08:03.829036 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m10:08:03.829036 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:08:03.844658 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m10:08:03.860286 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:08:03.860286 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:08:03.860286 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."stg_ecommerce__dbt_tmp" as 

SELECT
    
        CAST(User_ID AS VARCHAR) AS User_ID,
        CAST(Product_ID AS VARCHAR) AS Product_ID,
        CAST(Category AS VARCHAR) AS Category,
        CAST(Price AS FLOAT) AS Price,
        CAST(Discount AS INT) AS Discount,
        CAST(Final_Price AS FLOAT) AS Final_Price,
        CAST(Payment_Method AS VARCHAR) AS Payment_Method,
        CAST(Purchase_Date AS DATE) AS Purchase_Date
    
FROM "my_db"."dbo"."ecommerce";
    ')


[0m10:08:03.860286 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:08:03.860286 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m10:08:03.860286 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m10:08:03.875914 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:08:03.891535 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:08:03.891535 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce', 'stg_ecommerce__dbt_backup'
[0m10:08:04.157202 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:08:04.172790 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:08:04.172790 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce__dbt_tmp', 'stg_ecommerce'
[0m10:08:04.188445 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:08:04.204037 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: COMMIT
[0m10:08:04.204037 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."stg_ecommerce__dbt_backup"
[0m10:08:04.204037 [debug] [Thread-1 (]: dbt-sqlserver
[0m10:08:04.204037 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:08:04.219660 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'stg_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m10:08:04.250911 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:08:04.266535 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:08:04.266535 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."stg_ecommerce__dbt_backup";');

[0m10:08:04.266535 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:08:04.266535 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: ROLLBACK
[0m10:08:04.266535 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: Close
[0m10:08:04.282200 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '62ec4dd5-cab9-4fdf-a15a-d1287ced6b80', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002402FB27A90>]}
[0m10:08:04.282200 [info ] [Thread-1 (]: 2 of 2 OK created sql view model dbo.stg_ecommerce ............................. [[32mOK[0m in 0.47s]
[0m10:08:04.282200 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m10:08:04.282200 [debug] [MainThread]: On master: COMMIT
[0m10:08:04.282200 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:08:04.282200 [debug] [MainThread]: Connection 'list_my_db' was properly closed.
[0m10:08:04.282200 [debug] [MainThread]: Connection 'list_my_db_dbo' was properly closed.
[0m10:08:04.282200 [debug] [MainThread]: Connection 'model.dbt_databricks_cicd.stg_ecommerce' was properly closed.
[0m10:08:04.282200 [info ] [MainThread]: 
[0m10:08:04.282200 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 2.73 seconds (2.73s).
[0m10:08:04.297785 [debug] [MainThread]: Command end result
[0m10:08:04.375908 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m10:08:04.375908 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m10:08:04.407159 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m10:08:04.407159 [info ] [MainThread]: 
[0m10:08:04.407159 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:08:04.407159 [info ] [MainThread]: 
[0m10:08:04.407159 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m10:08:04.422785 [debug] [MainThread]: Command `dbt build` succeeded at 10:08:04.422785 after 8.87 seconds
[0m10:08:04.422785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000024026F33DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002402CA78A10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000240271904D0>]}
[0m10:08:04.422785 [debug] [MainThread]: Flushing usage events
[0m10:08:05.032158 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:16:55.612994 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000135FA053950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000135FA052F10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000135FA053810>]}


============================== 10:16:55.628661 | a3b5e783-43ad-43d0-a771-381fc80ddad5 ==============================
[0m10:16:55.628661 [info ] [MainThread]: Running with dbt=1.10.3
[0m10:16:55.628661 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --target databricks', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:16:57.581745 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m10:16:57.581745 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m10:16:57.581745 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m10:17:03.223752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a3b5e783-43ad-43d0-a771-381fc80ddad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000135FC629590>]}
[0m10:17:03.333130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a3b5e783-43ad-43d0-a771-381fc80ddad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000135F97C9D50>]}
[0m10:17:03.333130 [info ] [MainThread]: Registered adapter: databricks=1.10.4
[0m10:17:04.551836 [debug] [MainThread]: checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, vars: {}, profile: , target: databricks, version: 1.10.3
[0m10:17:04.739380 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m10:17:04.739380 [debug] [MainThread]: previous checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, current checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331
[0m10:17:04.739380 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m10:17:04.739380 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m10:17:04.754961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a3b5e783-43ad-43d0-a771-381fc80ddad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000135F9764310>]}
[0m10:17:09.926886 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m10:17:09.942510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a3b5e783-43ad-43d0-a771-381fc80ddad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013587A7C090>]}
[0m10:17:10.129962 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m10:17:10.129962 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m10:17:10.223752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a3b5e783-43ad-43d0-a771-381fc80ddad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013587B3E810>]}
[0m10:17:10.239377 [info ] [MainThread]: Found 9 models, 24 data tests, 1 source, 800 macros
[0m10:17:10.239377 [info ] [MainThread]: 
[0m10:17:10.239377 [info ] [MainThread]: Concurrency: 1 threads (target='databricks')
[0m10:17:10.239377 [info ] [MainThread]: 
[0m10:17:10.239377 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:17:10.239377 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:17:10.254999 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:17:10.254999 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace'
[0m10:17:10.254999 [debug] [ThreadPool]: Using databricks connection "list_workspace"
[0m10:17:10.254999 [debug] [ThreadPool]: On list_workspace: GetSchemas(database=workspace, schema=None)
[0m10:17:10.270627 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:17:11.817460 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f07cfe-d0cc-1a20-9af9-887914d25a09) - Created
[0m10:18:14.582688 [debug] [ThreadPool]: SQL status: OK in 64.310 seconds
[0m10:18:14.598321 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f07cfe-d0cc-1a20-9af9-887914d25a09, command-id=01f07cfe-f4f7-10a0-ab5b-468865f506cc) - Closing
[0m10:18:14.613937 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace_default, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:18:14.613937 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace_default'
[0m10:18:14.660871 [debug] [ThreadPool]: Using databricks connection "list_workspace_default"
[0m10:18:14.660871 [debug] [ThreadPool]: On list_workspace_default: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "connection_name": "list_workspace_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'workspace' 
  AND table_schema = 'default'

  
[0m10:18:14.660871 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:18:15.426437 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f07cfe-f6d3-1a7d-853b-9211edc6f53b) - Created
[0m10:18:20.629779 [debug] [ThreadPool]: SQL status: OK in 5.970 seconds
[0m10:18:20.660869 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f07cfe-f6d3-1a7d-853b-9211edc6f53b, command-id=01f07cfe-f702-19fb-bc03-a5278bc32f45) - Closing
[0m10:18:21.035820 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a3b5e783-43ad-43d0-a771-381fc80ddad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013587B63A90>]}
[0m10:18:21.051441 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m10:18:21.051441 [info ] [Thread-1 (]: 1 of 33 START sql view model default.src_ecommerce ............................. [RUN]
[0m10:18:21.067068 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_cicd.src_ecommerce, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:18:21.067068 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m10:18:21.067068 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m10:18:21.082727 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m10:18:21.082727 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m10:18:21.113972 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:18:21.113972 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m10:18:21.113972 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'a3b5e783-43ad-43d0-a771-381fc80ddad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013587EC35D0>]}
[0m10:18:21.145219 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`src_ecommerce`
[0m10:18:21.160846 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m10:18:21.176434 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.src_ecommerce"
[0m10:18:21.176434 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`src_ecommerce`
  
  as (
    SELECT * FROM default.sales_ecommerce
  )

[0m10:18:21.176434 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:18:21.910982 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5) - Created
[0m10:18:26.847290 [debug] [Thread-1 (]: SQL status: OK in 5.670 seconds
[0m10:18:26.847290 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cfe-fad6-1178-870c-fe51580c91fe) - Closing
[0m10:18:26.878266 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:18:26.878266 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3b5e783-43ad-43d0-a771-381fc80ddad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013587EC8C10>]}
[0m10:18:26.878266 [info ] [Thread-1 (]: 1 of 33 OK created sql view model default.src_ecommerce ........................ [[32mOK[0m in 5.81s]
[0m10:18:26.878266 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m10:18:26.893856 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m10:18:26.893856 [info ] [Thread-1 (]: 2 of 33 START sql view model default.stg_ecommerce ............................. [RUN]
[0m10:18:26.893856 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m10:18:26.893856 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=model.dbt_databricks_cicd.stg_ecommerce, idle-time=0.015590190887451172s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.src_ecommerce
[0m10:18:26.893856 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m10:18:26.893856 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:18:26.909511 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m10:18:26.909511 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:18:26.909511 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`stg_ecommerce`
[0m10:18:26.909511 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:18:26.925103 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:18:26.925103 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`stg_ecommerce`
  
  as (
    SELECT
  User_ID,
  Product_ID,
  Category,
  Price,
  Discount,
  Final_Price,
  Payment_Method,
  Purchase_Date
FROM `workspace`.`default`.`src_ecommerce`
  )

[0m10:18:27.909497 [debug] [Thread-1 (]: SQL status: OK in 0.980 seconds
[0m10:18:27.909497 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cfe-fdd0-1bf2-87a4-db4a78fb5aef) - Closing
[0m10:18:27.909497 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:18:27.925128 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3b5e783-43ad-43d0-a771-381fc80ddad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013587EDF550>]}
[0m10:18:27.925128 [info ] [Thread-1 (]: 2 of 33 OK created sql view model default.stg_ecommerce ........................ [[32mOK[0m in 1.03s]
[0m10:18:27.925128 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m10:18:27.925128 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_discount_by_category
[0m10:18:27.925128 [info ] [Thread-1 (]: 3 of 33 START sql view model default.avg_discount_by_category .................. [RUN]
[0m10:18:27.940730 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now model.dbt_databricks_cicd.avg_discount_by_category)
[0m10:18:27.940730 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=model.dbt_databricks_cicd.avg_discount_by_category, idle-time=0.01560211181640625s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.stg_ecommerce
[0m10:18:27.940730 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_discount_by_category
[0m10:18:27.940730 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m10:18:27.940730 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_discount_by_category
[0m10:18:27.956359 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:18:27.956359 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`avg_discount_by_category`
[0m10:18:27.956359 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m10:18:27.956359 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.avg_discount_by_category"
[0m10:18:27.956359 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_discount_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.avg_discount_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`avg_discount_by_category`
  
  as (
    SELECT
  Category,
  ROUND(AVG(CAST(`Discount` AS DOUBLE)), 2) AS avg_discount_percent
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY avg_discount_percent DESC
  )

[0m10:18:28.815832 [debug] [Thread-1 (]: SQL status: OK in 0.860 seconds
[0m10:18:28.831367 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cfe-fe6e-1c82-9457-1eb708a52e6f) - Closing
[0m10:18:28.831367 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:18:28.831367 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3b5e783-43ad-43d0-a771-381fc80ddad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013587F0A010>]}
[0m10:18:28.831367 [info ] [Thread-1 (]: 3 of 33 OK created sql view model default.avg_discount_by_category ............. [[32mOK[0m in 0.89s]
[0m10:18:28.831367 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_discount_by_category
[0m10:18:28.831367 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:18:28.831367 [info ] [Thread-1 (]: 4 of 33 START sql view model default.avg_ticket_by_category .................... [RUN]
[0m10:18:28.831367 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_discount_by_category, now model.dbt_databricks_cicd.avg_ticket_by_category)
[0m10:18:28.846982 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=model.dbt_databricks_cicd.avg_ticket_by_category, idle-time=0.015615224838256836s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.avg_discount_by_category
[0m10:18:28.846982 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:18:28.846982 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m10:18:28.846982 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:18:28.862644 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:18:28.862644 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`avg_ticket_by_category`
[0m10:18:28.862644 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m10:18:28.862644 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m10:18:28.862644 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_ticket_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.avg_ticket_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`avg_ticket_by_category`
  
  as (
    SELECT
  Category,
  ROUND(AVG(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS avg_ticket
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY avg_ticket DESC
  )

[0m10:18:29.628258 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m10:18:29.628258 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cfe-fef9-145b-a0e8-7fc93921054f) - Closing
[0m10:18:29.643877 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:18:29.643877 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3b5e783-43ad-43d0-a771-381fc80ddad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013587EDC510>]}
[0m10:18:29.643877 [info ] [Thread-1 (]: 4 of 33 OK created sql view model default.avg_ticket_by_category ............... [[32mOK[0m in 0.81s]
[0m10:18:29.643877 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:18:29.643877 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.monthly_revenue
[0m10:18:29.659477 [info ] [Thread-1 (]: 5 of 33 START sql view model default.monthly_revenue ........................... [RUN]
[0m10:18:29.659477 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_ticket_by_category, now model.dbt_databricks_cicd.monthly_revenue)
[0m10:18:29.659477 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=model.dbt_databricks_cicd.monthly_revenue, idle-time=0.01560068130493164s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:18:29.659477 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.monthly_revenue
[0m10:18:29.659477 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.monthly_revenue"
[0m10:18:29.659477 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.monthly_revenue
[0m10:18:29.675137 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:18:29.675137 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`monthly_revenue`
[0m10:18:29.675137 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.monthly_revenue"
[0m10:18:29.675137 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.monthly_revenue"
[0m10:18:29.675137 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.monthly_revenue: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.monthly_revenue"} */

  
  
  
  create or replace view `workspace`.`default`.`monthly_revenue`
  
  as (
    SELECT
  CAST(DATE_TRUNC('month', CAST(Purchase_Date AS DATE)) AS DATE) AS month,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS monthly_revenue
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY 1
ORDER BY 1
  )

[0m10:18:30.581602 [debug] [Thread-1 (]: SQL status: OK in 0.910 seconds
[0m10:18:30.581602 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cfe-ff75-154a-ab19-b3441e82082d) - Closing
[0m10:18:30.597051 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:18:30.597051 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3b5e783-43ad-43d0-a771-381fc80ddad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013587EDEC90>]}
[0m10:18:30.597051 [info ] [Thread-1 (]: 5 of 33 OK created sql view model default.monthly_revenue ...................... [[32mOK[0m in 0.94s]
[0m10:18:30.597051 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.monthly_revenue
[0m10:18:30.597051 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.payment_distribution
[0m10:18:30.612613 [info ] [Thread-1 (]: 6 of 33 START sql view model default.payment_distribution ...................... [RUN]
[0m10:18:30.612613 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.monthly_revenue, now model.dbt_databricks_cicd.payment_distribution)
[0m10:18:30.612613 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=model.dbt_databricks_cicd.payment_distribution, idle-time=0.015561580657958984s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.monthly_revenue
[0m10:18:30.612613 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.payment_distribution
[0m10:18:30.628225 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.payment_distribution"
[0m10:18:30.628225 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.payment_distribution
[0m10:18:30.628225 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:18:30.643849 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`payment_distribution`
[0m10:18:30.643849 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.payment_distribution"
[0m10:18:30.643849 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.payment_distribution"
[0m10:18:30.643849 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.payment_distribution: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.payment_distribution"} */

  
  
  
  create or replace view `workspace`.`default`.`payment_distribution`
  
  as (
    SELECT
  Payment_Method,
  COUNT(*) AS total_transactions,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_value
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Payment_Method
ORDER BY total_value DESC
  )

[0m10:18:31.394193 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m10:18:31.394193 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-0008-1f8a-98a0-a91a7b9ab5a8) - Closing
[0m10:18:31.409494 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:18:31.409494 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3b5e783-43ad-43d0-a771-381fc80ddad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001358865B090>]}
[0m10:18:31.409494 [info ] [Thread-1 (]: 6 of 33 OK created sql view model default.payment_distribution ................. [[32mOK[0m in 0.80s]
[0m10:18:31.409494 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.payment_distribution
[0m10:18:31.409494 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.sales_by_category
[0m10:18:31.425106 [info ] [Thread-1 (]: 7 of 33 START sql view model default.sales_by_category ......................... [RUN]
[0m10:18:31.425106 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.payment_distribution, now model.dbt_databricks_cicd.sales_by_category)
[0m10:18:31.425106 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=model.dbt_databricks_cicd.sales_by_category, idle-time=0.015611648559570312s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.payment_distribution
[0m10:18:31.425106 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.sales_by_category
[0m10:18:31.425106 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.sales_by_category"
[0m10:18:31.425106 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.sales_by_category
[0m10:18:31.440763 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:18:31.440763 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`sales_by_category`
[0m10:18:31.440763 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.sales_by_category"
[0m10:18:31.440763 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.sales_by_category"
[0m10:18:31.440763 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.sales_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.sales_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`sales_by_category`
  
  as (
    SELECT
  Category,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_revenue
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY total_revenue DESC
  )

[0m10:18:32.222040 [debug] [Thread-1 (]: SQL status: OK in 0.780 seconds
[0m10:18:32.222040 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-0082-1413-a694-576b95ba37bd) - Closing
[0m10:18:32.222040 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:18:32.237661 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3b5e783-43ad-43d0-a771-381fc80ddad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001358865B190>]}
[0m10:18:32.237661 [info ] [Thread-1 (]: 7 of 33 OK created sql view model default.sales_by_category .................... [[32mOK[0m in 0.81s]
[0m10:18:32.237661 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.sales_by_category
[0m10:18:32.237661 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_5_products
[0m10:18:32.237661 [info ] [Thread-1 (]: 8 of 33 START sql view model default.top_5_products ............................ [RUN]
[0m10:18:32.237661 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.sales_by_category, now model.dbt_databricks_cicd.top_5_products)
[0m10:18:32.237661 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=model.dbt_databricks_cicd.top_5_products, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.sales_by_category
[0m10:18:32.237661 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_5_products
[0m10:18:32.253266 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_5_products"
[0m10:18:32.253266 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_5_products
[0m10:18:32.253266 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:18:32.268855 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`top_5_products`
[0m10:18:32.268855 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_5_products"
[0m10:18:32.268855 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.top_5_products"
[0m10:18:32.268855 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_5_products: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.top_5_products"} */

  
  
  
  create or replace view `workspace`.`default`.`top_5_products`
  
  as (
    WITH base AS (
    SELECT
        product_id,
        ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_sales
    FROM `workspace`.`default`.`stg_ecommerce`
    GROUP BY product_id
)

SELECT
    product_id,
    total_sales
FROM base
ORDER BY total_sales DESC
LIMIT 5
  )

[0m10:18:33.019087 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m10:18:33.019087 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-0102-1087-911b-9b9b2c9ad964) - Closing
[0m10:18:33.019087 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:18:33.034514 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3b5e783-43ad-43d0-a771-381fc80ddad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013587EED5D0>]}
[0m10:18:33.034514 [info ] [Thread-1 (]: 8 of 33 OK created sql view model default.top_5_products ....................... [[32mOK[0m in 0.80s]
[0m10:18:33.034514 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_5_products
[0m10:18:33.034514 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_customers
[0m10:18:33.034514 [info ] [Thread-1 (]: 9 of 33 START sql view model default.top_customers ............................. [RUN]
[0m10:18:33.034514 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_5_products, now model.dbt_databricks_cicd.top_customers)
[0m10:18:33.034514 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=model.dbt_databricks_cicd.top_customers, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.top_5_products
[0m10:18:33.034514 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_customers
[0m10:18:33.050099 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_customers"
[0m10:18:33.050099 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_customers
[0m10:18:33.050099 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:18:33.065728 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`top_customers`
[0m10:18:33.065728 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_customers"
[0m10:18:33.065728 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.top_customers"
[0m10:18:33.065728 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_customers: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.top_customers"} */

  
  
  
  create or replace view `workspace`.`default`.`top_customers`
  
  as (
    SELECT
  User_ID,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_spent
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY User_ID
ORDER BY total_spent DESC
LIMIT 10
  )

[0m10:18:33.862622 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m10:18:33.862622 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-017a-1085-86c5-4813a771fd67) - Closing
[0m10:18:33.862622 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:18:33.878256 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3b5e783-43ad-43d0-a771-381fc80ddad5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000013588655C50>]}
[0m10:18:33.878256 [info ] [Thread-1 (]: 9 of 33 OK created sql view model default.top_customers ........................ [[32mOK[0m in 0.84s]
[0m10:18:33.878256 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_customers
[0m10:18:33.878256 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:18:33.878256 [info ] [Thread-1 (]: 10 of 33 START test non_negative_avg_discount_by_category_avg_discount_percent . [RUN]
[0m10:18:33.878256 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_customers, now test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f)
[0m10:18:33.893859 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f, idle-time=0.015602588653564453s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.top_customers
[0m10:18:33.893859 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:18:33.893859 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"
[0m10:18:33.893859 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:18:33.940728 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"
[0m10:18:33.940728 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"
[0m10:18:33.940728 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`avg_discount_by_category`
where TRY_CAST(REPLACE(avg_discount_percent, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:18:35.190759 [debug] [Thread-1 (]: SQL status: OK in 1.250 seconds
[0m10:18:35.206367 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-01fe-1daf-b76b-f4c06f2df1f4) - Closing
[0m10:18:35.206367 [info ] [Thread-1 (]: 10 of 33 PASS non_negative_avg_discount_by_category_avg_discount_percent ....... [[32mPASS[0m in 1.33s]
[0m10:18:35.206367 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:18:35.221984 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:18:35.221984 [info ] [Thread-1 (]: 11 of 33 START test not_null_avg_discount_by_category_Category ................. [RUN]
[0m10:18:35.221984 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b)
[0m10:18:35.221984 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, idle-time=0.015617609024047852s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:18:35.221984 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:18:35.237646 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m10:18:35.237646 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:18:35.237646 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m10:18:35.237646 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m10:18:35.253234 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_discount_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m10:18:36.112615 [debug] [Thread-1 (]: SQL status: OK in 0.860 seconds
[0m10:18:36.112615 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-02c8-1478-95a1-2920d20cb96d) - Closing
[0m10:18:36.112615 [info ] [Thread-1 (]: 11 of 33 PASS not_null_avg_discount_by_category_Category ....................... [[32mPASS[0m in 0.89s]
[0m10:18:36.128225 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:18:36.128225 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:18:36.128225 [info ] [Thread-1 (]: 12 of 33 START test not_null_avg_discount_by_category_avg_discount_percent ..... [RUN]
[0m10:18:36.128225 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101)
[0m10:18:36.128225 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, idle-time=0.015609264373779297s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:18:36.128225 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:18:36.143896 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m10:18:36.143896 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:18:36.143896 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m10:18:36.143896 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m10:18:36.143896 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_discount_percent
from `workspace`.`default`.`avg_discount_by_category`
where avg_discount_percent is null



  
  
      
    ) dbt_internal_test
[0m10:18:36.972232 [debug] [Thread-1 (]: SQL status: OK in 0.830 seconds
[0m10:18:36.987608 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-0350-1142-9565-4cd19687c482) - Closing
[0m10:18:36.987608 [info ] [Thread-1 (]: 12 of 33 PASS not_null_avg_discount_by_category_avg_discount_percent ........... [[32mPASS[0m in 0.86s]
[0m10:18:36.987608 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:18:36.987608 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:18:36.987608 [info ] [Thread-1 (]: 13 of 33 START test non_negative_avg_ticket_by_category_avg_ticket ............. [RUN]
[0m10:18:37.003236 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, now test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095)
[0m10:18:37.003236 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095, idle-time=0.015627622604370117s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:18:37.003236 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:18:37.003236 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"
[0m10:18:37.018887 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:18:37.018887 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"
[0m10:18:37.018887 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"
[0m10:18:37.018887 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`avg_ticket_by_category`
where TRY_CAST(REPLACE(avg_ticket, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:18:37.847211 [debug] [Thread-1 (]: SQL status: OK in 0.830 seconds
[0m10:18:37.862618 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-03d5-1a16-a34b-af32a3441fe2) - Closing
[0m10:18:37.862618 [info ] [Thread-1 (]: 13 of 33 PASS non_negative_avg_ticket_by_category_avg_ticket ................... [[32mPASS[0m in 0.86s]
[0m10:18:37.878283 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:18:37.878283 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:18:37.878283 [info ] [Thread-1 (]: 14 of 33 START test not_null_avg_ticket_by_category_Category ................... [RUN]
[0m10:18:37.878283 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f)
[0m10:18:37.878283 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, idle-time=0.015665292739868164s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:18:37.878283 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:18:37.893851 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m10:18:37.893851 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:18:37.909480 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m10:18:37.909480 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m10:18:37.909480 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_ticket_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m10:18:38.675138 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m10:18:38.690750 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-045c-147e-84a2-25c8bce49aa4) - Closing
[0m10:18:38.690750 [info ] [Thread-1 (]: 14 of 33 PASS not_null_avg_ticket_by_category_Category ......................... [[32mPASS[0m in 0.81s]
[0m10:18:38.690750 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:18:38.690750 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:18:38.690750 [info ] [Thread-1 (]: 15 of 33 START test not_null_avg_ticket_by_category_avg_ticket ................. [RUN]
[0m10:18:38.690750 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41)
[0m10:18:38.690750 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:18:38.706355 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:18:38.706355 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m10:18:38.706355 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:18:38.721978 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m10:18:38.721978 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m10:18:38.721978 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_ticket
from `workspace`.`default`.`avg_ticket_by_category`
where avg_ticket is null



  
  
      
    ) dbt_internal_test
[0m10:18:39.487601 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m10:18:39.503225 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-04d8-1ca0-805b-cddb212b3dd5) - Closing
[0m10:18:39.503225 [info ] [Thread-1 (]: 15 of 33 PASS not_null_avg_ticket_by_category_avg_ticket ....................... [[32mPASS[0m in 0.81s]
[0m10:18:39.503225 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:18:39.518853 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:18:39.518853 [info ] [Thread-1 (]: 16 of 33 START test non_negative_monthly_revenue_monthly_revenue ............... [RUN]
[0m10:18:39.518853 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, now test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294)
[0m10:18:39.518853 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294, idle-time=0.015627384185791016s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:18:39.518853 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:18:39.534487 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"
[0m10:18:39.550100 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:18:39.550100 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"
[0m10:18:39.550100 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"
[0m10:18:39.550100 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`monthly_revenue`
where TRY_CAST(REPLACE(monthly_revenue, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:18:40.518850 [debug] [Thread-1 (]: SQL status: OK in 0.970 seconds
[0m10:18:40.518850 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-0558-1a24-b9ce-7e470c1cdbbb) - Closing
[0m10:18:40.518850 [info ] [Thread-1 (]: 16 of 33 PASS non_negative_monthly_revenue_monthly_revenue ..................... [[32mPASS[0m in 1.00s]
[0m10:18:40.534475 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:18:40.534475 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:18:40.534475 [info ] [Thread-1 (]: 17 of 33 START test not_null_monthly_revenue_month ............................. [RUN]
[0m10:18:40.534475 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294, now test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b)
[0m10:18:40.534475 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, idle-time=0.015625476837158203s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:18:40.534475 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:18:40.550114 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m10:18:40.550114 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:18:40.565726 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m10:18:40.565726 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m10:18:40.565726 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select month
from `workspace`.`default`.`monthly_revenue`
where month is null



  
  
      
    ) dbt_internal_test
[0m10:18:41.534624 [debug] [Thread-1 (]: SQL status: OK in 0.970 seconds
[0m10:18:41.534624 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-05f2-1903-906d-e24a0c2262c8) - Closing
[0m10:18:41.534624 [info ] [Thread-1 (]: 17 of 33 PASS not_null_monthly_revenue_month ................................... [[32mPASS[0m in 1.00s]
[0m10:18:41.550101 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:18:41.550101 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:18:41.550101 [info ] [Thread-1 (]: 18 of 33 START test not_null_monthly_revenue_monthly_revenue ................... [RUN]
[0m10:18:41.550101 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, now test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b)
[0m10:18:41.550101 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, idle-time=0.015477657318115234s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:18:41.550101 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:18:41.565730 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m10:18:41.565730 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:18:41.565730 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m10:18:41.581358 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m10:18:41.581358 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select monthly_revenue
from `workspace`.`default`.`monthly_revenue`
where monthly_revenue is null



  
  
      
    ) dbt_internal_test
[0m10:18:42.315768 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m10:18:42.315768 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-068b-1f16-a6f2-641a4c23407c) - Closing
[0m10:18:42.315768 [info ] [Thread-1 (]: 18 of 33 PASS not_null_monthly_revenue_monthly_revenue ......................... [[32mPASS[0m in 0.77s]
[0m10:18:42.331355 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:18:42.331355 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:18:42.331355 [info ] [Thread-1 (]: 19 of 33 START test non_negative_payment_distribution_total_value .............. [RUN]
[0m10:18:42.331355 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, now test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282)
[0m10:18:42.331355 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282, idle-time=0.01558685302734375s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:18:42.331355 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:18:42.346981 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"
[0m10:18:42.346981 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:18:42.346981 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"
[0m10:18:42.346981 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"
[0m10:18:42.346981 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`payment_distribution`
where TRY_CAST(REPLACE(total_value, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:18:43.190757 [debug] [Thread-1 (]: SQL status: OK in 0.840 seconds
[0m10:18:43.206360 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-0703-14cb-b7a1-be635fa2a88b) - Closing
[0m10:18:43.206360 [info ] [Thread-1 (]: 19 of 33 PASS non_negative_payment_distribution_total_value .................... [[32mPASS[0m in 0.88s]
[0m10:18:43.206360 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:18:43.206360 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:18:43.206360 [info ] [Thread-1 (]: 20 of 33 START test not_null_payment_distribution_Payment_Method ............... [RUN]
[0m10:18:43.206360 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282, now test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae)
[0m10:18:43.206360 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:18:43.221977 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:18:43.221977 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m10:18:43.221977 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:18:43.237613 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m10:18:43.237613 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m10:18:43.237613 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`payment_distribution`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m10:18:44.034487 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m10:18:44.050118 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-0789-17f8-81b8-6cb1e2059697) - Closing
[0m10:18:44.050118 [info ] [Thread-1 (]: 20 of 33 PASS not_null_payment_distribution_Payment_Method ..................... [[32mPASS[0m in 0.84s]
[0m10:18:44.050118 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:18:44.050118 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:18:44.050118 [info ] [Thread-1 (]: 21 of 33 START test not_null_payment_distribution_total_transactions ........... [RUN]
[0m10:18:44.050118 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, now test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8)
[0m10:18:44.050118 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:18:44.065764 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:18:44.065764 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m10:18:44.081358 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:18:44.081358 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m10:18:44.081358 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m10:18:44.081358 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_transactions
from `workspace`.`default`.`payment_distribution`
where total_transactions is null



  
  
      
    ) dbt_internal_test
[0m10:18:45.128229 [debug] [Thread-1 (]: SQL status: OK in 1.050 seconds
[0m10:18:45.128229 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-080d-12cf-b5c0-e7c6f42af821) - Closing
[0m10:18:45.128229 [info ] [Thread-1 (]: 21 of 33 PASS not_null_payment_distribution_total_transactions ................. [[32mPASS[0m in 1.08s]
[0m10:18:45.128229 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:18:45.128229 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:18:45.128229 [info ] [Thread-1 (]: 22 of 33 START test not_null_payment_distribution_total_value .................. [RUN]
[0m10:18:45.128229 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, now test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03)
[0m10:18:45.143850 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, idle-time=0.01562047004699707s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:18:45.143850 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:18:45.143850 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m10:18:45.143850 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:18:45.159485 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m10:18:45.159485 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m10:18:45.159485 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_value
from `workspace`.`default`.`payment_distribution`
where total_value is null



  
  
      
    ) dbt_internal_test
[0m10:18:46.272732 [debug] [Thread-1 (]: SQL status: OK in 1.110 seconds
[0m10:18:46.272732 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-08af-132e-8c53-80baf13ebbb3) - Closing
[0m10:18:46.288368 [info ] [Thread-1 (]: 22 of 33 PASS not_null_payment_distribution_total_value ........................ [[32mPASS[0m in 1.16s]
[0m10:18:46.288368 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:18:46.288368 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:18:46.288368 [info ] [Thread-1 (]: 23 of 33 START test non_negative_sales_by_category_total_revenue ............... [RUN]
[0m10:18:46.288368 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, now test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41)
[0m10:18:46.288368 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:18:46.288368 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:18:46.303975 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"
[0m10:18:46.303975 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:18:46.303975 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"
[0m10:18:46.319603 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"
[0m10:18:46.319603 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`sales_by_category`
where TRY_CAST(REPLACE(total_revenue, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:18:47.475873 [debug] [Thread-1 (]: SQL status: OK in 1.140 seconds
[0m10:18:47.475873 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-0960-100c-9952-ce93b8d18d3c) - Closing
[0m10:18:47.475873 [info ] [Thread-1 (]: 23 of 33 PASS non_negative_sales_by_category_total_revenue ..................... [[32mPASS[0m in 1.19s]
[0m10:18:47.491477 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:18:47.491477 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:18:47.491477 [info ] [Thread-1 (]: 24 of 33 START test not_null_sales_by_category_Category ........................ [RUN]
[0m10:18:47.491477 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41, now test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507)
[0m10:18:47.491477 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, idle-time=0.015604496002197266s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:18:47.491477 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:18:47.522722 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m10:18:47.522722 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:18:47.538348 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m10:18:47.538348 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m10:18:47.538348 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`sales_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m10:18:48.543682 [debug] [Thread-1 (]: SQL status: OK in 1.010 seconds
[0m10:18:48.543682 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-0a1a-1398-ad78-fc1c0703e0a6) - Closing
[0m10:18:48.543682 [info ] [Thread-1 (]: 24 of 33 PASS not_null_sales_by_category_Category .............................. [[32mPASS[0m in 1.05s]
[0m10:18:48.543682 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:18:48.543682 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:18:48.559299 [info ] [Thread-1 (]: 25 of 33 START test not_null_sales_by_category_total_orders .................... [RUN]
[0m10:18:48.559299 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, now test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e)
[0m10:18:48.559299 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, idle-time=0.01561737060546875s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:18:48.559299 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:18:48.559299 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m10:18:48.574926 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:18:48.574926 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m10:18:48.574926 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m10:18:48.574926 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`sales_by_category`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m10:18:49.637439 [debug] [Thread-1 (]: SQL status: OK in 1.060 seconds
[0m10:18:49.637439 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-0ab9-1be9-8c45-e1ee128645d3) - Closing
[0m10:18:49.653066 [info ] [Thread-1 (]: 25 of 33 PASS not_null_sales_by_category_total_orders .......................... [[32mPASS[0m in 1.08s]
[0m10:18:49.653066 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:18:49.653066 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:18:49.653066 [info ] [Thread-1 (]: 26 of 33 START test not_null_sales_by_category_total_revenue ................... [RUN]
[0m10:18:49.653066 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, now test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd)
[0m10:18:49.653066 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, idle-time=0.015627145767211914s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:18:49.653066 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:18:49.668674 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m10:18:49.668674 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:18:49.668674 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m10:18:49.668674 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m10:18:49.684292 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_revenue
from `workspace`.`default`.`sales_by_category`
where total_revenue is null



  
  
      
    ) dbt_internal_test
[0m10:18:50.543824 [debug] [Thread-1 (]: SQL status: OK in 0.860 seconds
[0m10:18:50.559301 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-0b61-1855-8c36-990f5b8f4c20) - Closing
[0m10:18:50.559301 [info ] [Thread-1 (]: 26 of 33 PASS not_null_sales_by_category_total_revenue ......................... [[32mPASS[0m in 0.91s]
[0m10:18:50.559301 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:18:50.559301 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:18:50.559301 [info ] [Thread-1 (]: 27 of 33 START test non_negative_top_5_products_total_sales .................... [RUN]
[0m10:18:50.559301 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, now test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34)
[0m10:18:50.559301 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:18:50.559301 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:18:50.574929 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"
[0m10:18:50.574929 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:18:50.574929 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"
[0m10:18:50.574929 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"
[0m10:18:50.590551 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`top_5_products`
where TRY_CAST(REPLACE(total_sales, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:18:51.371798 [debug] [Thread-1 (]: SQL status: OK in 0.780 seconds
[0m10:18:51.387445 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-0beb-13c3-96cf-d03d22985388) - Closing
[0m10:18:51.387445 [info ] [Thread-1 (]: 27 of 33 PASS non_negative_top_5_products_total_sales .......................... [[32mPASS[0m in 0.83s]
[0m10:18:51.387445 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:18:51.387445 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:18:51.387445 [info ] [Thread-1 (]: 28 of 33 START test not_null_top_5_products_product_id ......................... [RUN]
[0m10:18:51.387445 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34, now test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe)
[0m10:18:51.403042 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, idle-time=0.015597105026245117s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:18:51.403042 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:18:51.403042 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m10:18:51.403042 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:18:51.418675 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m10:18:51.418675 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m10:18:51.418675 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select product_id
from `workspace`.`default`.`top_5_products`
where product_id is null



  
  
      
    ) dbt_internal_test
[0m10:18:52.199938 [debug] [Thread-1 (]: SQL status: OK in 0.780 seconds
[0m10:18:52.199938 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-0c6a-1b00-a85a-f7deb46aff30) - Closing
[0m10:18:52.199938 [info ] [Thread-1 (]: 28 of 33 PASS not_null_top_5_products_product_id ............................... [[32mPASS[0m in 0.81s]
[0m10:18:52.199938 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:18:52.215564 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:18:52.215564 [info ] [Thread-1 (]: 29 of 33 START test not_null_top_5_products_total_sales ........................ [RUN]
[0m10:18:52.215564 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, now test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818)
[0m10:18:52.215564 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, idle-time=0.015625715255737305s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:18:52.215564 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:18:52.215564 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m10:18:52.231204 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:18:52.231204 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m10:18:52.231204 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m10:18:52.231204 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_sales
from `workspace`.`default`.`top_5_products`
where total_sales is null



  
  
      
    ) dbt_internal_test
[0m10:18:53.153096 [debug] [Thread-1 (]: SQL status: OK in 0.920 seconds
[0m10:18:53.153096 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-0ce6-1ac0-ad30-79ab1530bcaf) - Closing
[0m10:18:53.168692 [info ] [Thread-1 (]: 29 of 33 PASS not_null_top_5_products_total_sales .............................. [[32mPASS[0m in 0.95s]
[0m10:18:53.168692 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:18:53.168692 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:18:53.168692 [info ] [Thread-1 (]: 30 of 33 START test non_negative_top_customers_total_spent ..................... [RUN]
[0m10:18:53.184302 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, now test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667)
[0m10:18:53.184302 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667, idle-time=0.015609979629516602s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:18:53.184302 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:18:53.184302 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"
[0m10:18:53.184302 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:18:53.199919 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"
[0m10:18:53.199919 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"
[0m10:18:53.199919 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`top_customers`
where TRY_CAST(REPLACE(total_spent, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:18:54.184584 [debug] [Thread-1 (]: SQL status: OK in 0.980 seconds
[0m10:18:54.199954 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-0d7a-1503-8363-4f6e61c7aefc) - Closing
[0m10:18:54.199954 [info ] [Thread-1 (]: 30 of 33 PASS non_negative_top_customers_total_spent ........................... [[32mPASS[0m in 1.03s]
[0m10:18:54.199954 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:18:54.199954 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:18:54.199954 [info ] [Thread-1 (]: 31 of 33 START test not_null_top_customers_User_ID ............................. [RUN]
[0m10:18:54.199954 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667, now test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0)
[0m10:18:54.215561 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, idle-time=0.015606880187988281s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:18:54.215561 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:18:54.215561 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m10:18:54.215561 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:18:54.231169 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m10:18:54.231169 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m10:18:54.231169 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`top_customers`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m10:18:54.871830 [debug] [Thread-1 (]: SQL status: OK in 0.640 seconds
[0m10:18:54.871830 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-0e17-17ed-95ab-beb1de21f2ce) - Closing
[0m10:18:54.887426 [info ] [Thread-1 (]: 31 of 33 PASS not_null_top_customers_User_ID ................................... [[32mPASS[0m in 0.69s]
[0m10:18:54.887426 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:18:54.887426 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:18:54.887426 [info ] [Thread-1 (]: 32 of 33 START test not_null_top_customers_total_orders ........................ [RUN]
[0m10:18:54.887426 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, now test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746)
[0m10:18:54.887426 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:18:54.887426 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:18:54.903062 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m10:18:54.903062 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:18:54.918666 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m10:18:54.918666 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m10:18:54.918666 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`top_customers`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m10:18:55.778065 [debug] [Thread-1 (]: SQL status: OK in 0.860 seconds
[0m10:18:55.793680 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-0e80-1d72-9b40-4c04d6848d09) - Closing
[0m10:18:55.793680 [info ] [Thread-1 (]: 32 of 33 PASS not_null_top_customers_total_orders .............................. [[32mPASS[0m in 0.91s]
[0m10:18:55.793680 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:18:55.793680 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m10:18:55.793680 [info ] [Thread-1 (]: 33 of 33 START test not_null_top_customers_total_spent ......................... [RUN]
[0m10:18:55.793680 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, now test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73)
[0m10:18:55.793680 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, name=test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:18:55.793680 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m10:18:55.809332 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m10:18:55.809332 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m10:18:55.809332 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m10:18:55.824965 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m10:18:55.824965 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_spent
from `workspace`.`default`.`top_customers`
where total_spent is null



  
  
      
    ) dbt_internal_test
[0m10:18:56.543768 [debug] [Thread-1 (]: SQL status: OK in 0.720 seconds
[0m10:18:56.559307 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5, command-id=01f07cff-0f0a-1df5-8cf2-1fe04f3ab7e0) - Closing
[0m10:18:56.559307 [info ] [Thread-1 (]: 33 of 33 PASS not_null_top_customers_total_spent ............................... [[32mPASS[0m in 0.77s]
[0m10:18:56.559307 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m10:18:56.559307 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=35.52348732948303s, language=None, compute-name=) - Reusing connection previously named master
[0m10:18:56.574921 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:18:56.574921 [debug] [MainThread]: Connection 'list_workspace' was properly closed.
[0m10:18:56.574921 [debug] [MainThread]: On list_workspace: Close
[0m10:18:56.574921 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07cfe-d0cc-1a20-9af9-887914d25a09) - Closing
[0m10:18:56.809441 [debug] [MainThread]: Connection 'list_workspace_default' was properly closed.
[0m10:18:56.809441 [debug] [MainThread]: On list_workspace_default: Close
[0m10:18:56.809441 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07cfe-f6d3-1a7d-853b-9211edc6f53b) - Closing
[0m10:18:57.042817 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73' was properly closed.
[0m10:18:57.042817 [debug] [MainThread]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: Close
[0m10:18:57.050815 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07cfe-fab6-142d-8c38-18ef8224e5d5) - Closing
[0m10:18:57.262375 [info ] [MainThread]: 
[0m10:18:57.262375 [info ] [MainThread]: Finished running 24 data tests, 9 view models in 0 hours 1 minutes and 47.02 seconds (107.02s).
[0m10:18:57.293431 [debug] [MainThread]: Command end result
[0m10:18:57.543430 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m10:18:57.543430 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m10:18:57.559050 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m10:18:57.574678 [info ] [MainThread]: 
[0m10:18:57.574678 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:18:57.574678 [info ] [MainThread]: 
[0m10:18:57.574678 [info ] [MainThread]: Done. PASS=33 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=33
[0m10:18:57.574678 [debug] [MainThread]: Command `dbt build` succeeded at 10:18:57.574678 after 122.12 seconds
[0m10:18:57.574678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000135F3573DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000135F37D10D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000135F37D04D0>]}
[0m10:18:57.574678 [debug] [MainThread]: Flushing usage events
[0m10:18:58.418607 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:40:44.507429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002259500E890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002259500FF90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002259500D810>]}


============================== 09:40:44.507429 | 19340174-2a1d-4a60-966d-779c2c19e7c4 ==============================
[0m09:40:44.507429 [info ] [MainThread]: Running with dbt=1.10.3
[0m09:40:44.507429 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt build --target sqlserver', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m09:40:48.788642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '19340174-2a1d-4a60-966d-779c2c19e7c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002259693EE50>]}
[0m09:40:48.898058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '19340174-2a1d-4a60-966d-779c2c19e7c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022593F72050>]}
[0m09:40:48.898058 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m09:40:49.898131 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m09:40:50.101141 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m09:40:50.101141 [debug] [MainThread]: previous checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, current checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9
[0m09:40:50.101141 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m09:40:50.101141 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m09:40:50.101141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '19340174-2a1d-4a60-966d-779c2c19e7c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022594714450>]}
[0m09:40:56.163652 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m09:40:56.179278 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m09:40:56.179278 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m09:40:56.179278 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m09:40:56.179278 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m09:40:56.179278 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m09:40:56.179278 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m09:40:56.179278 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m09:40:56.179278 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m09:40:56.179278 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m09:40:56.179278 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m09:40:56.179278 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m09:40:56.179278 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m09:40:56.179278 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m09:40:56.194900 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m09:40:56.194900 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m09:40:56.194900 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m09:40:56.194900 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m09:40:56.194900 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m09:40:56.194900 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m09:40:56.194900 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m09:40:56.194900 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m09:40:56.194900 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m09:40:56.194900 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m09:40:56.398038 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m09:40:56.413645 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '19340174-2a1d-4a60-966d-779c2c19e7c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022596EF62D0>]}
[0m09:40:56.648023 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m09:40:56.679270 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m09:40:56.898018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '19340174-2a1d-4a60-966d-779c2c19e7c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022596B74C10>]}
[0m09:40:56.898018 [info ] [MainThread]: Found 2 models, 1 source, 627 macros
[0m09:40:56.913642 [info ] [MainThread]: 
[0m09:40:56.913642 [info ] [MainThread]: Concurrency: 1 threads (target='sqlserver')
[0m09:40:56.913642 [info ] [MainThread]: 
[0m09:40:56.913642 [debug] [MainThread]: Acquiring new sqlserver connection 'master'
[0m09:40:56.929274 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db'
[0m09:40:56.960519 [debug] [ThreadPool]: dbt-sqlserver
[0m09:40:56.960519 [debug] [ThreadPool]: Using sqlserver connection "list_my_db"
[0m09:40:56.960519 [debug] [ThreadPool]: On list_my_db: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db"} */
USE [my_db];
    select  name as [schema]
    from sys.schemas with (nolock) 
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m09:40:56.960519 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:40:56.960519 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:40:57.241774 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m09:40:57.257393 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m09:40:57.257393 [debug] [ThreadPool]: On list_my_db: Close
[0m09:40:57.273019 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db_dbo'
[0m09:40:57.273019 [debug] [ThreadPool]: dbt-sqlserver
[0m09:40:57.273019 [debug] [ThreadPool]: Using sqlserver connection "list_my_db_dbo"
[0m09:40:57.273019 [debug] [ThreadPool]: On list_my_db_dbo: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db_dbo"} */
USE [my_db];
    with base as (
      select
        DB_NAME() as [database],
        t.name as [name],
        SCHEMA_NAME(t.schema_id) as [schema],
        'table' as table_type
      from sys.tables as t with (nolock)
      union all
      select
        DB_NAME() as [database],
        v.name as [name],
        SCHEMA_NAME(v.schema_id) as [schema],
        'view' as table_type
      from sys.views as v with (nolock)
    )
    select * from base
    where [schema] like 'dbo'
    
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m09:40:57.288643 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:40:57.288643 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:40:57.288643 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m09:40:57.335517 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m09:40:57.351142 [debug] [ThreadPool]: On list_my_db_dbo: ROLLBACK
[0m09:40:57.351142 [debug] [ThreadPool]: On list_my_db_dbo: Close
[0m09:40:57.351142 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '19340174-2a1d-4a60-966d-779c2c19e7c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022596FF0D50>]}
[0m09:40:57.351142 [debug] [MainThread]: On master: COMMIT
[0m09:40:57.366771 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m09:40:57.366771 [info ] [Thread-1 (]: 1 of 2 START sql view model dbo.src_ecommerce .................................. [RUN]
[0m09:40:57.366771 [debug] [Thread-1 (]: Acquiring new sqlserver connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m09:40:57.366771 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m09:40:57.382400 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m09:40:57.382400 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m09:40:57.444894 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m09:40:57.444894 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m09:40:57.444894 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."src_ecommerce__dbt_tmp" as 

select * from "my_db"."dbo"."ecommerce";
    ')


[0m09:40:57.460534 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m09:40:57.460534 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:40:57.460534 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m09:40:57.476143 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:40:57.491770 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m09:40:57.491770 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce', 'src_ecommerce__dbt_backup'
[0m09:40:57.710561 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:40:57.710561 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m09:40:57.710561 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce__dbt_tmp', 'src_ecommerce'
[0m09:40:57.710561 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:40:57.741767 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: COMMIT
[0m09:40:57.757393 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."src_ecommerce__dbt_backup"
[0m09:40:57.773016 [debug] [Thread-1 (]: dbt-sqlserver
[0m09:40:57.773016 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m09:40:57.773016 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'src_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m09:40:57.804307 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:40:57.804307 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m09:40:57.804307 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."src_ecommerce__dbt_backup";');

[0m09:40:57.819891 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:40:57.819891 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: ROLLBACK
[0m09:40:57.819891 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: Close
[0m09:40:57.819891 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19340174-2a1d-4a60-966d-779c2c19e7c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022596C1D410>]}
[0m09:40:57.835519 [info ] [Thread-1 (]: 1 of 2 OK created sql view model dbo.src_ecommerce ............................. [[32mOK[0m in 0.45s]
[0m09:40:57.835519 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m09:40:57.835519 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m09:40:57.835519 [info ] [Thread-1 (]: 2 of 2 START sql view model dbo.stg_ecommerce .................................. [RUN]
[0m09:40:57.835519 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m09:40:57.835519 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m09:40:57.851184 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:40:57.851184 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m09:40:57.851184 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:40:57.866810 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:40:57.866810 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."stg_ecommerce__dbt_tmp" as 

SELECT
    
        CAST(User_ID AS VARCHAR) AS User_ID,
        CAST(Product_ID AS VARCHAR) AS Product_ID,
        CAST(Category AS VARCHAR) AS Category,
        CAST(Price AS FLOAT) AS Price,
        CAST(Discount AS INT) AS Discount,
        CAST(Final_Price AS FLOAT) AS Final_Price,
        CAST(Payment_Method AS VARCHAR) AS Payment_Method,
        CAST(Purchase_Date AS DATE) AS Purchase_Date
    
FROM "my_db"."dbo"."ecommerce";
    ')


[0m09:40:57.866810 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m09:40:57.866810 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m09:40:57.866810 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m09:40:57.882551 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:40:57.882551 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:40:57.882551 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce', 'stg_ecommerce__dbt_backup'
[0m09:40:57.882551 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:40:57.898016 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:40:57.898016 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce__dbt_tmp', 'stg_ecommerce'
[0m09:40:57.898016 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:40:57.898016 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: COMMIT
[0m09:40:57.913643 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."stg_ecommerce__dbt_backup"
[0m09:40:57.913643 [debug] [Thread-1 (]: dbt-sqlserver
[0m09:40:57.913643 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:40:57.913643 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'stg_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m09:40:57.929266 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:40:57.929266 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:40:57.944937 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."stg_ecommerce__dbt_backup";');

[0m09:40:57.944937 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m09:40:57.944937 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: ROLLBACK
[0m09:40:57.944937 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: Close
[0m09:40:57.944937 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '19340174-2a1d-4a60-966d-779c2c19e7c4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022596D840D0>]}
[0m09:40:57.944937 [info ] [Thread-1 (]: 2 of 2 OK created sql view model dbo.stg_ecommerce ............................. [[32mOK[0m in 0.11s]
[0m09:40:57.944937 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m09:40:57.960536 [debug] [MainThread]: On master: COMMIT
[0m09:40:57.960536 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:40:57.960536 [debug] [MainThread]: Connection 'list_my_db' was properly closed.
[0m09:40:57.960536 [debug] [MainThread]: Connection 'list_my_db_dbo' was properly closed.
[0m09:40:57.960536 [debug] [MainThread]: Connection 'model.dbt_databricks_cicd.stg_ecommerce' was properly closed.
[0m09:40:57.960536 [info ] [MainThread]: 
[0m09:40:57.960536 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 1.05 seconds (1.05s).
[0m09:40:57.960536 [debug] [MainThread]: Command end result
[0m09:40:58.038648 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m09:40:58.038648 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m09:40:58.054271 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m09:40:58.054271 [info ] [MainThread]: 
[0m09:40:58.054271 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:40:58.054271 [info ] [MainThread]: 
[0m09:40:58.069893 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m09:40:58.069893 [debug] [MainThread]: Command `dbt build` succeeded at 09:40:58.069893 after 13.73 seconds
[0m09:40:58.069893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002258E5D3DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002258E8310D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002258E8304D0>]}
[0m09:40:58.069893 [debug] [MainThread]: Flushing usage events
[0m09:40:59.523213 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m09:41:13.782602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C7C8F1A50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C7C8F1B10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C7C8F1FD0>]}


============================== 09:41:13.782602 | 2c36247c-983d-43a8-a391-9da8816b0248 ==============================
[0m09:41:13.782602 [info ] [MainThread]: Running with dbt=1.10.3
[0m09:41:13.782602 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'invocation_command': 'dbt build --target databricks', 'send_anonymous_usage_stats': 'True'}
[0m09:41:15.860729 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m09:41:15.860729 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m09:41:15.860729 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m09:41:22.173232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2c36247c-983d-43a8-a391-9da8816b0248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C7C8FB150>]}
[0m09:41:22.376354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2c36247c-983d-43a8-a391-9da8816b0248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C7C069C90>]}
[0m09:41:22.376354 [info ] [MainThread]: Registered adapter: databricks=1.10.4
[0m09:41:23.563851 [debug] [MainThread]: checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, vars: {}, profile: , target: databricks, version: 1.10.3
[0m09:41:23.782612 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m09:41:23.782612 [debug] [MainThread]: previous checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, current checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331
[0m09:41:23.782612 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m09:41:23.782612 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m09:41:23.782612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2c36247c-983d-43a8-a391-9da8816b0248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C7C000250>]}
[0m09:41:28.704487 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m09:41:28.720106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2c36247c-983d-43a8-a391-9da8816b0248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C09A6EB10>]}
[0m09:41:28.907608 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m09:41:28.907608 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m09:41:29.001353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2c36247c-983d-43a8-a391-9da8816b0248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C09E22010>]}
[0m09:41:29.001353 [info ] [MainThread]: Found 9 models, 24 data tests, 1 source, 799 macros
[0m09:41:29.001353 [info ] [MainThread]: 
[0m09:41:29.016989 [info ] [MainThread]: Concurrency: 1 threads (target='databricks')
[0m09:41:29.016989 [info ] [MainThread]: 
[0m09:41:29.016989 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=0s, language=None, compute-name=) - Creating connection
[0m09:41:29.016989 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m09:41:29.032602 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace, idle-time=0s, language=None, compute-name=) - Creating connection
[0m09:41:29.032602 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace'
[0m09:41:29.032602 [debug] [ThreadPool]: Using databricks connection "list_workspace"
[0m09:41:29.032602 [debug] [ThreadPool]: On list_workspace: GetSchemas(database=workspace, schema=None)
[0m09:41:29.032602 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:41:30.907670 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f07dc2-ff22-1e09-9837-cda98767e01e) - Created
[0m09:42:33.918537 [debug] [ThreadPool]: SQL status: OK in 64.890 seconds
[0m09:42:33.918537 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f07dc2-ff22-1e09-9837-cda98767e01e, command-id=01f07dc3-235f-1e77-a3c2-f56a2c2126d7) - Closing
[0m09:42:33.934150 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace_default, idle-time=0s, language=None, compute-name=) - Creating connection
[0m09:42:33.934150 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace_default'
[0m09:42:33.949820 [debug] [ThreadPool]: Using databricks connection "list_workspace_default"
[0m09:42:33.949820 [debug] [ThreadPool]: On list_workspace_default: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "connection_name": "list_workspace_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'workspace' 
  AND table_schema = 'default'

  
[0m09:42:33.965409 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m09:42:34.746930 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f07dc3-254d-117a-aff2-07a008bcc57c) - Created
[0m09:42:39.856153 [debug] [ThreadPool]: SQL status: OK in 5.890 seconds
[0m09:42:39.887326 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f07dc3-254d-117a-aff2-07a008bcc57c, command-id=01f07dc3-2573-11d7-96a5-6b816b22fe34) - Closing
[0m09:42:40.246648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2c36247c-983d-43a8-a391-9da8816b0248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C096B7D50>]}
[0m09:42:40.246648 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m09:42:40.262273 [info ] [Thread-1 (]: 1 of 33 START sql view model default.src_ecommerce ............................. [RUN]
[0m09:42:40.262273 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_cicd.src_ecommerce, idle-time=0s, language=None, compute-name=) - Creating connection
[0m09:42:40.262273 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m09:42:40.262273 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m09:42:40.293525 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m09:42:40.293525 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m09:42:40.324779 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m09:42:40.324779 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m09:42:40.324779 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': '2c36247c-983d-43a8-a391-9da8816b0248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C09B19790>]}
[0m09:42:40.371653 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`src_ecommerce`
[0m09:42:40.387279 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m09:42:40.387279 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.src_ecommerce"
[0m09:42:40.387279 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`src_ecommerce`
  
  as (
    SELECT * FROM default.sales_ecommerce
  )

[0m09:42:40.387279 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m09:42:41.106295 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043) - Created
[0m09:42:45.059221 [debug] [Thread-1 (]: SQL status: OK in 4.670 seconds
[0m09:42:45.059221 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-2939-1315-aa1a-acdf1ed91bbf) - Closing
[0m09:42:45.074816 [debug] [Thread-1 (]: Applying tags to relation None
[0m09:42:45.090399 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c36247c-983d-43a8-a391-9da8816b0248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C09B033D0>]}
[0m09:42:45.090399 [info ] [Thread-1 (]: 1 of 33 OK created sql view model default.src_ecommerce ........................ [[32mOK[0m in 4.81s]
[0m09:42:45.090399 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m09:42:45.090399 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m09:42:45.090399 [info ] [Thread-1 (]: 2 of 33 START sql view model default.stg_ecommerce ............................. [RUN]
[0m09:42:45.090399 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m09:42:45.090399 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=model.dbt_databricks_cicd.stg_ecommerce, idle-time=0.015583276748657227s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.src_ecommerce
[0m09:42:45.090399 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m09:42:45.106066 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:42:45.106066 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m09:42:45.121710 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m09:42:45.121710 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`stg_ecommerce`
[0m09:42:45.121710 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:42:45.121710 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m09:42:45.121710 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`stg_ecommerce`
  
  as (
    SELECT
  User_ID,
  Product_ID,
  Category,
  Price,
  Discount,
  Final_Price,
  Payment_Method,
  Purchase_Date
FROM `workspace`.`default`.`src_ecommerce`
  )

[0m09:42:46.278051 [debug] [Thread-1 (]: SQL status: OK in 1.160 seconds
[0m09:42:46.278051 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-2b9f-11f4-a40c-72353ccfc4ee) - Closing
[0m09:42:46.278051 [debug] [Thread-1 (]: Applying tags to relation None
[0m09:42:46.293568 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c36247c-983d-43a8-a391-9da8816b0248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C09ED9010>]}
[0m09:42:46.293568 [info ] [Thread-1 (]: 2 of 33 OK created sql view model default.stg_ecommerce ........................ [[32mOK[0m in 1.20s]
[0m09:42:46.293568 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m09:42:46.293568 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_discount_by_category
[0m09:42:46.293568 [info ] [Thread-1 (]: 3 of 33 START sql view model default.avg_discount_by_category .................. [RUN]
[0m09:42:46.293568 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now model.dbt_databricks_cicd.avg_discount_by_category)
[0m09:42:46.293568 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=model.dbt_databricks_cicd.avg_discount_by_category, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.stg_ecommerce
[0m09:42:46.293568 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_discount_by_category
[0m09:42:46.309189 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m09:42:46.309189 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_discount_by_category
[0m09:42:46.324816 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m09:42:46.324816 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`avg_discount_by_category`
[0m09:42:46.324816 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m09:42:46.324816 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.avg_discount_by_category"
[0m09:42:46.324816 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_discount_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.avg_discount_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`avg_discount_by_category`
  
  as (
    SELECT
  Category,
  ROUND(AVG(CAST(`Discount` AS DOUBLE)), 2) AS avg_discount_percent
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY avg_discount_percent DESC
  )

[0m09:42:47.403131 [debug] [Thread-1 (]: SQL status: OK in 1.080 seconds
[0m09:42:47.418540 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-2c56-1edb-8125-3f0e989f364c) - Closing
[0m09:42:47.418540 [debug] [Thread-1 (]: Applying tags to relation None
[0m09:42:47.418540 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c36247c-983d-43a8-a391-9da8816b0248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C09EE6490>]}
[0m09:42:47.434154 [info ] [Thread-1 (]: 3 of 33 OK created sql view model default.avg_discount_by_category ............. [[32mOK[0m in 1.12s]
[0m09:42:47.434154 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_discount_by_category
[0m09:42:47.434154 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m09:42:47.434154 [info ] [Thread-1 (]: 4 of 33 START sql view model default.avg_ticket_by_category .................... [RUN]
[0m09:42:47.434154 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_discount_by_category, now model.dbt_databricks_cicd.avg_ticket_by_category)
[0m09:42:47.434154 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=model.dbt_databricks_cicd.avg_ticket_by_category, idle-time=0.015614748001098633s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.avg_discount_by_category
[0m09:42:47.434154 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_ticket_by_category
[0m09:42:47.449816 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m09:42:47.449816 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_ticket_by_category
[0m09:42:47.449816 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m09:42:47.465521 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`avg_ticket_by_category`
[0m09:42:47.465521 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m09:42:47.465521 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m09:42:47.465521 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_ticket_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.avg_ticket_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`avg_ticket_by_category`
  
  as (
    SELECT
  Category,
  ROUND(AVG(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS avg_ticket
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY avg_ticket DESC
  )

[0m09:42:48.278052 [debug] [Thread-1 (]: SQL status: OK in 0.810 seconds
[0m09:42:48.293562 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-2d04-1107-a66f-86a7994db876) - Closing
[0m09:42:48.293562 [debug] [Thread-1 (]: Applying tags to relation None
[0m09:42:48.293562 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c36247c-983d-43a8-a391-9da8816b0248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C09EA8C90>]}
[0m09:42:48.293562 [info ] [Thread-1 (]: 4 of 33 OK created sql view model default.avg_ticket_by_category ............... [[32mOK[0m in 0.86s]
[0m09:42:48.293562 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m09:42:48.293562 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.monthly_revenue
[0m09:42:48.293562 [info ] [Thread-1 (]: 5 of 33 START sql view model default.monthly_revenue ........................... [RUN]
[0m09:42:48.293562 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_ticket_by_category, now model.dbt_databricks_cicd.monthly_revenue)
[0m09:42:48.293562 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=model.dbt_databricks_cicd.monthly_revenue, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.avg_ticket_by_category
[0m09:42:48.309188 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.monthly_revenue
[0m09:42:48.309188 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.monthly_revenue"
[0m09:42:48.309188 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.monthly_revenue
[0m09:42:48.324819 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m09:42:48.324819 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`monthly_revenue`
[0m09:42:48.324819 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.monthly_revenue"
[0m09:42:48.324819 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.monthly_revenue"
[0m09:42:48.324819 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.monthly_revenue: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.monthly_revenue"} */

  
  
  
  create or replace view `workspace`.`default`.`monthly_revenue`
  
  as (
    SELECT
  CAST(DATE_TRUNC('month', CAST(Purchase_Date AS DATE)) AS DATE) AS month,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS monthly_revenue
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY 1
ORDER BY 1
  )

[0m09:42:49.152971 [debug] [Thread-1 (]: SQL status: OK in 0.830 seconds
[0m09:42:49.152971 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-2d88-1233-9db0-bcb4a7971671) - Closing
[0m09:42:49.152971 [debug] [Thread-1 (]: Applying tags to relation None
[0m09:42:49.152971 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c36247c-983d-43a8-a391-9da8816b0248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C09E31F50>]}
[0m09:42:49.152971 [info ] [Thread-1 (]: 5 of 33 OK created sql view model default.monthly_revenue ...................... [[32mOK[0m in 0.86s]
[0m09:42:49.168523 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.monthly_revenue
[0m09:42:49.168523 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.payment_distribution
[0m09:42:49.168523 [info ] [Thread-1 (]: 6 of 33 START sql view model default.payment_distribution ...................... [RUN]
[0m09:42:49.168523 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.monthly_revenue, now model.dbt_databricks_cicd.payment_distribution)
[0m09:42:49.168523 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=model.dbt_databricks_cicd.payment_distribution, idle-time=0.015552282333374023s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.monthly_revenue
[0m09:42:49.168523 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.payment_distribution
[0m09:42:49.184196 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.payment_distribution"
[0m09:42:49.184196 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.payment_distribution
[0m09:42:49.184196 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m09:42:49.199775 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`payment_distribution`
[0m09:42:49.199775 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.payment_distribution"
[0m09:42:49.199775 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.payment_distribution"
[0m09:42:49.199775 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.payment_distribution: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.payment_distribution"} */

  
  
  
  create or replace view `workspace`.`default`.`payment_distribution`
  
  as (
    SELECT
  Payment_Method,
  COUNT(*) AS total_transactions,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_value
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Payment_Method
ORDER BY total_value DESC
  )

[0m09:42:49.969137 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m09:42:49.969137 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-2e0c-1ae4-998e-662c2595a4f5) - Closing
[0m09:42:49.984515 [debug] [Thread-1 (]: Applying tags to relation None
[0m09:42:49.984515 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c36247c-983d-43a8-a391-9da8816b0248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C0A687790>]}
[0m09:42:49.984515 [info ] [Thread-1 (]: 6 of 33 OK created sql view model default.payment_distribution ................. [[32mOK[0m in 0.82s]
[0m09:42:50.000091 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.payment_distribution
[0m09:42:50.000091 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.sales_by_category
[0m09:42:50.000091 [info ] [Thread-1 (]: 7 of 33 START sql view model default.sales_by_category ......................... [RUN]
[0m09:42:50.000091 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.payment_distribution, now model.dbt_databricks_cicd.sales_by_category)
[0m09:42:50.000091 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=model.dbt_databricks_cicd.sales_by_category, idle-time=0.015575408935546875s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.payment_distribution
[0m09:42:50.000091 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.sales_by_category
[0m09:42:50.015733 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.sales_by_category"
[0m09:42:50.015733 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.sales_by_category
[0m09:42:50.031355 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m09:42:50.031355 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`sales_by_category`
[0m09:42:50.031355 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.sales_by_category"
[0m09:42:50.031355 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.sales_by_category"
[0m09:42:50.031355 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.sales_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.sales_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`sales_by_category`
  
  as (
    SELECT
  Category,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_revenue
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY total_revenue DESC
  )

[0m09:42:50.703490 [debug] [Thread-1 (]: SQL status: OK in 0.670 seconds
[0m09:42:50.718858 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-2e8b-1f6a-8d16-e23604575bbf) - Closing
[0m09:42:50.718858 [debug] [Thread-1 (]: Applying tags to relation None
[0m09:42:50.718858 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c36247c-983d-43a8-a391-9da8816b0248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C09ED8AD0>]}
[0m09:42:50.718858 [info ] [Thread-1 (]: 7 of 33 OK created sql view model default.sales_by_category .................... [[32mOK[0m in 0.72s]
[0m09:42:50.718858 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.sales_by_category
[0m09:42:50.718858 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_5_products
[0m09:42:50.718858 [info ] [Thread-1 (]: 8 of 33 START sql view model default.top_5_products ............................ [RUN]
[0m09:42:50.734478 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.sales_by_category, now model.dbt_databricks_cicd.top_5_products)
[0m09:42:50.734478 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=model.dbt_databricks_cicd.top_5_products, idle-time=0.015620708465576172s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.sales_by_category
[0m09:42:50.734478 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_5_products
[0m09:42:50.734478 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_5_products"
[0m09:42:50.734478 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_5_products
[0m09:42:50.750105 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m09:42:50.750105 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`top_5_products`
[0m09:42:50.750105 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_5_products"
[0m09:42:50.750105 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.top_5_products"
[0m09:42:50.750105 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_5_products: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.top_5_products"} */

  
  
  
  create or replace view `workspace`.`default`.`top_5_products`
  
  as (
    WITH base AS (
    SELECT
        product_id,
        ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_sales
    FROM `workspace`.`default`.`stg_ecommerce`
    GROUP BY product_id
)

SELECT
    product_id,
    total_sales
FROM base
ORDER BY total_sales DESC
LIMIT 5
  )

[0m09:42:51.437638 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m09:42:51.437638 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-2efa-100d-a8ec-bbab3f2f1f3e) - Closing
[0m09:42:51.437638 [debug] [Thread-1 (]: Applying tags to relation None
[0m09:42:51.453250 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c36247c-983d-43a8-a391-9da8816b0248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C09ED8AD0>]}
[0m09:42:51.453250 [info ] [Thread-1 (]: 8 of 33 OK created sql view model default.top_5_products ....................... [[32mOK[0m in 0.72s]
[0m09:42:51.453250 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_5_products
[0m09:42:51.453250 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_customers
[0m09:42:51.453250 [info ] [Thread-1 (]: 9 of 33 START sql view model default.top_customers ............................. [RUN]
[0m09:42:51.453250 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_5_products, now model.dbt_databricks_cicd.top_customers)
[0m09:42:51.453250 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=model.dbt_databricks_cicd.top_customers, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.top_5_products
[0m09:42:51.468853 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_customers
[0m09:42:51.468853 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_customers"
[0m09:42:51.468853 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_customers
[0m09:42:51.484443 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m09:42:51.484443 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`top_customers`
[0m09:42:51.484443 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_customers"
[0m09:42:51.484443 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.top_customers"
[0m09:42:51.484443 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_customers: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.top_customers"} */

  
  
  
  create or replace view `workspace`.`default`.`top_customers`
  
  as (
    SELECT
  User_ID,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_spent
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY User_ID
ORDER BY total_spent DESC
LIMIT 10
  )

[0m09:42:52.422209 [debug] [Thread-1 (]: SQL status: OK in 0.940 seconds
[0m09:42:52.437629 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-2f6a-152f-9f64-6b35db5f215b) - Closing
[0m09:42:52.437629 [debug] [Thread-1 (]: Applying tags to relation None
[0m09:42:52.437629 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2c36247c-983d-43a8-a391-9da8816b0248', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C0A660D10>]}
[0m09:42:52.437629 [info ] [Thread-1 (]: 9 of 33 OK created sql view model default.top_customers ........................ [[32mOK[0m in 0.98s]
[0m09:42:52.453202 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_customers
[0m09:42:52.453202 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m09:42:52.453202 [info ] [Thread-1 (]: 10 of 33 START test non_negative_avg_discount_by_category_avg_discount_percent . [RUN]
[0m09:42:52.453202 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_customers, now test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f)
[0m09:42:52.453202 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f, idle-time=0.015573263168334961s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.top_customers
[0m09:42:52.453202 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m09:42:52.468855 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"
[0m09:42:52.468855 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m09:42:52.500107 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"
[0m09:42:52.515689 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"
[0m09:42:52.515689 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`avg_discount_by_category`
where TRY_CAST(REPLACE(avg_discount_percent, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m09:42:57.406329 [debug] [Thread-1 (]: SQL status: OK in 4.890 seconds
[0m09:42:57.422017 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-3007-1974-8030-4b717b2f0870) - Closing
[0m09:42:57.437624 [info ] [Thread-1 (]: 10 of 33 PASS non_negative_avg_discount_by_category_avg_discount_percent ....... [[32mPASS[0m in 4.98s]
[0m09:42:57.437624 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m09:42:57.437624 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:42:57.437624 [info ] [Thread-1 (]: 11 of 33 START test not_null_avg_discount_by_category_Category ................. [RUN]
[0m09:42:57.437624 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b)
[0m09:42:57.453190 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, idle-time=0.015565633773803711s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m09:42:57.453190 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:42:57.453190 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m09:42:57.468855 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:42:57.468855 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m09:42:57.468855 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m09:42:57.468855 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_discount_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:42:58.359662 [debug] [Thread-1 (]: SQL status: OK in 0.890 seconds
[0m09:42:58.359662 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-32fb-15ae-982b-d33239e1a788) - Closing
[0m09:42:58.375111 [info ] [Thread-1 (]: 11 of 33 PASS not_null_avg_discount_by_category_Category ....................... [[32mPASS[0m in 0.94s]
[0m09:42:58.375111 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:42:58.375111 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:42:58.375111 [info ] [Thread-1 (]: 12 of 33 START test not_null_avg_discount_by_category_avg_discount_percent ..... [RUN]
[0m09:42:58.375111 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101)
[0m09:42:58.375111 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m09:42:58.375111 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:42:58.390690 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m09:42:58.390690 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:42:58.406363 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m09:42:58.406363 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m09:42:58.406363 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_discount_percent
from `workspace`.`default`.`avg_discount_by_category`
where avg_discount_percent is null



  
  
      
    ) dbt_internal_test
[0m09:42:59.422002 [debug] [Thread-1 (]: SQL status: OK in 1.020 seconds
[0m09:42:59.422002 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-3389-13c2-8689-53dbfbb7df22) - Closing
[0m09:42:59.437625 [info ] [Thread-1 (]: 12 of 33 PASS not_null_avg_discount_by_category_avg_discount_percent ........... [[32mPASS[0m in 1.05s]
[0m09:42:59.437625 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:42:59.437625 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m09:42:59.437625 [info ] [Thread-1 (]: 13 of 33 START test non_negative_avg_ticket_by_category_avg_ticket ............. [RUN]
[0m09:42:59.437625 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, now test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095)
[0m09:42:59.437625 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095, idle-time=0.015623807907104492s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m09:42:59.437625 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m09:42:59.453226 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"
[0m09:42:59.453226 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m09:42:59.468880 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"
[0m09:42:59.468880 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"
[0m09:42:59.468880 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`avg_ticket_by_category`
where TRY_CAST(REPLACE(avg_ticket, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m09:43:00.515692 [debug] [Thread-1 (]: SQL status: OK in 1.050 seconds
[0m09:43:00.531315 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-342b-12d8-ba10-262163391492) - Closing
[0m09:43:00.531315 [info ] [Thread-1 (]: 13 of 33 PASS non_negative_avg_ticket_by_category_avg_ticket ................... [[32mPASS[0m in 1.09s]
[0m09:43:00.531315 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m09:43:00.531315 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:43:00.546937 [info ] [Thread-1 (]: 14 of 33 START test not_null_avg_ticket_by_category_Category ................... [RUN]
[0m09:43:00.546937 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f)
[0m09:43:00.546937 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, idle-time=0.015622377395629883s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m09:43:00.546937 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:43:00.546937 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m09:43:00.562566 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:43:00.562566 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m09:43:00.578187 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m09:43:00.578187 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_ticket_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:43:01.312630 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m09:43:01.312630 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-34d5-18de-87e5-04fbf4a1cb97) - Closing
[0m09:43:01.312630 [info ] [Thread-1 (]: 14 of 33 PASS not_null_avg_ticket_by_category_Category ......................... [[32mPASS[0m in 0.77s]
[0m09:43:01.328203 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:43:01.328203 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:43:01.328203 [info ] [Thread-1 (]: 15 of 33 START test not_null_avg_ticket_by_category_avg_ticket ................. [RUN]
[0m09:43:01.328203 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41)
[0m09:43:01.343883 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, idle-time=0.015572547912597656s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m09:43:01.343883 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:43:01.359482 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m09:43:01.359482 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:43:01.359482 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m09:43:01.359482 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m09:43:01.375064 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_ticket
from `workspace`.`default`.`avg_ticket_by_category`
where avg_ticket is null



  
  
      
    ) dbt_internal_test
[0m09:43:02.359642 [debug] [Thread-1 (]: SQL status: OK in 0.980 seconds
[0m09:43:02.375122 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-354d-1259-87ee-0de5f5a11812) - Closing
[0m09:43:02.375122 [info ] [Thread-1 (]: 15 of 33 PASS not_null_avg_ticket_by_category_avg_ticket ....................... [[32mPASS[0m in 1.05s]
[0m09:43:02.375122 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:43:02.390693 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m09:43:02.390693 [info ] [Thread-1 (]: 16 of 33 START test non_negative_monthly_revenue_monthly_revenue ............... [RUN]
[0m09:43:02.390693 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, now test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294)
[0m09:43:02.390693 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294, idle-time=0.015571355819702148s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m09:43:02.390693 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m09:43:02.406357 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"
[0m09:43:02.406357 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m09:43:02.406357 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"
[0m09:43:02.406357 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"
[0m09:43:02.406357 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`monthly_revenue`
where TRY_CAST(REPLACE(monthly_revenue, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m09:43:03.421936 [debug] [Thread-1 (]: SQL status: OK in 1.020 seconds
[0m09:43:03.421936 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-35ee-1006-9651-399d56f99618) - Closing
[0m09:43:03.421936 [info ] [Thread-1 (]: 16 of 33 PASS non_negative_monthly_revenue_monthly_revenue ..................... [[32mPASS[0m in 1.03s]
[0m09:43:03.437566 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m09:43:03.437566 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:43:03.437566 [info ] [Thread-1 (]: 17 of 33 START test not_null_monthly_revenue_month ............................. [RUN]
[0m09:43:03.437566 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294, now test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b)
[0m09:43:03.437566 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, idle-time=0.015630006790161133s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m09:43:03.437566 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:43:03.453189 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m09:43:03.453189 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:43:03.468819 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m09:43:03.468819 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m09:43:03.468819 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select month
from `workspace`.`default`.`monthly_revenue`
where month is null



  
  
      
    ) dbt_internal_test
[0m09:43:04.406631 [debug] [Thread-1 (]: SQL status: OK in 0.940 seconds
[0m09:43:04.422003 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-368e-15ac-89ec-93e520b5ded9) - Closing
[0m09:43:04.422003 [info ] [Thread-1 (]: 17 of 33 PASS not_null_monthly_revenue_month ................................... [[32mPASS[0m in 0.98s]
[0m09:43:04.422003 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:43:04.422003 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:43:04.437606 [info ] [Thread-1 (]: 18 of 33 START test not_null_monthly_revenue_monthly_revenue ................... [RUN]
[0m09:43:04.437606 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, now test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b)
[0m09:43:04.437606 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, idle-time=0.015602350234985352s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m09:43:04.437606 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:43:04.437606 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m09:43:04.453200 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:43:04.453200 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m09:43:04.453200 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m09:43:04.453200 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select monthly_revenue
from `workspace`.`default`.`monthly_revenue`
where monthly_revenue is null



  
  
      
    ) dbt_internal_test
[0m09:43:05.437635 [debug] [Thread-1 (]: SQL status: OK in 0.980 seconds
[0m09:43:05.453250 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-3725-1ab9-b782-f5408c636af5) - Closing
[0m09:43:05.453250 [info ] [Thread-1 (]: 18 of 33 PASS not_null_monthly_revenue_monthly_revenue ......................... [[32mPASS[0m in 1.02s]
[0m09:43:05.453250 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:43:05.453250 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m09:43:05.453250 [info ] [Thread-1 (]: 19 of 33 START test non_negative_payment_distribution_total_value .............. [RUN]
[0m09:43:05.453250 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, now test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282)
[0m09:43:05.468852 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m09:43:05.468852 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m09:43:05.468852 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"
[0m09:43:05.468852 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m09:43:05.484439 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"
[0m09:43:05.484439 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"
[0m09:43:05.484439 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`payment_distribution`
where TRY_CAST(REPLACE(total_value, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m09:43:06.515760 [debug] [Thread-1 (]: SQL status: OK in 1.030 seconds
[0m09:43:06.531384 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-37c2-1602-8c16-8653b31e3416) - Closing
[0m09:43:06.531384 [info ] [Thread-1 (]: 19 of 33 PASS non_negative_payment_distribution_total_value .................... [[32mPASS[0m in 1.08s]
[0m09:43:06.531384 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m09:43:06.531384 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:43:06.546939 [info ] [Thread-1 (]: 20 of 33 START test not_null_payment_distribution_Payment_Method ............... [RUN]
[0m09:43:06.546939 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282, now test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae)
[0m09:43:06.546939 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, idle-time=0.015555381774902344s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m09:43:06.546939 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:43:06.546939 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m09:43:06.562563 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:43:06.562563 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m09:43:06.562563 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m09:43:06.562563 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`payment_distribution`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m09:43:07.469127 [debug] [Thread-1 (]: SQL status: OK in 0.910 seconds
[0m09:43:07.484508 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-3868-1caf-a8da-1b00b1a62b57) - Closing
[0m09:43:07.484508 [info ] [Thread-1 (]: 20 of 33 PASS not_null_payment_distribution_Payment_Method ..................... [[32mPASS[0m in 0.94s]
[0m09:43:07.500076 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:43:07.500076 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:43:07.500076 [info ] [Thread-1 (]: 21 of 33 START test not_null_payment_distribution_total_transactions ........... [RUN]
[0m09:43:07.500076 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, now test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8)
[0m09:43:07.500076 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, idle-time=0.015567541122436523s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m09:43:07.500076 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:43:07.515731 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m09:43:07.515731 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:43:07.531354 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m09:43:07.531354 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m09:43:07.531354 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_transactions
from `workspace`.`default`.`payment_distribution`
where total_transactions is null



  
  
      
    ) dbt_internal_test
[0m09:43:08.592862 [debug] [Thread-1 (]: SQL status: OK in 1.060 seconds
[0m09:43:08.592862 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-38fa-136d-83f1-ed9f551a2978) - Closing
[0m09:43:08.592862 [info ] [Thread-1 (]: 21 of 33 PASS not_null_payment_distribution_total_transactions ................. [[32mPASS[0m in 1.09s]
[0m09:43:08.592862 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:43:08.592862 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:43:08.592862 [info ] [Thread-1 (]: 22 of 33 START test not_null_payment_distribution_total_value .................. [RUN]
[0m09:43:08.608425 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, now test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03)
[0m09:43:08.608425 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, idle-time=0.015563011169433594s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m09:43:08.608425 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:43:08.608425 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m09:43:08.608425 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:43:08.624056 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m09:43:08.624056 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m09:43:08.624056 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_value
from `workspace`.`default`.`payment_distribution`
where total_value is null



  
  
      
    ) dbt_internal_test
[0m09:43:09.624233 [debug] [Thread-1 (]: SQL status: OK in 1.000 seconds
[0m09:43:09.624233 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-39a1-190f-86d8-ec774cccfad7) - Closing
[0m09:43:09.624233 [info ] [Thread-1 (]: 22 of 33 PASS not_null_payment_distribution_total_value ........................ [[32mPASS[0m in 1.02s]
[0m09:43:09.639711 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:43:09.639711 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m09:43:09.639711 [info ] [Thread-1 (]: 23 of 33 START test non_negative_sales_by_category_total_revenue ............... [RUN]
[0m09:43:09.639711 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, now test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41)
[0m09:43:09.639711 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41, idle-time=0.015477180480957031s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m09:43:09.639711 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m09:43:09.655296 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"
[0m09:43:09.655296 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m09:43:09.655296 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"
[0m09:43:09.655296 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"
[0m09:43:09.670960 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`sales_by_category`
where TRY_CAST(REPLACE(total_revenue, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m09:43:10.468049 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m09:43:10.483490 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-3a3f-1a65-b275-711fd501af7d) - Closing
[0m09:43:10.483490 [info ] [Thread-1 (]: 23 of 33 PASS non_negative_sales_by_category_total_revenue ..................... [[32mPASS[0m in 0.84s]
[0m09:43:10.499049 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m09:43:10.499049 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:43:10.499049 [info ] [Thread-1 (]: 24 of 33 START test not_null_sales_by_category_Category ........................ [RUN]
[0m09:43:10.499049 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41, now test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507)
[0m09:43:10.499049 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, idle-time=0.015559196472167969s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m09:43:10.499049 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:43:10.514713 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m09:43:10.514713 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:43:10.514713 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m09:43:10.530345 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m09:43:10.530345 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`sales_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m09:43:11.295987 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m09:43:11.295987 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-3ac4-1d2a-99cb-0569d9fa9765) - Closing
[0m09:43:11.295987 [info ] [Thread-1 (]: 24 of 33 PASS not_null_sales_by_category_Category .............................. [[32mPASS[0m in 0.80s]
[0m09:43:11.295987 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:43:11.295987 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:43:11.295987 [info ] [Thread-1 (]: 25 of 33 START test not_null_sales_by_category_total_orders .................... [RUN]
[0m09:43:11.311547 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, now test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e)
[0m09:43:11.311547 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, idle-time=0.015560150146484375s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m09:43:11.311547 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:43:11.311547 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m09:43:11.327189 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:43:11.327189 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m09:43:11.327189 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m09:43:11.327189 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`sales_by_category`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m09:43:11.999115 [debug] [Thread-1 (]: SQL status: OK in 0.670 seconds
[0m09:43:11.999115 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-3b3d-13d6-a184-3f0dd783b490) - Closing
[0m09:43:11.999115 [info ] [Thread-1 (]: 25 of 33 PASS not_null_sales_by_category_total_orders .......................... [[32mPASS[0m in 0.69s]
[0m09:43:11.999115 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:43:11.999115 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:43:12.014691 [info ] [Thread-1 (]: 26 of 33 START test not_null_sales_by_category_total_revenue ................... [RUN]
[0m09:43:12.014691 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, now test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd)
[0m09:43:12.014691 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, idle-time=0.01557612419128418s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m09:43:12.014691 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:43:12.014691 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m09:43:12.030297 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:43:12.030297 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m09:43:12.030297 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m09:43:12.030297 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_revenue
from `workspace`.`default`.`sales_by_category`
where total_revenue is null



  
  
      
    ) dbt_internal_test
[0m09:43:12.780342 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m09:43:12.780342 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-3ba8-1dad-a7d7-3cf06a28579f) - Closing
[0m09:43:12.780342 [info ] [Thread-1 (]: 26 of 33 PASS not_null_sales_by_category_total_revenue ......................... [[32mPASS[0m in 0.77s]
[0m09:43:12.780342 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:43:12.780342 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m09:43:12.780342 [info ] [Thread-1 (]: 27 of 33 START test non_negative_top_5_products_total_sales .................... [RUN]
[0m09:43:12.795922 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, now test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34)
[0m09:43:12.795922 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34, idle-time=0.015579462051391602s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m09:43:12.795922 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m09:43:12.795922 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"
[0m09:43:12.795922 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m09:43:12.811546 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"
[0m09:43:12.811546 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"
[0m09:43:12.811546 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`top_5_products`
where TRY_CAST(REPLACE(total_sales, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m09:43:13.889687 [debug] [Thread-1 (]: SQL status: OK in 1.080 seconds
[0m09:43:13.905299 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-3c20-1996-8e44-6efee2f0acd8) - Closing
[0m09:43:13.905299 [info ] [Thread-1 (]: 27 of 33 PASS non_negative_top_5_products_total_sales .......................... [[32mPASS[0m in 1.11s]
[0m09:43:13.905299 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m09:43:13.905299 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:43:13.905299 [info ] [Thread-1 (]: 28 of 33 START test not_null_top_5_products_product_id ......................... [RUN]
[0m09:43:13.920924 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34, now test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe)
[0m09:43:13.920924 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, idle-time=0.015625s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m09:43:13.920924 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:43:13.920924 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m09:43:13.920924 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:43:13.936550 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m09:43:13.936550 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m09:43:13.936550 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select product_id
from `workspace`.`default`.`top_5_products`
where product_id is null



  
  
      
    ) dbt_internal_test
[0m09:43:14.811616 [debug] [Thread-1 (]: SQL status: OK in 0.880 seconds
[0m09:43:14.811616 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-3ccc-1309-807f-7fdc318990e8) - Closing
[0m09:43:14.811616 [info ] [Thread-1 (]: 28 of 33 PASS not_null_top_5_products_product_id ............................... [[32mPASS[0m in 0.89s]
[0m09:43:14.811616 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:43:14.811616 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:43:14.827209 [info ] [Thread-1 (]: 29 of 33 START test not_null_top_5_products_total_sales ........................ [RUN]
[0m09:43:14.827209 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, now test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818)
[0m09:43:14.827209 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, idle-time=0.015592813491821289s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m09:43:14.827209 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:43:14.827209 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m09:43:14.842845 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:43:14.842845 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m09:43:14.842845 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m09:43:14.842845 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_sales
from `workspace`.`default`.`top_5_products`
where total_sales is null



  
  
      
    ) dbt_internal_test
[0m09:43:15.671186 [debug] [Thread-1 (]: SQL status: OK in 0.830 seconds
[0m09:43:15.671186 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-3d56-1d56-a542-4255b243c36e) - Closing
[0m09:43:15.686587 [info ] [Thread-1 (]: 29 of 33 PASS not_null_top_5_products_total_sales .............................. [[32mPASS[0m in 0.86s]
[0m09:43:15.686587 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:43:15.686587 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m09:43:15.686587 [info ] [Thread-1 (]: 30 of 33 START test non_negative_top_customers_total_spent ..................... [RUN]
[0m09:43:15.686587 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, now test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667)
[0m09:43:15.686587 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m09:43:15.686587 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m09:43:15.702216 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"
[0m09:43:15.702216 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m09:43:15.702216 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"
[0m09:43:15.717842 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"
[0m09:43:15.717842 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`top_customers`
where TRY_CAST(REPLACE(total_spent, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m09:43:16.499062 [debug] [Thread-1 (]: SQL status: OK in 0.780 seconds
[0m09:43:16.514679 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-3dda-1955-99cf-b7cfcfab892d) - Closing
[0m09:43:16.514679 [info ] [Thread-1 (]: 30 of 33 PASS non_negative_top_customers_total_spent ........................... [[32mPASS[0m in 0.83s]
[0m09:43:16.514679 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m09:43:16.514679 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:43:16.514679 [info ] [Thread-1 (]: 31 of 33 START test not_null_top_customers_User_ID ............................. [RUN]
[0m09:43:16.514679 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667, now test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0)
[0m09:43:16.514679 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m09:43:16.514679 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:43:16.530335 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m09:43:16.530335 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:43:16.545923 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m09:43:16.545923 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m09:43:16.545923 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`top_customers`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m09:43:17.296076 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m09:43:17.311586 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-3e59-19eb-9863-13759fc66f36) - Closing
[0m09:43:17.311586 [info ] [Thread-1 (]: 31 of 33 PASS not_null_top_customers_User_ID ................................... [[32mPASS[0m in 0.80s]
[0m09:43:17.311586 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:43:17.311586 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:43:17.311586 [info ] [Thread-1 (]: 32 of 33 START test not_null_top_customers_total_orders ........................ [RUN]
[0m09:43:17.311586 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, now test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746)
[0m09:43:17.311586 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m09:43:17.311586 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:43:17.327213 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m09:43:17.327213 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:43:17.342856 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m09:43:17.342856 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m09:43:17.342856 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`top_customers`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m09:43:17.968036 [debug] [Thread-1 (]: SQL status: OK in 0.630 seconds
[0m09:43:17.983465 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-3ed3-1c6c-9e5f-cb5f8dd02a47) - Closing
[0m09:43:17.983465 [info ] [Thread-1 (]: 32 of 33 PASS not_null_top_customers_total_orders .............................. [[32mPASS[0m in 0.67s]
[0m09:43:17.983465 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:43:17.983465 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:43:17.983465 [info ] [Thread-1 (]: 33 of 33 START test not_null_top_customers_total_spent ......................... [RUN]
[0m09:43:17.983465 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, now test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73)
[0m09:43:17.983465 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, name=test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m09:43:17.983465 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:43:17.999086 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m09:43:17.999086 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:43:17.999086 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m09:43:18.014699 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m09:43:18.014699 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_spent
from `workspace`.`default`.`top_customers`
where total_spent is null



  
  
      
    ) dbt_internal_test
[0m09:43:18.749108 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m09:43:18.749108 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043, command-id=01f07dc3-3f3a-1be8-a1e8-56508c61d93a) - Closing
[0m09:43:18.749108 [info ] [Thread-1 (]: 33 of 33 PASS not_null_top_customers_total_spent ............................... [[32mPASS[0m in 0.77s]
[0m09:43:18.764715 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m09:43:18.764715 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=38.51806688308716s, language=None, compute-name=) - Reusing connection previously named master
[0m09:43:18.764715 [debug] [MainThread]: Connection 'master' was properly closed.
[0m09:43:18.764715 [debug] [MainThread]: Connection 'list_workspace' was properly closed.
[0m09:43:18.764715 [debug] [MainThread]: On list_workspace: Close
[0m09:43:18.764715 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07dc2-ff22-1e09-9837-cda98767e01e) - Closing
[0m09:43:18.983670 [debug] [MainThread]: Connection 'list_workspace_default' was properly closed.
[0m09:43:18.999054 [debug] [MainThread]: On list_workspace_default: Close
[0m09:43:18.999054 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07dc3-254d-117a-aff2-07a008bcc57c) - Closing
[0m09:43:19.202452 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73' was properly closed.
[0m09:43:19.202452 [debug] [MainThread]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: Close
[0m09:43:19.202452 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07dc3-291b-104d-adc7-c21f05f9c043) - Closing
[0m09:43:19.452188 [info ] [MainThread]: 
[0m09:43:19.452188 [info ] [MainThread]: Finished running 24 data tests, 9 view models in 0 hours 1 minutes and 50.44 seconds (110.44s).
[0m09:43:19.483429 [debug] [MainThread]: Command end result
[0m09:43:19.686552 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m09:43:19.686552 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m09:43:19.702181 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m09:43:19.702181 [info ] [MainThread]: 
[0m09:43:19.702181 [info ] [MainThread]: [32mCompleted successfully[0m
[0m09:43:19.702181 [info ] [MainThread]: 
[0m09:43:19.717800 [info ] [MainThread]: Done. PASS=33 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=33
[0m09:43:19.717800 [debug] [MainThread]: Command `dbt build` succeeded at 09:43:19.717800 after 126.08 seconds
[0m09:43:19.717800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C75EC3DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C761210D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016C761204D0>]}
[0m09:43:19.717800 [debug] [MainThread]: Flushing usage events
[0m09:43:20.467811 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:56:19.343835 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D976A80D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D976ABE90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D97671350>]}


============================== 10:56:19.356662 | 977a8c08-6cb8-4bed-b324-06fd55b2568e ==============================
[0m10:56:19.356662 [info ] [MainThread]: Running with dbt=1.10.3
[0m10:56:19.360664 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'version_check': 'True', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --target sqlserver', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m10:56:24.335427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '977a8c08-6cb8-4bed-b324-06fd55b2568e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D98DEEA90>]}
[0m10:56:24.577403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '977a8c08-6cb8-4bed-b324-06fd55b2568e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D965E2090>]}
[0m10:56:24.579409 [info ] [MainThread]: Registered adapter: sqlserver=1.9.0
[0m10:56:26.067519 [debug] [MainThread]: checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, vars: {}, profile: , target: sqlserver, version: 1.10.3
[0m10:56:26.429087 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m10:56:26.429087 [debug] [MainThread]: previous checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331, current checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9
[0m10:56:26.445365 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m10:56:26.447371 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m10:56:26.450372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '977a8c08-6cb8-4bed-b324-06fd55b2568e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D96D84510>]}
[0m10:56:35.118824 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m10:56:35.120839 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m10:56:35.122823 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m10:56:35.125473 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_customers' which is disabled
[0m10:56:35.127476 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m10:56:35.130474 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m10:56:35.132602 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'top_5_products' which is disabled
[0m10:56:35.134600 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m10:56:35.137598 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m10:56:35.139597 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'monthly_revenue' which is disabled
[0m10:56:35.141600 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m10:56:35.142608 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m10:56:35.144610 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_discount_by_category' which is disabled
[0m10:56:35.145604 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m10:56:35.147718 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m10:56:35.149720 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'avg_ticket_by_category' which is disabled
[0m10:56:35.151725 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m10:56:35.153720 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m10:56:35.155721 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m10:56:35.157724 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'payment_distribution' which is disabled
[0m10:56:35.158719 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m10:56:35.159725 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m10:56:35.161722 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m10:56:35.162848 [debug] [MainThread]: [[33mWARNING[0m]: Test 'test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41' (dbt_databricks_cicd/models\mart\databricks\schema.yml) depends on a node named 'sales_by_category' which is disabled
[0m10:56:35.488336 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m10:56:35.542342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '977a8c08-6cb8-4bed-b324-06fd55b2568e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D99732950>]}
[0m10:56:36.053621 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m10:56:36.091993 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m10:56:36.316022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '977a8c08-6cb8-4bed-b324-06fd55b2568e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D9930D210>]}
[0m10:56:36.318020 [info ] [MainThread]: Found 2 models, 1 source, 626 macros
[0m10:56:36.330020 [info ] [MainThread]: 
[0m10:56:36.335025 [info ] [MainThread]: Concurrency: 1 threads (target='sqlserver')
[0m10:56:36.338024 [info ] [MainThread]: 
[0m10:56:36.343022 [debug] [MainThread]: Acquiring new sqlserver connection 'master'
[0m10:56:36.364020 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db'
[0m10:56:36.434018 [debug] [ThreadPool]: dbt-sqlserver
[0m10:56:36.436018 [debug] [ThreadPool]: Using sqlserver connection "list_my_db"
[0m10:56:36.438029 [debug] [ThreadPool]: On list_my_db: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db"} */
USE [my_db];
    select  name as [schema]
    from sys.schemas with (nolock) 
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m10:56:36.440018 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:56:36.442020 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m10:56:36.626023 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m10:56:36.648022 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m10:56:36.653023 [debug] [ThreadPool]: On list_my_db: Close
[0m10:56:36.666026 [debug] [ThreadPool]: Acquiring new sqlserver connection 'list_my_db_dbo'
[0m10:56:36.692019 [debug] [ThreadPool]: dbt-sqlserver
[0m10:56:36.694022 [debug] [ThreadPool]: Using sqlserver connection "list_my_db_dbo"
[0m10:56:36.696023 [debug] [ThreadPool]: On list_my_db_dbo: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "connection_name": "list_my_db_dbo"} */
USE [my_db];
    with base as (
      select
        DB_NAME() as [database],
        t.name as [name],
        SCHEMA_NAME(t.schema_id) as [schema],
        'table' as table_type
      from sys.tables as t with (nolock)
      union all
      select
        DB_NAME() as [database],
        v.name as [name],
        SCHEMA_NAME(v.schema_id) as [schema],
        'view' as table_type
      from sys.views as v with (nolock)
    )
    select * from base
    where [schema] like 'dbo'
    
    OPTION (LABEL = 'dbt-sqlserver');

  
[0m10:56:36.698022 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:56:36.700022 [debug] [ThreadPool]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m10:56:36.705023 [debug] [ThreadPool]: sqlserver adapter: Connected to db: my_db
[0m10:56:36.826019 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m10:56:36.831020 [debug] [ThreadPool]: On list_my_db_dbo: ROLLBACK
[0m10:56:36.833020 [debug] [ThreadPool]: On list_my_db_dbo: Close
[0m10:56:36.838019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '977a8c08-6cb8-4bed-b324-06fd55b2568e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D997A5A10>]}
[0m10:56:36.840027 [debug] [MainThread]: On master: COMMIT
[0m10:56:36.851020 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m10:56:36.853020 [info ] [Thread-1 (]: 1 of 2 START sql view model dbo.src_ecommerce .................................. [RUN]
[0m10:56:36.856025 [debug] [Thread-1 (]: Acquiring new sqlserver connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m10:56:36.860021 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m10:56:36.894020 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m10:56:36.898022 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m10:56:37.022021 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m10:56:37.026020 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m10:56:37.028022 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."src_ecommerce__dbt_tmp" as 

select * from "my_db"."dbo"."ecommerce";
    ')


[0m10:56:37.030021 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:56:37.032021 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m10:56:37.041021 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m10:56:37.048021 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:56:37.076020 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m10:56:37.078019 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce', 'src_ecommerce__dbt_backup'
[0m10:56:37.458471 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:56:37.471474 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m10:56:37.473471 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.src_ecommerce__dbt_tmp', 'src_ecommerce'
[0m10:56:37.479265 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:56:37.545048 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: COMMIT
[0m10:56:37.569354 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."src_ecommerce__dbt_backup"
[0m10:56:37.599478 [debug] [Thread-1 (]: dbt-sqlserver
[0m10:56:37.602479 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m10:56:37.605479 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'src_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m10:56:37.665791 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:56:37.671793 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.src_ecommerce"
[0m10:56:37.673792 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."src_ecommerce__dbt_backup";');

[0m10:56:37.679938 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:56:37.685937 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: ROLLBACK
[0m10:56:37.687939 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: Close
[0m10:56:37.691940 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '977a8c08-6cb8-4bed-b324-06fd55b2568e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D99296750>]}
[0m10:56:37.694062 [info ] [Thread-1 (]: 1 of 2 OK created sql view model dbo.src_ecommerce ............................. [[32mOK[0m in 0.83s]
[0m10:56:37.700065 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m10:56:37.702062 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m10:56:37.705063 [info ] [Thread-1 (]: 2 of 2 START sql view model dbo.stg_ecommerce .................................. [RUN]
[0m10:56:37.707063 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m10:56:37.709065 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m10:56:37.721185 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:56:37.724181 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m10:56:37.736336 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:56:37.739335 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:56:37.741461 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
    
    

    

    
    USE [my_db];
    EXEC('
        create view "dbo"."stg_ecommerce__dbt_tmp" as 

SELECT
    
        CAST(User_ID AS VARCHAR) AS User_ID,
        CAST(Product_ID AS VARCHAR) AS Product_ID,
        CAST(Category AS VARCHAR) AS Category,
        CAST(Price AS FLOAT) AS Price,
        CAST(Discount AS INT) AS Discount,
        CAST(Final_Price AS FLOAT) AS Final_Price,
        CAST(Payment_Method AS VARCHAR) AS Payment_Method,
        CAST(Purchase_Date AS DATE) AS Purchase_Date
    
FROM "my_db"."dbo"."ecommerce";
    ')


[0m10:56:37.743464 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m10:56:37.744460 [debug] [Thread-1 (]: sqlserver adapter: Using connection string: DRIVER={ODBC Driver 17 for SQL Server};SERVER=LAPTOP-NV4PR600,1433;Database=my_db;UID={dbt_user};PWD=***;encrypt=Yes;TrustServerCertificate=Yes;APP=dbt-sqlserver/1.9.0
[0m10:56:37.746464 [debug] [Thread-1 (]: sqlserver adapter: Connected to db: my_db
[0m10:56:37.753463 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:56:37.765583 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:56:37.767585 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce', 'stg_ecommerce__dbt_backup'
[0m10:56:37.774223 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:56:37.787226 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:56:37.789325 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */
USE [my_db];
      EXEC sp_rename 'dbo.stg_ecommerce__dbt_tmp', 'stg_ecommerce'
[0m10:56:37.794322 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:56:37.799324 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: COMMIT
[0m10:56:37.808453 [debug] [Thread-1 (]: Applying DROP to: "my_db"."dbo"."stg_ecommerce__dbt_backup"
[0m10:56:37.811454 [debug] [Thread-1 (]: dbt-sqlserver
[0m10:56:37.812452 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:56:37.814453 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

        USE [my_db];
        select
            sch.name as schema_name,
            obj.name as view_name
        from sys.sql_expression_dependencies refs
        inner join sys.objects obj
        on refs.referencing_id = obj.object_id
        inner join sys.schemas sch
        on obj.schema_id = sch.schema_id
        where refs.referenced_database_name = 'my_db'
        and refs.referenced_schema_name = 'dbo'
        and refs.referenced_entity_name = 'stg_ecommerce__dbt_backup'
        and refs.referencing_class = 1
        and obj.type = 'V'
        
    OPTION (LABEL = 'dbt-sqlserver');

      
[0m10:56:37.837978 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:56:37.842978 [debug] [Thread-1 (]: Using sqlserver connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:56:37.844978 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "profile_name": "dbt_databricks_cicd", "target_name": "sqlserver", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

      
      
    
    USE [my_db];
    EXEC('DROP view IF EXISTS "dbo"."stg_ecommerce__dbt_backup";');

[0m10:56:37.850112 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m10:56:37.854113 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: ROLLBACK
[0m10:56:37.856113 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: Close
[0m10:56:37.858115 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '977a8c08-6cb8-4bed-b324-06fd55b2568e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D99515810>]}
[0m10:56:37.860117 [info ] [Thread-1 (]: 2 of 2 OK created sql view model dbo.stg_ecommerce ............................. [[32mOK[0m in 0.15s]
[0m10:56:37.865134 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m10:56:37.869291 [debug] [MainThread]: On master: COMMIT
[0m10:56:37.871291 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:56:37.873289 [debug] [MainThread]: Connection 'list_my_db' was properly closed.
[0m10:56:37.875290 [debug] [MainThread]: Connection 'list_my_db_dbo' was properly closed.
[0m10:56:37.876290 [debug] [MainThread]: Connection 'model.dbt_databricks_cicd.stg_ecommerce' was properly closed.
[0m10:56:37.877291 [info ] [MainThread]: 
[0m10:56:37.880294 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 1.53 seconds (1.53s).
[0m10:56:37.884713 [debug] [MainThread]: Command end result
[0m10:56:38.000612 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m10:56:38.006797 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m10:56:38.027924 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m10:56:38.029925 [info ] [MainThread]: 
[0m10:56:38.031928 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:56:38.035929 [info ] [MainThread]: 
[0m10:56:38.038215 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m10:56:38.042219 [debug] [MainThread]: Command `dbt build` succeeded at 10:56:38.042219 after 18.94 seconds
[0m10:56:38.044219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D90C53DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D90EB1090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028D90EB04D0>]}
[0m10:56:38.045218 [debug] [MainThread]: Flushing usage events
[0m10:56:38.882444 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m10:56:53.936943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AB6980710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AB69B8090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AB6675310>]}


============================== 10:56:53.948942 | dd6c0cf3-127c-42e1-9b67-cfd647fc00c0 ==============================
[0m10:56:53.948942 [info ] [MainThread]: Running with dbt=1.10.3
[0m10:56:53.951941 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': 'D:\\Documentos\\Python-SQL\\Projetos\\Projeto DBT Databricks CICD\\logs', 'debug': 'False', 'profiles_dir': 'C:\\Users\\diniz\\.dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt build --target databricks', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m10:56:57.028665 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m10:56:57.028665 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m10:56:57.044284 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m10:57:06.273417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'dd6c0cf3-127c-42e1-9b67-cfd647fc00c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AB698AC90>]}
[0m10:57:06.507790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'dd6c0cf3-127c-42e1-9b67-cfd647fc00c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AB60E9A10>]}
[0m10:57:06.523416 [info ] [MainThread]: Registered adapter: databricks=1.10.4
[0m10:57:08.384014 [debug] [MainThread]: checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, vars: {}, profile: , target: databricks, version: 1.10.3
[0m10:57:08.733298 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m10:57:08.733298 [debug] [MainThread]: previous checksum: 3fbc73d786818920aecb1b2190495121ce0b60768fe54c46d521f1e82da30af9, current checksum: 136566b3e36444f529acd895ee0315ebaa97f244a4cd6a9860c3053f0a594331
[0m10:57:08.733298 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m10:57:08.733298 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m10:57:08.748926 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'dd6c0cf3-127c-42e1-9b67-cfd647fc00c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AC1BD5F50>]}
[0m10:57:18.012472 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_databricks_cicd.mart.sqlserver
[0m10:57:18.075422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dd6c0cf3-127c-42e1-9b67-cfd647fc00c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AC3226510>]}
[0m10:57:18.458244 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m10:57:18.466241 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m10:57:18.584668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dd6c0cf3-127c-42e1-9b67-cfd647fc00c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AC3603FD0>]}
[0m10:57:18.584668 [info ] [MainThread]: Found 9 models, 24 data tests, 1 source, 798 macros
[0m10:57:18.584668 [info ] [MainThread]: 
[0m10:57:18.600293 [info ] [MainThread]: Concurrency: 1 threads (target='databricks')
[0m10:57:18.600293 [info ] [MainThread]: 
[0m10:57:18.600293 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:57:18.600293 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:57:18.631543 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:57:18.631543 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace'
[0m10:57:18.631543 [debug] [ThreadPool]: Using databricks connection "list_workspace"
[0m10:57:18.631543 [debug] [ThreadPool]: On list_workspace: GetSchemas(database=workspace, schema=None)
[0m10:57:18.631543 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:57:19.985530 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f07dcd-9699-126c-a39f-a8988e2d1d31) - Created
[0m10:58:22.850192 [debug] [ThreadPool]: SQL status: OK in 64.220 seconds
[0m10:58:22.850192 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f07dcd-9699-126c-a39f-a8988e2d1d31, command-id=01f07dcd-bac4-1e53-bf1b-eed073e5114e) - Closing
[0m10:58:22.865821 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_workspace_default, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:58:22.865821 [debug] [ThreadPool]: Acquiring new databricks connection 'list_workspace_default'
[0m10:58:22.928323 [debug] [ThreadPool]: Using databricks connection "list_workspace_default"
[0m10:58:22.928323 [debug] [ThreadPool]: On list_workspace_default: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "connection_name": "list_workspace_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'workspace' 
  AND table_schema = 'default'

  
[0m10:58:22.943946 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:58:23.818964 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f07dcd-bcc5-194f-9c77-2c74366d297a) - Created
[0m10:58:28.631960 [debug] [ThreadPool]: SQL status: OK in 5.690 seconds
[0m10:58:28.647584 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f07dcd-bcc5-194f-9c77-2c74366d297a, command-id=01f07dcd-bce7-167f-baac-ed3e005aa7a4) - Closing
[0m10:58:28.913982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dd6c0cf3-127c-42e1-9b67-cfd647fc00c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AC331D190>]}
[0m10:58:28.913982 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.src_ecommerce
[0m10:58:28.929609 [info ] [Thread-1 (]: 1 of 33 START sql view model default.src_ecommerce ............................. [RUN]
[0m10:58:28.929609 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_databricks_cicd.src_ecommerce, idle-time=0s, language=None, compute-name=) - Creating connection
[0m10:58:28.929609 [debug] [Thread-1 (]: Acquiring new databricks connection 'model.dbt_databricks_cicd.src_ecommerce'
[0m10:58:28.929609 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.src_ecommerce
[0m10:58:28.959947 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.src_ecommerce"
[0m10:58:28.959947 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.src_ecommerce
[0m10:58:28.991203 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:58:28.991203 [warn ] [Thread-1 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m10:58:28.991203 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'BehaviorChangeEvent', 'label': 'dd6c0cf3-127c-42e1-9b67-cfd647fc00c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AC36847D0>]}
[0m10:58:29.068300 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`src_ecommerce`
[0m10:58:29.086586 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.src_ecommerce"
[0m10:58:29.086586 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.src_ecommerce"
[0m10:58:29.086586 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.src_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.src_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`src_ecommerce`
  
  as (
    SELECT * FROM default.sales_ecommerce
  )

[0m10:58:29.086586 [debug] [Thread-1 (]: Opening a new connection, currently in state init
[0m10:58:29.836267 [debug] [Thread-1 (]: Databricks adapter: Connection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7) - Created
[0m10:58:33.053530 [debug] [Thread-1 (]: SQL status: OK in 3.970 seconds
[0m10:58:33.053530 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-c07b-110b-af08-216680aa7bdf) - Closing
[0m10:58:33.095310 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:58:33.106577 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd6c0cf3-127c-42e1-9b67-cfd647fc00c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AC364EE90>]}
[0m10:58:33.109582 [info ] [Thread-1 (]: 1 of 33 OK created sql view model default.src_ecommerce ........................ [[32mOK[0m in 4.17s]
[0m10:58:33.112578 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.src_ecommerce
[0m10:58:33.114579 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.stg_ecommerce
[0m10:58:33.117957 [info ] [Thread-1 (]: 2 of 33 START sql view model default.stg_ecommerce ............................. [RUN]
[0m10:58:33.121983 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.src_ecommerce, now model.dbt_databricks_cicd.stg_ecommerce)
[0m10:58:33.123960 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=model.dbt_databricks_cicd.stg_ecommerce, idle-time=0.02238321304321289s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.src_ecommerce
[0m10:58:33.125958 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.stg_ecommerce
[0m10:58:33.132028 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:58:33.132028 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.stg_ecommerce
[0m10:58:33.163285 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:58:33.163285 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`stg_ecommerce`
[0m10:58:33.178904 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:58:33.178904 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.stg_ecommerce"
[0m10:58:33.178904 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.stg_ecommerce: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.stg_ecommerce"} */

  
  
  
  create or replace view `workspace`.`default`.`stg_ecommerce`
  
  as (
    SELECT
  User_ID,
  Product_ID,
  Category,
  Price,
  Discount,
  Final_Price,
  Payment_Method,
  Purchase_Date
FROM `workspace`.`default`.`src_ecommerce`
  )

[0m10:58:34.296546 [debug] [Thread-1 (]: SQL status: OK in 1.120 seconds
[0m10:58:34.296546 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-c27d-1254-8dc6-0d0d9292f22f) - Closing
[0m10:58:34.296546 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:58:34.296546 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd6c0cf3-127c-42e1-9b67-cfd647fc00c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AC36BB410>]}
[0m10:58:34.296546 [info ] [Thread-1 (]: 2 of 33 OK created sql view model default.stg_ecommerce ........................ [[32mOK[0m in 1.18s]
[0m10:58:34.312165 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.stg_ecommerce
[0m10:58:34.312165 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_discount_by_category
[0m10:58:34.312165 [info ] [Thread-1 (]: 3 of 33 START sql view model default.avg_discount_by_category .................. [RUN]
[0m10:58:34.312165 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.stg_ecommerce, now model.dbt_databricks_cicd.avg_discount_by_category)
[0m10:58:34.327792 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=model.dbt_databricks_cicd.avg_discount_by_category, idle-time=0.031245946884155273s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.stg_ecommerce
[0m10:58:34.331864 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_discount_by_category
[0m10:58:34.350317 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m10:58:34.351420 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_discount_by_category
[0m10:58:34.367046 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:58:34.367046 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`avg_discount_by_category`
[0m10:58:34.367046 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_discount_by_category"
[0m10:58:34.367046 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.avg_discount_by_category"
[0m10:58:34.382669 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_discount_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.avg_discount_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`avg_discount_by_category`
  
  as (
    SELECT
  Category,
  ROUND(AVG(CAST(`Discount` AS DOUBLE)), 2) AS avg_discount_percent
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY avg_discount_percent DESC
  )

[0m10:58:35.398023 [debug] [Thread-1 (]: SQL status: OK in 1.020 seconds
[0m10:58:35.398023 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-c330-1fed-81c1-1ed9a019dcc7) - Closing
[0m10:58:35.413649 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:58:35.413649 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd6c0cf3-127c-42e1-9b67-cfd647fc00c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AC36A0710>]}
[0m10:58:35.413649 [info ] [Thread-1 (]: 3 of 33 OK created sql view model default.avg_discount_by_category ............. [[32mOK[0m in 1.10s]
[0m10:58:35.413649 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_discount_by_category
[0m10:58:35.413649 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:58:35.413649 [info ] [Thread-1 (]: 4 of 33 START sql view model default.avg_ticket_by_category .................... [RUN]
[0m10:58:35.429273 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_discount_by_category, now model.dbt_databricks_cicd.avg_ticket_by_category)
[0m10:58:35.429273 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=model.dbt_databricks_cicd.avg_ticket_by_category, idle-time=0.015623331069946289s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.avg_discount_by_category
[0m10:58:35.429273 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:58:35.453302 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m10:58:35.456321 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:58:35.461655 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:58:35.461655 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`avg_ticket_by_category`
[0m10:58:35.461655 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m10:58:35.477284 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.avg_ticket_by_category"
[0m10:58:35.477284 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.avg_ticket_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.avg_ticket_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`avg_ticket_by_category`
  
  as (
    SELECT
  Category,
  ROUND(AVG(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS avg_ticket
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY avg_ticket DESC
  )

[0m10:58:36.251660 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m10:58:36.255664 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-c3d7-1781-bb23-03d10789ba8d) - Closing
[0m10:58:36.258662 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:58:36.262665 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd6c0cf3-127c-42e1-9b67-cfd647fc00c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AC3610E90>]}
[0m10:58:36.265661 [info ] [Thread-1 (]: 4 of 33 OK created sql view model default.avg_ticket_by_category ............... [[32mOK[0m in 0.83s]
[0m10:58:36.269662 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:58:36.273665 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.monthly_revenue
[0m10:58:36.276662 [info ] [Thread-1 (]: 5 of 33 START sql view model default.monthly_revenue ........................... [RUN]
[0m10:58:36.279663 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.avg_ticket_by_category, now model.dbt_databricks_cicd.monthly_revenue)
[0m10:58:36.282664 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=model.dbt_databricks_cicd.monthly_revenue, idle-time=0.018999099731445312s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.avg_ticket_by_category
[0m10:58:36.284663 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.monthly_revenue
[0m10:58:36.301659 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.monthly_revenue"
[0m10:58:36.305664 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.monthly_revenue
[0m10:58:36.320662 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:58:36.324661 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`monthly_revenue`
[0m10:58:36.328668 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.monthly_revenue"
[0m10:58:36.331680 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.monthly_revenue"
[0m10:58:36.334660 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.monthly_revenue: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.monthly_revenue"} */

  
  
  
  create or replace view `workspace`.`default`.`monthly_revenue`
  
  as (
    SELECT
  CAST(DATE_TRUNC('month', CAST(Purchase_Date AS DATE)) AS DATE) AS month,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS monthly_revenue
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY 1
ORDER BY 1
  )

[0m10:58:37.070577 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m10:58:37.070577 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-c45c-1c45-a7d8-58b9d4f4ef66) - Closing
[0m10:58:37.070577 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:58:37.070577 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd6c0cf3-127c-42e1-9b67-cfd647fc00c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AC362CF10>]}
[0m10:58:37.086205 [info ] [Thread-1 (]: 5 of 33 OK created sql view model default.monthly_revenue ...................... [[32mOK[0m in 0.79s]
[0m10:58:37.086205 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.monthly_revenue
[0m10:58:37.086205 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.payment_distribution
[0m10:58:37.086205 [info ] [Thread-1 (]: 6 of 33 START sql view model default.payment_distribution ...................... [RUN]
[0m10:58:37.086205 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.monthly_revenue, now model.dbt_databricks_cicd.payment_distribution)
[0m10:58:37.086205 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=model.dbt_databricks_cicd.payment_distribution, idle-time=0.01562809944152832s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.monthly_revenue
[0m10:58:37.101830 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.payment_distribution
[0m10:58:37.101830 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.payment_distribution"
[0m10:58:37.117454 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.payment_distribution
[0m10:58:37.128891 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:58:37.134253 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`payment_distribution`
[0m10:58:37.134253 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.payment_distribution"
[0m10:58:37.134253 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.payment_distribution"
[0m10:58:37.134253 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.payment_distribution: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.payment_distribution"} */

  
  
  
  create or replace view `workspace`.`default`.`payment_distribution`
  
  as (
    SELECT
  Payment_Method,
  COUNT(*) AS total_transactions,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_value
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Payment_Method
ORDER BY total_value DESC
  )

[0m10:58:37.850481 [debug] [Thread-1 (]: SQL status: OK in 0.720 seconds
[0m10:58:37.850481 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-c4d5-18ff-bd1d-f977a972a01f) - Closing
[0m10:58:37.850481 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:58:37.850481 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd6c0cf3-127c-42e1-9b67-cfd647fc00c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AB63F7D90>]}
[0m10:58:37.866067 [info ] [Thread-1 (]: 6 of 33 OK created sql view model default.payment_distribution ................. [[32mOK[0m in 0.76s]
[0m10:58:37.866067 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.payment_distribution
[0m10:58:37.866067 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.sales_by_category
[0m10:58:37.866067 [info ] [Thread-1 (]: 7 of 33 START sql view model default.sales_by_category ......................... [RUN]
[0m10:58:37.866067 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.payment_distribution, now model.dbt_databricks_cicd.sales_by_category)
[0m10:58:37.881692 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=model.dbt_databricks_cicd.sales_by_category, idle-time=0.031211137771606445s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.payment_distribution
[0m10:58:37.881692 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.sales_by_category
[0m10:58:37.897314 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.sales_by_category"
[0m10:58:37.897314 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.sales_by_category
[0m10:58:37.913014 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:58:37.913014 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`sales_by_category`
[0m10:58:37.913014 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.sales_by_category"
[0m10:58:37.913014 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.sales_by_category"
[0m10:58:37.913014 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.sales_by_category: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.sales_by_category"} */

  
  
  
  create or replace view `workspace`.`default`.`sales_by_category`
  
  as (
    SELECT
  Category,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_revenue
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY Category
ORDER BY total_revenue DESC
  )

[0m10:58:38.694756 [debug] [Thread-1 (]: SQL status: OK in 0.780 seconds
[0m10:58:38.694756 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-c54c-1fb0-9219-544e0f4aafc0) - Closing
[0m10:58:38.710355 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:58:38.710355 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd6c0cf3-127c-42e1-9b67-cfd647fc00c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AC32D4490>]}
[0m10:58:38.710355 [info ] [Thread-1 (]: 7 of 33 OK created sql view model default.sales_by_category .................... [[32mOK[0m in 0.84s]
[0m10:58:38.710355 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.sales_by_category
[0m10:58:38.710355 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_5_products
[0m10:58:38.725979 [info ] [Thread-1 (]: 8 of 33 START sql view model default.top_5_products ............................ [RUN]
[0m10:58:38.725979 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.sales_by_category, now model.dbt_databricks_cicd.top_5_products)
[0m10:58:38.725979 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=model.dbt_databricks_cicd.top_5_products, idle-time=0.015623092651367188s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.sales_by_category
[0m10:58:38.725979 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_5_products
[0m10:58:38.741608 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_5_products"
[0m10:58:38.741608 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_5_products
[0m10:58:38.757227 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:58:38.757227 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`top_5_products`
[0m10:58:38.757227 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_5_products"
[0m10:58:38.757227 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.top_5_products"
[0m10:58:38.757227 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_5_products: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.top_5_products"} */

  
  
  
  create or replace view `workspace`.`default`.`top_5_products`
  
  as (
    WITH base AS (
    SELECT
        product_id,
        ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_sales
    FROM `workspace`.`default`.`stg_ecommerce`
    GROUP BY product_id
)

SELECT
    product_id,
    total_sales
FROM base
ORDER BY total_sales DESC
LIMIT 5
  )

[0m10:58:39.476572 [debug] [Thread-1 (]: SQL status: OK in 0.720 seconds
[0m10:58:39.476572 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-c5cd-1fcc-b765-41eea869ee05) - Closing
[0m10:58:39.476572 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:58:39.476572 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd6c0cf3-127c-42e1-9b67-cfd647fc00c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AC36CE650>]}
[0m10:58:39.476572 [info ] [Thread-1 (]: 8 of 33 OK created sql view model default.top_5_products ....................... [[32mOK[0m in 0.75s]
[0m10:58:39.492199 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_5_products
[0m10:58:39.492199 [debug] [Thread-1 (]: Began running node model.dbt_databricks_cicd.top_customers
[0m10:58:39.492199 [info ] [Thread-1 (]: 9 of 33 START sql view model default.top_customers ............................. [RUN]
[0m10:58:39.492199 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_5_products, now model.dbt_databricks_cicd.top_customers)
[0m10:58:39.492199 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=model.dbt_databricks_cicd.top_customers, idle-time=0.01562666893005371s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.top_5_products
[0m10:58:39.492199 [debug] [Thread-1 (]: Began compiling node model.dbt_databricks_cicd.top_customers
[0m10:58:39.523447 [debug] [Thread-1 (]: Writing injected SQL for node "model.dbt_databricks_cicd.top_customers"
[0m10:58:39.523447 [debug] [Thread-1 (]: Began executing node model.dbt_databricks_cicd.top_customers
[0m10:58:39.539076 [debug] [Thread-1 (]: MATERIALIZING VIEW
[0m10:58:39.539076 [debug] [Thread-1 (]: Creating view `workspace`.`default`.`top_customers`
[0m10:58:39.539076 [debug] [Thread-1 (]: Writing runtime sql for node "model.dbt_databricks_cicd.top_customers"
[0m10:58:39.539076 [debug] [Thread-1 (]: Using databricks connection "model.dbt_databricks_cicd.top_customers"
[0m10:58:39.539076 [debug] [Thread-1 (]: On model.dbt_databricks_cicd.top_customers: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "model.dbt_databricks_cicd.top_customers"} */

  
  
  
  create or replace view `workspace`.`default`.`top_customers`
  
  as (
    SELECT
  User_ID,
  COUNT(*) AS total_orders,
  ROUND(SUM(CAST(REPLACE(`Final_Price`, ',', '.') AS DOUBLE)), 2) AS total_spent
FROM `workspace`.`default`.`stg_ecommerce`
GROUP BY User_ID
ORDER BY total_spent DESC
LIMIT 10
  )

[0m10:58:40.265561 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m10:58:40.269851 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-c644-1c72-ab95-9266ca293cff) - Closing
[0m10:58:40.272133 [debug] [Thread-1 (]: Applying tags to relation None
[0m10:58:40.275828 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dd6c0cf3-127c-42e1-9b67-cfd647fc00c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AB63DA950>]}
[0m10:58:40.275828 [info ] [Thread-1 (]: 9 of 33 OK created sql view model default.top_customers ........................ [[32mOK[0m in 0.78s]
[0m10:58:40.275828 [debug] [Thread-1 (]: Finished running node model.dbt_databricks_cicd.top_customers
[0m10:58:40.275828 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:58:40.275828 [info ] [Thread-1 (]: 10 of 33 START test non_negative_avg_discount_by_category_avg_discount_percent . [RUN]
[0m10:58:40.275828 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.dbt_databricks_cicd.top_customers, now test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f)
[0m10:58:40.275828 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named model.dbt_databricks_cicd.top_customers
[0m10:58:40.291455 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:58:40.291455 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"
[0m10:58:40.291455 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:58:40.351004 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"
[0m10:58:40.366619 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"
[0m10:58:40.366619 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`avg_discount_by_category`
where TRY_CAST(REPLACE(avg_discount_percent, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:58:41.711382 [debug] [Thread-1 (]: SQL status: OK in 1.340 seconds
[0m10:58:41.711382 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-c6c2-162d-b1b2-71aa2503d738) - Closing
[0m10:58:41.731006 [info ] [Thread-1 (]: 10 of 33 PASS non_negative_avg_discount_by_category_avg_discount_percent ....... [[32mPASS[0m in 1.46s]
[0m10:58:41.734998 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:58:41.738998 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:58:41.741016 [info ] [Thread-1 (]: 11 of 33 START test not_null_avg_discount_by_category_Category ................. [RUN]
[0m10:58:41.744695 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b)
[0m10:58:41.747702 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, idle-time=0.016695499420166016s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_avg_discount_by_category_avg_discount_percent.c2755bf97f
[0m10:58:41.749692 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:58:41.759955 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m10:58:41.759955 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:58:41.775631 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m10:58:41.775631 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"
[0m10:58:41.791208 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_discount_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m10:58:42.516303 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m10:58:42.521297 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-c79b-1053-a1f0-ccae2fc7c255) - Closing
[0m10:58:42.523676 [info ] [Thread-1 (]: 11 of 33 PASS not_null_avg_discount_by_category_Category ....................... [[32mPASS[0m in 0.78s]
[0m10:58:42.523676 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:58:42.523676 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:58:42.523676 [info ] [Thread-1 (]: 12 of 33 START test not_null_avg_discount_by_category_avg_discount_percent ..... [RUN]
[0m10:58:42.523676 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b, now test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101)
[0m10:58:42.523676 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_Category.237c8c010b
[0m10:58:42.539302 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:58:42.554931 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m10:58:42.554931 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:58:42.570551 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m10:58:42.570551 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"
[0m10:58:42.570551 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_discount_percent
from `workspace`.`default`.`avg_discount_by_category`
where avg_discount_percent is null



  
  
      
    ) dbt_internal_test
[0m10:58:43.413323 [debug] [Thread-1 (]: SQL status: OK in 0.840 seconds
[0m10:58:43.413323 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-c813-1c43-aad0-d8b5c5f33d44) - Closing
[0m10:58:43.428909 [info ] [Thread-1 (]: 12 of 33 PASS not_null_avg_discount_by_category_avg_discount_percent ........... [[32mPASS[0m in 0.89s]
[0m10:58:43.428909 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:58:43.428909 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:58:43.428909 [info ] [Thread-1 (]: 13 of 33 START test non_negative_avg_ticket_by_category_avg_ticket ............. [RUN]
[0m10:58:43.428909 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101, now test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095)
[0m10:58:43.428909 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095, idle-time=0.015585660934448242s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_discount_by_category_avg_discount_percent.622396a101
[0m10:58:43.444531 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:58:43.460156 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"
[0m10:58:43.460156 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:58:43.475784 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"
[0m10:58:43.475784 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"
[0m10:58:43.475784 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`avg_ticket_by_category`
where TRY_CAST(REPLACE(avg_ticket, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:58:44.272572 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m10:58:44.288194 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-c89d-1e20-b4cb-1b032f57fd26) - Closing
[0m10:58:44.288194 [info ] [Thread-1 (]: 13 of 33 PASS non_negative_avg_ticket_by_category_avg_ticket ................... [[32mPASS[0m in 0.86s]
[0m10:58:44.288194 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:58:44.288194 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:58:44.288194 [info ] [Thread-1 (]: 14 of 33 START test not_null_avg_ticket_by_category_Category ................... [RUN]
[0m10:58:44.288194 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f)
[0m10:58:44.303817 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, idle-time=0.015622615814208984s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_avg_ticket_by_category_avg_ticket.6ca601b095
[0m10:58:44.303817 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:58:44.303817 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m10:58:44.319446 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:58:44.319446 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m10:58:44.319446 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"
[0m10:58:44.319446 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`avg_ticket_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m10:58:45.023403 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m10:58:45.027786 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-c91e-11ee-bdb6-9e2346f44019) - Closing
[0m10:58:45.030784 [info ] [Thread-1 (]: 14 of 33 PASS not_null_avg_ticket_by_category_Category ......................... [[32mPASS[0m in 0.74s]
[0m10:58:45.033778 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:58:45.036783 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:58:45.040121 [info ] [Thread-1 (]: 15 of 33 START test not_null_avg_ticket_by_category_avg_ticket ................. [RUN]
[0m10:58:45.040121 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f, now test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41)
[0m10:58:45.040121 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, idle-time=0.010339021682739258s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_Category.e0cd76451f
[0m10:58:45.040121 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:58:45.055748 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m10:58:45.055748 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:58:45.055748 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m10:58:45.071375 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"
[0m10:58:45.071375 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select avg_ticket
from `workspace`.`default`.`avg_ticket_by_category`
where avg_ticket is null



  
  
      
    ) dbt_internal_test
[0m10:58:45.804046 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m10:58:45.804046 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-c991-13da-a982-cce87a87ce47) - Closing
[0m10:58:45.804046 [info ] [Thread-1 (]: 15 of 33 PASS not_null_avg_ticket_by_category_avg_ticket ....................... [[32mPASS[0m in 0.76s]
[0m10:58:45.819668 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:58:45.819668 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:58:45.826264 [info ] [Thread-1 (]: 16 of 33 START test non_negative_monthly_revenue_monthly_revenue ............... [RUN]
[0m10:58:45.829261 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41, now test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294)
[0m10:58:45.831262 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294, idle-time=0.027215242385864258s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_avg_ticket_by_category_avg_ticket.68d6992a41
[0m10:58:45.833261 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:58:45.840261 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"
[0m10:58:45.840261 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:58:45.855888 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"
[0m10:58:45.855888 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"
[0m10:58:45.855888 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`monthly_revenue`
where TRY_CAST(REPLACE(monthly_revenue, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:58:46.647128 [debug] [Thread-1 (]: SQL status: OK in 0.780 seconds
[0m10:58:46.647128 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-ca09-18ec-ba7a-65a559152cc6) - Closing
[0m10:58:46.662696 [info ] [Thread-1 (]: 16 of 33 PASS non_negative_monthly_revenue_monthly_revenue ..................... [[32mPASS[0m in 0.83s]
[0m10:58:46.662696 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:58:46.662696 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:58:46.662696 [info ] [Thread-1 (]: 17 of 33 START test not_null_monthly_revenue_month ............................. [RUN]
[0m10:58:46.662696 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294, now test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b)
[0m10:58:46.662696 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_monthly_revenue_monthly_revenue.68b6895294
[0m10:58:46.679101 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:58:46.695105 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m10:58:46.698099 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:58:46.705101 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m10:58:46.707099 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"
[0m10:58:46.709099 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select month
from `workspace`.`default`.`monthly_revenue`
where month is null



  
  
      
    ) dbt_internal_test
[0m10:58:47.506636 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m10:58:47.506636 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-ca89-1b69-be52-3a8588dd0f66) - Closing
[0m10:58:47.506636 [info ] [Thread-1 (]: 17 of 33 PASS not_null_monthly_revenue_month ................................... [[32mPASS[0m in 0.84s]
[0m10:58:47.522269 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:58:47.522269 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:58:47.522269 [info ] [Thread-1 (]: 18 of 33 START test not_null_monthly_revenue_monthly_revenue ................... [RUN]
[0m10:58:47.522269 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b, now test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b)
[0m10:58:47.522269 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, idle-time=0.015633344650268555s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_month.ee51ac609b
[0m10:58:47.522269 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:58:47.537893 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m10:58:47.537893 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:58:47.537893 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m10:58:47.537893 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"
[0m10:58:47.553547 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select monthly_revenue
from `workspace`.`default`.`monthly_revenue`
where monthly_revenue is null



  
  
      
    ) dbt_internal_test
[0m10:58:48.241132 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m10:58:48.241132 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-cb0a-1530-89ce-133c45a2d7db) - Closing
[0m10:58:48.256764 [info ] [Thread-1 (]: 18 of 33 PASS not_null_monthly_revenue_monthly_revenue ......................... [[32mPASS[0m in 0.73s]
[0m10:58:48.256764 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:58:48.256764 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:58:48.256764 [info ] [Thread-1 (]: 19 of 33 START test non_negative_payment_distribution_total_value .............. [RUN]
[0m10:58:48.272384 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b, now test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282)
[0m10:58:48.272384 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282, idle-time=0.015619993209838867s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_monthly_revenue_monthly_revenue.02fcba701b
[0m10:58:48.272384 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:58:48.288012 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"
[0m10:58:48.288012 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:58:48.288012 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"
[0m10:58:48.303632 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"
[0m10:58:48.303632 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`payment_distribution`
where TRY_CAST(REPLACE(total_value, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:58:49.054794 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m10:58:49.070422 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-cb7d-11f2-86a6-9488fd0e0667) - Closing
[0m10:58:49.070422 [info ] [Thread-1 (]: 19 of 33 PASS non_negative_payment_distribution_total_value .................... [[32mPASS[0m in 0.80s]
[0m10:58:49.070422 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:58:49.070422 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:58:49.070422 [info ] [Thread-1 (]: 20 of 33 START test not_null_payment_distribution_Payment_Method ............... [RUN]
[0m10:58:49.086045 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282, now test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae)
[0m10:58:49.086045 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, idle-time=0.015622854232788086s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_payment_distribution_total_value.c4ae109282
[0m10:58:49.086045 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:58:49.086045 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m10:58:49.104515 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:58:49.115508 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m10:58:49.119745 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"
[0m10:58:49.119745 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Payment_Method
from `workspace`.`default`.`payment_distribution`
where Payment_Method is null



  
  
      
    ) dbt_internal_test
[0m10:58:49.897392 [debug] [Thread-1 (]: SQL status: OK in 0.780 seconds
[0m10:58:49.913014 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-cbfa-1c63-982d-36df9b121d2b) - Closing
[0m10:58:49.913014 [info ] [Thread-1 (]: 20 of 33 PASS not_null_payment_distribution_Payment_Method ..................... [[32mPASS[0m in 0.84s]
[0m10:58:49.913014 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:58:49.913014 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:58:49.928638 [info ] [Thread-1 (]: 21 of 33 START test not_null_payment_distribution_total_transactions ........... [RUN]
[0m10:58:49.928638 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae, now test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8)
[0m10:58:49.928638 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, idle-time=0.015624284744262695s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_Payment_Method.bd80df3cae
[0m10:58:49.928638 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:58:49.944265 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m10:58:49.944265 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:58:49.959904 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m10:58:49.959904 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"
[0m10:58:49.975515 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_transactions
from `workspace`.`default`.`payment_distribution`
where total_transactions is null



  
  
      
    ) dbt_internal_test
[0m10:58:50.615767 [debug] [Thread-1 (]: SQL status: OK in 0.640 seconds
[0m10:58:50.631400 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-cc7c-1390-aa11-0fadd4feb744) - Closing
[0m10:58:50.631400 [info ] [Thread-1 (]: 21 of 33 PASS not_null_payment_distribution_total_transactions ................. [[32mPASS[0m in 0.70s]
[0m10:58:50.631400 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:58:50.631400 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:58:50.631400 [info ] [Thread-1 (]: 22 of 33 START test not_null_payment_distribution_total_value .................. [RUN]
[0m10:58:50.631400 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8, now test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03)
[0m10:58:50.631400 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_transactions.928411e2e8
[0m10:58:50.647022 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:58:50.662646 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m10:58:50.662646 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:58:50.678273 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m10:58:50.678273 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"
[0m10:58:50.678273 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_value
from `workspace`.`default`.`payment_distribution`
where total_value is null



  
  
      
    ) dbt_internal_test
[0m10:58:51.445273 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m10:58:51.460792 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-cce8-1241-958a-bb009d8b8545) - Closing
[0m10:58:51.460792 [info ] [Thread-1 (]: 22 of 33 PASS not_null_payment_distribution_total_value ........................ [[32mPASS[0m in 0.83s]
[0m10:58:51.460792 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:58:51.460792 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:58:51.460792 [info ] [Thread-1 (]: 23 of 33 START test non_negative_sales_by_category_total_revenue ............... [RUN]
[0m10:58:51.460792 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03, now test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41)
[0m10:58:51.460792 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_payment_distribution_total_value.58135f5f03
[0m10:58:51.460792 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:58:51.485805 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"
[0m10:58:51.487775 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:58:51.490839 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"
[0m10:58:51.490839 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"
[0m10:58:51.490839 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`sales_by_category`
where TRY_CAST(REPLACE(total_revenue, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:58:52.288298 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m10:58:52.288298 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-cd63-1d67-9116-9fb6c0c919b1) - Closing
[0m10:58:52.303801 [info ] [Thread-1 (]: 23 of 33 PASS non_negative_sales_by_category_total_revenue ..................... [[32mPASS[0m in 0.84s]
[0m10:58:52.303801 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:58:52.303801 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:58:52.303801 [info ] [Thread-1 (]: 24 of 33 START test not_null_sales_by_category_Category ........................ [RUN]
[0m10:58:52.303801 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41, now test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507)
[0m10:58:52.303801 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_sales_by_category_total_revenue.8ad171ef41
[0m10:58:52.303801 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:58:52.325783 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m10:58:52.327740 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:58:52.336038 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m10:58:52.338040 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"
[0m10:58:52.339041 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select Category
from `workspace`.`default`.`sales_by_category`
where Category is null



  
  
      
    ) dbt_internal_test
[0m10:58:53.085970 [debug] [Thread-1 (]: SQL status: OK in 0.750 seconds
[0m10:58:53.101592 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-cde4-110a-8798-43f68162e8f3) - Closing
[0m10:58:53.101592 [info ] [Thread-1 (]: 24 of 33 PASS not_null_sales_by_category_Category .............................. [[32mPASS[0m in 0.80s]
[0m10:58:53.101592 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:58:53.101592 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:58:53.101592 [info ] [Thread-1 (]: 25 of 33 START test not_null_sales_by_category_total_orders .................... [RUN]
[0m10:58:53.117220 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507, now test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e)
[0m10:58:53.117220 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, idle-time=0.01562786102294922s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_Category.e69cdf4507
[0m10:58:53.117220 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:58:53.132843 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m10:58:53.148507 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:58:53.210966 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m10:58:53.210966 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"
[0m10:58:53.210966 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`sales_by_category`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m10:58:53.914093 [debug] [Thread-1 (]: SQL status: OK in 0.690 seconds
[0m10:58:53.929716 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-ce6b-1ef3-ba68-87ed45077465) - Closing
[0m10:58:53.929716 [info ] [Thread-1 (]: 25 of 33 PASS not_null_sales_by_category_total_orders .......................... [[32mPASS[0m in 0.81s]
[0m10:58:53.929716 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:58:53.929716 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:58:53.945343 [info ] [Thread-1 (]: 26 of 33 START test not_null_sales_by_category_total_revenue ................... [RUN]
[0m10:58:53.945343 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e, now test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd)
[0m10:58:53.945343 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, idle-time=0.015627384185791016s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_orders.024c423e1e
[0m10:58:53.945343 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:58:53.976595 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m10:58:53.976595 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:58:53.992216 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m10:58:54.023469 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"
[0m10:58:54.023469 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_revenue
from `workspace`.`default`.`sales_by_category`
where total_revenue is null



  
  
      
    ) dbt_internal_test
[0m10:58:54.773468 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m10:58:54.789096 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-cee8-1ac0-9860-74158bc2e9c8) - Closing
[0m10:58:54.789096 [info ] [Thread-1 (]: 26 of 33 PASS not_null_sales_by_category_total_revenue ......................... [[32mPASS[0m in 0.84s]
[0m10:58:54.789096 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:58:54.804719 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:58:54.804719 [info ] [Thread-1 (]: 27 of 33 START test non_negative_top_5_products_total_sales .................... [RUN]
[0m10:58:54.804719 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd, now test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34)
[0m10:58:54.804719 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34, idle-time=0.015623807907104492s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_sales_by_category_total_revenue.fb1162affd
[0m10:58:54.804719 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:58:54.835975 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"
[0m10:58:54.835975 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:58:54.851592 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"
[0m10:58:54.851592 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"
[0m10:58:54.851592 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`top_5_products`
where TRY_CAST(REPLACE(total_sales, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:58:55.593678 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m10:58:55.600676 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-cf66-1629-afc0-444fbbf7c825) - Closing
[0m10:58:55.603675 [info ] [Thread-1 (]: 27 of 33 PASS non_negative_top_5_products_total_sales .......................... [[32mPASS[0m in 0.80s]
[0m10:58:55.607675 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:58:55.611678 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:58:55.613677 [info ] [Thread-1 (]: 28 of 33 START test not_null_top_5_products_product_id ......................... [RUN]
[0m10:58:55.616678 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34, now test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe)
[0m10:58:55.619681 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, idle-time=0.0160064697265625s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_top_5_products_total_sales.b51b2dea34
[0m10:58:55.621676 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:58:55.642824 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m10:58:55.646823 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:58:55.662006 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m10:58:55.665010 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"
[0m10:58:55.667007 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select product_id
from `workspace`.`default`.`top_5_products`
where product_id is null



  
  
      
    ) dbt_internal_test
[0m10:58:56.398116 [debug] [Thread-1 (]: SQL status: OK in 0.730 seconds
[0m10:58:56.413780 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-cfe0-148c-9e3a-653afe1de11d) - Closing
[0m10:58:56.413780 [info ] [Thread-1 (]: 28 of 33 PASS not_null_top_5_products_product_id ............................... [[32mPASS[0m in 0.80s]
[0m10:58:56.413780 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:58:56.413780 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:58:56.413780 [info ] [Thread-1 (]: 29 of 33 START test not_null_top_5_products_total_sales ........................ [RUN]
[0m10:58:56.413780 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe, now test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818)
[0m10:58:56.413780 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, idle-time=0.0s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_product_id.c6ac160bfe
[0m10:58:56.429412 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:58:56.429412 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m10:58:56.429412 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:58:56.445009 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m10:58:56.445009 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"
[0m10:58:56.445009 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_sales
from `workspace`.`default`.`top_5_products`
where total_sales is null



  
  
      
    ) dbt_internal_test
[0m10:58:57.241404 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m10:58:57.241404 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-d058-1b19-b1f9-80986685afb9) - Closing
[0m10:58:57.257035 [info ] [Thread-1 (]: 29 of 33 PASS not_null_top_5_products_total_sales .............................. [[32mPASS[0m in 0.83s]
[0m10:58:57.259846 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:58:57.260846 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:58:57.261846 [info ] [Thread-1 (]: 30 of 33 START test non_negative_top_customers_total_spent ..................... [RUN]
[0m10:58:57.264122 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818, now test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667)
[0m10:58:57.266191 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667, idle-time=0.023769617080688477s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_5_products_total_sales.e20b869818
[0m10:58:57.267159 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:58:57.273277 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"
[0m10:58:57.273277 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:58:57.273277 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"
[0m10:58:57.273277 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"
[0m10:58:57.288907 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
select *
from `workspace`.`default`.`top_customers`
where TRY_CAST(REPLACE(total_spent, ',', '.') AS DOUBLE) < 0

  
  
      
    ) dbt_internal_test
[0m10:58:58.086349 [debug] [Thread-1 (]: SQL status: OK in 0.800 seconds
[0m10:58:58.086349 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-d0d8-1511-aeaa-7ae6e2c9856a) - Closing
[0m10:58:58.086349 [info ] [Thread-1 (]: 30 of 33 PASS non_negative_top_customers_total_spent ........................... [[32mPASS[0m in 0.82s]
[0m10:58:58.101833 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:58:58.101833 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:58:58.101833 [info ] [Thread-1 (]: 31 of 33 START test not_null_top_customers_User_ID ............................. [RUN]
[0m10:58:58.101833 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667, now test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0)
[0m10:58:58.101833 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, idle-time=0.015485048294067383s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.non_negative_top_customers_total_spent.38e4f29667
[0m10:58:58.101833 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:58:58.117494 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m10:58:58.117494 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:58:58.117494 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m10:58:58.117494 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"
[0m10:58:58.117494 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select User_ID
from `workspace`.`default`.`top_customers`
where User_ID is null



  
  
      
    ) dbt_internal_test
[0m10:58:59.131802 [debug] [Thread-1 (]: SQL status: OK in 1.000 seconds
[0m10:58:59.147433 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-d158-1d53-ad09-5c3d056d39ef) - Closing
[0m10:58:59.147433 [info ] [Thread-1 (]: 31 of 33 PASS not_null_top_customers_User_ID ................................... [[32mPASS[0m in 1.05s]
[0m10:58:59.147433 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:58:59.147433 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:58:59.147433 [info ] [Thread-1 (]: 32 of 33 START test not_null_top_customers_total_orders ........................ [RUN]
[0m10:58:59.147433 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0, now test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746)
[0m10:58:59.163051 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, idle-time=0.015618562698364258s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_User_ID.7df96963c0
[0m10:58:59.163051 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:58:59.178676 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m10:58:59.178676 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:58:59.194302 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m10:58:59.194302 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"
[0m10:58:59.194302 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_orders
from `workspace`.`default`.`top_customers`
where total_orders is null



  
  
      
    ) dbt_internal_test
[0m10:58:59.960468 [debug] [Thread-1 (]: SQL status: OK in 0.770 seconds
[0m10:58:59.960468 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-d1fb-1b00-bef6-f65afbdd5508) - Closing
[0m10:58:59.960468 [info ] [Thread-1 (]: 32 of 33 PASS not_null_top_customers_total_orders .............................. [[32mPASS[0m in 0.81s]
[0m10:58:59.960468 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:58:59.960468 [debug] [Thread-1 (]: Began running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m10:58:59.960468 [info ] [Thread-1 (]: 33 of 33 START test not_null_top_customers_total_spent ......................... [RUN]
[0m10:58:59.976058 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746, now test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73)
[0m10:58:59.976058 [debug] [Thread-1 (]: Databricks adapter: DatabricksDBTConnection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, name=test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73, idle-time=0.015589237213134766s, language=sql, compute-name=) - Reusing connection previously named test.dbt_databricks_cicd.not_null_top_customers_total_orders.32b439c746
[0m10:58:59.976058 [debug] [Thread-1 (]: Began compiling node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m10:58:59.976058 [debug] [Thread-1 (]: Writing injected SQL for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m10:58:59.976058 [debug] [Thread-1 (]: Began executing node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m10:58:59.997317 [debug] [Thread-1 (]: Writing runtime sql for node "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m10:58:59.999307 [debug] [Thread-1 (]: Using databricks connection "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"
[0m10:59:00.000285 [debug] [Thread-1 (]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: /* {"app": "dbt", "dbt_version": "1.10.3", "dbt_databricks_version": "1.10.4", "databricks_sql_connector_version": "4.0.5", "profile_name": "dbt_databricks_cicd", "target_name": "databricks", "node_id": "test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select total_spent
from `workspace`.`default`.`top_customers`
where total_spent is null



  
  
      
    ) dbt_internal_test
[0m10:59:00.647246 [debug] [Thread-1 (]: SQL status: OK in 0.650 seconds
[0m10:59:00.647246 [debug] [Thread-1 (]: Databricks adapter: Cursor(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7, command-id=01f07dcd-d275-10e5-9c48-82377a8629ef) - Closing
[0m10:59:00.647246 [info ] [Thread-1 (]: 33 of 33 PASS not_null_top_customers_total_spent ............................... [[32mPASS[0m in 0.67s]
[0m10:59:00.647246 [debug] [Thread-1 (]: Finished running node test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73
[0m10:59:00.662841 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master, idle-time=31.748859167099s, language=None, compute-name=) - Reusing connection previously named master
[0m10:59:00.662841 [debug] [MainThread]: Connection 'master' was properly closed.
[0m10:59:00.662841 [debug] [MainThread]: Connection 'list_workspace' was properly closed.
[0m10:59:00.662841 [debug] [MainThread]: On list_workspace: Close
[0m10:59:00.662841 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07dcd-9699-126c-a39f-a8988e2d1d31) - Closing
[0m10:59:00.882979 [debug] [MainThread]: Connection 'list_workspace_default' was properly closed.
[0m10:59:00.882979 [debug] [MainThread]: On list_workspace_default: Close
[0m10:59:00.882979 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07dcd-bcc5-194f-9c77-2c74366d297a) - Closing
[0m10:59:01.101461 [debug] [MainThread]: Connection 'test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73' was properly closed.
[0m10:59:01.101461 [debug] [MainThread]: On test.dbt_databricks_cicd.not_null_top_customers_total_spent.426b0eae73: Close
[0m10:59:01.101461 [debug] [MainThread]: Databricks adapter: Connection(session-id=01f07dcd-c05e-1089-8c0a-3a0e68d86eb7) - Closing
[0m10:59:01.320016 [info ] [MainThread]: 
[0m10:59:01.320016 [info ] [MainThread]: Finished running 24 data tests, 9 view models in 0 hours 1 minutes and 42.72 seconds (102.72s).
[0m10:59:01.320016 [debug] [MainThread]: Command end result
[0m10:59:01.616225 [debug] [MainThread]: Wrote artifact WritableManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\manifest.json
[0m10:59:01.616225 [debug] [MainThread]: Wrote artifact SemanticManifest to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\semantic_manifest.json
[0m10:59:01.631809 [debug] [MainThread]: Wrote artifact RunExecutionResult to D:\Documentos\Python-SQL\Projetos\Projeto DBT Databricks CICD\target\run_results.json
[0m10:59:01.647440 [info ] [MainThread]: 
[0m10:59:01.647440 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:59:01.647440 [info ] [MainThread]: 
[0m10:59:01.647440 [info ] [MainThread]: Done. PASS=33 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=33
[0m10:59:01.647440 [debug] [MainThread]: Command `dbt build` succeeded at 10:59:01.647440 after 127.98 seconds
[0m10:59:01.647440 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AAFEF3DD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AB69E3D10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022AB69E1590>]}
[0m10:59:01.663061 [debug] [MainThread]: Flushing usage events
[0m10:59:02.428817 [debug] [MainThread]: An error was encountered while trying to flush usage events
